---
title: "User Defined Contrasts and Joint Tests"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{User Defined Contrasts and Joint Tests}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r set-options, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  dev = "png",
  fig.width = 7,
  fig.height = 3.5,
  message = FALSE,
  warning = FALSE,
  package.startup.message = FALSE
)
options(width = 800)

pkgs <- c("marginaleffects", "parameters")

if (!all(insight::check_if_installed(pkgs, quietly = TRUE))) {
  knitr::opts_chunk$set(eval = FALSE)
}
```


This vignette is the second in a 5-part series:

1. [**Contrasts and Pairwise Comparisons**](https://easystats.github.io/modelbased/articles/introduction_comparisons_1.html)

2. **User Defined Contrasts and Joint Tests**

3. [**Comparisons of Slopes, Floodlight and Spotlight Analysis (Johnson-Neyman Intervals)**](https://easystats.github.io/modelbased/articles/introduction_comparisons_3.html)

4. [**Contrasts and Comparisons for Generalized Linear Models**](https://easystats.github.io/modelbased/articles/introduction_comparisons_4.html)

5. [**Contrasts and Comparisons for Zero-Inflation Models**](https://easystats.github.io/modelbased/articles/introduction_comparisons_5.html)

# User defined contrasts

The first example demonstrates how to define and apply user-defined contrasts to a factor variable within a linear model, respectively how to avoid defining specific contrasts and instead directly formulate the desired contrast as custom hypothesis in `estimate_contrasts()`.

First, we define two specific contrasts: `treat_vs_none` (comparing the average of two treatment levels to a control level) and `short_vs_long` (comparing two treatment levels against each other).

To illustrate the effect of these custom contrasts, the code creates a copy of the original treatment factor (`dose_original`) before applying the new contrasts to the `dose` factor. It also centers a continuous predictor, `puppy_love`, to better interpret the main effects of the interaction term.

Two linear models are then fitted: `m1` uses the `dose` factor with the user-defined contrasts, while `m2` uses the original `dose_original` factor. The `compare_parameters()` function is used to show that `m1` directly estimates coefficients corresponding to `treat_vs_none` and `short_vs_long`, which are not directly available in `m2`.

Finally, the code uses `estimate_means()` on `m2` to get the marginal means for the original factor levels, to identify which estimated means refer to which factor level. This is required for the next step, where we use `estimate_contrasts()` to perform hypothesis tests equivalent to the user-defined contrasts, `((b2+b3)/2) = b1` (*the average of two treatment levels - `b2 + b3 / 2` - to a control level*) and `b3 = b2` (*comparing two treatment levels against each other*), showing how such comparisons can be made even without pre-defining contrasts on the factor itself.

Data stems from the `{discovr}` package (Field 2025).

```{r}
library(modelbased)
library(parameters)

data(puppy_love, package = "modelbased")

# the levels for our treatment variable
levels(puppy_love$dose)

# set contrasts
treat_vs_none <- c(-2 / 3, 1 / 3, 1 / 3)
short_vs_long <- c(0, -1 / 2, 1 / 2)

# we copy this variable to compare original factor contrasts with
# user-defined factor contrasts
puppy_love$dose_original <- puppy_love$dose
contrasts(puppy_love$dose) <- cbind(treat_vs_none, short_vs_long)

# center variable
puppy_love$puppy_love <- puppy_love$puppy_love - mean(puppy_love$puppy_love)

# fit model, with user defined contrasts
m1 <- lm(happiness ~ puppy_love * dose, data = puppy_love)
# fit model without user defined contrasts
m2 <- lm(happiness ~ puppy_love * dose_original, data = puppy_love)

# we're interested in the effect (i.e. coefficient) of "treat_vs_none"
# and "short_vs_long". These are 1.94 and 0.13 in model 1. In model 2,
# we don't have these coefficient, because we didn't define related contrasts
compare_parameters(m1, m2)

# we first use `estimate_means()` to find which estimate relates
# to which factor level of interest. we want to average the two
# treatment level and compare it to the control level
estimate_means(m2, "dose_original")

# treat_vs_none (i.e. average of short and long vs. none)
# this contrasts corresponds to the estimate of the model m1, 1.94
estimate_contrasts(m2, "dose_original", comparison = "((b2+b3)/2) = b1")

# short_vs_long
# this contrasts corresponds to the estimate of the model m1, 0.13
estimate_contrasts(m2, "dose_original", comparison = "b3 = b2")
```

# Using a matrix for contrasts

Comparisons are extremely flexible. For instance, it is possible to calculate the marginal effects for the predictor `puppy_love`, or the marginal effects for `puppy_love` at each level of the treatment, `dose_original`. We can do this by using `estimate_slopes()`.

```{r}
# marginal effect for "puppy_love"
estimate_slopes(m2, "puppy_love")

# marginal effect for "puppy_love" at levels of "dose_original"
estimate_slopes(m2, "puppy_love", by = "dose_original")
```

Again, it it possible to combine levels, by using a matrix that defines the contrasts of interest, and pass this matrix as value for the `comparison` argument.

In essence, in the next example, the marginal effect (slope) of `puppy_love` within each level of `dose_original` is calculated, and then two specific weighted combinations of these slopes as defined by the `cond_tx` matrix are computed. The first combination isolates and scales the slope from the first level of `dose_original`, while the second creates a weighted sum of the slopes from the second and third levels.

```{r}
# we want the marginal effects of slopes for treatment vs. no treatment
# this is represented by the following contrast matrix
cond_tx <- cbind("no treatment" = c(-2 / 3, 0, 0), "treatment" = c(0, 1 / 3, 1 / 3))

# marginal effect for "puppy_love" at average effect of "treatment" (short + long)
# and "no treatment"
estimate_slopes(m2, "puppy_love", by = "dose_original", comparison = cond_tx)
```

# Jointly test multiple hypotheses

The next example fits a linear model to predict `alertness` based on an interaction between `time` and `coffee`. It then calculates standard pairwise comparisons for the levels of `time` separately within each level of `coffee`. The final and key step performs a joint test: for each level of `coffee`, it tests the overall hypothesis that there is _any_ significant difference among the levels of `time`, rather than looking at individual pairwise differences. This provides an omnibus test for the effect of `time` within each `coffee` group. To conduct joint tests, set `comparison = "joint"`.

```{r}
data(coffee_data, package = "modelbased")

# 2 way interaction
m <- lm(alertness ~ time * coffee, data = coffee_data)

# contrasts of pairwise comparisons of levels of "time" within the
# different levels of "coffee"
estimate_contrasts(m, contrast = "time", by = "coffee")

# jointly test whether the contrasts of all levels of time have an
# effect within each level of "coffee"
estimate_contrasts(m, contrast = "time", by = "coffee", comparison = "joint")
```

The above example can be easily expanded to three-way interactions.

```{r}
# 3 way interaction
m <- lm(alertness ~ time * coffee * sex, data = coffee_data)

# joint test of "time" levels within each group of coffee and sex
estimate_contrasts(
  m,
  contrast = "time",
  by = c("coffee", "sex"),
  comparison = "joint"
)
```

# Conclusion

This vignette showed advanced techniques for hypothesis testing in R using the **modelbased** package.

Some key takeaways:

- **Flexible Custom Comparisons:** You can move beyond default contrasts by either directly defining contrast vectors for your factors or, more flexibly, by specifying custom hypotheses as strings (e.g., `"((b2+b3)/2) = b1"`) or using matrices within functions like `estimate_contrasts()` and `estimate_slopes()`. This allows for highly specific and theoretically driven comparisons, such as comparing an average of multiple treatment levels to a control, or creating weighted combinations of slopes.

- **Powerful Joint Hypothesis Testing:** The `comparison = "joint"` argument in `estimate_contrasts()` enables omnibus tests. This is particularly useful for interactions, as it allows you to test whether a factor (e.g., `time`) has any significant effect within each level of another factor (e.g., `coffee`), providing a global assessment before (or instead of) diving into all individual pairwise comparisons.

[Go to next vignette: **Comparisons of Slopes, Floodlight and Spotlight Analysis (Johnson-Neyman Intervals)**](https://easystats.github.io/modelbased/articles/introduction_comparisons_3.html)

# References

Field, A. P. (2025). Discovering statistics using R and RStudio (2nd ed.). London: Sage.
