---
title: "User Defined Contrasts and Joint Tests"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{User Defined Contrasts and Joint Tests}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r set-options, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  dev = "png",
  fig.width = 7,
  fig.height = 3.5,
  message = FALSE,
  warning = FALSE,
  package.startup.message = FALSE
)
options(width = 800)
arrow_color <- "#FF00cc"
my_predictions <- NULL

pkgs <- c("marginaleffects", "parameters")

options(modelbased_join_dots = FALSE)
options(modelbased_select = "minimal")

if (!all(insight::check_if_installed(pkgs, quietly = TRUE))) {
  knitr::opts_chunk$set(eval = FALSE)
}
```


This vignette is the second in a 5-part series:

1. [**Contrasts and Pairwise Comparisons**](https://easystats.github.io/modelbased/articles/introduction_comparisons_1.html)

2. **User Defined Contrasts and Joint Tests**

3. [**Comparisons of Slopes, Floodlight and Spotlight Analysis (Johnson-Neyman Intervals)**](https://easystats.github.io/modelbased/articles/introduction_comparisons_3.html)

4. [**Contrasts and Comparisons for Generalized Linear Models**](https://easystats.github.io/modelbased/articles/introduction_comparisons_4.html)

5. [**Contrasts and Comparisons for Zero-Inflation Models**](https://easystats.github.io/modelbased/articles/introduction_comparisons_5.html)


This vignette demonstrates how to define and apply user-defined contrasts to a factor variable within a linear model.

First, we define two specific contrasts: `treat_vs_none` (comparing the average of two treatment levels to a control level) and `short_vs_long` (comparing two treatment levels against each other).

To illustrate the effect of these custom contrasts, the code creates a copy of the original treatment factor (`tx_ori`) before applying the new contrasts to the tx factor. It also centers a continuous predictor, `score`, to better interpret the main effects of the interaction term.

Two linear models are then fitted: `m1` uses the `tx` factor with the user-defined contrasts, while `m2` uses the original `tx_ori` factor. The `compare_parameters()` function is used to show that `m1` directly estimates coefficients corresponding to `treat_vs_none` and `short_vs_long`, which are not directly available in `m2`.

Finally, the code uses `estimate_means()` on `m2` to get the marginal means for the original factor levels, to identify which estimated means refer to which factor level. This is required for the next step, where we use `estimate_contrasts()` to perform hypothesis tests equivalent to the user-defined contrasts, `((b2+b3)/2) = b1` (*the average of two treatment levels - `b2 + b3 / 2` - to a control level*) and `b3 = b2` (*comparing two treatment levels against each other*), showing how such comparisons can be made even without pre-defining contrasts on the factor itself.

```{r}
library(modelbased)
library(parameters)

data(contrast_example, package = "modelbased")

# the levels for our treatment variable
levels(contrast_example$tx)

# set contrasts
treat_vs_none <- c(-2 / 3, 1 / 3, 1 / 3)
short_vs_long <- c(0, -1 / 2, 1 / 2)

# we copy this variable to compare original factor contrasts with
# user-defined factor contrasts
contrast_example$tx_ori <- contrast_example$tx
contrasts(contrast_example$tx) <- cbind(treat_vs_none, short_vs_long)

# center variable
contrast_example$score <- contrast_example$score - mean(contrast_example$score)

# fit model, with user defined contrasts
m1 <- lm(outcome ~ score * tx, data = contrast_example)
# fit model without user defined contrasts
m2 <- lm(outcome ~ score * tx_ori, data = contrast_example)

# we're interested in the effect (i.e. coefficient) of "treat_vs_none"
# and "short_vs_long". These are 1.94 and 0.13 in model 1. In model 2,
# we don't have these coefficient, because we didn't define related contrasts
compare_parameters(m1, m2)

# we first use `estimate_means()` to find which estimate relates
# to which factor level of interest. we want to average the two
# treatment level and compare it to the control level
estimate_means(m2, "tx_ori")

# treat_vs_none (i.e. average of short and long vs. none)
# this contrasts corresponds to the estimate of the model m1, 1.94
estimate_contrasts(m2, "tx_ori", comparison = "((b2+b3)/2) = b1")

# short_vs_long
# this contrasts corresponds to the estimate of the model m1, 0.13
estimate_contrasts(m2, "tx_ori", comparison = "b3 = b2")
```

# Conclusion

While the current implementation in `estimate_contrasts()` already covers many common use cases for testing contrasts and pairwise comparison, there still might be the need for more sophisticated comparisons. In this case, we recommend using the [*marginaleffects*](https://marginaleffects.com/) package directly. Some further related recommended readings are the vignettes about [Comparisons](https://marginaleffects.com/chapters/comparisons.html) or [Hypothesis Tests](https://marginaleffects.com/chapters/hypothesis.html).

[Go to next vignette: **Comparisons of Slopes, Floodlight and Spotlight Analysis (Johnson-Neyman Intervals)**](https://easystats.github.io/modelbased/articles/introduction_comparisons_3.html)
