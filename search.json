[{"path":[]},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement dom.makowski@gmail.com. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.1, available https://www.contributor-covenant.org/version/2/1/code_of_conduct.html. Community Impact Guidelines inspired [Mozilla’s code conduct enforcement ladder][https://github.com/mozilla/inclusion]. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"https://easystats.github.io/modelbased/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contribution Guidelines","title":"Contribution Guidelines","text":"easystats guidelines 0.1.0 people much welcome contribute code, documentation, testing suggestions. package aims beginner-friendly. Even ’re new open-source way life, new coding github stuff, encourage try submitting pull requests (PRs). “’d like help, ’m good enough programming yet” ’s alright, don’t worry! can always dig code, documentation tests. always typos fix, docs improve, details add, code lines document, tests add… Even smaller PRs appreciated. “’d like help, don’t know start” can look around issue section find features / ideas / bugs start working . can also open new issue just say ’re , interested helping . might ideas adapted skills. “’m sure suggestion idea worthwile” Enough impostor syndrom! suggestions opinions good, even ’s just thought , ’s always good receive feedback. “waste time ? get credit?” Software contributions getting valued academic world, good time collaborate us! Authors substantial contributions added within authors list. ’re also keen including eventual academic publications. Anyway, starting important! enter whole new world, new fantastic point view… fork repo, changes submit . work together make best :)","code":""},{"path":"https://easystats.github.io/modelbased/CONTRIBUTING.html","id":"code","dir":"","previous_headings":"","what":"Code","title":"Contribution Guidelines","text":"Please document comment code, purpose step (code line) stated clear understandable way. submitting change, please read R style guide particular easystats convention code-style keep consistency code formatting. Regarding style guide, note exception: put readability clarity everything. Thus, like underscores full names (prefer model_performance modelperf interpret_odds_logistic intoddslog). start code, make sure ’re dev branch (“advanced”). , can create new branch named feature (e.g., feature_lightsaber) changes. Finally, submit branch merged dev branch. , every now , dev branch merge master, new package version.","code":""},{"path":"https://easystats.github.io/modelbased/CONTRIBUTING.html","id":"checks-to-do-before-submission","dir":"","previous_headings":"","what":"Checks to do before submission","title":"Contribution Guidelines","text":"Make sure documentation (roxygen) good Make sure add tests new functions Run: styler::style_pkg(): Automatic style formatting lintr::lint_package(): Style checks devtools::check(): General checks","code":""},{"path":"https://easystats.github.io/modelbased/CONTRIBUTING.html","id":"useful-materials","dir":"","previous_headings":"","what":"Useful Materials","title":"Contribution Guidelines","text":"Understanding GitHub flow","code":""},{"path":"https://easystats.github.io/modelbased/SUPPORT.html","id":null,"dir":"","previous_headings":"","what":"Getting help with {modelbased}","title":"Getting help with {modelbased}","text":"Thanks using modelbased. filing issue, places explore pieces put together make process smooth possible. Start making minimal reproducible example using reprex package. haven’t heard used reprex , ’re treat! Seriously, reprex make R-question-asking endeavors easier (pretty insane ROI five ten minutes ’ll take learn ’s ). additional reprex pointers, check Get help! resource used tidyverse team. Armed reprex, next step figure ask: ’s question: start StackOverflow. people answer questions. ’s bug: ’re right place, file issue. ’re sure: let’s discuss try figure ! problem bug feature request, can easily return report . opening new issue, sure search issues pull requests make sure bug hasn’t reported /already fixed development version. default, search pre-populated :issue :open. can edit qualifiers (e.g. :pr, :closed) needed. example, ’d simply remove :open search issues repo, open closed. Thanks help!","code":""},{"path":"https://easystats.github.io/modelbased/articles/derivatives.html","id":"the-traditional-approach","dir":"Articles","previous_headings":"","what":"The Traditional Approach","title":"Interpret simple and complex models using the power of effect derivatives","text":"Let’s say interested relationship y x following dataset:  Upon visualizing data, people might say: “well, straightforward thing run correlation analysis” (might wrong, sake demonstration, push things ). Let’s start : Great, know significant correlation two variables! 🥳 like know every increase 1 x, much y increase? words, slope relationship? traditional approach fit linear model, assess parameters. Indeed, slope linear relationship predictor outcome actually effects estimated regression correspond . Let’s fit linear regression model, visualize , describe parameters.  parameters table shows us effect x 12.75. means every increase 1 x, y increases 12.75. Congrats, ’ve answered question!","code":"# Package to fit GAMs library(mgcv)  # Tidyverse library(ggplot2) library(easystats)  set.seed(333)  # Generate data data <- bayestestR::simulate_correlation(r = 0.85, n = 1000, names = c(\"y\", \"x\"), mean = c(100, 0), sd = c(15, 1))  ggplot(data, aes(x, y)) +   geom_point() rez <- cor.test(data$y, data$x) report::report(rez) > Effect sizes were labelled following Funder's (2019) recommendations. >  > The Pearson's product-moment correlation between data$y and data$x is positive, > statistically significant, and very large (r = 0.85, 95% CI [0.83, 0.87], > t(998) = 50.97, p < .001) model_lm <- lm(y ~ x, data = data)  modelbased::estimate_relation(model_lm) |>   plot() parameters::parameters(model_lm) > Parameter   | Coefficient |   SE |          95% CI | t(998) |      p > -------------------------------------------------------------------- > (Intercept) |      100.00 | 0.25 | [99.51, 100.49] | 400.00 | < .001 > x           |       12.75 | 0.25 | [12.26,  13.24] |  50.97 | < .001"},{"path":"https://easystats.github.io/modelbased/articles/derivatives.html","id":"gams-can-be-used-for-linear-relationships-too","dir":"Articles","previous_headings":"","what":"GAMs can be used for linear relationships too!","title":"Interpret simple and complex models using the power of effect derivatives","text":"new player entered game. might heard General Additive Models, aka GAMs, extend general linear models (GLMs) enabling elegant robust way modelling non-linear relationships. ’s good curvy relationships simple stuff ! can even use linear links, , general, sure exact shape relationship. GAMs usually penalize wiggly patterns, problems approximating linear relationship, data indicates. GAMs can fitted using mgcv package, change need specify smooth term (s()) variable want estimate (non-necessarily linear) relationship.  Wow, GAM-based modeled relationship near-exactly GLM! GAMs powerful 😎 Okay, ’s cool, ’s one slight issue. look parameters table, indeed one line “smooth term”, … coefficient! Indeed, GAMs don’t model straight lines, doesn’t return value slope. ’s people consider GAMs complicated discuss statistically, parameters easily interpretable. Owww, issue considering question effect x y 😕 ?","code":"model_gam <- mgcv::gam(y ~ s(x), data = data)  modelbased::estimate_relation(model_gam) |>   plot(line = list(color = \"blue\")) parameters::parameters(model_gam) > # Fixed Effects >  > Parameter   | Coefficient |   SE |          95% CI | t(998.00) |      p > ----------------------------------------------------------------------- > (Intercept) |      100.00 | 0.25 | [99.51, 100.49] |    400.00 | < .001 >  > # Smooth Terms >  > Parameter       |       F |   df |      p > ----------------------------------------- > Smooth term (x) | 2598.40 | 1.00 | < .001"},{"path":"https://easystats.github.io/modelbased/articles/derivatives.html","id":"effect-derivatives","dir":"Articles","previous_headings":"","what":"Effect Derivatives","title":"Interpret simple and complex models using the power of effect derivatives","text":"Let us introduce another concept likely get popular near future within world regressions. Derivatives. might remember math class high school derivatives basically pattern slope pattern (pattern-ception much).  figure , plot shows non-linear relationship variables, -plot shows 1st order derivative, .e., evolution slope curve. might take bit time mentally wrap head around transformation, get , become easy think terms derivatives. can see derivative peaks slope relationship highest (steepest), decrease reaching 0. zero-crossing derivative means inversion trend; relationship starts negative. Derivatives can computed statistical models, including simple ones linear regressions. look answer , try think imagine derivative plot previously computed linear model look like? know slope 12.75 (parameters analysis). change across course relationship? , straight line, slope constant. slope constant, derivative … constant line , right? Let’s verify . compute derivative, can use estimate_slopes() function, specify want know: trend x course (“”) .  plot shows straight horizontal line 12.75, fixed confidence interval (parameter table). expected, definition, linear model models straight line fixed slope. running summary() derivative, obtain summary “segments” (positive, flat, negative). , one segment, average coefficient corresponds regression parameter. means don’t really need parameters table. Indeed, information slope can retrieved effect derivative. guess … can applied model! GAMs. Lets’ GAM model:  Isn’t amazing, results identical. moral story GAMs can used wide variety contexts, even simple cases, derivatives easy way interpreting . Let’s jump another example!","code":"deriv <- modelbased::estimate_slopes(model_lm, trend = \"x\", by = \"x\")  plot(deriv) + # add a dashed line at 0 to show absence of effect   geom_hline(yintercept = 0, linetype = \"dashed\") summary(deriv) > Johnson-Neymann Intervals >  > Start |  End | Direction | Confidence  > -------------------------------------- > -3.38 | 3.28 | positive  | Significant >  > Marginal effects estimated for x > Type of slope was dY/dX deriv <- modelbased::estimate_slopes(model_gam, trend = \"x\", by = \"x\")  plot(deriv, line = list(color = \"blue\")) +   geom_hline(yintercept = 0, linetype = \"dashed\") summary(deriv) > Johnson-Neymann Intervals >  > Start |  End | Direction | Confidence  > -------------------------------------- > -3.38 | 3.28 | positive  | Significant >  > Marginal effects estimated for x > Type of slope was dY/dX"},{"path":"https://easystats.github.io/modelbased/articles/derivatives.html","id":"gam-derivatives-lm-a-polynomial-regression-example","dir":"Articles","previous_headings":"","what":"GAM + Derivatives > LM: a polynomial regression example","title":"Interpret simple and complex models using the power of effect derivatives","text":"mentioned one GAMs “limitation” parameters easily interpretable. assuming classes models, GLMs, case. However, common difficult--interpret parameters normal regression models ! Let’s take case polynomial regression, use model following data:  Let us fit polynomial regression:  look parameters table, also bit unclear coefficient refer . interpret numbers? Trying understand require lot search understanding polynomials work. Ain’t nobody got time dat’! Instead, can rely good ol’ derivatives obtain “linear slope” every point curve.  know bit theory derivatives, won’t surprised find derivative 2nd order polynomial (x + x^2) actually linear line. can conclude plot slope (significantly, confidence interval cover 0) negative 0, becomes positive. 0 corresponds indeed point inversion curve. Moral story? Derivatives can used easily interpret draw conclusions relationships models parameters straightforward interpret. , ’ve attentive point, might wonder: bother polynomials GAMs can trick?   conclusion similar, shows significant effect goes negative positive becomes flat (.e., non-significant) around 0. 3rd-degree-type relationships? works way:   , GAM nicely recovered shape relationship. summary, effects derivatives can used easily leverage power GAMs.","code":"data$y2 <- data$x^2 + rnorm(nrow(data), sd = 0.5)  ggplot(data, aes(x, y2)) +   geom_point() model_poly <- lm(y2 ~ poly(x, 2), data = data)  # Length is increased to have a smoother line modelbased::estimate_relation(model_poly, length = 30) |>   plot() parameters::parameters(model_poly) > Parameter      | Coefficient |   SE |         95% CI | t(997) |      p > ---------------------------------------------------------------------- > (Intercept)    |        1.01 | 0.02 | [ 0.98,  1.04] |  62.32 | < .001 > x [1st degree] |       -1.37 | 0.51 | [-2.38, -0.37] |  -2.68 | 0.007  > x [2nd degree] |       44.82 | 0.51 | [43.82, 45.83] |  87.38 | < .001 deriv <- modelbased::estimate_slopes(model_poly, trend = \"x\", by = \"x\", length = 100)  plot(deriv) +   geom_hline(yintercept = 0, linetype = \"dashed\") summary(deriv) > Johnson-Neymann Intervals >  > Start |   End | Direction | Confidence      > ------------------------------------------- > -3.38 | -0.08 | negative  | Significant     > -0.01 | -0.01 | negative  | Not Significant > 0.05  |  3.28 | positive  | Significant     >  > Marginal effects estimated for x > Type of slope was dY/dX model_gam2 <- mgcv::gam(y2 ~ s(x), data = data)  plot(modelbased::estimate_relation(model_gam2, length = 100), line = list(color = \"blue\")) # Increase precision deriv <- modelbased::estimate_slopes(model_gam2, trend = \"x\", by = \"x\", length = 100)  plot(deriv, line = list(color = \"blue\")) +   geom_hline(yintercept = 0, linetype = \"dashed\") summary(deriv) > Johnson-Neymann Intervals >  > Start |   End | Direction | Confidence      > ------------------------------------------- > -3.38 | -0.08 | negative  | Significant     > -0.01 | -0.01 | negative  | Not Significant > 0.05  |  0.05 | positive  | Not Significant > 0.12  |  3.28 | positive  | Significant     >  > Marginal effects estimated for x > Type of slope was dY/dX data$y3 <- data$x^3 + rnorm(nrow(data), sd = 1)  model_gam3 <- mgcv::gam(y3 ~ s(x), data = data)  plot(modelbased::estimate_relation(model_gam3, length = 100), line = list(color = \"blue\")) deriv <- modelbased::estimate_slopes(model_gam3, trend = \"x\", by = \"x\", length = 100)  plot(deriv, line = list(color = \"blue\")) +   geom_hline(yintercept = 0, linetype = \"dashed\")"},{"path":"https://easystats.github.io/modelbased/articles/estimate_contrasts.html","id":"testing-pairwise-differences","dir":"Articles","previous_headings":"","what":"Testing pairwise differences","title":"Contrast analysis","text":"previous tutorial, computed marginal means 3 different Species levels iris dataset. However, one might also want statistically test differences levels, can achieved contrast analysis. Although procedure much powerful, aim analogous post hoc analysis (pretty much consisting pairwise t-tests), heavily utilized behavioral sciences way follow hypotheses global differences tested ANOVAs specific hypotheses pairwise differences. Let’s carry contrast analysis simple model previous tutorial:  Contrast analysis can achieved estimate_contrasts function: can conclude pairwise differences statistically significant.","code":"library(ggplot2) library(modelbased) data(iris)  model <- lm(Sepal.Width ~ Species, data = iris) means <- estimate_means(model, by = \"Species\")  plot(means, point = list(width = 0.1)) +   theme_minimal() estimate_contrasts(model, contrast = \"Species\") > Marginal Contrasts Analysis >  > Level1     | Level2     | Difference |   SE |         95% CI | t(147) |      p > ------------------------------------------------------------------------------ > versicolor | setosa     |      -0.66 | 0.07 | [-0.79, -0.52] |  -9.69 | < .001 > virginica  | setosa     |      -0.45 | 0.07 | [-0.59, -0.32] |  -6.68 | < .001 > virginica  | versicolor |       0.20 | 0.07 | [ 0.07,  0.34] |   3.00 |  0.003 >  > Variable predicted: Sepal.Width > Predictors contrasted: Species > p-values are uncorrected."},{"path":"https://easystats.github.io/modelbased/articles/estimate_contrasts.html","id":"complex-model","dir":"Articles","previous_headings":"","what":"Complex model","title":"Contrast analysis","text":", contrast analysis based marginal means, can applied complex models: instance, add Petal.Width model, can see difference versicolor virginica becomes significant (even changes sign). Note can plot simple contrast analysis lighthouse plots:  represent estimated means CI range (black), grey areas show CI range difference (compared point estimate). One easy way interpret lighthouse plots whole beam goes (.e., upper limit lower limit direction), difference likely significant.","code":"model <- lm(Sepal.Width ~ Species * Petal.Width, data = iris) contrasts <- estimate_contrasts(model, contrast = \"Species\") contrasts > Marginal Contrasts Analysis >  > Level1     | Level2     | Difference |   SE |         95% CI | t(144) |      p > ------------------------------------------------------------------------------ > versicolor | setosa     |      -1.59 | 0.39 | [-2.37, -0.81] |  -4.04 | < .001 > virginica  | setosa     |      -1.77 | 0.41 | [-2.59, -0.96] |  -4.29 | < .001 > virginica  | versicolor |      -0.18 | 0.15 | [-0.47,  0.10] |  -1.27 |  0.205 >  > Variable predicted: Sepal.Width > Predictors contrasted: Species > Predictors averaged: Petal.Width (1.2) > p-values are uncorrected. plot(contrasts, estimate_means(model, by = \"Species\")) +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/articles/estimate_contrasts.html","id":"changes-in-difference","dir":"Articles","previous_headings":"","what":"Changes in difference","title":"Contrast analysis","text":"Interestingly, can also see differences modulated another continuous variable. Based model (including interaction Petal.Width), compute contrasts 100 equally-spaced points Petal.Width, visualise.  can see, difference versicolor virginica increases Petal.Width increases.","code":"contrasts <- estimate_contrasts(   model,   contrast = \"Species\",   by = \"Petal.Width\",   length = 100,   # we use a emmeans here because marginaleffects doesn't   # generate more than 25 rows for pairwise comparisons   backend = \"emmeans\" )  # Create a variable with the two levels concatenated contrasts$Contrast <- paste(contrasts$Level1, \"-\", contrasts$Level2)  # Visualise the changes in the differences ggplot(contrasts, aes(x = Petal.Width, y = Difference)) +   geom_ribbon(aes(fill = Contrast, ymin = CI_low, ymax = CI_high), alpha = 0.2) +   geom_line(aes(colour = Contrast), linewidth = 1) +   geom_hline(yintercept = 0, linetype = \"dashed\") +   theme_minimal() +   ylab(\"Difference\")"},{"path":"https://easystats.github.io/modelbased/articles/estimate_contrasts.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Contrast analysis","text":"Contrast analysis can powerful tool interpret understand statistical models.","code":""},{"path":[]},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/estimate_grouplevel.html","id":"population-level-effects","dir":"Articles","previous_headings":"Speed (RT)","what":"Population-level Effects","title":"How to use Mixed models to Estimate Individuals' Scores","text":"reaction time, start removing incorrect responses, since reflective “successful” cognitive process. , plot RT according condition stimulus category.  descriptive visualisation indeed seems suggest people slower accuracy condition compared speed condition. also slight effect frequency. Let’s verify using modelisation approach. Let’s unpack formula model. ’re tying predict reaction_time using different terms. can separated two groups, fixed effects random effects. condition fixed effect means interested estimating “general” effect condition, across subjects items (.e., population level). top effect condition, second ‘fixed’ parameter implicitly specified estimated, intercept (might know, one explicitly remove reaction_time ~ 0 + condition, otherwise added automatically). Let’s investigate two fixed parameters first: condition factor two levels, parameters easily interpretable. intercept corresponds reaction_time baseline level factor (accuracy), effect condition corresponds change reaction_time intercept speed condition. words, effect condition refers difference two conditions, speed - accuracy. can see, difference significant, people , general, lower reaction_time (sign negative) speed condition. Let’s visualize marginal means estimated model:  Now, ’s random effects. formula, specified random intercepts (.e., right part bar | symbol) id (participants) stim. means participant stimulus “Intercept” parameter (, ’ve seen , corresponds reaction_time accuracy condition). Additionally, ’ve specified random effect (“random slope” - left side bar) condition participant. means participant effect condition computed. need complex model? Let’s compare model without specifying random intercepts stimuli. Mmmh, seems simpler model performs lot worse (Bayes Factor lower 1). run compare_performance() learn details, example go ahead keep worse model (simplicity conciseness inspecting random effects later, keep mind real life ’s surely best thing ).","code":"library(ggplot2) data_rt <- data_filter(data, error == 0)  ggplot(data = data_rt, aes(y = reaction_time, x = condition, fill = condition)) +   geom_violin() library(lme4) model_full <- lmer(   reaction_time ~ condition + (1 + condition | id) + (1 | stim),   data = data_rt ) parameters(model_full, effects = \"fixed\") > # Fixed Effects >  > Parameter         | Coefficient |   SE |         95% CI | t(4506) |      p > -------------------------------------------------------------------------- > (Intercept)       |        0.69 | 0.02 | [ 0.65,  0.74] |   30.44 | < .001 > condition [speed] |       -0.16 | 0.02 | [-0.19, -0.12] |   -8.53 | < .001 means <- estimate_means(model_full, by = \"condition\", backend = \"marginaleffects\")  plot(means, point = list(alpha = 0.1, width = 0.1)) +   theme_minimal() model <- lmer(reaction_time ~ condition + (condition | id), data = data_rt)  test_performance(model_full, model) > Name       |   Model |      BF | df | df_diff |  Chi2 |      p > -------------------------------------------------------------- > model_full | lmerMod |         |  7 |         |       |        > model      | lmerMod | < 0.001 |  6 |   -1.00 | 36.78 | < .001 > Models were detected as nested (in terms of fixed parameters) and are compared in sequential order."},{"path":"https://easystats.github.io/modelbased/articles/estimate_grouplevel.html","id":"group-level-effects","dir":"Articles","previous_headings":"Speed (RT)","what":"Group-level Effects","title":"How to use Mixed models to Estimate Individuals' Scores","text":"’s nice know, actually get access group-level scores. can use estimate_grouplevel() function retrieve . participant (Level column), numbered 1 17, two rows, corresponding deviation main effect intercept condition effect. can easily visualize random effects:  Note: need use hline effectively add vline 0 coordinates flipped plot. can also use reshape_grouplevel() select Coefficient column (skip information uncertainty - real life equally important!) make match original data. resulting table length original dataset can merged : ’s convenient way re-incorporate random effects data re-use. can see, first row repeated corresponds participant (random effects ). Note can use summary() remove duplicate rows. Let’s add original data. Wow! can see, lot -participants variability. random parameters correspond ?","code":"random <- estimate_grouplevel(model) random > Group | Level | Parameter         | Coefficient |   SE |         95% CI > ----------------------------------------------------------------------- > id    | 1     | (Intercept)       |       -0.10 | 0.01 | [-0.12, -0.07] > id    | 1     | condition [speed] |        0.09 | 0.02 | [ 0.06,  0.12] > id    | 2     | (Intercept)       |        0.08 | 0.02 | [ 0.04,  0.12] > id    | 2     | conditionspeed    |       -0.03 | 0.02 | [-0.07,  0.01] > id    | 3     | (Intercept)       |        0.02 | 0.01 | [ 0.00,  0.05] > id    | 3     | conditionspeed    |       -0.02 | 0.02 | [-0.05,  0.01] > id    | 4     | (Intercept)       |       -0.13 | 0.01 | [-0.15, -0.10] > id    | 4     | conditionspeed    |        0.08 | 0.02 | [ 0.05,  0.11] > id    | 5     | (Intercept)       |       -0.05 | 0.01 | [-0.08, -0.03] > id    | 5     | conditionspeed    |    6.67e-03 | 0.02 | [-0.02,  0.04] > id    | 6     | (Intercept)       |       -0.08 | 0.01 | [-0.10, -0.05] > id    | 6     | conditionspeed    |        0.04 | 0.02 | [ 0.01,  0.07] > id    | 7     | (Intercept)       |       -0.09 | 0.01 | [-0.12, -0.07] > id    | 7     | conditionspeed    |        0.10 | 0.02 | [ 0.06,  0.13] > id    | 8     | (Intercept)       |        0.21 | 0.01 | [ 0.19,  0.24] > id    | 8     | conditionspeed    |       -0.18 | 0.02 | [-0.21, -0.14] > id    | 9     | (Intercept)       |        0.03 | 0.01 | [ 0.00,  0.05] > id    | 9     | conditionspeed    |       -0.02 | 0.02 | [-0.05,  0.01] > id    | 10    | (Intercept)       |       -0.10 | 0.01 | [-0.13, -0.08] > id    | 10    | conditionspeed    |        0.07 | 0.02 | [ 0.04,  0.10] > id    | 11    | (Intercept)       |       -0.09 | 0.01 | [-0.11, -0.07] > id    | 11    | conditionspeed    |        0.07 | 0.02 | [ 0.04,  0.11] > id    | 12    | (Intercept)       |   -6.47e-04 | 0.01 | [-0.03,  0.02] > id    | 12    | conditionspeed    |    3.65e-03 | 0.02 | [-0.03,  0.04] > id    | 13    | (Intercept)       |        0.08 | 0.01 | [ 0.05,  0.10] > id    | 13    | conditionspeed    |       -0.06 | 0.02 | [-0.09, -0.02] > id    | 14    | (Intercept)       |        0.03 | 0.01 | [ 0.01,  0.06] > id    | 14    | conditionspeed    |       -0.03 | 0.02 | [-0.06,  0.00] > id    | 15    | (Intercept)       |        0.09 | 0.01 | [ 0.07,  0.11] > id    | 15    | conditionspeed    |       -0.07 | 0.02 | [-0.10, -0.04] > id    | 16    | (Intercept)       |        0.04 | 0.01 | [ 0.02,  0.06] > id    | 16    | conditionspeed    |       -0.01 | 0.02 | [-0.05,  0.02] > id    | 17    | (Intercept)       |        0.06 | 0.01 | [ 0.03,  0.08] > id    | 17    | conditionspeed    |       -0.05 | 0.02 | [-0.08, -0.02] plot(random) +   geom_hline(yintercept = 0, linetype = \"dashed\") +   theme_lucid() reshaped <- reshape_grouplevel(random, indices = \"Coefficient\")  head(reshaped) >   id Intercept conditionspeed > 1  1    -0.097          0.094 > 2  1    -0.097          0.094 > 3  1    -0.097          0.094 > 4  1    -0.097          0.094 > 5  1    -0.097          0.094 > 6  1    -0.097          0.094 data_rt <- data_join(data_rt, reshaped, join = \"full\", by = \"id\")"},{"path":"https://easystats.github.io/modelbased/articles/estimate_grouplevel.html","id":"correlation-with-empirical-scores","dir":"Articles","previous_headings":"Speed (RT)","what":"Correlation with empirical scores","title":"How to use Mixed models to Estimate Individuals' Scores","text":"said random effects group-level (group unit , model, participants) version population-level effects (fixed effects). One important thing note represent deviation fixed effect, coefficient close 0 means participants’ effect population-level effect. words, ’s “norm” (note can also obtain group-specific effect corresponding sum fixed random changing type argument). Nevertheless, let’s compute empirical scores, condition averages participant. group data participant condition, get mean RT, reshape data , participant, two means two columns. , create new dataframe (use - overwrite - keep concise), keep mean RT accuracy condition, difference speed condition (reminds something?). Now, empirical scores compare random effects estimated model? Let’s merge empirical scores random effects scores. , run summary() reshaped random effects remove duplicate rows (one row per participant, matches format data_sub). can now reshape random effects format data_sub merge . Let’s run correlation model-based scores empirical scores.  First thing notice everything significantly strongly correlated!. , empirical scores accuracy condition, corresponding “raw” average RT, correlate almost perfectly model-based counterpart (r_{empirical\\_accuracy/Coefficient\\_Intercept} = 1; r_{empirical\\_condition/Coefficient\\_conditionspeed} > .99). ’s reassuring, means model managed estimate intuitive parameters! Finally, can observe strong negative correlation (even salient model-based indices) RT accuracy condition effect speed condition:  slower accuracy condition, bigger difference speed condition.","code":"data_sub <- aggregate(reaction_time ~ id + condition, data_rt, mean) data_sub <- data_rt |>   data_summary(reaction_time = mean(reaction_time), by = c(\"id\", \"condition\")) |>   reshape_wider(     names_from = \"condition\", values_from = \"reaction_time\", names_prefix = \"empirical_\"   ) |>   data_modify(empirical_speed = empirical_accuracy - empirical_speed) data_sub >    id empirical_accuracy empirical_speed > 1   1               0.59           0.053 > 2   2               0.77           0.165 > 3   3               0.72           0.175 > 4   4               0.56           0.086 > 5   5               0.64           0.165 > 6   6               0.62           0.130 > 7   7               0.59           0.042 > 8   8               0.91           0.353 > 9   9               0.72           0.174 > 10 10               0.59           0.089 > 11 11               0.60           0.078 > 12 12               0.69           0.153 > 13 13               0.77           0.214 > 14 14               0.72           0.195 > 15 15               0.78           0.229 > 16 16               0.73           0.164 > 17 17               0.75           0.206 data_sub <- data_join(data_sub, summary(reshaped), by = \"id\") data_sub >    id empirical_accuracy empirical_speed Intercept conditionspeed > 1   1               0.59           0.053  -0.09676         0.0941 > 2   2               0.77           0.165   0.07896        -0.0324 > 3   3               0.72           0.175   0.02481        -0.0176 > 4   4               0.56           0.086  -0.12699         0.0784 > 5   5               0.64           0.165  -0.05216         0.0067 > 6   6               0.62           0.130  -0.07711         0.0372 > 7   7               0.59           0.042  -0.09326         0.0973 > 8   8               0.91           0.353   0.21236        -0.1785 > 9   9               0.72           0.174   0.02704        -0.0173 > 10 10               0.59           0.089  -0.10344         0.0711 > 11 11               0.60           0.078  -0.08936         0.0749 > 12 12               0.69           0.153  -0.00065         0.0036 > 13 13               0.77           0.214   0.07838        -0.0564 > 14 14               0.72           0.195   0.03066        -0.0324 > 15 15               0.78           0.229   0.09098        -0.0690 > 16 16               0.73           0.164   0.04005        -0.0143 > 17 17               0.75           0.206   0.05650        -0.0454 correlation(data_sub) |>   summary(redundant = TRUE) |>   cor_sort() |>   plot() ggplot(data_sub, aes(x = Intercept, y = conditionspeed)) +   geom_point() +   geom_smooth(method = \"lm\") +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/articles/estimate_grouplevel.html","id":"reliability","dir":"Articles","previous_headings":"Speed (RT)","what":"Reliability","title":"How to use Mixed models to Estimate Individuals' Scores","text":"Extracting random effects also useful compute reliability given paradigm. key idea compare inter-individual variability random effects intra-individual variability data (Williams et al., 2020). , first need compute variability (SD) point-estimates across participants. , compute average variability (SE) random effects within participants, add previous table. reliability ratio -participants variability within-participants variability. estimate varies -participants compared within participants, reliable . Reliability values 1 suggest higher variability participants within participants, good sign reliability estimates.","code":"reliability <- random |>   data_summary(sd_between = sd(Coefficient), by = \"Parameter\") reliability > Parameter      | sd_between > --------------------------- > (Intercept)    |       0.09 > conditionspeed |       0.07 reliability <- random |>   data_summary(sd_within = mean(SE), by = \"Parameter\") |>   data_join(reliability) reliability > Parameter      | sd_within | sd_between > --------------------------------------- > (Intercept)    |      0.01 |       0.09 > conditionspeed |      0.02 |       0.07 reliability |>   data_modify(reliability = sd_between / sd_within) > Parameter      | sd_within | sd_between | reliability > ----------------------------------------------------- > (Intercept)    |      0.01 |       0.09 |        7.24 > conditionspeed |      0.02 |       0.07 |        4.39"},{"path":"https://easystats.github.io/modelbased/articles/estimate_grouplevel.html","id":"accuracy","dir":"Articles","previous_headings":"","what":"Accuracy","title":"How to use Mixed models to Estimate Individuals' Scores","text":"section, take interest accuracy - probability making errors, using logistic models. , use dataset still includes errors (data, data_rt used previous section). fit logistic mixed model predict likelihood making error depending condition. Similarly, specified random intercept random effect condition participants. parameters suggest general, participants indeed make errors speed condition compared accuracy condition. can visualize average probability (.e., marginal means) making errors two conditions.  Similarly, can extract group-level effects, clean (rename columns, otherwise names RT model), merge previous ones.","code":"model <- glmer(   error ~ condition + (1 + condition | id),   data = data,   family = \"binomial\" )  parameters(model, effects = \"fixed\") > # Fixed Effects >  > Parameter         | Log-Odds |   SE |         95% CI |      z |      p > ---------------------------------------------------------------------- > (Intercept)       |    -2.91 | 0.19 | [-3.28, -2.53] | -15.16 | < .001 > condition [speed] |     1.32 | 0.15 | [ 1.02,  1.61] |   8.73 | < .001 plot(estimate_means(model, by = \"condition\"), show_data = FALSE) random <- estimate_grouplevel(model)  plot(random)"},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/estimate_means.html","id":"raw-means","dir":"Articles","previous_headings":"","what":"Raw Means","title":"What are, why use and how to get marginal means","text":"iris dataset, available base R, contains observations three types iris flowers (Species variable); Setosa, Versicolor Virginica, different features measured, length width sepals petals. traditional starting point, reporting data, start descriptive statistics. instance, mean Sepal.Width three species. can compute means easily grouping observations species, computing mean standard deviation (SD): can also visualize plot:  However, raw means might biased, number observations group might different. Moreover, might hidden covariance mediation variables dataset, creating “spurious” influence (confounding) means. can take influences account calculating means?","code":"library(easystats)  iris |>   data_group(\"Species\") |>   describe_distribution(select = \"Sepal.Width\") > # Species=setosa >  > Variable    | Mean |   SD |  IQR |        Range | Skewness | Kurtosis |  n | n_Missing > -------------------------------------------------------------------------------------- > Sepal.Width | 3.43 | 0.38 | 0.52 | [2.30, 4.40] |     0.04 |     0.95 | 50 |         0 >  > # Species=versicolor >  > Variable    | Mean |   SD |  IQR |        Range | Skewness | Kurtosis |  n | n_Missing > -------------------------------------------------------------------------------------- > Sepal.Width | 2.77 | 0.31 | 0.50 | [2.00, 3.40] |    -0.36 |    -0.37 | 50 |         0 >  > # Species=virginica >  > Variable    | Mean |   SD |  IQR |        Range | Skewness | Kurtosis |  n | n_Missing > -------------------------------------------------------------------------------------- > Sepal.Width | 2.97 | 0.32 | 0.40 | [2.20, 3.80] |     0.37 |     0.71 | 50 |         0 library(ggplot2) ggplot(iris, aes(x = Species, y = Sepal.Width, fill = Species)) +   geom_violin() +   geom_jitter(width = 0.05) +   theme_modern()"},{"path":"https://easystats.github.io/modelbased/articles/estimate_means.html","id":"marginal-means","dir":"Articles","previous_headings":"","what":"Marginal Means","title":"What are, why use and how to get marginal means","text":"Another way analysing means actually statistically model , rather simply describe appear data. instance, fit simple Bayesian linear regression modelling relationship Species Sepal.Width. Marginal means basically means extracted statistical model, represent average response variable (, Sepal.Width) level predictor variable (, Species). Note means computed different raw means created . can surmise many spurious influences need worry iris dataset. might case dataset. can now add means, well credible interval (CI) representing uncertainty estimation, overlay previous plot:  Note modelbased provides automated plotting capabilities quick visual checks:","code":"library(modelbased) model <- lm(Sepal.Width ~ Species, data = iris) means <- estimate_means(model, by = \"Species\") means > Estimated Marginal Means >  > Species    | Mean |   SE |       95% CI | t(147) > ------------------------------------------------ > setosa     | 3.43 | 0.05 | [3.33, 3.52] |  71.36 > versicolor | 2.77 | 0.05 | [2.68, 2.86] |  57.66 > virginica  | 2.97 | 0.05 | [2.88, 3.07] |  61.91 >  > Variable predicted: Sepal.Width > Predictors modulated: Species p <- ggplot(iris, aes(x = Species, y = Sepal.Width, fill = Species)) +   geom_violin() +   geom_jitter(width = 0.05) +   geom_line(data = means, aes(y = Mean, group = 1)) +   geom_pointrange(     data = means,     aes(y = Mean, ymin = CI_low, ymax = CI_high),     size = 1,     color = \"white\"   ) +   theme_minimal() p plot(means)"},{"path":"https://easystats.github.io/modelbased/articles/estimate_means.html","id":"complex-models","dir":"Articles","previous_headings":"","what":"Complex Models","title":"What are, why use and how to get marginal means","text":"power marginal means resides fact can estimated much complex models. instance, fit model takes account interaction variable, Petal.Width. estimated means “adjusted” (take account) variations components. Now let’s add previous plot marginal means complex model (shown purple) next , help us notice adjusted means change depending predictors.  ’s interesting! seems adjusting (“controlling ”) model petal characteristics, differences Species seem magnified! differences “significant”? ’s contrast analysis comes play! Click read tutorial contrast analysis.","code":"model <- lm(Sepal.Width ~ Species + Petal.Width, data = iris) means_complex <- estimate_means(model, by = \"Species\")  means_complex > Estimated Marginal Means >  > Species    | Mean |   SE |       95% CI | t(146) > ------------------------------------------------ > setosa     | 4.17 | 0.12 | [3.93, 4.42] |  33.89 > versicolor | 2.67 | 0.05 | [2.58, 2.76] |  59.07 > virginica  | 2.33 | 0.11 | [2.11, 2.54] |  21.39 >  > Variable predicted: Sepal.Width > Predictors modulated: Species > Predictors averaged: Petal.Width (1.2) p +   geom_line(data = means_complex, aes(y = Mean, group = 1), color = \"purple\") +   geom_pointrange(     data = means_complex,     aes(y = Mean, ymin = CI_low, ymax = CI_high),     size = 1,     color = \"purple\"   )"},{"path":[]},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/estimate_relation.html","id":"linear-relationship","dir":"Articles","previous_headings":"Simple regression","what":"Linear relationship","title":"Visualize effects and interactions","text":"","code":"library(modelbased)  model <- lm(Sepal.Length ~ Sepal.Width, data = iris)  visualization_data <- estimate_relation(model) head(visualization_data) > Model-based Predictions >  > Sepal.Width | Predicted |   SE |       95% CI > --------------------------------------------- > 2.00        |      6.08 | 0.18 | [5.73, 6.43] > 2.27        |      6.02 | 0.14 | [5.74, 6.30] > 2.53        |      5.96 | 0.11 | [5.75, 6.17] > 2.80        |      5.90 | 0.08 | [5.75, 6.06] > 3.07        |      5.84 | 0.07 | [5.71, 5.97] > 3.33        |      5.78 | 0.08 | [5.62, 5.94] >  > Variable predicted: Sepal.Length > Predictors modulated: Sepal.Width library(ggplot2) plot(visualization_data, line = list(color = \"red\")) +   theme_minimal()"},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/estimate_relation.html","id":"polynomial","dir":"Articles","previous_headings":"More complex regressions","what":"Polynomial","title":"Visualize effects and interactions","text":"","code":"lm(Sepal.Length ~ poly(Sepal.Width, 2), data = iris) |>   modelbased::estimate_relation(length = 50) |>   plot()"},{"path":"https://easystats.github.io/modelbased/articles/estimate_relation.html","id":"additive-models","dir":"Articles","previous_headings":"More complex regressions","what":"Additive Models","title":"Visualize effects and interactions","text":"","code":"library(mgcv) > Loading required package: nlme > This is mgcv 1.9-3. For overview type 'help(\"mgcv-package\")'. mgcv::gam(Sepal.Length ~ s(Sepal.Width), data = iris) |>   modelbased::estimate_relation(length = 50) |>   plot()"},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/estimate_response.html","id":"prediction-against-original-data","dir":"Articles","previous_headings":"","what":"Prediction against original data","title":"Use a model to make predictions","text":"Generating prediction model can used wide variety reasons, one visualisation. can achieved via estimate_expectation() function visualisation spinoff, estimate_relation(). Let’s start fitting linear regression. might interested comparing values predicted model actual “true” values. can done generating predictions: output data frame containing predicted values (median CI posterior distribution) value original data frame (used fitting model). Hence, can simply add original response column (Petal.Length) data plot original predicted data (top identity line, representing perfect relationship).  seems like model perform bad. added information Species model? now plot second observations, based complex model, red overlay previous points:  new model generated much accurate predictions (closer underlying regression line).","code":"library(modelbased)  model <- lm(Petal.Length ~ Sepal.Length, data = iris) pred_data <- estimate_expectation(model) head(pred_data) > Model-based Predictions >  > Sepal.Length | Predicted |   SE |       95% CI | Residuals > ---------------------------------------------------------- > 5.10         |      2.38 | 0.10 | [2.19, 2.57] |     -0.98 > 4.90         |      2.00 | 0.11 | [1.79, 2.22] |     -0.60 > 4.70         |      1.63 | 0.12 | [1.39, 1.87] |     -0.33 > 4.60         |      1.45 | 0.13 | [1.19, 1.70] |      0.05 > 5.00         |      2.19 | 0.10 | [1.99, 2.39] |     -0.79 > 5.40         |      2.93 | 0.08 | [2.78, 3.09] |     -1.23 >  > Variable predicted: Petal.Length library(ggplot2)  pred_data$Petal.Length <- iris$Petal.Length  pred_data |>   ggplot(aes(x = Petal.Length, y = Predicted)) +   geom_line(aes(x = Petal.Length, y = Petal.Length), linetype = \"dashed\") +   geom_point() +   ylab(\"Petal.Length (predicted)\") +   theme_minimal() model <- lm(Petal.Length ~ Sepal.Length * Species, data = iris)  pred_data$Predicted_2 <- estimate_expectation(model)$Predicted pred_data |>   ggplot() +   geom_line(aes(x = Petal.Length, y = Petal.Length), linetype = \"dashed\") +   geom_point(aes(x = Petal.Length, y = Predicted), color = \"grey\") +   geom_point(aes(x = Petal.Length, y = Predicted_2), color = \"red\") +   ylab(\"Petal.Length (predicted)\") +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/articles/estimate_response.html","id":"estimating-response-vs--relation","dir":"Articles","previous_headings":"","what":"Estimating response vs. relation","title":"Use a model to make predictions","text":"Rather visualizing predictions made model, often interested visualizing relation. model , relationship response two predictors. can achieved generating predictions data grid model’s data instead original dataset. visualise relationship response (Petal.Length) predictors (Sepal.Length Species).  However, might notice Credible Interval (CI) bands quite big. estimate_relation() coming . traditional, frequentist, regression, predictions deterministic: always fall regression line. However, Bayesian framework, probabilistic. Hence , predicting response predicting link (.e., regression line uncertainty interval associated line). order facilitate visualization links, added estimate_relation() shortcut estimate_expectation() data = \"grid\" , Bayesian models, predict = \"link\" smoothing default. estimate_expectation() used context generating actual predictions existing new data, whereas estimate_relation() relevant context visualization plotting.","code":"predicted <- estimate_expectation(model, data = \"grid\")  iris |>   ggplot(aes(x = Sepal.Length)) +   geom_point(aes(y = Petal.Length, color = Species)) +   geom_ribbon(data = predicted, aes(ymin = CI_low, ymax = CI_high, fill = Species), alpha = 0.3) +   geom_line(data = predicted, aes(y = Predicted, color = Species), linewidth = 1) +   theme_minimal() predicted <- estimate_relation(model)  iris |>   ggplot(aes(x = Sepal.Length)) +   geom_point(aes(y = Petal.Length, color = Species)) +   geom_ribbon(data = predicted, aes(ymin = CI_low, ymax = CI_high, fill = Species), alpha = 0.3) +   geom_line(data = predicted, aes(y = Predicted, color = Species), linewidth = 1) +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/articles/estimate_response.html","id":"different-ci-levels","dir":"Articles","previous_headings":"","what":"Different CI levels","title":"Use a model to make predictions","text":"purpose CI bands provide information uncertainty related estimation. Bayesian framework, credible intervals directly related shape posterior distribution. Thus, showing different CI levels (instance, 69%, 89% 99%).","code":"predicted <- estimate_relation(model, ci = c(0.69, 0.89, 0.99))  iris |>   ggplot(aes(x = Sepal.Length)) +   geom_point(aes(y = Petal.Length, color = Species)) +   geom_ribbon(data = predicted, aes(ymin = CI_low_0.99, ymax = CI_high_0.99, fill = Species), alpha = 0.2) +   geom_ribbon(data = predicted, aes(ymin = CI_low_0.89, ymax = CI_high_0.89, fill = Species), alpha = 0.3) +   geom_ribbon(data = predicted, aes(ymin = CI_low_0.69, ymax = CI_high_0.69, fill = Species), alpha = 0.3) +   geom_line(data = predicted, aes(y = Predicted, color = Species), linewidth = 1) +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/articles/estimate_response.html","id":"adding-individual-iterations","dir":"Articles","previous_headings":"","what":"Adding individual iterations","title":"Use a model to make predictions","text":"Let’s now fit model Bayesian framework. Note: ’re familiar Bayesian framework, recommend starting gentle introduction. refresh seed arguments included reproducibility readability, critical model. Instead (addition ) representing confidence intervals, one can also represent every individual posterior draw, correspond random selection possible links compatible observed data. nice insight “true” underlying probabilities.  Note also possible obtain similar plots without Bayesian models, bootstrapping predictions. can done setting iterations argument number (e.g., 50).","code":"library(rstanarm)  model <- stan_glm(Petal.Length ~ Sepal.Length * Species,   refresh = 0, seed = 3,   data = iris ) # Keep only 100 draws (keeping all the draws is slower) predicted <- estimate_relation(model, keep_iterations = TRUE, iterations = 100)  # Format draws for plotting iterations <- bayestestR::reshape_iterations(predicted) iterations$group <- paste0(iterations$iter_group, iterations$Species)  iris |>   ggplot(aes(x = Sepal.Length)) +   geom_point(aes(y = Petal.Length, color = Species)) +   geom_line(data = iterations, aes(y = iter_value, color = Species, group = group), alpha = 0.1) +   geom_line(data = predicted, aes(y = Predicted, color = Species), linewidth = 1) +   theme_minimal() model <- lm(Petal.Length ~ Sepal.Length * Species, data = iris)  # Bootstrap with n=50 iterations predicted <- estimate_relation(model, keep_iterations = TRUE, iterations = 50)  # Format draws for plotting iterations <- bayestestR::reshape_iterations(predicted) iterations$group <- paste0(iterations$iter_group, iterations$Species)  p <- iris |>   ggplot(aes(x = Sepal.Length)) +   geom_point(aes(y = Petal.Length, color = Species)) +   geom_line(data = iterations, aes(y = iter_value, color = Species, group = group), alpha = 0.1) +   geom_line(data = predicted, aes(y = Predicted, color = Species), linewidth = 1) +   theme_minimal() p"},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/estimate_slopes.html","id":"marginal-effects-over-a-factors-levels","dir":"Articles","previous_headings":"","what":"Marginal effects over a factor’s levels","title":"Estimate marginal effects","text":"Let’s fit linear model factor interacting continuous predictor visualize .  seems like slope effect roughly similar (direction) across different factor levels. Moreover, interaction significant. However, see removing interaction substantially improve model’s performance. , sake demonstration, let’s say want keep maximal effect structure. Although satisfied model performance, imagine interested effect Petal.Length different Species, rather, general trend “across” different species. need compute marginal effect predictor, corresponds slope averaged (’s bit complex simple averaging ’s idea) different factor levels. can see effect Petal.Length, marginalized Species, positive significant.","code":"library(ggplot2) library(parameters) library(performance) library(modelbased)  model <- lm(Sepal.Length ~ Petal.Length * Species, data = iris)  estimate_relation(model) |>   plot() parameters(model) > Parameter                           | Coefficient |   SE |         95% CI > ------------------------------------------------------------------------- > (Intercept)                         |        4.21 | 0.41 | [ 3.41,  5.02] > Petal Length                        |        0.54 | 0.28 | [ 0.00,  1.09] > Species [versicolor]                |       -1.81 | 0.60 | [-2.99, -0.62] > Species [virginica]                 |       -3.15 | 0.63 | [-4.41, -1.90] > Petal Length × Species [versicolor] |        0.29 | 0.30 | [-0.30,  0.87] > Petal Length × Species [virginica]  |        0.45 | 0.29 | [-0.12,  1.03] >  > Parameter                           | t(144) |      p > ----------------------------------------------------- > (Intercept)                         |  10.34 | < .001 > Petal Length                        |   1.96 | 0.052  > Species [versicolor]                |  -3.02 | 0.003  > Species [virginica]                 |  -4.97 | < .001 > Petal Length × Species [versicolor] |   0.97 | 0.334  > Petal Length × Species [virginica]  |   1.56 | 0.120 model2 <- lm(Sepal.Length ~ Petal.Length + Species, data = iris)  test_performance(model, model2) > Name   | Model |    BF | df | df_diff | Chi2 |     p > ---------------------------------------------------- > model  |    lm |       |  7 |         |      |       > model2 |    lm | 26.52 |  5 |   -2.00 | 3.47 | 0.177 > Models were detected as nested (in terms of fixed parameters) and are compared in sequential order. slopes <- estimate_slopes(model, trend = \"Petal.Length\")  slopes > Estimated Marginal Effects >  > Slope |   SE |       95% CI |    t |      p > ------------------------------------------- > 0.79  | 0.10 | [0.59, 0.99] | 7.69 | < .001 >  > Marginal effects estimated for Petal.Length > Type of slope was dY/dX"},{"path":"https://easystats.github.io/modelbased/articles/estimate_slopes.html","id":"effects-for-each-factors-levels","dir":"Articles","previous_headings":"","what":"Effects for each factor’s levels","title":"Estimate marginal effects","text":"","code":"slopes <- estimate_slopes(model, trend = \"Petal.Length\", by = \"Species\")  slopes > Estimated Marginal Effects >  > Species    | Slope |   SE |        95% CI |     t |      p > ---------------------------------------------------------- > setosa     |  0.54 | 0.28 | [ 0.00, 1.08] |  1.96 |  0.050 > versicolor |  0.83 | 0.10 | [ 0.63, 1.03] |  8.10 | < .001 > virginica  |  1.00 | 0.09 | [ 0.83, 1.17] | 11.43 | < .001 >  > Marginal effects estimated for Petal.Length > Type of slope was dY/dX plot(slopes)"},{"path":"https://easystats.github.io/modelbased/articles/estimate_slopes.html","id":"interactions-between-two-continuous-variables","dir":"Articles","previous_headings":"","what":"Interactions between two continuous variables","title":"Estimate marginal effects","text":"Interactions two continuous variables often straightforward visualize interpret. Thanks model-based approach, one can represent effect one variables function variable. plot, also referred Johnson-Neyman intervals, shows effect (“slope”) one variable varies depending another variable. useful case complex interactions continuous variables. See also vignette details. instance, plot shows effect hp (y-axis) significantly negative wt low (< ~4).","code":"model <- lm(mpg ~ hp * wt, data = mtcars)  slopes <- estimate_slopes(model, trend = \"hp\", by = \"wt\")  plot(slopes) +   geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/articles/estimate_slopes.html","id":"describing-and-reporting-non-linear-relationships-e-g--in-gams","dir":"Articles","previous_headings":"","what":"Describing and reporting non-linear relationships (e.g., in GAMs)","title":"Estimate marginal effects","text":"Complex problems require modern solutions. General Additive Models (GAMs) powerful class models extend capabilities traditional GLMs. particular, able parsimoniously model possibly non-linear relationship. Let’s take instance following model:  GAMs nicely models complex relationship two variables (don’t take account different species course). interpret report manuscript results? can’t simply paste figure right? Right? Reviewers want statistics, numbers brackets, otherwise doesn’t look serious . problem GAMs parameters (.e., coefficients), easily interpretable. can see one line corresponding smooth term. ’s significant, great, mean? run GAM using packages (e.g., rstanarm brms), parameters . ! meaning parameters somewhat disconnected need relationship understanding, another possibility compute marginal linear effect smooth term, .e., “derivative”, using estimate_slopes.  plot represents “slope” curve point curve. can see, significant negative trend (Petal.Length = 2), followed significant positive trend (around Petal.Length = 4). Marginal derivatives allow us make inferences point relationship! Finally, help reporting manuscript, can divide chunks obtain summary trend chunk, including direction effects whether statistically significant .","code":"# Fit a non-linear General Additive Model (GAM) model <- mgcv::gam(Sepal.Width ~ s(Petal.Length), data = iris)  estimate_relation(model, length = 50) |>   plot() parameters::parameters(model) > # Fixed Effects >  > Parameter   | Coefficient |   SE |       95% CI | t(142.33) |      p > -------------------------------------------------------------------- > (Intercept) |        3.06 | 0.03 | [3.01, 3.11] |    118.31 | < .001 >  > # Smooth Terms >  > Parameter                  |     F |   df |      p > -------------------------------------------------- > Smooth term (Petal Length) | 17.52 | 6.67 | < .001 # Compute derivative deriv <- estimate_slopes(model,   trend = \"Petal.Length\",   by = \"Petal.Length\",   length = 100 )  # Visualise plot(deriv) +   geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +   theme_minimal() summary(deriv) > Johnson-Neymann Intervals >  > Start |  End | Direction | Confidence      > ------------------------------------------ > 1.00  | 1.72 | positive  | Not Significant > 1.77  | 1.95 | negative  | Not Significant > 2.01  | 3.15 | negative  | Significant     > 3.21  | 3.44 | negative  | Not Significant > 3.50  | 3.68 | positive  | Not Significant > 3.74  | 4.28 | positive  | Significant     > 4.34  | 6.24 | positive  | Not Significant > 6.30  | 6.90 | negative  | Not Significant >  > Marginal effects estimated for Petal.Length > Type of slope was dY/dX"},{"path":"https://easystats.github.io/modelbased/articles/estimate_slopes.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Estimate marginal effects","text":"Johnson, P.O. & Fay, L.C. (1950). Johnson-Neyman technique, theory application. Psychometrika, 15, 349-367. doi: 10.1007/BF02288864","code":""},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_1.html","id":"hypothesis-testing-for-categorical-predictors","dir":"Articles","previous_headings":"","what":"Hypothesis testing for categorical predictors","title":"Contrasts and pairwise comparisons","text":"reason compute adjusted predictions (estimated marginal means) help understanding relationship predictors outcome regression model. next step, often follows , see statistically significant differences. , example, differences groups, .e. levels categorical predictors whether trends differ significantly . modelbased package provides function, estimate_contrasts(), exactly : testing differences predictions marginal means statistical significance. usually called contrasts (pairwise) comparisons, marginal effects (difference refers one-unit change predictors). vignette shows examples use estimate_contrasts() function test whether differences predictions statistically significant. First, different examples pairwise comparisons shown, later see test differences--differences (emmeans package, also called interaction contrasts).","code":""},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_1.html","id":"within-episode-do-levels-differ","dir":"Articles","previous_headings":"Hypothesis testing for categorical predictors","what":"Within episode, do levels differ?","title":"Contrasts and pairwise comparisons","text":"start toy example, linear model two categorical predictors. interaction involved now. display simple table regression coefficients, created model_parameters() parameters package.","code":"library(modelbased) library(parameters) library(ggplot2)  set.seed(123) n <- 200 d <- data.frame(   outcome = rnorm(n),   grp = as.factor(sample(c(\"treatment\", \"control\"), n, TRUE)),   episode = as.factor(sample(1:3, n, TRUE)),   sex = as.factor(sample(c(\"female\", \"male\"), n, TRUE, prob = c(0.4, 0.6))) ) model1 <- lm(outcome ~ grp + episode, data = d) model_parameters(model1) #> Parameter       | Coefficient |   SE |        95% CI | t(196) |     p #> --------------------------------------------------------------------- #> (Intercept)     |       -0.08 | 0.13 | [-0.33, 0.18] |  -0.60 | 0.552 #> grp [treatment] |       -0.17 | 0.13 | [-0.44, 0.09] |  -1.30 | 0.197 #> episode [2]     |        0.36 | 0.16 | [ 0.03, 0.68] |   2.18 | 0.031 #> episode [3]     |        0.10 | 0.16 | [-0.22, 0.42] |   0.62 | 0.538"},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_1.html","id":"predictions","dir":"Articles","previous_headings":"Hypothesis testing for categorical predictors > Within episode, do levels differ?","what":"Predictions","title":"Contrasts and pairwise comparisons","text":"Let us look adjusted predictions.  now see , instance, predicted outcome espisode = 2 0.2.","code":"my_predictions <- estimate_means(model1, \"episode\") my_predictions #> Estimated Marginal Means #>  #> episode |           Mean (CI) #> ----------------------------- #> 1       | -0.16 (-0.39, 0.07) #> 2       |  0.20 (-0.04, 0.43) #> 3       | -0.06 (-0.28, 0.16) #>  #> Variable predicted: outcome #> Predictors modulated: episode #> Predictors averaged: grp  plot(my_predictions)"},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_1.html","id":"pairwise-comparisons","dir":"Articles","previous_headings":"Hypothesis testing for categorical predictors > Within episode, do levels differ?","what":"Pairwise comparisons","title":"Contrasts and pairwise comparisons","text":"now ask whether predicted outcome episode = 1 significantly different predicted outcome episode = 2.  , use estimate_contrasts() function. default, pairwise comparison performed. can specify comparisons well, using comparison argument. now, go simpler example contrasts pairwise comparisons. quantity interest, contrast episode levels 2 1, see value 0.36, exactly difference predicted outcome episode = 1 (-0.16) episode = 2 (0.20). related p-value 0.031, indicating difference predicted values outcome two levels factor episode indeed statistically significant. can also define “representative values” via contrast arguments. example, specify levels episode directly, simplify output:","code":"# argument `comparison` defaults to \"pairwise\" estimate_contrasts(model1, \"episode\") #> Marginal Contrasts Analysis #>  #> Level1 | Level2 |     Difference (CI) |     p #> --------------------------------------------- #> 2      | 1      |  0.36 ( 0.03, 0.68) | 0.031 #> 3      | 1      |  0.10 (-0.22, 0.42) | 0.538 #> 3      | 2      | -0.26 (-0.58, 0.06) | 0.112 #>  #> Variable predicted: outcome #> Predictors contrasted: episode #> Predictors averaged: grp #> p-values are uncorrected. estimate_contrasts(model1, contrast = \"episode=c(1,2)\") #> Marginal Contrasts Analysis #>  #> Level1 | Level2 |   Difference (CI) |     p #> ------------------------------------------- #> 2      | 1      | 0.36 (0.03, 0.68) | 0.031 #>  #> Variable predicted: outcome #> Predictors contrasted: episode=c(1,2) #> Predictors averaged: grp #> p-values are uncorrected."},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_1.html","id":"does-same-level-of-episode-differ-between-groups","dir":"Articles","previous_headings":"Hypothesis testing for categorical predictors","what":"Does same level of episode differ between groups?","title":"Contrasts and pairwise comparisons","text":"next example includes pairwise comparison interaction two categorical predictors.","code":"model2 <- lm(outcome ~ grp * episode, data = d) model_parameters(model2) #> Parameter                     | Coefficient |   SE |        95% CI | t(194) |     p #> ----------------------------------------------------------------------------------- #> (Intercept)                   |        0.03 | 0.15 | [-0.27, 0.33] |   0.18 | 0.853 #> grp [treatment]               |       -0.42 | 0.23 | [-0.88, 0.04] |  -1.80 | 0.074 #> episode [2]                   |        0.20 | 0.22 | [-0.23, 0.63] |   0.94 | 0.350 #> episode [3]                   |       -0.07 | 0.22 | [-0.51, 0.37] |  -0.32 | 0.750 #> grp [treatment] × episode [2] |        0.36 | 0.33 | [-0.29, 1.02] |   1.09 | 0.277 #> grp [treatment] × episode [3] |        0.37 | 0.32 | [-0.27, 1.00] |   1.14 | 0.254"},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_1.html","id":"predictions-1","dir":"Articles","previous_headings":"Hypothesis testing for categorical predictors > Does same level of episode differ between groups?","what":"Predictions","title":"Contrasts and pairwise comparisons","text":"First, look predicted values outcome combinations involved interaction term.","code":"my_predictions <- estimate_means(model2, by = c(\"episode\", \"grp\")) my_predictions #> Estimated Marginal Means #>  #> episode | grp       |            Mean (CI) #> ------------------------------------------ #> 1       | control   |  0.03 (-0.27,  0.33) #> 2       | control   |  0.23 (-0.08,  0.54) #> 3       | control   | -0.04 (-0.36,  0.28) #> 1       | treatment | -0.39 (-0.74, -0.04) #> 2       | treatment |  0.18 (-0.18,  0.53) #> 3       | treatment | -0.09 (-0.39,  0.21) #>  #> Variable predicted: outcome #> Predictors modulated: episode, grp  plot(my_predictions)"},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_1.html","id":"pairwise-comparisons-1","dir":"Articles","previous_headings":"Hypothesis testing for categorical predictors > Does same level of episode differ between groups?","what":"Pairwise comparisons","title":"Contrasts and pairwise comparisons","text":"now ask whether predicted outcome episode = 2 significantly different depending level grp? words, groups treatment control differ episode = 2?  , answer question, calculate pairwise comparisons, .e. comparison (test differences) combinations focal predictors. focal predictors ’re interested two variables used interaction. quantity interest, contrast groups treatment control episode = 2 0.06. find comparison row 10 output. can see, estimate_contrasts() returns pairwise comparisons possible combinations factor levels focal variables. ’re interested specific comparison, two options simplify output: directly formulate comparison. Therefore, need know parameters interests (see ). pass specific values levels contrast argument.","code":"# we want \"episode = 2-2\" and \"grp = control-treatment\" estimate_contrasts(model2, contrast = c(\"episode\", \"grp\")) #> Marginal Contrasts Analysis #>  #> Level1       | Level2       |     Difference (CI) |     p #> --------------------------------------------------------- #> 1, treatment | 1, control   | -0.42 (-0.88, 0.04) | 0.074 #> 2, control   | 1, control   |  0.20 (-0.23, 0.63) | 0.350 #> 2, treatment | 1, control   |  0.15 (-0.32, 0.61) | 0.529 #> 3, control   | 1, control   | -0.07 (-0.51, 0.37) | 0.750 #> 3, treatment | 1, control   | -0.12 (-0.54, 0.30) | 0.573 #> 2, control   | 1, treatment |  0.62 ( 0.16, 1.09) | 0.009 #> 2, treatment | 1, treatment |  0.57 ( 0.07, 1.06) | 0.026 #> 3, control   | 1, treatment |  0.35 (-0.13, 0.82) | 0.150 #> 3, treatment | 1, treatment |  0.30 (-0.16, 0.76) | 0.203 #> 2, treatment | 2, control   | -0.06 (-0.52, 0.41) | 0.816 #> 3, control   | 2, control   | -0.27 (-0.72, 0.17) | 0.225 #> 3, treatment | 2, control   | -0.32 (-0.75, 0.10) | 0.137 #> 3, control   | 2, treatment | -0.22 (-0.70, 0.26) | 0.368 #> 3, treatment | 2, treatment | -0.27 (-0.73, 0.19) | 0.254 #> 3, treatment | 3, control   | -0.05 (-0.49, 0.39) | 0.821 #>  #> Variable predicted: outcome #> Predictors contrasted: episode, grp #> p-values are uncorrected."},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_1.html","id":"option-1-directly-specify-the-comparison","dir":"Articles","previous_headings":"Hypothesis testing for categorical predictors > Does same level of episode differ between groups? > Pairwise comparisons","what":"Option 1: Directly specify the comparison","title":"Contrasts and pairwise comparisons","text":"output, row considered one coefficient interest. groups want include comparison rows two (grp = control episode = 2) five (grp = treatment episode = 2), “quantities interest” b2 b5. null hypothesis want test whether predictions equal, .e. comparison = \"b5 = b2\" (also specify \"b2 = b5\", results , just signs switched). can now calculate desired comparison directly:","code":"estimate_means(model2, by = c(\"episode\", \"grp\")) #> Estimated Marginal Means #>  #> episode | grp       |            Mean (CI) #> ------------------------------------------ #> 1       | control   |  0.03 (-0.27,  0.33) #> 2       | control   |  0.23 (-0.08,  0.54) #> 3       | control   | -0.04 (-0.36,  0.28) #> 1       | treatment | -0.39 (-0.74, -0.04) #> 2       | treatment |  0.18 (-0.18,  0.53) #> 3       | treatment | -0.09 (-0.39,  0.21) #>  #> Variable predicted: outcome #> Predictors modulated: episode, grp # compute specific contrast directly estimate_contrasts(model2, contrast = c(\"episode\", \"grp\"), comparison = \"b2 = b5\") #> Marginal Contrasts Analysis #>  #> Parameter |    Difference (CI) |     p #> -------------------------------------- #> b2=b5     | 0.06 (-0.41, 0.52) | 0.816 #>  #> Variable predicted: outcome #> Predictors contrasted: episode, grp #> p-values are uncorrected. #> Parameters: #> b2 = episode [2], grp [control] #> b5 = episode [2], grp [treatment]"},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_1.html","id":"option-2-specify-values-or-levels","dir":"Articles","previous_headings":"Hypothesis testing for categorical predictors > Does same level of episode differ between groups? > Pairwise comparisons","what":"Option 2: Specify values or levels","title":"Contrasts and pairwise comparisons","text":", using representative values contrast argument, can also simplify output using alternative syntax: equivalent example, directly specified comparison ’re interested . However, comparison argument might provide flexibility case want complex comparisons. See examples .","code":"# return pairwise comparisons for specific values, in # this case for episode = 2 in both groups estimate_contrasts(model2, contrast = c(\"episode=2\", \"grp\")) #> Marginal Contrasts Analysis #>  #> Level1    | Level2  |     Difference (CI) |     p #> ------------------------------------------------- #> treatment | control | -0.06 (-0.52, 0.41) | 0.816 #>  #> Variable predicted: outcome #> Predictors contrasted: episode=2, grp #> p-values are uncorrected."},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_1.html","id":"do-different-episode-levels-differ-between-groups","dir":"Articles","previous_headings":"Hypothesis testing for categorical predictors","what":"Do different episode levels differ between groups?","title":"Contrasts and pairwise comparisons","text":"can repeat steps shown test combination group levels differences.","code":""},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_1.html","id":"pairwise-comparisons-2","dir":"Articles","previous_headings":"Hypothesis testing for categorical predictors > Do different episode levels differ between groups?","what":"Pairwise comparisons","title":"Contrasts and pairwise comparisons","text":"instance, now ask whether predicted outcome episode = 1 treatment group significantly different predicted outcome episode = 3 control group.  contrast interested episode = 1 treatment group episode = 3 control group. predicted values rows three four (c.f. table predicted values), thus comparison whether \"b4 = b3\". Another way produce pairwise comparison, can reduce table predicted values providing specific values levels contrast argument: episode = 1 treatment group episode = 3 control group refer now rows two three reduced output, thus also can obtain desired comparison way:","code":"estimate_contrasts(model2, contrast = c(\"episode\", \"grp\"), comparison = \"b4 = b3\") #> Marginal Contrasts Analysis #>  #> Parameter |     Difference (CI) |     p #> --------------------------------------- #> b4=b3     | -0.35 (-0.82, 0.13) | 0.150 #>  #> Variable predicted: outcome #> Predictors contrasted: episode, grp #> p-values are uncorrected. #> Parameters: #> b4 = episode [1], grp [treatment] #> b3 = episode [3], grp [control] estimate_means(model2, by = c(\"episode=c(1,3)\", \"grp\")) #> Estimated Marginal Means #>  #> episode | grp       |            Mean (CI) #> ------------------------------------------ #> 1       | control   |  0.03 (-0.27,  0.33) #> 3       | control   | -0.04 (-0.36,  0.28) #> 1       | treatment | -0.39 (-0.74, -0.04) #> 3       | treatment | -0.09 (-0.39,  0.21) #>  #> Variable predicted: outcome #> Predictors modulated: episode=c(1,3), grp estimate_contrasts(   model2,   contrast = c(\"episode = c(1, 3)\", \"grp\"),   comparison = \"b3 = b2\" ) #> Marginal Contrasts Analysis #>  #> Parameter |     Difference (CI) |     p #> --------------------------------------- #> b3=b2     | -0.35 (-0.82, 0.13) | 0.150 #>  #> Variable predicted: outcome #> Predictors contrasted: episode = c(1, 3), grp #> p-values are uncorrected. #> Parameters: #> b3 = episode [1], grp [treatment] #> b2 = episode [3], grp [control]"},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_1.html","id":"does-difference-between-two-levels-of-episode-in-the-control-group-differ-from-difference-of-same-two-levels-in-the-treatment-group","dir":"Articles","previous_headings":"Hypothesis testing for categorical predictors","what":"Does difference between two levels of episode in the control group differ from difference of same two levels in the treatment group?","title":"Contrasts and pairwise comparisons","text":"comparison argument also allows us compare difference--differences (aka interaction contrasts). example, difference two episode levels one group significantly different difference two episode levels group?  reminder, look table predictions : first difference episode levels 1 2 control group refer rows one two table (b1 b2). difference episode levels treatment group refer difference rows four five (b4 b5). Thus, b1 - b2 b4 - b5, null hypothesis two differences equal: comparison = \"(b1 - b2) = (b4 - b5)\". Let’s replicate step--step: Predicted value outcome episode = 1 control group 0.03. Predicted value outcome episode = 2 control group 0.23. first difference 0.20. Predicted value outcome episode = 1 treatment group -0.39. Predicted value outcome episode = 2 treatment group 0.18. second difference -0.17. quantity interest difference two differences, (considering rounding inaccuracy) 0.36. difference statistically significant (p = 0.277).","code":"estimate_means(model2, c(\"episode\", \"grp\")) #> Estimated Marginal Means #>  #> episode | grp       |            Mean (CI) #> ------------------------------------------ #> 1       | control   |  0.03 (-0.27,  0.33) #> 2       | control   |  0.23 (-0.08,  0.54) #> 3       | control   | -0.04 (-0.36,  0.28) #> 1       | treatment | -0.39 (-0.74, -0.04) #> 2       | treatment |  0.18 (-0.18,  0.53) #> 3       | treatment | -0.09 (-0.39,  0.21) #>  #> Variable predicted: outcome #> Predictors modulated: episode, grp estimate_contrasts(   model2,   c(\"episode\", \"grp\"),   comparison = \"(b1 - b2) = (b4 - b5)\" ) #> Marginal Contrasts Analysis #>  #> Parameter   |    Difference (CI) |     p #> ---------------------------------------- #> b1-b2=b4-b5 | 0.36 (-0.29, 1.02) | 0.277 #>  #> Variable predicted: outcome #> Predictors contrasted: episode, grp #> p-values are uncorrected. #> Parameters: #> b1 = episode [1], grp [control] #> b2 = episode [2], grp [control] #> b4 = episode [1], grp [treatment] #> b5 = episode [2], grp [treatment]"},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_1.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Contrasts and pairwise comparisons","text":"current implementation estimate_contrasts() already covers many common use cases testing contrasts pairwise comparison, still might need sophisticated comparisons. case, recommend using marginaleffects package directly. related recommended readings vignettes Comparisons Hypothesis Tests. Go next vignette: Comparisons Slopes, Floodlight Spotlight Analysis (Johnson-Neyman Intervals)","code":""},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_2.html","id":"contrasts-and-comparisons-for-slopes-of-numeric-predictors","dir":"Articles","previous_headings":"","what":"Contrasts and comparisons for slopes of numeric predictors","title":"Slopes, floodlight and spotlight analysis (Johnson-Neyman intervals)","text":"numeric focal terms, possible calculate contrasts slopes, linear trend focal terms. Let’s start simple example . can already see coefficient table slope Sepal.Length 0.35. thus find increase predicted values outcome focal variable, Sepal.Length increases one unit. Consequently, case simple slope, see result estimated linear trend Sepal.Length:","code":"library(modelbased) library(parameters) data(iris) m <- lm(Sepal.Width ~ Sepal.Length + Species, data = iris) model_parameters(m) #> Parameter            | Coefficient |   SE |         95% CI | t(146) |      p #> ---------------------------------------------------------------------------- #> (Intercept)          |        1.68 | 0.24 | [ 1.21,  2.14] |   7.12 | < .001 #> Sepal Length         |        0.35 | 0.05 | [ 0.26,  0.44] |   7.56 | < .001 #> Species [versicolor] |       -0.98 | 0.07 | [-1.13, -0.84] | -13.64 | < .001 #> Species [virginica]  |       -1.01 | 0.09 | [-1.19, -0.82] | -10.80 | < .001 estimate_means(m, \"Sepal.Length=c(4,5,6,7)\") #> Estimated Marginal Means #>  #> Sepal.Length | Mean |   SE |       95% CI | t(146) #> -------------------------------------------------- #> 4            | 2.41 | 0.09 | [2.24, 2.59] |  27.24 #> 5            | 2.76 | 0.05 | [2.67, 2.85] |  60.55 #> 6            | 3.11 | 0.02 | [3.06, 3.16] | 126.07 #> 7            | 3.46 | 0.06 | [3.35, 3.58] |  59.16 #>  #> Variable predicted: Sepal.Width #> Predictors modulated: Sepal.Length=c(4,5,6,7) #> Predictors averaged: Species estimate_slopes(m, \"Sepal.Length\") #> Estimated Marginal Effects #>  #> Slope |   SE |       95% CI |    t |      p #> ------------------------------------------- #> 0.35  | 0.05 | [0.26, 0.44] | 7.56 | < .001 #>  #> Marginal effects estimated for Sepal.Length #> Type of slope was dY/dX"},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_2.html","id":"is-the-linear-trend-of-sepal-length-significant-for-the-different-levels-of-species","dir":"Articles","previous_headings":"Contrasts and comparisons for slopes of numeric predictors","what":"Is the linear trend of Sepal.Length significant for the different levels of Species?","title":"Slopes, floodlight and spotlight analysis (Johnson-Neyman intervals)","text":"Let’s move complex example interaction numeric categorical variable.","code":""},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_2.html","id":"predictions","dir":"Articles","previous_headings":"Contrasts and comparisons for slopes of numeric predictors > Is the linear trend of Sepal.Length significant for the different levels of Species?","what":"Predictions","title":"Slopes, floodlight and spotlight analysis (Johnson-Neyman intervals)","text":"","code":"m <- lm(Sepal.Width ~ Sepal.Length * Species, data = iris) pred <- estimate_means(m, c(\"Sepal.Length\", \"Species\")) plot(pred)"},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_2.html","id":"slopes-by-group","dir":"Articles","previous_headings":"Contrasts and comparisons for slopes of numeric predictors > Is the linear trend of Sepal.Length significant for the different levels of Species?","what":"Slopes by group","title":"Slopes, floodlight and spotlight analysis (Johnson-Neyman intervals)","text":"can see slope Sepal.Length different within group Species.  Since don’t want pairwise comparisons, still use estimate_slopes() test whether linear trend (groups) significant . case, interaction terms included, linear trend (slope) numeric focal predictor, Sepal.Length, tested level Species. can see, three slopes significant, .e. “significant” linear trends.","code":"estimate_slopes(m, \"Sepal.Length\", by = \"Species\") #> Estimated Marginal Effects #>  #> Species    | Slope |   SE |       95% CI |    t |      p #> -------------------------------------------------------- #> setosa     |  0.80 | 0.11 | [0.58, 1.01] | 7.23 | < .001 #> versicolor |  0.32 | 0.08 | [0.17, 0.47] | 4.24 | < .001 #> virginica  |  0.23 | 0.06 | [0.11, 0.35] | 3.79 | < .001 #>  #> Marginal effects estimated for Sepal.Length #> Type of slope was dY/dX"},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_2.html","id":"pairwise-comparisons","dir":"Articles","previous_headings":"Contrasts and comparisons for slopes of numeric predictors > Is the linear trend of Sepal.Length significant for the different levels of Species?","what":"Pairwise comparisons","title":"Slopes, floodlight and spotlight analysis (Johnson-Neyman intervals)","text":"Next question whether linear trends differ significantly , .e. test differences slopes, pairwise comparison slopes. , use estimate_contrasts(). linear trend Sepal.Length within setosa significantly different linear trend versicolor also virginica. difference slopes virginica versicolor statistically significant (p = 0.366).","code":"estimate_contrasts(m, \"Sepal.Length\", by = \"Species\") #> Marginal Contrasts Analysis #>  #> Level1     | Level2     | Difference |   SE |         95% CI |     t |      p #> ----------------------------------------------------------------------------- #> versicolor | setosa     |      -0.48 | 0.13 | [-0.74, -0.22] | -3.58 | < .001 #> virginica  | setosa     |      -0.57 | 0.13 | [-0.81, -0.32] | -4.49 | < .001 #> virginica  | versicolor |      -0.09 | 0.10 | [-0.28,  0.10] | -0.90 |  0.366 #>  #> Variable predicted: Sepal.Width #> Predictors contrasted: Sepal.Length #> Predictors averaged: Sepal.Length (5.8) #> p-values are uncorrected."},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_2.html","id":"is-the-difference-linear-trends-of-sepal-length-in-between-two-groups-of-species-significantly-different-from-the-difference-of-two-linear-trends-between-two-other-groups","dir":"Articles","previous_headings":"Contrasts and comparisons for slopes of numeric predictors","what":"Is the difference linear trends of Sepal.Length in between two groups of Species significantly different from the difference of two linear trends between two other groups?","title":"Slopes, floodlight and spotlight analysis (Johnson-Neyman intervals)","text":"Similar example categorical predictors, can also test difference--differences example. instance, difference slopes Sepal.Length setosa versicolor different slope-difference groups setosa vigninica? Let’s first look different slopes separately , .e. slopes Sepal.Length levels Species: first difference slopes ’re interested one setosa (0.80) versicolor (0.32), .e. b1 - b2 (=0.48). second difference levels setosa (0.80) virginica (0.23), b1 - b3 (=0.57). test null hypothesis (b1 - b2) = (b1 - b3). difference two differences -0.09 statistically significant (p = 0.366).","code":"estimate_slopes(m, \"Sepal.Length\", by = \"Species\") #> Estimated Marginal Effects #>  #> Species    | Slope |   SE |       95% CI |    t |      p #> -------------------------------------------------------- #> setosa     |  0.80 | 0.11 | [0.58, 1.01] | 7.23 | < .001 #> versicolor |  0.32 | 0.08 | [0.17, 0.47] | 4.24 | < .001 #> virginica  |  0.23 | 0.06 | [0.11, 0.35] | 3.79 | < .001 #>  #> Marginal effects estimated for Sepal.Length #> Type of slope was dY/dX estimate_contrasts(   m,   \"Sepal.Length\",   by = \"Species\",   comparison = \"(b1 - b2) = (b1 - b3)\" ) #> Marginal Contrasts Analysis #>  #> Parameter   | Difference |   SE |        95% CI |     t |     p #> --------------------------------------------------------------- #> b1-b2=b1-b3 |      -0.09 | 0.10 | [-0.28, 0.10] | -0.90 | 0.366 #>  #> Variable predicted: Sepal.Width #> Predictors contrasted: Sepal.Length #> Predictors averaged: Sepal.Length (5.8) #> p-values are uncorrected. #> Parameters: #> b1 = Species [setosa] #> b2 = Species [versicolor] #> b1 = Species [setosa] #> b3 = Species [virginica]"},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_2.html","id":"is-the-linear-trend-of-sepal-length-significant-at-different-values-of-another-numeric-predictor","dir":"Articles","previous_headings":"Contrasts and comparisons for slopes of numeric predictors","what":"Is the linear trend of Sepal.Length significant at different values of another numeric predictor?","title":"Slopes, floodlight and spotlight analysis (Johnson-Neyman intervals)","text":"two numeric terms interaction, comparison becomes difficult, find meaningful (representative) values moderator, associations predictor outcome tested. longer distinct categories moderator variable.","code":""},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_2.html","id":"spotlight-analysis-floodlight-analysis-and-johnson-neyman-intervals","dir":"Articles","previous_headings":"Contrasts and comparisons for slopes of numeric predictors > Is the linear trend of Sepal.Length significant at different values of another numeric predictor?","what":"Spotlight analysis, floodlight analysis and Johnson-Neyman intervals","title":"Slopes, floodlight and spotlight analysis (Johnson-Neyman intervals)","text":"following examples show interactions two numeric predictors. case numeric interaction terms, makes sense calculate adjusted predictions representative values, e.g. mean +/- SD. sometimes also called “spotlight analysis” (Spiller et al. 2013). next example, Petal.Width second interaction term, thus see predicted values Sepal.Width (outcome) Petal.Length three different, representative values Petal.Width: Mean (1.2), 1 SD mean (1.96) 1 SD mean (0.44).","code":""},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_2.html","id":"predictions-1","dir":"Articles","previous_headings":"Contrasts and comparisons for slopes of numeric predictors > Is the linear trend of Sepal.Length significant at different values of another numeric predictor?","what":"Predictions","title":"Slopes, floodlight and spotlight analysis (Johnson-Neyman intervals)","text":"First, want see value Petal.Width slopes Petal.Length significant. pairwise comparison now, hence use estimate_slopes().","code":"m <- lm(Sepal.Width ~ Petal.Length * Petal.Width, data = iris) pred <- estimate_means(m, c(\"Petal.Length\", \"Petal.Width=[sd]\")) plot(pred) estimate_slopes(m, \"Petal.Length\", by = \"Petal.Width=[sd]\") #> Estimated Marginal Effects #>  #> Petal.Width | Slope |   SE |         95% CI |     t |      p #> ------------------------------------------------------------ #> 0.44        | -0.28 | 0.06 | [-0.39, -0.16] | -4.80 | < .001 #> 1.20        | -0.11 | 0.06 | [-0.23,  0.01] | -1.80 |  0.072 #> 1.96        |  0.06 | 0.07 | [-0.09,  0.20] |  0.78 |  0.433 #>  #> Marginal effects estimated for Petal.Length #> Type of slope was dY/dX"},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_2.html","id":"pairwise-comparisons-1","dir":"Articles","previous_headings":"Contrasts and comparisons for slopes of numeric predictors > Is the linear trend of Sepal.Length significant at different values of another numeric predictor?","what":"Pairwise comparisons","title":"Slopes, floodlight and spotlight analysis (Johnson-Neyman intervals)","text":"results pairwise comparison shown . tell us linear trends (slopes) significantly different , .e. slope green line significantly different slope red line, .","code":"estimate_contrasts(m, \"Petal.Length\", by = \"Petal.Width=[sd]\", digits = 1) #> Marginal Contrasts Analysis #>  #> Level1 | Level2 | Difference |   SE |       95% CI |    t |      p #> ------------------------------------------------------------------ #> 1.2    | 0.4    |       0.18 | 0.02 | [0.13, 0.22] | 7.13 | < .001 #> 2      | 0.4    |       0.35 | 0.05 | [0.25, 0.45] | 7.13 | < .001 #> 2      | 1.2    |       0.18 | 0.02 | [0.13, 0.22] | 7.13 | < .001 #>  #> Variable predicted: Sepal.Width #> Predictors contrasted: Petal.Length #> Predictors averaged: Petal.Length (3.8) #> p-values are uncorrected."},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_2.html","id":"floodlight-analysis-and-johnson-neyman-intervals","dir":"Articles","previous_headings":"Contrasts and comparisons for slopes of numeric predictors > Is the linear trend of Sepal.Length significant at different values of another numeric predictor?","what":"Floodlight analysis and Johnson-Neyman intervals","title":"Slopes, floodlight and spotlight analysis (Johnson-Neyman intervals)","text":"Another way handle models two numeric variables interaction use -called floodlight analysis, spotlight analysis values moderator variable. intervals indicate values moderator slope predictor significant (cf. Johnson et al. 1950, McCabe et al. 2018). Let’s look example. first plot predicted values Income Murder different values Illiteracy.  ’s difficult say values Illiteracy, association Murder Income might statistically significant. still can use estimate_slopes(): can seen, results might indicate lower upper tails Illiteracy, .e. Illiteracy roughly smaller 0.8 larger 2.6, association Murder Income statistically significant. However, test can simplified using summary() function. show us detail values Illiteracy interaction term statistically significant, whether association Murder outcome positive negative. Furthermore, possible create spotlight-plot.  results spotlight analysis suggest values 0.82 2.57 significantly different zero, values . can plot predictions values see differences. red green line represent values Illiteracy find clear positive resp. negative associations Murder Income, find clear (positive negative) association red line. example, using values three “ranges” Johnson-Neyman-Interval: red blue lines significantly positive negative associated outcome, green line significant.  Go next vignette: Contrasts Comparisons Generalized Linear Models","code":"states <- as.data.frame(state.x77) states$HSGrad <- states$`HS Grad` m_mod <- lm(Income ~ HSGrad + Murder * Illiteracy, data = states)  pr <- estimate_means(m_mod, c(\"Murder\", \"Illiteracy\")) plot(pr) estimate_slopes(m_mod, \"Murder\", by = \"Illiteracy\") #> Estimated Marginal Effects #>  #> Illiteracy |   Slope |    SE |            95% CI |     t |     p #> ---------------------------------------------------------------- #> 0.50       |   82.08 | 31.48 | [  20.38, 143.78] |  2.61 | 0.009 #> 0.76       |   57.24 | 26.93 | [   4.46, 110.02] |  2.13 | 0.034 #> 1.01       |   32.49 | 25.04 | [ -16.58,  81.57] |  1.30 | 0.194 #> 1.27       |    7.65 | 26.41 | [ -44.12,  59.42] |  0.29 | 0.772 #> 1.52       |  -17.09 | 30.58 | [ -77.02,  42.84] | -0.56 | 0.576 #> 1.78       |  -41.93 | 36.64 | [-113.74,  29.87] | -1.14 | 0.252 #> 2.03       |  -66.68 | 43.77 | [-152.47,  19.11] | -1.52 | 0.128 #> 2.29       |  -91.52 | 51.57 | [-192.59,   9.54] | -1.77 | 0.076 #> 2.54       | -116.27 | 59.70 | [-233.27,   0.74] | -1.95 | 0.051 #> 2.80       | -141.11 | 68.16 | [-274.70,  -7.52] | -2.07 | 0.038 #>  #> Marginal effects estimated for Murder #> Type of slope was dY/dX # we will force to calculate slopes at 200 values for \"Illiteracy\" using `length` slopes <- estimate_slopes(m_mod, \"Murder\", by = \"Illiteracy\", length = 200) summary(slopes) #> Johnson-Neymann Intervals #>  #> Start |  End | Direction | Confidence      #> ------------------------------------------ #> 0.50  | 0.81 | positive  | Significant     #> 0.82  | 1.34 | positive  | Not Significant #> 1.35  | 2.56 | negative  | Not Significant #> 2.57  | 2.80 | negative  | Significant     #>  #> Marginal effects estimated for Murder #> Type of slope was dY/dX plot(slopes) pr <- estimate_means(m_mod, c(\"Murder\", \"Illiteracy=c(0.7,1.5,2.8)\")) plot(pr) + ggplot2::facet_wrap(~Illiteracy)"},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_2.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Slopes, floodlight and spotlight analysis (Johnson-Neyman intervals)","text":"Johnson, P.O. & Fay, L.C. (1950). Johnson-Neyman technique, theory application. Psychometrika, 15, 349-367. doi: 10.1007/BF02288864 McCabe CJ, Kim DS, King KM. (2018). Improving Present Practices Visual Display Interactions. Advances Methods Practices Psychological Science, 1(2):147-165. doi:10.1177/2515245917746792 Spiller, S. ., Fitzsimons, G. J., Lynch, J. G., & McClelland, G. H. (2013). Spotlights, Floodlights, Magic Number Zero: Simple Effects Tests Moderated Regression. Journal Marketing Research, 50(2), 277–288. doi:10.1509/jmr.12.0420","code":""},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_3.html","id":"contrasts-and-comparisons-for-glm---logistic-regression-example","dir":"Articles","previous_headings":"","what":"Contrasts and comparisons for GLM - logistic regression example","title":"Contrasts and comparisons for generalized linear models","text":"now show example non-Gaussian models. GLM’s (generalized linear models) (non-Gaussian) link-functions, estimate_means() default returns predicted values response scale. example, predicted values logistic regression models shown probabilities. Let’s look simple example.","code":"library(modelbased) set.seed(1234) dat <- data.frame(   outcome = rbinom(n = 100, size = 1, prob = 0.35),   x1 = as.factor(sample(1:3, size = 100, TRUE, prob = c(0.5, 0.2, 0.3))),   x2 = rnorm(n = 100, mean = 10, sd = 7),   x3 = as.factor(sample(1:4, size = 100, TRUE, prob = c(0.1, 0.4, 0.2, 0.3))) )  m <- glm(outcome ~ x1 + x2 + x3, data = dat, family = binomial()) estimate_means(m, \"x1\") #> Estimated Marginal Means #>  #> x1 | Probability |       95% CI #> ------------------------------- #> 1  |        0.21 | [0.11, 0.36] #> 2  |        0.14 | [0.05, 0.34] #> 3  |        0.31 | [0.16, 0.51] #>  #> Variable predicted: outcome #> Predictors modulated: x1 #> Predictors averaged: x2 (10), x3 #> Predictions are on the response-scale."},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_3.html","id":"contrasts-and-comparisons-for-categorical-focal-terms","dir":"Articles","previous_headings":"Contrasts and comparisons for GLM - logistic regression example","what":"Contrasts and comparisons for categorical focal terms","title":"Contrasts and comparisons for generalized linear models","text":"Contrasts comparisons - like predictions (see ) - default response scale, .e. ’re represented difference probabilities (percentage points). difference predicted probability x1 = 1 (21.2%) x1 = 2 (13.9%) roughly 7.3 percentage points. difference statistically significant (p = 0.417). Contrasts comparisons can also represented link-scale, case log-odds. , use predict = \"link\". transform argument estimate_contrasts() can used transform comparisons. example, transform contrasts odds ratios, can use transform = exp combination predict = \"link\". Go next vignette: Contrasts Comparisons Zero-Inflation Models","code":"estimate_contrasts(m, \"x1\") #> Marginal Contrasts Analysis #>  #> Level1 | Level2 | Difference |   SE |        95% CI |     z |     p #> ------------------------------------------------------------------- #> 2      | 1      |      -0.07 | 0.09 | [-0.25, 0.10] | -0.81 | 0.417 #> 3      | 1      |       0.09 | 0.10 | [-0.11, 0.30] |  0.92 | 0.357 #> 3      | 2      |       0.17 | 0.11 | [-0.05, 0.38] |  1.51 | 0.130 #>  #> Variable predicted: outcome #> Predictors contrasted: x1 #> Predictors averaged: x2 (10), x3 #> p-values are uncorrected. #> Contrasts are on the response-scale (in %-points). estimate_contrasts(m, \"x1\", predict = \"link\") #> Marginal Contrasts Analysis #>  #> Level1 | Level2 | Difference |   SE |        95% CI |     z |     p #> ------------------------------------------------------------------- #> 2      | 1      |      -0.51 | 0.66 | [-1.80, 0.79] | -0.77 | 0.443 #> 3      | 1      |       0.50 | 0.53 | [-0.54, 1.55] |  0.94 | 0.345 #> 3      | 2      |       1.01 | 0.70 | [-0.36, 2.38] |  1.45 | 0.147 #>  #> Variable predicted: outcome #> Predictors contrasted: x1 #> Predictors averaged: x2 (10), x3 #> p-values are uncorrected. #> Contrasts are on the link-scale. estimate_contrasts(m, \"x1\", predict = \"link\", transform = exp) #> Marginal Contrasts Analysis #>  #> Level1 | Level2 | Difference |        95% CI |     p #> ---------------------------------------------------- #> 2      | 1      |       0.60 | [0.16,  2.20] | 0.443 #> 3      | 1      |       1.65 | [0.58,  4.71] | 0.345 #> 3      | 2      |       2.75 | [0.70, 10.78] | 0.147 #>  #> Variable predicted: outcome #> Predictors contrasted: x1 #> Predictors averaged: x2 (10), x3 #> p-values are uncorrected. #> Contrasts are on the link-scale."},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_4.html","id":"contrasts-and-comparisons-for-zero-inflation-models","dir":"Articles","previous_headings":"","what":"Contrasts and comparisons for Zero-Inflation Models","title":"Contrasts and comparisons for zero-inflation models","text":"Lastly, show example models zero-inflation component.","code":""},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_4.html","id":"what-is-a-zero-inflated-model","dir":"Articles","previous_headings":"Contrasts and comparisons for Zero-Inflation Models","what":"What is a zero-inflated model?","title":"Contrasts and comparisons for zero-inflation models","text":"zero-inflated model statistical approach used dealing count data excessive number zero values. Imagine counting something can zero, like number customers store gets day, happens lot zeros data typical count model (e.g., Poisson regression) expect. ’s need zero-inflated regression models. models consider two ways zeros can happen: True Zeros: days store naturally closed, maybe ’s just demand product. Counting Zeros: days store open just happens get customers. Maybe ’s bad luck, random fluctuation. model treats differently. uses one part (zero-inflation component, logistic regression) predict probability true zero, based things make store less likely open . uses another part (conditional, count component, count regression) predict number customers days store actually open, considering factors like weather discounts. Consequently, regression models usually two parts formula, (depending package) separate formulas count zero-inflation components. Adjusted predictions can calculated parts, contrasts comparisons can calculated parts, .","code":""},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_4.html","id":"how-to-choose-predictors-for-zero-inflation-models","dir":"Articles","previous_headings":"Contrasts and comparisons for Zero-Inflation Models","what":"How to choose predictors for zero-inflation models?","title":"Contrasts and comparisons for zero-inflation models","text":"two model parts necessarily need use predictors. Therefore, always straightforward find predictors can used zero-inflation model. Think excess zeros data. true zeros (inherently counts) due limitations (measurement limitations, biological process, …)? Choose variables explain data points zero counts even conditions might allow count. instance, modeling customer complaints, store location remote area might predict zero complaints due fewer customers.","code":""},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_4.html","id":"zero-inflation-models-using-the-glmmtmb-package","dir":"Articles","previous_headings":"","what":"Zero-inflation models using the glmmTMB package","title":"Contrasts and comparisons for zero-inflation models","text":"following example, use Salamanders dataset glmmTMB package.fit zero-inflated Poisson regression model data, mined predictor variable. Adjusted predictions using estimate_means() can made different model components: conditional, count component, predicts average count salamanders. Depending model-class (.e. package used fit model), use predict = \"conditional\" (e.g., package glmmTMB) predict = \"count\" (e.g., package pscl). return predicted mean count component , conditional mean (average counts) response “counting zeros”. take account probability “true zeros”. full model, predicts average count response, including zero-inflation component. return expected value response average observation, can “true zero” “count zero”. default, uses predict = \"response\". example, use option want predict average number customers per week, including days store closed. zero-inflation probabilities, predicts probabilities whether observation “true zero” . , option depends model-class. Use option like predict = \"zprob\" predict = \"zero\". predictions related zero-inflation component model.","code":"library(modelbased) library(glmmTMB)  data(Salamanders) m <- glmmTMB(count ~ mined + (1 | site),   ziformula = ~mined,   family = poisson(),   data = Salamanders )"},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_4.html","id":"contrasts-and-comparisons-for-the-conditional-model","dir":"Articles","previous_headings":"Zero-inflation models using the glmmTMB package","what":"Contrasts and comparisons for the conditional model","title":"Contrasts and comparisons for zero-inflation models","text":"start conditional mean. zero-inflated models, conditional mean predicted using predict = \"conditional\". average count response, excluding zero-inflation component.","code":"# predicting the conditional mean estimate_means(m, \"mined\", predict = \"conditional\") #> Estimated Marginal Means #>  #> mined | Mean |   SE |       95% CI |     z #> ------------------------------------------ #> yes   | 1.12 | 0.26 | [0.61, 1.63] |  4.29 #> no    | 3.51 | 0.32 | [2.89, 4.14] | 11.00 #>  #> Variable predicted: count #> Predictors modulated: mined #> Predictors averaged: site #> Predictions are on the conditional-scale.  estimate_contrasts(m, \"mined\", predict = \"conditional\") #> Marginal Contrasts Analysis #>  #> Level1 | Level2 | Difference |   SE |       95% CI |    z |      p #> ------------------------------------------------------------------ #> no     | yes    |       2.39 | 0.40 | [1.60, 3.18] | 5.93 | < .001 #>  #> Variable predicted: count #> Predictors contrasted: mined #> Predictors averaged: site #> p-values are uncorrected. #> Contrasts are on the conditional-scale."},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_4.html","id":"contrasts-and-comparisons-for-the-full-model","dir":"Articles","previous_headings":"Zero-inflation models using the glmmTMB package","what":"Contrasts and comparisons for the full model","title":"Contrasts and comparisons for zero-inflation models","text":"default, adjusted predictions returned full model, .e. average expected count response, including zero-inflation component.","code":"# predicting the expected value of the response estimate_means(m, \"mined\") #> Estimated Marginal Means #>  #> mined | Mean |   SE |       95% CI |     z #> ------------------------------------------ #> yes   | 0.27 | 0.05 | [0.17, 0.37] |  5.47 #> no    | 2.27 | 0.22 | [1.83, 2.70] | 10.19 #>  #> Variable predicted: count #> Predictors modulated: mined #> Predictors averaged: site #> Predictions are on the response-scale.  estimate_contrasts(m, \"mined\") #> Marginal Contrasts Analysis #>  #> Level1 | Level2 | Difference |   SE |       95% CI |    z |      p #> ------------------------------------------------------------------ #> no     | yes    |       1.99 | 0.23 | [1.55, 2.44] | 8.78 | < .001 #>  #> Variable predicted: count #> Predictors contrasted: mined #> Predictors averaged: site #> p-values are uncorrected. #> Contrasts are on the response-scale."},{"path":"https://easystats.github.io/modelbased/articles/introduction_comparisons_4.html","id":"contrasts-and-comparisons-for-the-zero-inflation-probabilities","dir":"Articles","previous_headings":"Zero-inflation models using the glmmTMB package","what":"Contrasts and comparisons for the zero-inflation probabilities","title":"Contrasts and comparisons for zero-inflation models","text":"’re interested probabilities “true zero” , use predict = \"zprob\".","code":"# predicting the zero-inflation probabilities estimate_means(m, \"mined\", predict = \"zprob\") #> Estimated Marginal Means #>  #> mined | Probability |   SE |       95% CI |     z #> ------------------------------------------------- #> yes   |        0.76 | 0.04 | [0.67, 0.84] | 17.54 #> no    |        0.36 | 0.03 | [0.30, 0.41] | 12.75 #>  #> Variable predicted: count #> Predictors modulated: mined #> Predictors averaged: site #> Predictions are on the zprob-scale.  estimate_contrasts(m, \"mined\", predict = \"zprob\") #> Marginal Contrasts Analysis #>  #> Level1 | Level2 | Difference |   SE |         95% CI |     z |      p #> --------------------------------------------------------------------- #> no     | yes    |      -0.40 | 0.05 | [-0.50, -0.30] | -7.92 | < .001 #>  #> Variable predicted: count #> Predictors contrasted: mined #> Predictors averaged: site #> p-values are uncorrected. #> Contrasts are on the zprob-scale (in %-points)."},{"path":"https://easystats.github.io/modelbased/articles/mixed_models.html","id":"estimated-marginal-means-in-mixed-effects-models-navigating-conditional-and-marginal-effects","dir":"Articles","previous_headings":"","what":"Estimated Marginal Means in Mixed Effects Models: Navigating Conditional and Marginal Effects","title":"Mixed effects models","text":"Mixed models, ability account hierarchical clustered data, offer powerful tools understanding complex relationships. key aspect interpreting models understanding estimated marginal means (EMMs), represent predicted outcome specific groups conditions, holding variables constant. However, calculating EMMs mixed models always straightforward, results can vary depending approach taken. One crucial distinction conditional marginal predictions (effects). Conditional predictions specific particular level random effect (e.g., predicted outcome specific individual study). Marginal predictions, hand, average random effects, providing overall estimate effect population. crucial difference, marginal effect often quantity interest want generalize population (Heiss 2022). Based definitions Heiss (2022), can say: conditional vs. marginal distinction applies sort hierarchical structure multilevel models: Conditional effect = effect variable average cluster (.e., group-specific, subject-specific cluster-specific effect, average typical cluster) Marginal effect = effect variable across clusters average (.e., global/population-level effect, clusters average). working mixed models, modelbased package offers flexibility calculating EMMs different backends. \"marginaleffects\" backend \"emmeans\" backend employ different underlying methodologies. marginaleffects typically focuses marginal predictions averaging random effects, emmeans provides conditional predictions. Consequently, EMMs obtained using two backends may differ. see, conditional marginal predictions fixed effects focal predictors… … usually similar linear mixed models … usually different generalized linear mixed models … usually different linear generalized linear models, data “imbalanced” “average” predictions requested (.e., estimate = \"average\"); imbalanced mean equally distributed levels. Note: request unit-level predictions - , predictions specific individual levels random effects (achieved including random effect variables ) - conditional marginal predictions also differ linear mixed models. delve unit-level predictions vignette. essence, choice backend understanding whether looking conditional marginal predictions critical correctly interpreting results mixed models. Carefully considering research question nature random effects guide selection appropriate approach. Technical Notes: backend = \"marginaleffects\", re.form argument set NULL mixed models default, calculate marginal predictions. can use instance re.form = NA estimate_means() call change default value (NA produce conditional predictions). default, backends calculate predictions balanced data grid representing combinations focal predictor levels (specified ). represents “typical” observation based data grid useful comparing groups. Setting estimate = \"average\" can useful calculate average expected outcome observations sample hand, however, option available backend = \"marginaleffects\". vignette shows examples demonstrate results similar differ.","code":""},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/mixed_models.html","id":"balanced-data","dir":"Articles","previous_headings":"Linear mixed models","what":"Balanced Data","title":"Mixed effects models","text":"section demonstrates calculation estimated marginal means (EMMs) linear mixed model using balanced data. ’ll use sleepstudy dataset lme4 package. example, fit linear mixed model predicting Reaction based Days, random intercepts slopes Subject. calculate EMMs Days using default \"marginaleffects\" backend \"emmeans\" backend. data balanced linear, results similar (exception: find small differences confidence intervals, ignore now…). , calculate marginal predictions Days variable using estimate = \"average\" argument. case, model linear data balanced, predictions previous results, .e., averaging across observations makes difference .","code":"library(modelbased) data(sleepstudy, package = \"lme4\") # for later, create a slightly imbalanced distributed predictor set.seed(1234) sleepstudy$x <- as.factor(sample.int(3, nrow(sleepstudy), replace = TRUE))  model <- lme4::lmer(Reaction ~ Days + (1 + Days | Subject), data = sleepstudy)  # default, marginaleffects backend (marginal predictions) # in this case, same result as for conditional predictions estimate_means(model, \"Days\") #> Estimated Marginal Means #>  #> Days |               Mean (CI) #> ------------------------------ #> 0    | 251.41 (237.94, 264.87) #> 1    | 261.87 (248.48, 275.27) #> 2    | 272.34 (258.34, 286.34) #> 3    | 282.81 (267.60, 298.02) #> 4    | 293.27 (276.39, 310.16) #> 5    | 303.74 (284.83, 322.65) #> 6    | 314.21 (293.03, 335.39) #> 7    | 324.68 (301.05, 348.31) #> 8    | 335.14 (308.94, 361.35) #> 9    | 345.61 (316.74, 374.48) #>  #> Variable predicted: Reaction #> Predictors modulated: Days #> Predictors averaged: Subject  # emmeans backend, always conditional predictions estimate_means(model, \"Days\", backend = \"emmeans\") #> Estimated Marginal Means #>  #> Days |               Mean (CI) #> ------------------------------ #> 0    | 251.41 (237.01, 265.80) #> 1    | 261.87 (247.55, 276.19) #> 2    | 272.34 (257.37, 287.31) #> 3    | 282.81 (266.55, 299.06) #> 4    | 293.27 (275.22, 311.32) #> 5    | 303.74 (283.53, 323.96) #> 6    | 314.21 (291.57, 336.85) #> 7    | 324.68 (299.42, 349.94) #> 8    | 335.14 (307.13, 363.16) #> 9    | 345.61 (314.75, 376.47) #>  #> Variable predicted: Reaction #> Predictors modulated: Days # marginal predictions, averaged across all observations, # same as conditional predictions above estimate_means(model, \"Days\", estimate = \"average\") #> Average Predictions #>  #> Days |               Mean (CI) #> ------------------------------ #> 0    | 251.41 (237.94, 264.87) #> 1    | 261.87 (248.48, 275.27) #> 2    | 272.34 (258.34, 286.34) #> 3    | 282.81 (267.60, 298.02) #> 4    | 293.27 (276.39, 310.16) #> 5    | 303.74 (284.83, 322.65) #> 6    | 314.21 (293.03, 335.39) #> 7    | 324.68 (301.05, 348.31) #> 8    | 335.14 (308.94, 361.35) #> 9    | 345.61 (316.74, 374.48) #>  #> Variable predicted: Reaction #> Predictors modulated: Days"},{"path":"https://easystats.github.io/modelbased/articles/mixed_models.html","id":"imbalanced-data","dir":"Articles","previous_headings":"Linear mixed models","what":"Imbalanced Data","title":"Mixed effects models","text":"section explores impact imbalanced data EMM calculations linear mixed models. ’ll use penguins dataset, imbalanced groups use higher-level unit, well imbalanced predictors. Since still linear mixed model, marginal conditional predictions still similar. Since imbalanced data, results “average” predictions differ results , \"emmeans\" backend default estimate setting \"marginaleffects\" backend produce “data grid based” predictions, average across observations (see also documentation estimate argument details). Furthermore, imbalanced data, conditional marginal predictions differ averaged across observations.","code":"data(penguins, package = \"palmerpenguins\") model <- lme4::lmer(bill_length_mm ~ sex + island + (1 | species), data = penguins)  # marginal predictions estimate_means(model, \"sex\") #> Estimated Marginal Means #>  #> sex    |            Mean (CI) #> ----------------------------- #> female | 43.29 (37.00, 49.58) #> male   | 46.99 (40.70, 53.28) #>  #> Variable predicted: bill_length_mm #> Predictors modulated: sex #> Predictors averaged: island, species  # conditional predictions estimate_means(model, \"sex\", backend = \"emmeans\") #> Estimated Marginal Means #>  #> sex    |            Mean (CI) #> ----------------------------- #> female | 43.29 (29.54, 57.04) #> male   | 46.99 (33.24, 60.74) #>  #> Variable predicted: bill_length_mm #> Predictors modulated: sex # average marginal predictions estimate_means(model, \"sex\", estimate = \"average\") #> Average Predictions #>  #> sex    |            Mean (CI) #> ----------------------------- #> female | 42.10 (35.81, 48.39) #> male   | 45.85 (39.57, 52.14) #>  #> Variable predicted: bill_length_mm #> Predictors modulated: sex  # average conditional predictions estimate_means(model, \"sex\", estimate = \"average\", re.form = NA) #> Average Predictions #>  #> sex    |            Mean (CI) #> ----------------------------- #> female | 43.26 (36.97, 49.54) #> male   | 46.95 (40.66, 53.24) #>  #> Variable predicted: bill_length_mm #> Predictors modulated: sex"},{"path":"https://easystats.github.io/modelbased/articles/mixed_models.html","id":"generalized-linear-mixed-models","dir":"Articles","previous_headings":"","what":"Generalized linear mixed models","title":"Mixed effects models","text":"generalized linear mixed model (GLMM) example, using Poisson distribution model fish counts, demonstrates substantial differences marginal conditional predictions non-linear models. examining effect camper variable, marginal predictions yield higher estimated means (1.26 camper = 0 3.21 camper = 1) compared conditional predictions (using re.form = NA \"emmeans\" backend), lower (0.66 camper = 0 1.68 camper = 1). Furthermore, using estimate = \"average\" average across observations, differences marginal conditional predictions persist, marginal predictions showing higher means (1.52 4.54) conditional predictions (1.20 3.19), results differ predictions “typical” observations based default estimate option (\"emmeans\" backend), shown previous output. highlights GLMMs, choice marginal conditional predictions significantly impacts estimated means , consequently, interpretation model’s results. case, marginal predictions higher conditional predictions.","code":"data(\"fish\", package = \"insight\") model <- lme4::glmer(   count ~ child + camper + (1 | persons),   data = fish,   family = poisson() )  # marginal predictions estimate_means(model, \"camper\") #> Estimated Marginal Means #>  #> camper |          Mean (CI) #> --------------------------- #> 0      | 1.26 (-0.28, 2.79) #> 1      | 3.21 (-0.68, 7.10) #>  #> Variable predicted: count #> Predictors modulated: camper #> Predictors averaged: child (0.68), persons (1) #> Predictions are on the response-scale.  # conditional predictions estimate_means(model, \"camper\", re.form = NA) #> Estimated Marginal Means #>  #> camper |          Mean (CI) #> --------------------------- #> 0      | 0.66 (-0.14, 1.46) #> 1      | 1.68 (-0.36, 3.71) #>  #> Variable predicted: count #> Predictors modulated: camper #> Predictors averaged: child (0.68), persons (1) #> Predictions are on the response-scale.  # conditional predictions estimate_means(model, \"camper\", backend = \"emmeans\") #> Estimated Marginal Means #>  #> camper |         Rate (CI) | Rate #> --------------------------------- #> 0      | 0.66 (0.19, 2.23) | 0.66 #> 1      | 1.68 (0.50, 5.64) | 1.68 #>  #> Variable predicted: count #> Predictors modulated: camper #> Predictions are on the response-scale. # average marginal predictions estimate_means(model, \"camper\", estimate = \"average\") #> Average Predictions #>  #> camper |           Mean (CI) #> ---------------------------- #> 0      | 1.52 (-0.33,  3.38) #> 1      | 4.54 (-0.95, 10.03) #>  #> Variable predicted: count #> Predictors modulated: camper #> Predictions are on the response-scale.  # average conditional predictions estimate_means(model, \"camper\", estimate = \"average\", re.form = NA) #> Average Predictions #>  #> camper |          Mean (CI) #> --------------------------- #> 0      | 1.20 (-0.26, 2.66) #> 1      | 3.19 (-0.67, 7.04) #>  #> Variable predicted: count #> Predictors modulated: camper #> Predictions are on the response-scale."},{"path":"https://easystats.github.io/modelbased/articles/mixed_models.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Mixed effects models","text":"vignette demonstrated nuances calculating estimated marginal means (EMMs) mixed models, highlighting critical distinction conditional marginal predictions. conditional predictions focus specific levels random effects, marginal predictions average , providing population-level perspective. ’ve seen linear mixed models balanced data, two approaches often yield similar results. However, generalized linear mixed models (GLMMs), differences conditional marginal predictions can substantial. Furthermore, default approach calculating predictions balanced data grid, useful comparing groups, necessarily reflect actual distribution observations sample. imbalanced data, can yield significantly different results even linear mixed models comparison average predictions (using estimate = \"average\"). Therefore, recommend combining marginal predictions (using default backend = \"marginaleffects\") averaging across observations (setting estimate = \"average\") working mixed models. approach effectively incorporates variation inherent random effects (higher-level units) provides EMMs accurately reflect overall patterns observed within actual sample data. averaging observed data, obtain robust representative estimate population-level effects, making preferred strategy interpreting mixed model results.","code":""},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/modelisation_approach.html","id":"the-empirical-approach-classic","dir":"Articles","previous_headings":"","what":"The Empirical Approach (Classic)","title":"The Modelisation Approach","text":"","code":"library(easystats) library(emmeans) library(ggplot2)"},{"path":"https://easystats.github.io/modelbased/articles/modelisation_approach.html","id":"data-simulation","dir":"Articles","previous_headings":"The Empirical Approach (Classic)","what":"Data Simulation","title":"The Modelisation Approach","text":"First run function simulate data. ’s need understand hows whys, explain everything due time.","code":"generate_data <- function(effect = 5, noise = 0.5) {   data <- data.frame()   n <- 100   for (i in 1:length(effect)) {     participant <- data.frame(Experimental_Variable = c(seq(-3, 3, length = n / 2), seq(-3, 3, length = n / 2)))     participant$RT <- c(participant$Experimental_Variable[1:(n / 2)]**2 - effect[i], (participant$Experimental_Variable[(n / 2 + 1):n] + effect[i])) + rnorm(n, 0, abs(noise[i]))     participant$Condition <- rep(c(\"A\", \"B\"), each = n / 2)     participant$Participant <- paste0(\"S\", i)     data <- rbind(data, participant)   }   data$RT <- (100 + data$RT) * 10   data }  data <- generate_data(effect = rnorm(30, 2, 2), noise = rnorm(30, 0, 0.4)) # # library(rtdists) # # data <- data.frame( #   Participant = paste0(\"S\", speed_acc$id), #   Item = as.numeric(speed_acc$stim), #   Condition = speed_acc$condition, #   Correct = ifelse(as.character(speed_acc$stim_cat) == as.character(speed_acc$response), 1, 0), #   RT = speed_acc$rt * 1000 # )"},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/modelisation_approach.html","id":"anovas","dir":"Articles","previous_headings":"The Empirical Approach (Classic)","what":"ANOVAs","title":"The Modelisation Approach","text":"ANOVAs, ’s groups. Even though people also add continuous variables (creating ANCOVAs, MANOVAs monstrosities), ’s really “spirit”: ANOVAs made compare groups. take, participant, 20… can conclude ? Absolutely nothing! need investigate details, instance running post-hoc comparison tests. uninformativeness one reason ANOVA banned psychological science.","code":"data_anova <- data data_anova$Category <- recode_into(   Experimental_Variable < -1.5 ~ \"Low\",   Experimental_Variable > 1.5 ~ \"High\",   default = \"Middle\",   data = data_anova ) data_anova$Category <- factor(data_anova$Category, levels = c(\"Low\", \"Middle\", \"High\"))  data_anova <<- data_anova |>   data_group(c(\"Participant\", \"Condition\", \"Category\")) |>   data_summary(RT = mean(RT))  results <- aov(RT ~ Condition * Category + Error(Participant), data = data_anova) parameters(results) > # Participant >  > Parameter | Sum_Squares | df | Mean_Square > ------------------------------------------ > Residuals |       33.32 | 29 |        1.15 >  > # Within >  > Parameter          | Sum_Squares |  df | Mean_Square |     F |      p > --------------------------------------------------------------------- > Condition          |       73.09 |   1 |       73.09 |  0.14 | 0.705  > Category           |    37375.24 |   2 |    18687.62 | 36.84 | < .001 > Condition:Category |    36990.41 |   2 |    18495.20 | 36.46 | < .001 > Residuals          |    73550.75 | 145 |      507.25 |       |        >  > Anova Table (Type 1 tests)"},{"path":"https://easystats.github.io/modelbased/articles/modelisation_approach.html","id":"post-hoc-comparison-tests","dir":"Articles","previous_headings":"The Empirical Approach (Classic)","what":"Post-hoc comparison tests","title":"The Modelisation Approach","text":"","code":"posthoc <- get_emmeans(results, by = c(\"Condition\", \"Category\")) |>   pairs() parameters(posthoc) > contrast            | Coefficient |   SE |           95% CI | t(145) |      p > ----------------------------------------------------------------------------- > A Low - B Low       |       36.83 | 5.82 | [ 25.33,  48.32] |   6.33 | < .001 > A Low - A Middle    |       46.52 | 5.82 | [ 35.02,  58.01] |   8.00 | < .001 > A Low - B Middle    |       14.18 | 5.82 | [  2.69,  25.67] |   2.44 | 0.491  > A Low - A High      |       -0.23 | 5.82 | [-11.73,  11.26] |  -0.04 | > .999 > A Low - B High      |       -8.54 | 5.82 | [-20.04,   2.95] |  -1.47 | 0.979  > B Low - A Middle    |        9.69 | 5.82 | [ -1.80,  21.18] |   1.67 | 0.940  > B Low - B Middle    |      -22.65 | 5.82 | [-34.14, -11.15] |  -3.89 | 0.012  > B Low - A High      |      -37.06 | 5.82 | [-48.55, -25.56] |  -6.37 | < .001 > B Low - B High      |      -45.37 | 5.82 | [-56.86, -33.87] |  -7.80 | < .001 > A Middle - B Middle |      -32.34 | 5.82 | [-43.83, -20.84] |  -5.56 | < .001 > A Middle - A High   |      -46.75 | 5.82 | [-58.24, -35.25] |  -8.04 | < .001 > A Middle - B High   |      -55.06 | 5.82 | [-66.55, -43.57] |  -9.47 | < .001 > B Middle - A High   |      -14.41 | 5.82 | [-25.90,  -2.92] |  -2.48 | 0.463  > B Middle - B High   |      -22.72 | 5.82 | [-34.21, -11.23] |  -3.91 | 0.012  > A High - B High     |       -8.31 | 5.82 | [-19.80,   3.18] |  -1.43 | 0.983  >  > p-value adjustment method: Tukey data_anova |>   ggplot(aes(x = Category, y = RT, fill = Condition)) +   geom_boxplot() +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/articles/modelisation_approach.html","id":"the-modelisation-approach","dir":"Articles","previous_headings":"","what":"The Modelisation Approach","title":"The Modelisation Approach","text":"model made parameters, ‘real’ meaning, opposed indices significance (abstract).","code":""},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/modelisation_approach.html","id":"draw-what-you-want-to-visualize","dir":"Articles","previous_headings":"The Modelisation Approach","what":"1. Draw what you want to visualize","title":"The Modelisation Approach","text":"can use geom_smooth(), can fit non-linear relationships empirical way, give us idea shape relationships.","code":"data |>   data_group(c(\"Participant\", \"Condition\")) |>   ggplot(aes(x = Experimental_Variable, y = RT, color = Condition)) +   geom_jitter(alpha = 0.4) +   geom_smooth(method = \"loess\", se = FALSE) +   theme_minimal()"},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/overview_of_vignettes.html","id":"function-overview","dir":"Articles","previous_headings":"","what":"Function Overview","title":"Overview of Vignettes","text":"Function Documentation","code":""},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/overview_of_vignettes.html","id":"basics","dir":"Articles","previous_headings":"Introductions","what":"Basics","title":"Overview of Vignettes","text":"Data grids , use get marginal means Contrast analysis Marginal effects derivatives Mixed effects models","code":""},{"path":"https://easystats.github.io/modelbased/articles/overview_of_vignettes.html","id":"interpretation","dir":"Articles","previous_headings":"Introductions","what":"Interpretation","title":"Overview of Vignettes","text":"Use model make predictions Interpret simple complex models using power Effect Derivatives use Mixed models Estimate Individuals’ Scores","code":""},{"path":"https://easystats.github.io/modelbased/articles/overview_of_vignettes.html","id":"visualization","dir":"Articles","previous_headings":"Introductions","what":"Visualization","title":"Overview of Vignettes","text":"Plotting estimated marginal means Visualize effects interactions Modelisation Approach Statistics","code":""},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/overview_of_vignettes.html","id":"workflows","dir":"Articles","previous_headings":"Case Studies","what":"Workflows","title":"Overview of Vignettes","text":"Understanding models Causal inference observational data Intersectionality analysis using MAIHDA framework","code":""},{"path":"https://easystats.github.io/modelbased/articles/overview_of_vignettes.html","id":"contrasts","dir":"Articles","previous_headings":"Case Studies","what":"Contrasts","title":"Overview of Vignettes","text":"Contrasts pairwise comparisons Slopes, floodlight spotlight analysis (Johnson-Neyman intervals) Contrasts comparisons generalized linear models Contrasts comparisons zero-inflation models","code":""},{"path":"https://easystats.github.io/modelbased/articles/plotting.html","id":"one-predictor---categorical","dir":"Articles","previous_headings":"","what":"One predictor - categorical","title":"Plotting estimated marginal means","text":"simplest case possibly plotting one categorical predictor. Predicted values level confidence intervals shown.","code":"library(modelbased) data(efc, package = \"modelbased\") efc <- datawizard::to_factor(efc, c(\"e16sex\", \"c172code\", \"e42dep\"))  m <- lm(neg_c_7 ~ e16sex + c172code + barthtot, data = efc) estimate_means(m, \"c172code\") |> plot()"},{"path":"https://easystats.github.io/modelbased/articles/plotting.html","id":"one-predictor---numeric","dir":"Articles","previous_headings":"","what":"One predictor - numeric","title":"Plotting estimated marginal means","text":"numeric predictors, range predictions different values focal predictor plotted, uncertainty displayed confidence band.","code":"estimate_means(m, \"barthtot\") |> plot()"},{"path":"https://easystats.github.io/modelbased/articles/plotting.html","id":"two-predictors---categorical","dir":"Articles","previous_headings":"","what":"Two predictors - categorical","title":"Plotting estimated marginal means","text":"two categorical predictors, first focal predictors plotted along x-axis, levels second predictor mapped different colors.","code":"m <- lm(neg_c_7 ~ e16sex * c172code + e42dep, data = efc) estimate_means(m, c(\"e16sex\", \"c172code\")) |> plot()"},{"path":"https://easystats.github.io/modelbased/articles/plotting.html","id":"two-predictors---numeric-categorical","dir":"Articles","previous_headings":"","what":"Two predictors - numeric * categorical","title":"Plotting estimated marginal means","text":"two predictors, first numeric second categorical, range predictions including confidence bands shown, different levels second (categorical) predictor mapped colors .  general, plots can modified using functions ggplot2 package. Thereby, themes, color scales, faceting , can applies.","code":"m <- lm(neg_c_7 ~ barthtot * c172code + e42dep, data = efc) estimate_means(m, c(\"barthtot\", \"c172code\")) |> plot() library(ggplot2) estimate_means(m, c(\"barthtot\", \"c172code\")) |>   plot() +   see::theme_modern(show.ticks = TRUE) estimate_means(m, c(\"barthtot\", \"c172code\")) |>   plot() +   facet_grid(~c172code) estimate_means(m, c(\"barthtot\", \"c172code\")) |>   plot() +   scale_color_brewer(palette = \"Dark2\") +   scale_fill_brewer(palette = \"Dark2\")"},{"path":"https://easystats.github.io/modelbased/articles/plotting.html","id":"two-predictors---categorical-numeric","dir":"Articles","previous_headings":"","what":"Two predictors - categorical * numeric","title":"Plotting estimated marginal means","text":"numeric predictor second focal term, values still mapped colors, however, default continuous (gradient) scale, range representative values numeric predictor used default. Focal predictors specified estimate_means() passed insight::get_datagrid(). specified otherwise, representative values numeric predictors evenly distributed minimum maximum, total number length values covering range. .e., default, arguments range = \"range\" length = 10 insight::get_datagrid(), thus numeric predictors, range length values used estimate predictions.  means length argument can used control many values (lines) numeric predictors chosen.  Another option use range = \"grid\", case mean +/- one standard deviation around mean chosen representative values numeric predictors.  also possible specify representative values, estimated marginal means outcome plotted. , consult documentation ?ìnsight::get_datagrid details.","code":"# by default, `range = \"range\"` and `length = 10` estimate_means(m, c(\"c172code\", \"barthtot\")) |> plot() estimate_means(m, c(\"c172code\", \"barthtot\"), length = 20) |> plot() estimate_means(m, c(\"c172code\", \"barthtot\"), range = \"grid\") |> plot() estimate_means(   m,   c(     \"c172code = c('low level of education', 'high level of education')\",     \"barthtot = c(30, 50, 80)\"   ) ) |> plot() estimate_means(m, c(\"c172code\", \"barthtot = [fivenum]\")) |> plot()"},{"path":"https://easystats.github.io/modelbased/articles/plotting.html","id":"three-numeric-predictors","dir":"Articles","previous_headings":"","what":"Three numeric predictors","title":"Plotting estimated marginal means","text":"default plot-setting three numeric predictors can rather confusing.  Instead, recommended use length, create “reference grid”, specify meaningful values directly argument.","code":"m <- lm(neg_c_7 ~ c12hour * barthtot * c160age, data = efc) estimate_means(m, c(\"c12hour\", \"barthtot\", \"c160age\")) |> plot() estimate_means(m, c(\"c12hour\", \"barthtot\", \"c160age\"), length = 2) |> plot() estimate_means(m, c(\"c12hour\", \"barthtot\", \"c160age\"), range = \"grid\") |> plot()"},{"path":"https://easystats.github.io/modelbased/articles/plotting.html","id":"three-categorical-predictors","dir":"Articles","previous_headings":"","what":"Three categorical predictors","title":"Plotting estimated marginal means","text":"Multiple categorical predictors usually less problematic, since discrete color scales faceting used distinguish factor levels.","code":"m <- lm(neg_c_7 ~ e16sex * c172code * e42dep, data = efc) estimate_means(m, c(\"e16sex\", \"c172code\", \"e42dep\")) |> plot()"},{"path":"https://easystats.github.io/modelbased/articles/plotting.html","id":"smooth-plots","dir":"Articles","previous_headings":"","what":"Smooth plots","title":"Plotting estimated marginal means","text":"Remember default range ten values chosen numeric focal predictors. mostly works well plotting linear relationships, plots may look less smooth certain models involve quadratic cubic terms, splines, instance GAMs.  case, simply increase number representative values setting length higher number.","code":"m <- lm(neg_c_7 ~ e16sex * c12hour + e16sex * I(c12hour^2), data = efc) estimate_means(m, c(\"c12hour\", \"e16sex\")) |> plot() estimate_means(m, c(\"c12hour\", \"e16sex\"), length = 200) |> plot()"},{"path":"https://easystats.github.io/modelbased/articles/practical_causality.html","id":"the-lack-of-randomization","dir":"Articles","previous_headings":"","what":"The lack of randomization","title":"Case Study: Causal inference for observational data using modelbased","text":"Randomized controlled trials (RCTs) frequently employed estimate average treatment effect (ATE), represents average difference outcomes individuals treatment control groups (.e., outcome differ, average, participants treated versus participants treated). context RCTs, ATE can interpreted causal effect. Estimating causal effects observational data, treatment control group assignments randomized, presents greater challenge due potential confounding bias. observational studies, individual characteristics associated outcome (e.g., age, gender, education, health status) likely unequally distributed treatment control groups. imbalance violates key assumption causal effect estimation, assumption typically satisfied randomization RCTs often unmet observational data.","code":""},{"path":"https://easystats.github.io/modelbased/articles/practical_causality.html","id":"propensity-scores-and-g-computation","dir":"Articles","previous_headings":"","what":"Propensity scores and G-computation","title":"Case Study: Causal inference for observational data using modelbased","text":"Two primary methods exist addressing lack randomization observational data: propensity scores g-computation. Regarding propensity scores, vignette focuses inverse probability weighting (IPW), common technique estimating propensity scores (Chatton Rohrer 2024; Gabriel et al. 2024). established techniques involve matching (Ho et al. 2005), , however, beyond scope discussion. IPW assigns weights individual observations reflect contribution outcome assumption exchangeability groups. specific characteristics -represented treatment group, IPW assigns lower weights individuals, thereby adjusting imbalanced distribution confounders treatment control groups. G-computation, rooted traditional methods stratification standardization, addresses confounding observational studies partitioning study population strata, calculating stratum-specific outcomes, weighting outcomes represent target population (e.g., general population). modelbased, g-computation can implemented setting estimate = \"population\". approach directly models counterfactual scenarios creating copies observation, effectively assigning individual treatment control conditions. final estimate derived averaging predictions across counterfactual observations (Dickerman Hernán 2020). propensity score g-computation methods offer distinct advantages disadvantages. IPW, instance, can directly incorporated weights within regression models, facilitating straightforward interpretation treatment coefficient average treatment effect (ATE). However, deriving ATE becomes complex models incorporating interaction terms complexities. Conversely, modelbased g-computation readily estimates ATE even within complex model specifications. robust approach often involves combining IPW g-computation achieve “doubly robust” estimation ATE (Chatton Rohrer 2024; Gabriel et al. 2024). Illustrative examples follow.","code":""},{"path":"https://easystats.github.io/modelbased/articles/practical_causality.html","id":"calculating-inverse-probability-weights","dir":"Articles","previous_headings":"","what":"Calculating inverse probability weights","title":"Case Study: Causal inference for observational data using modelbased","text":"First, create toy data treatment effect roughly 9 points higher effect control group. example data set health related quality life QoL outcome, measured 188 cancer patient three time points (baseline, two follow-ups). treatment variable simulated part original data set. Since repeated measurements, use glmmTMB package fit linear mixed model data. first look simple effect treatment, 9.3. Next, inverse probability weights calculated. involves employing regression model predictor interest, treatment, outcome variable. model estimates probability observed confounder variables given treatment assignment. binary predictors, treatment variable analysis, logistic regression model utilized. Potential confounders serve independent variables model, generating predicted probabilities observation’s membership either treatment control group. Based probabilities, IPW calculated.","code":"# example library(modelbased) library(datawizard) library(parameters) data(qol_cancer, package = \"parameters\")  # sort and group data by patient ID, then assign each patient either to # the treatment or control condition, with higher educated patients having # a higher chance belonging to the treatment group set.seed(1234) d <- qol_cancer |>   data_arrange(\"ID\") |>   data_group(\"ID\") |>   data_modify(treatment = rbinom(1, 1, ifelse(education == \"high\", 0.7, 0.4))) |>   data_ungroup()  # create a treatment effect that increased over time # with more improvements for higher educated patients d$QoL <- d$QoL + rnorm(   nrow(d),   (d$treatment * d$time * 5) + ifelse(d$education == \"high\", 5, 0),   sd = 2 )  # convert to factors d <- to_factor(d, c(\"treatment\", \"time\")) # simple pooled effect m1 <- glmmTMB::glmmTMB(   QoL ~ treatment + time + education + hospital + age + phq4 + (1 | ID),   data = d )  # we don't need the full summary table, # only the coefficient for treatment model_parameters(m1, keep = \"^treatment\") #> # Fixed Effects #>  #> Parameter     | Coefficient |   SE |        95% CI |    z |      p #> ------------------------------------------------------------------ #> treatment [1] |        9.27 | 1.96 | [5.43, 13.11] | 4.73 | < .001 # logistic regression model m_ipw <- glm(   treatment ~ time + hospital + phq4 + education + age,   data = d,   family = binomial() )  # add predictions, i.e. the probability of belonging to treatment # or control for each patient in the sample (propensity score) d$propensity_score <- predict(m_ipw, newdata = d, type = \"response\")  # calculating the IPW d$ipw <- ifelse(   d$treatment == 1,   1 / d$propensity_score, # IPW for treatment group   1 / (1 - d$propensity_score) # IPW for control group )"},{"path":"https://easystats.github.io/modelbased/articles/practical_causality.html","id":"calculating-matching-and-overlap-weights","dir":"Articles","previous_headings":"","what":"Calculating matching and overlap weights","title":"Case Study: Causal inference for observational data using modelbased","text":"IPW may suffer extreme values, certain observations can get high low weights, good match group. Extreme weights can bias estimates increase variance, especially ATE. weights may signal need shift focus overlap population, groups comparable. Two common alternatives IPW overlap weights (OW) matching weights (MW), latter acting weighting analog pair matching (Li Greene 2013; Kostouraki et al. 2024). demonstrate calculation Matching Weights (MW) Overlap Weights (OW) , use Inverse Probability Weighting (IPW) illustrative purposes subsequent examples.","code":"# calculating matching weights d$matching_weights <- ifelse(   d$treatment == 1,   min(d$propensity_score, 1 - d$propensity_score) / d$propensity_score,   min(d$propensity_score, 1 - d$propensity_score) / (1 - d$propensity_score) )  # calculating overlap weights d$overlap_weights <- ifelse(   d$treatment == 1,   1 - d$propensity_score,   d$propensity_score )"},{"path":"https://easystats.github.io/modelbased/articles/practical_causality.html","id":"ate-calculated-from-ipw-in-simpler-models","dir":"Articles","previous_headings":"","what":"ATE calculated from IPW in simpler models","title":"Case Study: Causal inference for observational data using modelbased","text":"Now run model , including weights. see treatment effect, weighting, 9 points, .e. treatment average results 9-point higher score QoL. Given simplicity model, g-computation offers significant advantage calculating contrasts treatment levels, results equivalent simpler approach.","code":"m2 <- glmmTMB::glmmTMB(   QoL ~ treatment + time + education + hospital + age + phq4 + (1 | ID),   weights = ipw,   data = d ) model_parameters(m2, keep = \"^treatment\") #> # Fixed Effects #>  #> Parameter     | Coefficient |   SE |        95% CI |    z |      p #> ------------------------------------------------------------------ #> treatment [1] |        9.04 | 1.99 | [5.13, 12.95] | 4.53 | < .001 estimate_contrasts(m2, \"treatment\", estimate = \"population\") #> Counterfactual Contrasts Analysis (G-computation) #>  #> Level1 | Level2 |    Difference (CI) |      p #> --------------------------------------------- #> 1      | 0      | 9.04 (5.13, 12.95) | <0.001 #>  #> Variable predicted: QoL #> Predictors contrasted: treatment #> Predictors averaged: time, education, hospital (0.95), age (0.22), phq4 (-0.076), ID #> p-values are uncorrected."},{"path":"https://easystats.github.io/modelbased/articles/practical_causality.html","id":"ate-calculated-from-ipw-and-g-computation-in-more-complex-models","dir":"Articles","previous_headings":"","what":"ATE calculated from IPW and g-computation in more complex models","title":"Case Study: Causal inference for observational data using modelbased","text":"However, properly modelled longitudinal nature data. Since patients’ quality life (QoL) measured three distinct time points, allowing examination treatment effects time, need include interaction treatment time. revealed substantially greater increase QoL time within treatment group. complex modeling scenarios, g-computation becomes particularly advantageous.  now see coefficient table longer helpful, treatment effect isolated. want know ATE treatment, need calculate contrasts levels treatment predictor. even complex scenarios, g-computation remains valuable tool generating accurate estimates. example compares “simple” contrasts derived IPW model contrasts generated model using g-computation. results clearly demonstrate increased accuracy achieved combining IPW g-computation situations.","code":"# interaction terms involved m3 <- glmmTMB::glmmTMB(   QoL ~ treatment * time + education + hospital + age + phq4 + (1 | ID),   weights = ipw,   data = d )  # estimated marginal means, to show how treatment # develops over time between treatment and control conditions estimate_means(   m3,   c(\"time\", \"treatment\"),   estimate = \"population\" ) |> plot() # ATE no longer visible from coefficient table model_parameters(m3, keep = \"^treatment\") #> # Fixed Effects #>  #> Parameter                | Coefficient |   SE |         95% CI |    z |      p #> ------------------------------------------------------------------------------ #> treatment [1]            |        4.11 | 2.22 | [-0.24,  8.46] | 1.85 | 0.064  #> treatment [1] × time [2] |        5.05 | 1.64 | [ 1.84,  8.26] | 3.08 | 0.002  #> treatment [1] × time [3] |        9.63 | 1.64 | [ 6.42, 12.84] | 5.88 | < .001  # contrasts of treatment levels, using g-computation estimate_contrasts(m3, \"treatment\", estimate = \"population\") #> Counterfactual Contrasts Analysis (G-computation) #>  #> Level1 | Level2 |    Difference (CI) |      p #> --------------------------------------------- #> 1      | 0      | 9.00 (5.07, 12.94) | <0.001 #>  #> Variable predicted: QoL #> Predictors contrasted: treatment #> Predictors averaged: time, education, hospital (0.95), age (0.22), phq4 (-0.076), ID #> p-values are uncorrected. # more complex model m4 <- glmmTMB::glmmTMB(   QoL ~ treatment * time + treatment * education + hospital + age + phq4 + (1 | ID),   weights = ipw,   data = d )  # complex model, no g-computation estimate_contrasts(m4, \"treatment\") #> Marginal Contrasts Analysis #>  #> Level1 | Level2 |     Difference (CI) |      p #> ---------------------------------------------- #> 1      | 0      | 10.97 (6.70, 15.23) | <0.001 #>  #> Variable predicted: QoL #> Predictors contrasted: treatment #> Predictors averaged: time, education, hospital (0.95), age (0.22), phq4 (-0.076), ID #> p-values are uncorrected.  # complex model, with IPW *and* G-computation (double-robust) is accurate! estimate_contrasts(m4, \"treatment\", estimate = \"population\") #> Counterfactual Contrasts Analysis (G-computation) #>  #> Level1 | Level2 |    Difference (CI) |      p #> --------------------------------------------- #> 1      | 0      | 8.99 (5.10, 12.88) | <0.001 #>  #> Variable predicted: QoL #> Predictors contrasted: treatment #> Predictors averaged: time, education, hospital (0.95), age (0.22), phq4 (-0.076), ID #> p-values are uncorrected."},{"path":"https://easystats.github.io/modelbased/articles/practical_causality.html","id":"average-treatment-effect-on-the-treated-and-untreated","dir":"Articles","previous_headings":"","what":"Average treatment effect on the treated and untreated","title":"Case Study: Causal inference for observational data using modelbased","text":"last example completes “causal inference” topic showing calculate average treatment effect treated (ATT), average treatment effect untreated (ATU). ATT measures much treatment changes outcome already received . can help decide whether program treatment discontinued people currently benefiting . Likewise, ATU estimates much treatment change outcome given didn’t already receive . helps us decide whether program treatment expanded include haven’t yet benefited . helps assess potential benefits extending program treatment wider population.","code":"library(insight)  # we need the data used to fit the model - this may not be # identical to the original data due to case-wise deletion model_data <- get_data(m4)  # the ATT - apply g-computation only to the subset of the treated estimate_contrasts(   m4,   \"treatment\",   newdata = subset(model_data, treatment == 1),   estimate = \"population\" ) #> Counterfactual Contrasts Analysis (G-computation) #>  #> Level1 | Level2 |    Difference (CI) |      p #> --------------------------------------------- #> 1      | 0      | 9.79 (5.42, 14.15) | <0.001 #>  #> Variable predicted: QoL #> Predictors contrasted: treatment #> Predictors averaged: time, education, hospital (0.95), age (0.22), phq4 (-0.076), ID #> p-values are uncorrected.  # the ATU - apply g-computation only to the subset of the conrol estimate_contrasts(   m4,   \"treatment\",   newdata = subset(model_data, treatment == 0),   estimate = \"population\" ) #> Counterfactual Contrasts Analysis (G-computation) #>  #> Level1 | Level2 |    Difference (CI) |      p #> --------------------------------------------- #> 1      | 0      | 8.35 (4.34, 12.37) | <0.001 #>  #> Variable predicted: QoL #> Predictors contrasted: treatment #> Predictors averaged: time, education, hospital (0.95), age (0.22), phq4 (-0.076), ID #> p-values are uncorrected."},{"path":"https://easystats.github.io/modelbased/articles/practical_causality.html","id":"an-important-note-on-variance-estimators","dir":"Articles","previous_headings":"","what":"An important note on variance estimators","title":"Case Study: Causal inference for observational data using modelbased","text":"performing statistical inference inverse probability weighting (IPW), using standard variance estimators discouraged. estimators often fail account variance introduced IPW , resulting conservative standard errors average treatment effect (ATE), especially observations large extreme weights. average treatment effect treated (ATT), standard errors can either - underestimated. robust methods therefore recommended, bootstrapping, using overlap matching weights, calculating robust standard errors (Huber-White sandwich estimators) (Gabriel et al. 2024; Kostouraki et al. 2024; Reifeis Hudgens 2022). robust standard errors can easily computed many models using vcov argument within estimate_contrasts() function, option currently available models built glmmTMB package. Consequently, glmmTMB models, bootstrapping applying matching overlap weights preferred method obtaining robust standard errors. fully Bayesian approach, demonstrated , also provides robust alternative.","code":"# Same model as m4, within a Bayesian framework, using the Stan and brms package library(brms) m5 <- brm(   QoL | weights(ipw) ~ treatment * time + treatment * education + hospital +     age + phq4 + (1 | ID),   refresh = 0,   seed = 123,   data = d ) estimate_contrasts(m5, \"treatment\", estimate = \"population\") #> Counterfactual Contrasts Analysis (G-computation) #>  #> Level1 | Level2 |        Median (CI) |   pd #> ------------------------------------------- #> 1      | 0      | 8.90 (4.94, 12.84) | 100% #>  #> Variable predicted: QoL, ipw #> Predictors contrasted: treatment #> Predictors averaged: time, education, hospital (0.95), age (0.22), phq4 (-0.076), ID"},{"path":"https://easystats.github.io/modelbased/articles/practical_causality.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Case Study: Causal inference for observational data using modelbased","text":"vignette explored estimation average treatment effects (ATEs) observational data, focusing application inverse probability weighting (IPW) g-computation. methods address confounding bias inherent non-randomized studies, offer distinct strengths. IPW provides straightforward approach incorporating weights regression models, simplifying ATE interpretation basic models. However, g-computation excels complex scenarios, involving longitudinal data interaction terms, isolating treatment effects becomes challenging. examples demonstrated utility methods. Specifically, showed IPW effectively estimates ATE simple model, g-computation becomes essential modeling interaction treatment time. IPW performs well rare outcomes, whereas g-computation better suited studies imbalanced treatment group sizes. Therefore, combining IPW g-computation, illustrated last examples, offers increased accuracy, highlighting benefits “doubly robust” approach estimating ATEs complex models. Combining IPW g-computation doesn’t introduce additional bias hence negative effects. IPW alone can sometimes less accurate g-computation, particularly g-computation feasible, reliable estimates achieved using methods together. Therefore, recommend combined use.","code":""},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/practical_intersectionality.html","id":"preparing-the-data-and-defining-intersectional-strata","dir":"Articles","previous_headings":"","what":"1. Preparing the data and defining intersectional strata","title":"Case Study: Intersectionality Analysis Using The MAIHDA Framework","text":"First, load required packages prepare sample data set. use efc data modelbased package, contains data family carers care elderly relatives. outcome interest quality life family carers (score ranging 0 25 points), different dimensions intersectionality groups gender (male/female), employment status (currently employed yes/) age (three groups: 40, 41 64 65 older). assume might health-related inequalities, .e. quality life differs depending characteristics define intersectional strata. include intersectional strata variables gender, employed age mixed model, define interacting random effects (excluding main effects interactions): (1 | gender:employed:age) (see also ). idea truly unique combinations model, similar create factor variable combinations manually: now choice either use strata variable group factor random effects, gender:employed:age. plotting predictions (see section 4), get clearer plots include three factors gender, employed age instead integrated strata factor.","code":"library(modelbased) # predictions and significance testing library(insight) # extracting random effects variances library(datawizard) # data wrangling and preparation library(parameters) # model summaries library(performance) # model fit indices, ICC library(glmmTMB) # multilevel modelling  # sample data set data(efc, package = \"modelbased\")  efc <- efc |>   # numeric to factors, set labels as levels   to_factor(select = c(\"c161sex\", \"c172code\", \"c175empl\")) |>   # recode age into three groups   recode_values(     select = \"c160age\",     recode = list(`1` = \"min:40\", `2` = 41:64, `3` = \"65:max\")   ) |>   # rename variables   data_rename(     select = c(\"c161sex\", \"c160age\", \"quol_5\", \"c175empl\"),     replacement = c(\"gender\", \"age\", \"qol\", \"employed\")   ) |>   # age into factor, set levels, and change labels for education   data_modify(age = factor(age, labels = c(\"-40\", \"41-64\", \"65+\"))) efc$strata <- ifelse(   is.na(efc$employed) | is.na(efc$gender) | is.na(efc$age),   NA_character_,   paste0(efc$gender, \", \", efc$employed, \", \", efc$age) ) efc$strata <- factor(efc$strata) data_tabulate(efc$strata) #> efc$strata <categorical> #> # total N=908 valid N=900 #>  #> Value              |   N | Raw % | Valid % | Cumulative % #> -------------------+-----+-------+---------+------------- #> Female, no, -40    |  37 |  4.07 |    4.11 |         4.11 #> Female, no, 41-64  | 238 | 26.21 |   26.44 |        30.56 #> Female, no, 65+    | 135 | 14.87 |   15.00 |        45.56 #> Female, yes, -40   |  63 |  6.94 |    7.00 |        52.56 #> Female, yes, 41-64 | 210 | 23.13 |   23.33 |        75.89 #> Female, yes, 65+   |   3 |  0.33 |    0.33 |        76.22 #> Male, no, -40      |  15 |  1.65 |    1.67 |        77.89 #> Male, no, 41-64    |  42 |  4.63 |    4.67 |        82.56 #> Male, no, 65+      |  50 |  5.51 |    5.56 |        88.11 #> Male, yes, -40     |  34 |  3.74 |    3.78 |        91.89 #> Male, yes, 41-64   |  70 |  7.71 |    7.78 |        99.67 #> Male, yes, 65+     |   3 |  0.33 |    0.33 |       100.00 #> <NA>               |   8 |  0.88 |    <NA> |         <NA>"},{"path":"https://easystats.github.io/modelbased/articles/practical_intersectionality.html","id":"fitting-the-simple-intersectional-model","dir":"Articles","previous_headings":"","what":"2. Fitting the simple intersectional model","title":"Case Study: Intersectionality Analysis Using The MAIHDA Framework","text":"Intersectionality analysis aims recognizing effects belonging specific strata simultaneously. context MAIHDA framework, interest lies analysing variation strata regarding outcome interest. Thus, indicators define intersectional dimensions used interacting random effects (group factors) multilevel model (random-intercept model). start fitting linear mixed effects model, includes fixed effects, different intersectional dimensions: gender, employed age. purpose model quantify “discriminatory accuracy”, achieved calculating ICC (see performance::icc()) model. higher ICC, greater degree similarity within strata (regarding quality life) greater difference quality life intersectional strata. .e., higher ICC, better model discriminating individuals higher lower quality life score, opposed models lower ICC. now look model parameters ICC simple intersectional model. ICC value 4% rather low. Usually, indicates dimensions used define intersectional strata suggest larger social inequalities regarding quality life. ignore fact now, purpose demonstrating analysis approach rarely affected.","code":"# Quality of Life score ranges from 0 to 25 m_null <- glmmTMB(qol ~ 1 + (1 | gender:employed:age), data = efc)  # the above model is identical to: # m_null <- glmmTMB(qol ~ 1 + (1 | strata), data = efc) model_parameters(m_null) #> # Fixed Effects #>  #> Parameter   | Coefficient |   SE |         95% CI |     z |      p #> ------------------------------------------------------------------ #> (Intercept) |       14.91 | 0.40 | [14.13, 15.70] | 37.41 | < .001 #>  #> # Random Effects #>  #> Parameter                           | Coefficient |       95% CI #> ---------------------------------------------------------------- #> SD (Intercept: gender:employed:age) |        1.03 | [0.56, 1.89] #> SD (Residual)                       |        5.23 | [4.99, 5.48]  icc(m_null) #> # Intraclass Correlation Coefficient #>  #>     Adjusted ICC: 0.038 #>   Unadjusted ICC: 0.038"},{"path":"https://easystats.github.io/modelbased/articles/practical_intersectionality.html","id":"partially-adjusted-intersectional-model-and-pcv","dir":"Articles","previous_headings":"","what":"3. Partially-adjusted intersectional model and PCV","title":"Case Study: Intersectionality Analysis Using The MAIHDA Framework","text":"next step want find , intersectional dimension contributes possible inequalities, .e. group factors gender, employed age explains -stratum variance random effects. achieved fitting partially-adjusted intersectional models. “purpose partially adjusted model quantify degree different dimensions used construct intersectional strata contributed stratum variance seen previous model.” intersectional dimensions, multilevel model including dimension fixed effect fitted. can look ICCs partially-adjusted models, well proportional change -stratum variance, -called PCV coefficients. First, fit three models one dimension predictor. regression coefficients already give impression strong association single dimension outcome , taking -stratum variance account. larger (absolute values) coefficients, higher degree dimension contributed -stratum variance. Looking summary tables , seems like gender dimension explains least -stratum variance, .e. gender seems characteristic contributes least potential social inequalities. age, turn, seems important characteristic regarding inequalities. Since fixed effects now take away proportion variance explained grouping factors (random effects), expect ICC models lower. Indeed, ICC correlates fixed effects coefficients, .e. larger coefficient (absolute values), lower ICC. Next, want quantify degree different dimensions contribute variance groups accurately. , calculate proportional change -stratum variance, PCV. coefficient explains much total proportion explained variance strata can explained single dimension define strata. PCV ranges 0 1, closer 1, particular dimension explains social inequalities. , see PCV line models’ ICC’s regression coefficients. see highest proportional change age, meaning - although gender education can contribute inequalities - age relevant predictor.","code":"m_gender <- glmmTMB(qol ~ gender + (1 | gender:employed:age), data = efc) m_employment <- glmmTMB(qol ~ employed + (1 | gender:employed:age), data = efc) m_age <- glmmTMB(qol ~ age + (1 | gender:employed:age), data = efc) compare_parameters(m_gender, m_employment, m_age) #> Parameter       |             m_gender |         m_employment |                m_age #> ------------------------------------------------------------------------------------ #> (Intercept)     | 15.55 (14.51, 16.60) | 14.23 (13.35, 15.12) | 16.25 (15.33, 17.17) #> gender [Female] | -1.18 (-2.54,  0.17) |                      |                      #> employed [yes]  |                      |  1.38 ( 0.07,  2.68) |                      #> age [41-64]     |                      |                      | -1.99 (-3.14, -0.84) #> age [65+]       |                      |                      | -2.55 (-3.88, -1.23) #> ------------------------------------------------------------------------------------ #> Observations    |                  895 |                  895 |                  895 icc(m_gender)$ICC_adjusted #> [1] 0.02583979 icc(m_employment)$ICC_adjusted #> [1] 0.02341412 icc(m_age)$ICC_adjusted #> [1] 0.00461901 # extract random effect variances from all models v_null <- get_variance(m_null) v_gender <- get_variance(m_gender) v_employment <- get_variance(m_employment) v_age <- get_variance(m_age)  # PCV (proportional change in between-stratum variance) # from null-model to gender-model (v_null$var.random - v_gender$var.random) / v_null$var.random #> [1] 0.3202535  # PCV from null-model to employment-model (v_null$var.random - v_employment$var.random) / v_null$var.random #> [1] 0.3859538  # PCV from null-model to age-model (v_null$var.random - v_age$var.random) / v_null$var.random #> [1] 0.8809532"},{"path":"https://easystats.github.io/modelbased/articles/practical_intersectionality.html","id":"predict-between-stratum-variance-and-test-for-significant-differences","dir":"Articles","previous_headings":"","what":"4. Predict between-stratum variance and test for significant differences","title":"Case Study: Intersectionality Analysis Using The MAIHDA Framework","text":"Finally, may want clearer picture different strata vary, combination characteristics defines highest maybe lowest risk group. , calculate predictions random effects (unit-level predictions). following code shows predicted average quality life scores different groups.  According results, employed male family carers, older 40 years, show average highest quality life. hand, unemployed female carers aged 65 older lowest quality life. can now calculate pairwise comparisons show differences groups statistically significant. Since combinations pairwise comparisons return 66 rows total, just show first ten rows demonstrating purpose. want modulate one factor compare groups within levels groups, can use argument. reduces output compares focal term(s) within levels remaining predictors. E.g., look plot want know whether female persons aged 65+ differ depending employment status, can use following code:","code":"predictions <- estimate_relation(m_null, by = c(\"gender\", \"employed\", \"age\")) plot(predictions) # just show first 10 rows of output... estimate_contrasts(predictions, contrast = c(\"gender\", \"employed\", \"age\"))[1:10, ] #> Model-based Contrasts Analysis #>  #> Level1           | Level2           |     Difference (CI) |     p #> ----------------------------------------------------------------- #> Male, no, -40    | Female, no, -40  |  0.07 (-2.11, 2.25) | 0.951 #> Male, no, -40    | Male, yes, -40   | -0.88 (-3.18, 1.43) | 0.455 #> Female, no, -40  | Male, yes, -40   | -0.95 (-2.99, 1.10) | 0.364 #> Male, no, -40    | Female, yes, -40 | -0.79 (-2.89, 1.30) | 0.457 #> Female, no, -40  | Female, yes, -40 | -0.86 (-2.67, 0.94) | 0.348 #> Male, yes, -40   | Female, yes, -40 |  0.08 (-1.86, 2.03) | 0.932 #> Male, no, -40    | Male, no, 41-64  |  0.30 (-1.84, 2.45) | 0.781 #> Female, no, -40  | Male, no, 41-64  |  0.24 (-1.63, 2.10) | 0.805 #> Male, yes, -40   | Male, no, 41-64  |  1.18 (-0.83, 3.19) | 0.248 #> Female, yes, -40 | Male, no, 41-64  |  1.10 (-0.66, 2.86) | 0.221 #>  #> Variable predicted: qol #> Predictors contrasted: gender, employed, age # Compare levels of gender and employment status for age groups estimate_contrasts(predictions, contrast = c(\"gender\", \"employed\"), by = \"age\") #> Model-based Contrasts Analysis #>  #> Parameter             | age   |      Difference (CI) |     p #> ------------------------------------------------------------ #> Male no -Female no    | -40   |  0.07 (-2.11,  2.25) | 0.951 #> Male no -Male yes     | -40   | -0.88 (-3.18,  1.43) | 0.455 #> Female no -Male yes   | -40   | -0.95 (-2.99,  1.10) | 0.364 #> Male no -Female yes   | -40   | -0.79 (-2.89,  1.30) | 0.457 #> Female no -Female yes | -40   | -0.86 (-2.67,  0.94) | 0.348 #> Male yes -Female yes  | -40   |  0.08 (-1.86,  2.03) | 0.932 #> Male no -Female no    | 41-64 |  1.18 (-0.26,  2.63) | 0.109 #> Male no -Male yes     | 41-64 | -0.53 (-2.22,  1.16) | 0.538 #> Female no -Male yes   | 41-64 | -1.71 (-2.98, -0.44) | 0.008 #> Male no -Female yes   | 41-64 |  0.84 (-0.62,  2.30) | 0.258 #> Female no -Female yes | 41-64 | -0.34 (-1.28,  0.60) | 0.476 #> Male yes -Female yes  | 41-64 |  1.37 ( 0.09,  2.66) | 0.036 #> Male no -Female no    | 65+   |  0.88 (-0.62,  2.38) | 0.250 #> Male no -Male yes     | 65+   | -0.93 (-3.39,  1.53) | 0.459 #> Female no -Male yes   | 65+   | -1.81 (-4.10,  0.48) | 0.122 #> Male no -Female yes   | 65+   | -0.44 (-2.82,  1.94) | 0.717 #> Female no -Female yes | 65+   | -1.32 (-3.53,  0.89) | 0.241 #> Male yes -Female yes  | 65+   |  0.49 (-2.45,  3.43) | 0.745 #>  #> Variable predicted: qol #> Predictors contrasted: gender, employed # Compare levels employment status by gender and age groups estimate_contrasts(predictions, contrast = \"employed\", by = c(\"gender\", \"age\")) #> Model-based Contrasts Analysis #>  #> Level1 | Level2 | gender | age   |     Difference (CI) |     p #> -------------------------------------------------------------- #> no     | yes    | Female | -40   | -0.86 (-2.67, 0.94) | 0.348 #> no     | yes    | Male   | -40   | -0.88 (-3.18, 1.43) | 0.455 #> no     | yes    | Female | 41-64 | -0.34 (-1.28, 0.60) | 0.476 #> no     | yes    | Male   | 41-64 | -0.53 (-2.22, 1.16) | 0.538 #> no     | yes    | Female | 65+   | -1.32 (-3.53, 0.89) | 0.241 #> no     | yes    | Male   | 65+   | -0.93 (-3.39, 1.53) | 0.459 #>  #> Variable predicted: qol #> Predictors contrasted: employed"},{"path":"https://easystats.github.io/modelbased/articles/practical_intersectionality.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"5. Conclusion","title":"Case Study: Intersectionality Analysis Using The MAIHDA Framework","text":"Intersectional multilevel analysis individual heterogeneity, using MAIHDA framework, new approach social epidemiology, helps understand interaction social indicators regard social inequalities. approach requires application multilevel models, ICC PCV relevant coefficients. modelbased package allows go beyond quantifying degree different intersectional dimensions contribute inequalities predicting average outcome group, thereby explicitly showing differences groups (strata). Furthermore, modelbased possible compare differences groups test whether differences statistically significant , .e. whether find “evidence” social inequalities data certain groups (risk).","code":""},{"path":"https://easystats.github.io/modelbased/articles/practical_intersectionality.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Case Study: Intersectionality Analysis Using The MAIHDA Framework","text":"Axelsson Fisk S, Mulinari S, Wemrell M, Leckie G, Perez Vicente R, Merlo J. Chronic Obstructive Pulmonary Disease Sweden: intersectional multilevel analysis individual heterogeneity discriminatory accuracy. SSM - Population Health (2018) 4:334-346. doi: 10.1016/j.ssmph.2018.03.005 Evans CR, Leckie G, Subramanian SV, Bell , Merlo J. tutorial conducting intersectional multilevel analysis individual heterogeneity discriminatory accuracy (MAIHDA). SSM - Population Health (2024) 26; doi: 10.1016/j.ssmph.2024.101664","code":""},{"path":"https://easystats.github.io/modelbased/articles/visualisation_matrix.html","id":"simple-linear-regression","dir":"Articles","previous_headings":"","what":"Simple linear regression","title":"Data grids","text":"instance, let’s fit simple linear model models relationship Sepal.Width Sepal.Length. obvious way representing model plot data points add regression line using geom_smooth function ggplot2:  “access” data regression line? One good option select values predictor (Sepal.Length), predict (using base R predict() method now) response (Sepal.Width) using model. Using x y points, can create regression line. Let’s try get_datagrid() function insight package. pass numeric column function, return vector equally spread points (range, .e., minimum maximum, original data). default length 10, can adjust length argument. instance, linear relationships (.e., straight line), two points theory sufficient. Let’s generate predictions using reference grid predictor. Now x y values, can plot line overlay actual data points:  can see, quite similar previous plot. , can useful?","code":"library(easystats) library(ggplot2)  model <- lm(Sepal.Width ~ Sepal.Length, data = iris) parameters(model) > Parameter    | Coefficient |   SE |        95% CI | t(148) |      p > ------------------------------------------------------------------- > (Intercept)  |        3.42 | 0.25 | [ 2.92, 3.92] |  13.48 | < .001 > Sepal Length |       -0.06 | 0.04 | [-0.15, 0.02] |  -1.44 | 0.152 ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width)) +   geom_point() +   geom_smooth(method = \"lm\") +   theme_minimal() get_datagrid(iris[\"Sepal.Length\"]) > Visualisation Grid >  > Sepal.Length > ------------ > 4.30         > 4.70         > 5.10         > 5.50         > 5.90         > 6.30         > 6.70         > 7.10         > 7.50         > 7.90 vizdata <- get_datagrid(iris[\"Sepal.Length\"], length = 2) vizdata$Predicted <- predict(model, vizdata) vizdata > Visualisation Grid >  > Sepal.Length | Predicted > ------------------------ > 4.30         |      3.15 > 7.90         |      2.93 ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width)) +   geom_point() +   geom_line(data = vizdata, aes(y = Predicted), linewidth = 1, color = \"red\") +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/articles/visualisation_matrix.html","id":"mixed-models","dir":"Articles","previous_headings":"","what":"Mixed models","title":"Data grids","text":"Data grids useful represent complex models. instance, models , negative relationship length width sepals fact biased presence three different species. One way adjusting model grouping structure add random effect mixed model. model , “fixed” effects (parameters interest) adjusted (“averaged ”) random effects. can see, adjusting species, relationship two variables become positive! can represent using procedure , note instead using base R predict() function, using get_predicted(), insight package, robust user-friendly version predict().","code":"library(lme4)  model <- lmer(Sepal.Width ~ Sepal.Length + (1 | Species), data = iris) parameters(model) > # Fixed Effects >  > Parameter    | Coefficient |   SE |       95% CI | t(146) |      p > ------------------------------------------------------------------ > (Intercept)  |        1.04 | 0.43 | [0.20, 1.89] |   2.45 | 0.015  > Sepal Length |        0.34 | 0.05 | [0.25, 0.44] |   7.47 | < .001 >  > # Random Effects >  > Parameter               | Coefficient > ------------------------------------- > SD (Intercept: Species) |        0.57 > SD (Residual)           |        0.29 vizdata <- get_datagrid(iris[\"Sepal.Length\"]) vizdata$Predicted <- get_predicted(model, vizdata)  ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width)) +   geom_point(aes(color = Species)) +   geom_line(data = vizdata, aes(y = Predicted), linewidth = 1) +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/articles/visualisation_matrix.html","id":"fixed-variables","dir":"Articles","previous_headings":"","what":"Fixed variables","title":"Data grids","text":"way constructing reference grid, .e., providing single column data function, almost equivalent following: However, variables (present dataframe selected ) “fixed”, .e., maintained specific values. useful variables model whose effect interested. default, factors fixed “reference” level numeric variables fixed mean. However, can easily changed:","code":"vizdata <- get_datagrid(iris, by = \"Sepal.Length\") vizdata > Visualisation Grid >  > Sepal.Length | Sepal.Width | Petal.Length | Petal.Width | Species > ----------------------------------------------------------------- > 4.30         |        3.06 |         3.76 |        1.20 | setosa  > 4.70         |        3.06 |         3.76 |        1.20 | setosa  > 5.10         |        3.06 |         3.76 |        1.20 | setosa  > 5.50         |        3.06 |         3.76 |        1.20 | setosa  > 5.90         |        3.06 |         3.76 |        1.20 | setosa  > 6.30         |        3.06 |         3.76 |        1.20 | setosa  > 6.70         |        3.06 |         3.76 |        1.20 | setosa  > 7.10         |        3.06 |         3.76 |        1.20 | setosa  > 7.50         |        3.06 |         3.76 |        1.20 | setosa  > 7.90         |        3.06 |         3.76 |        1.20 | setosa  >  > Maintained constant: Sepal.Width, Petal.Length, Petal.Width, Species vizdata <- get_datagrid(iris, by = \"Sepal.Length\", numerics = \"min\") vizdata > Visualisation Grid >  > Sepal.Length | Sepal.Width | Petal.Length | Petal.Width | Species > ----------------------------------------------------------------- > 4.30         |           2 |            1 |        0.10 | setosa  > 4.70         |           2 |            1 |        0.10 | setosa  > 5.10         |           2 |            1 |        0.10 | setosa  > 5.50         |           2 |            1 |        0.10 | setosa  > 5.90         |           2 |            1 |        0.10 | setosa  > 6.30         |           2 |            1 |        0.10 | setosa  > 6.70         |           2 |            1 |        0.10 | setosa  > 7.10         |           2 |            1 |        0.10 | setosa  > 7.50         |           2 |            1 |        0.10 | setosa  > 7.90         |           2 |            1 |        0.10 | setosa  >  > Maintained constant: Sepal.Width, Petal.Length, Petal.Width, Species"},{"path":"https://easystats.github.io/modelbased/articles/visualisation_matrix.html","id":"target-variables","dir":"Articles","previous_headings":"","what":"Target variables","title":"Data grids","text":"one target variable selected, get_datagrid() return combination (.e., unique values crossed together). can useful case interaction numeric variable factor. Let’s visualise regression line levels Species:","code":"model <- lm(Sepal.Width ~ Sepal.Length * Species, data = iris)  vizdata <- get_datagrid(iris, by = c(\"Sepal.Length\", \"Species\"), length = 5) vizdata$Predicted <- get_predicted(model, vizdata) vizdata > Visualisation Grid >  > Sepal.Length | Species    | Sepal.Width | Petal.Length | Petal.Width | Predicted > -------------------------------------------------------------------------------- > 4.30         | setosa     |        3.06 |         3.76 |        1.20 |      2.86 > 5.20         | setosa     |        3.06 |         3.76 |        1.20 |      3.58 > 6.10         | setosa     |        3.06 |         3.76 |        1.20 |      4.30 > 7.00         | setosa     |        3.06 |         3.76 |        1.20 |      5.02 > 7.90         | setosa     |        3.06 |         3.76 |        1.20 |      5.74 > 4.30         | versicolor |        3.06 |         3.76 |        1.20 |      2.25 > 5.20         | versicolor |        3.06 |         3.76 |        1.20 |      2.53 > 6.10         | versicolor |        3.06 |         3.76 |        1.20 |      2.82 > 7.00         | versicolor |        3.06 |         3.76 |        1.20 |      3.11 > 7.90         | versicolor |        3.06 |         3.76 |        1.20 |      3.40 > 4.30         | virginica  |        3.06 |         3.76 |        1.20 |      2.44 > 5.20         | virginica  |        3.06 |         3.76 |        1.20 |      2.65 > 6.10         | virginica  |        3.06 |         3.76 |        1.20 |      2.86 > 7.00         | virginica  |        3.06 |         3.76 |        1.20 |      3.07 > 7.90         | virginica  |        3.06 |         3.76 |        1.20 |      3.28 >  > Maintained constant: Sepal.Width, Petal.Length, Petal.Width ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +   geom_point() +   geom_line(data = vizdata, aes(y = Predicted), linewidth = 1) +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/articles/visualisation_matrix.html","id":"preserve-range","dir":"Articles","previous_headings":"","what":"Preserve range","title":"Data grids","text":"However, generally good practice extend regression lines beyond range original data, case red line. preserve_range option allows remove observations “outside” original dataset (however, length increased improve precision toward edges):","code":"vizdata <- get_datagrid(iris,   by = c(\"Sepal.Length\", \"Species\"),   length = 100,   preserve_range = TRUE )  vizdata$Predicted_Sepal.Width <- get_predicted(model, vizdata)  ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +   geom_point() +   geom_line(data = vizdata, aes(y = Predicted_Sepal.Width), linewidth = 1) +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/articles/visualisation_matrix.html","id":"visualising-an-interaction-between-two-numeric-variables-three-way-interaction","dir":"Articles","previous_headings":"","what":"Visualising an interaction between two numeric variables (three-way interaction)","title":"Data grids","text":"idea can also used visualise interactions two numeric variables, aka nightmare every scientist. One possibility basically represent relationship response one predictor representative values second predictor. case, represent regression line Sepal.Length Petal.Length 5 equally spaced values Petal.Length, get feel interaction. can obtain right reference grid quite easily chaining two data grids together follows: ? started generating reference grid containing combinations 10 equally spread values two target variables, creating 10 * 10 = 100 rows. next step reduce Petal.Length set 5 values, without touching variables (.e., keeping 10 values created Petal.Length). achieved using numerics = \"\". can visualise follows:  plot can clear expressing interaction variable terms deviations mean (standardized variable).  Petal.Width increases (becomes yellow), coefficient Petal.Length Sepal.Length increases (slope steep). Although, can guess, fact captures underlying effect species… ’ll leave discussing meaningfulness models :)","code":"model <- lm(Sepal.Length ~ Petal.Length * Petal.Width, data = iris) parameters(model) > Parameter                  | Coefficient |   SE |         95% CI | t(146) |      p > ---------------------------------------------------------------------------------- > (Intercept)                |        4.58 | 0.11 | [ 4.36,  4.80] |  40.89 | < .001 > Petal Length               |        0.44 | 0.07 | [ 0.31,  0.57] |   6.74 | < .001 > Petal Width                |       -1.24 | 0.22 | [-1.67, -0.81] |  -5.65 | < .001 > Petal Length × Petal Width |        0.19 | 0.03 | [ 0.12,  0.25] |   5.62 | < .001 vizdata <- iris |>   get_datagrid(c(\"Petal.Length\", \"Petal.Width\"), length = 10) |>   get_datagrid(\"Petal.Width\", length = 5, numerics = \"all\") vizdata$Predicted <- get_predicted(model, vizdata)  iris |>   ggplot(aes(x = Petal.Length, y = Sepal.Length, color = Petal.Width)) +   geom_point() +   geom_line(data = vizdata, aes(y = Predicted, group = Petal.Width), linewidth = 1) +   scale_color_viridis_c() +   theme_minimal() # Express values in an abstract way vizdata$Petal.Width <- effectsize::format_standardize(   vizdata$Petal.Width,   reference = iris$Petal.Width )  ggplot(iris, aes(x = Petal.Length, y = Sepal.Length)) +   # Only shapes from 21 to 25 have a fill aesthetic   geom_point2(aes(fill = Petal.Width), color = \"white\", shape = 21, size = 5) +   geom_line(data = vizdata, aes(y = Predicted, color = Petal.Width), linewidth = 1) +   scale_color_viridis_d(direction = -1) +   scale_fill_viridis_c(guide = \"none\") +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/articles/visualisation_matrix.html","id":"get_datagrid-also-runs-directly-on-model-objects","dir":"Articles","previous_headings":"","what":"get_datagrid() also runs directly on model objects","title":"Data grids","text":"illustrate , let’s set general additive mixed model (GAMM), going specify smooth term (non-linear relationship; specified s() function) random effects structure. One can directly extract visualization matrix model entering entire object function: also skip smooth term interested fixed effects: can also include random effects:","code":"library(gamm4)  model <- gamm4::gamm4(   formula = Petal.Length ~ Petal.Width + s(Sepal.Length),   random = ~ (1 | Species),   data = iris ) get_datagrid(model, length = 3, include_random = FALSE) > Visualisation Grid >  > Petal.Width | Sepal.Length > -------------------------- > 0.10        |         4.30 > 1.30        |         4.30 > 2.50        |         4.30 > 0.10        |         6.10 > 1.30        |         6.10 > 2.50        |         6.10 > 0.10        |         7.90 > 1.30        |         7.90 > 2.50        |         7.90 get_datagrid(model, length = 3, include_random = FALSE, include_smooth = FALSE) > Visualisation Grid >  > Petal.Width > ----------- > 0.10        > 1.30        > 2.50        >  > Maintained constant: Sepal.Length get_datagrid(model, length = 5, include_random = TRUE) > Visualisation Grid >  > Petal.Width | Sepal.Length | Species    > --------------------------------------- > 0.10        |         4.30 | setosa     > 0.10        |         5.20 | setosa     > 1.30        |         5.20 | versicolor > 1.30        |         6.10 | versicolor > 1.30        |         7.00 | versicolor > 1.90        |         5.20 | virginica  > 2.50        |         5.20 | virginica  > 1.90        |         6.10 | virginica  > 2.50        |         6.10 | virginica  > 1.90        |         7.00 | virginica  > 2.50        |         7.00 | virginica  > 1.90        |         7.90 | virginica  > 2.50        |         7.90 | virginica"},{"path":"https://easystats.github.io/modelbased/articles/visualisation_matrix.html","id":"controlled-standardized-change","dir":"Articles","previous_headings":"","what":"Controlled standardized change","title":"Data grids","text":"Although plot nice, , like standardized changes SD smoother (e.g., increments 1 SD). can achieved first requesting values want, unstandardizing . Let’s use model , obtain data grid specific values Petal.Width.","code":"vizdata <- lm(Sepal.Length ~ Petal.Length * Petal.Width, data = iris) |>   get_datagrid(by = c(\"Petal.Length\", \"Petal.Width = seq(-3, 3)\")) |>   unstandardize(vizdata, select = \"Petal.Width\") |>   estimate_relation(vizdata)  vizdata$Petal.Width <- effectsize::format_standardize(vizdata$Petal.Width, reference = iris$Petal.Width)  # 6. Plot ggplot(iris, aes(x = Petal.Length, y = Sepal.Length)) +   geom_point2(aes(fill = Petal.Width), shape = 21, size = 5) +   geom_line(data = vizdata, aes(y = Predicted, color = Petal.Width), linewidth = 1) +   scale_color_viridis_d(direction = -1) +   scale_fill_viridis_c(guide = \"none\") +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/articles/workflow_modelbased.html","id":"preparing-the-data-and-fitting-a-model","dir":"Articles","previous_headings":"","what":"Preparing the data and fitting a model","title":"Case Study: Understanding your models","text":"first step usually importing preparing data (recoding, re-shaping data - usual data wrangling tasks), easily done using datawizard package. example, use datawizard minor recodings. coffee_data data set included modelbased package. data set contains information effect coffee consumption alertness time. outcome variable binary (alertness), predictor variables coffee consumption (treatment) time.","code":"library(datawizard) # for data management, e.g. recodings  data(coffee_data, package = \"modelbased\")  # dichotomize outcome variable coffee_data$alertness <- categorize(coffee_data$alertness, lowest = 0) # rename variable coffee_data <- data_rename(coffee_data, select = c(treatment = \"coffee\"))  # model model <- glm(alertness ~ treatment * time, data = coffee_data, family = binomial())"},{"path":"https://easystats.github.io/modelbased/articles/workflow_modelbased.html","id":"exploring-the-model---model-coefficients","dir":"Articles","previous_headings":"","what":"Exploring the model - model coefficients","title":"Case Study: Understanding your models","text":"Let’s start examining model coefficients. package manages everything related model coefficients parameters package. can use model_parameters() function extract coefficients model. setting exponentiate = TRUE, can obtain odds ratios coefficients. model coefficients difficult interpret directly, particular since interaction effect. Instead, use modelbased package calculate adjusted predictions model.","code":"library(parameters)  # coefficients model_parameters(model, exponentiate = TRUE) #> Parameter                              | Odds Ratio |   SE |        95% CI |         z |      p #> ----------------------------------------------------------------------------------------------- #> (Intercept)                            |       1.00 | 0.45 | [0.41,  2.44] | -1.54e-15 | > .999 #> treatment [control]                    |       0.33 | 0.23 | [0.08,  1.23] |     -1.61 | 0.108  #> time [noon]                            |       0.54 | 0.35 | [0.15,  1.90] |     -0.96 | 0.339  #> time [afternoon]                       |       3.00 | 2.05 | [0.81, 12.24] |      1.61 | 0.108  #> treatment [control] × time [noon]      |      10.35 | 9.85 | [1.66, 70.73] |      2.45 | 0.014  #> treatment [control] × time [afternoon] |       1.00 | 0.97 | [0.15,  6.74] | -6.10e-16 | > .999 #>  #> Uncertainty intervals (profile-likelihood) and p-values (two-tailed) computed using a Wald z-distribution approximation."},{"path":"https://easystats.github.io/modelbased/articles/workflow_modelbased.html","id":"predicted-probabilities---understanding-the-model","dir":"Articles","previous_headings":"","what":"Predicted probabilities - understanding the model","title":"Case Study: Understanding your models","text":"mentioned , interpreting model results can hard, sometimes even misleading, look regression coefficients. Instead, useful estimate model-based means probabilities outcome. Ab absolutely easy way make interpretation easier use modelbased package. just need provide predictors interest, called focal terms. Since interested interaction effect coffee consumption (treatment) alertness depending different times day, simply specify two variables focal terms estimate_means() function. function calculates predictions response scale regression model. logistic regression models, predicted probabilities calculated. refer adjusted probabilities outcome (higher alertness) depending predictor variables (treatment time). now see high alertness likely coffee group afternoon time (75% probability high alertness afternoon-coffee group). can also visualize results, using plot() method. short, give us visual interpretation model.  can also see predicted probabilities alertness higher participants consumed coffee compared , morning afternoon. Furthermore, see differences coffee control group time point - differences statistically significant?","code":"library(modelbased)  # predicted probabilities predictions <- estimate_means(model, c(\"time\", \"treatment\")) predictions #> Estimated Marginal Means #>  #> time      | treatment | Probability |       95% CI #> -------------------------------------------------- #> morning   | coffee    |        0.50 | [0.29, 0.71] #> noon      | coffee    |        0.35 | [0.18, 0.57] #> afternoon | coffee    |        0.75 | [0.52, 0.89] #> morning   | control   |        0.25 | [0.11, 0.48] #> noon      | control   |        0.65 | [0.43, 0.82] #> afternoon | control   |        0.50 | [0.29, 0.71] #>  #> Variable predicted: alertness #> Predictors modulated: time, treatment #> Predictions are on the response-scale. # plot predicted probabilities plot(predictions)"},{"path":"https://easystats.github.io/modelbased/articles/workflow_modelbased.html","id":"pairwise-comparisons---testing-the-differences","dir":"Articles","previous_headings":"","what":"Pairwise comparisons - testing the differences","title":"Case Study: Understanding your models","text":"check , finally use estimate_contrasts() function perform pairwise comparisons predicted probabilities. function needs know variables compared, contrasted. first step, want compare levels variables involved interaction term (focal terms ). output, see possible pairwise comparisons predicted probabilities. table quite long, can also group comparisons, e.g. variable time. output shows differences coffee control group statistically significant noon time.","code":"# pairwise comparisons - quite long table estimate_contrasts(model, c(\"time\", \"treatment\")) #> Marginal Contrasts Analysis #>  #> Level1             | Level2            | Difference |   SE |        95% CI |        z |      p #> ---------------------------------------------------------------------------------------------- #> morning, control   | morning, coffee   |      -0.25 | 0.15 | [-0.54, 0.04] |    -1.69 |  0.091 #> noon, coffee       | morning, coffee   |      -0.15 | 0.15 | [-0.45, 0.15] |    -0.97 |  0.332 #> noon, control      | morning, coffee   |       0.15 | 0.15 | [-0.15, 0.45] |     0.97 |  0.332 #> afternoon, coffee  | morning, coffee   |       0.25 | 0.15 | [-0.04, 0.54] |     1.69 |  0.091 #> afternoon, control | morning, coffee   |   1.11e-16 | 0.16 | [-0.31, 0.31] | 7.02e-16 | > .999 #> noon, coffee       | morning, control  |       0.10 | 0.14 | [-0.18, 0.38] |     0.69 |  0.488 #> noon, control      | morning, control  |       0.40 | 0.14 | [ 0.12, 0.68] |     2.78 |  0.005 #> afternoon, coffee  | morning, control  |       0.50 | 0.14 | [ 0.23, 0.77] |     3.65 | < .001 #> afternoon, control | morning, control  |       0.25 | 0.15 | [-0.04, 0.54] |     1.69 |  0.091 #> noon, control      | noon, coffee      |       0.30 | 0.15 | [ 0.00, 0.60] |     1.99 |  0.047 #> afternoon, coffee  | noon, coffee      |       0.40 | 0.14 | [ 0.12, 0.68] |     2.78 |  0.005 #> afternoon, control | noon, coffee      |       0.15 | 0.15 | [-0.15, 0.45] |     0.97 |  0.332 #> afternoon, coffee  | noon, control     |       0.10 | 0.14 | [-0.18, 0.38] |     0.69 |  0.488 #> afternoon, control | noon, control     |      -0.15 | 0.15 | [-0.45, 0.15] |    -0.97 |  0.332 #> afternoon, control | afternoon, coffee |      -0.25 | 0.15 | [-0.54, 0.04] |    -1.69 |  0.091 #>  #> Variable predicted: alertness #> Predictors contrasted: time, treatment #> p-values are uncorrected. #> Contrasts are on the response-scale (in %-points). # group comparisons by \"time\" estimate_contrasts(model, \"treatment\", by = \"time\") #> Marginal Contrasts Analysis #>  #> Level1  | Level2 | time      | Difference |   SE |        95% CI |     z |     p #> -------------------------------------------------------------------------------- #> control | coffee | morning   |      -0.25 | 0.15 | [-0.54, 0.04] | -1.69 | 0.091 #> control | coffee | noon      |       0.30 | 0.15 | [ 0.00, 0.60] |  1.99 | 0.047 #> control | coffee | afternoon |      -0.25 | 0.15 | [-0.54, 0.04] | -1.69 | 0.091 #>  #> Variable predicted: alertness #> Predictors contrasted: treatment #> p-values are uncorrected. #> Contrasts are on the response-scale (in %-points)."},{"path":"https://easystats.github.io/modelbased/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Dominique Makowski. Author, maintainer. Daniel Lüdecke. Author. Mattan S. Ben-Shachar. Author. Indrajeet Patil. Author. Rémi Thériault. Author.","code":""},{"path":"https://easystats.github.io/modelbased/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Makowski, D., Ben-Shachar, M. S., Patil, ., & Lüdecke, D. (2020). Estimation Model-Based Predictions, Contrasts Means. CRAN.","code":"@Article{,   title = {Estimation of Model-Based Predictions, Contrasts and Means.},   author = {Dominique Makowski and Mattan S. Ben-Shachar and Indrajeet Patil and Daniel Lüdecke},   journal = {CRAN},   year = {2020},   url = {https://github.com/easystats/modelbased}, }"},{"path":"https://easystats.github.io/modelbased/index.html","id":"modelbased-","dir":"","previous_headings":"","what":"Estimation of Model-Based Predictions, Contrasts and Means","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Make models modelbased package helping model-based estimations, easily compute marginal means, contrast analysis model predictions.","code":""},{"path":"https://easystats.github.io/modelbased/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"modelbased package available CRAN, latest development version available R-universe (rOpenSci). downloaded package, can load using: Tip: Instead library(modelbased), use library(easystats). make features easystats-ecosystem available. stay updated, use easystats::install_latest().","code":"library(\"modelbased\")"},{"path":"https://easystats.github.io/modelbased/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Access package documentation, check-vignettes: Data grids , use get marginal means Contrast analysis Marginal effects derivatives Use model make predictions Interpret simple complex models using power effect derivatives use mixed models estimate individuals’ scores Visualize effects interactions modelisation approach statistics","code":""},{"path":"https://easystats.github.io/modelbased/index.html","id":"features","dir":"","previous_headings":"","what":"Features","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"core idea behind modelbased package statistical models often contain lot insights get simply looking model parameters. many cases, like models multiple interactions, non-linear effects, non-standard families, complex random effect structures, parameters can hard interpret. modelbased package comes . give simply example, imagine interested effect 3 conditions , B C variable Y. simple linear model Y ~ Condition give 3 parameters: intercept (average value Y condition ), relative effect condition B C. like also get average value Y conditions . Many people compute average “hand” (.e., empirical average) directly averaging observed data groups. know estimated average (can much relevant, e.g., adjust variables model) contained model, can get easily running estimate_means()? modelbased package built around 4 main functions: estimate_means(): Estimates average values factor levels estimate_contrasts(): Estimates tests contrasts different factor levels estimate_slopes(): Estimates slopes numeric predictors different factor levels alongside numeric predictor estimate_prediction(): Make predictions using model functions based important statistical concepts, like data grids, predictions marginal effects, leverages packages like emmeans marginaleffects. recommend reading get deeper understanding hidden power models.","code":""},{"path":[]},{"path":"https://easystats.github.io/modelbased/index.html","id":"estimate-marginal-means","dir":"","previous_headings":"Examples","what":"Estimate marginal means","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Problem: model factor predictor, parameters return difference levels intercept. want see values factor level. Solution: Estimate model-based means (“marginal means”). can visualize plotting confidence interval original data. Check-function documentation vignette detailed walkthrough marginal means.  can also get “quick” plot using plot() function:","code":"library(modelbased) library(ggplot2)  # 1. The model model <- lm(Sepal.Width ~ Species, data = iris)  # 2. Obtain estimated means means <- estimate_means(model, by = \"Species\") means ## Estimated Marginal Means ##  ## Species    | Mean |   SE |       95% CI | t(147) ## ------------------------------------------------ ## setosa     | 3.43 | 0.05 | [3.33, 3.52] |  71.36 ## versicolor | 2.77 | 0.05 | [2.68, 2.86] |  57.66 ## virginica  | 2.97 | 0.05 | [2.88, 3.07] |  61.91 ##  ## Variable predicted: Sepal.Width ## Predictors modulated: Species  # 3. Custom plot ggplot(iris, aes(x = Species, y = Sepal.Width)) +   # Add base data   geom_violin(aes(fill = Species), color = \"white\") +   geom_jitter(width = 0.1, height = 0, alpha = 0.5, size = 3) +   # Add pointrange and line for means   geom_line(data = means, aes(y = Mean, group = 1), linewidth = 1) +   geom_pointrange(     data = means,     aes(y = Mean, ymin = CI_low, ymax = CI_high),     size = 1,     color = \"white\"   ) +   # Improve colors   scale_fill_manual(values = c(\"pink\", \"lightblue\", \"lightgreen\")) +   theme_minimal() plot(means)"},{"path":"https://easystats.github.io/modelbased/index.html","id":"contrast-analysis","dir":"","previous_headings":"Examples","what":"Contrast analysis","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Problem: parameters model return difference factor levels intercept. want see differences levels, post-hoc comparison tests ANOVAs. Solution: Estimate model-based contrasts (“marginal contrasts”). can visualize plotting confidence interval. Check-vignette detailed walkthrough contrast analysis.","code":"# 1. The model model <- lm(Sepal.Width ~ Species, data = iris)  # 2. Estimate marginal contrasts contrasts <- estimate_contrasts(model, contrast = \"Species\") contrasts ## Marginal Contrasts Analysis ##  ## Level1     | Level2     | Difference |   SE |         95% CI | t(147) |      p ## ------------------------------------------------------------------------------ ## versicolor | setosa     |      -0.66 | 0.07 | [-0.79, -0.52] |  -9.69 | < .001 ## virginica  | setosa     |      -0.45 | 0.07 | [-0.59, -0.32] |  -6.68 | < .001 ## virginica  | versicolor |       0.20 | 0.07 | [ 0.07,  0.34] |   3.00 |  0.003 ##  ## Variable predicted: Sepal.Width ## Predictors contrasted: Species ## p-values are uncorrected."},{"path":"https://easystats.github.io/modelbased/index.html","id":"check-the-contrasts-at-different-points-of-another-linear-predictor","dir":"","previous_headings":"Examples","what":"Check the contrasts at different points of another linear predictor","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Problem: case interaction factor continuous variable, might interested computing differences factor levels (contrasts) change depending continuous variable. Solution: can estimate marginal contrasts different values continuous variable (modulator), plot differences (significant 95% CI doesn’t cover 0).","code":"model <- lm(Sepal.Width ~ Species * Petal.Length, data = iris) difference <- estimate_contrasts(   model,   contrast = \"Species\",   by = \"Petal.Length\",   length = 3 ) # no line break for table print(difference, table_width = Inf) ## Marginal Contrasts Analysis ##  ## Level1     | Level2     | Petal.Length | Difference |   SE |         95% CI | t(144) |      p ## --------------------------------------------------------------------------------------------- ## versicolor | setosa     |         1.00 |      -1.70 | 0.34 | [-2.37, -1.02] |  -4.97 | < .001 ## virginica  | setosa     |         1.00 |      -1.34 | 0.40 | [-2.13, -0.56] |  -3.38 | < .001 ## virginica  | versicolor |         1.00 |       0.36 | 0.49 | [-0.61,  1.33] |   0.73 |  0.468 ## versicolor | setosa     |         3.95 |      -1.74 | 0.65 | [-3.03, -0.45] |  -2.67 |  0.008 ## virginica  | setosa     |         3.95 |      -1.79 | 0.66 | [-3.11, -0.48] |  -2.70 |  0.008 ## virginica  | versicolor |         3.95 |      -0.06 | 0.15 | [-0.35,  0.24] |  -0.37 |  0.710 ## versicolor | setosa     |         6.90 |      -1.78 | 1.44 | [-4.62,  1.06] |  -1.24 |  0.218 ## virginica  | setosa     |         6.90 |      -2.25 | 1.42 | [-5.06,  0.56] |  -1.58 |  0.116 ## virginica  | versicolor |         6.90 |      -0.47 | 0.28 | [-1.03,  0.09] |  -1.65 |  0.101 ##  ## Variable predicted: Sepal.Width ## Predictors contrasted: Species ## p-values are uncorrected. # Recompute contrasts with a higher precision (for a smoother plot) contrasts <- estimate_contrasts(   model,   contrast = \"Species\",   by = \"Petal.Length\",   length = 20,   # we use a emmeans here because marginaleffects doesn't   # generate more than 25 rows for pairwise comparisons   backend = \"emmeans\" )  # Add Contrast column by concatenating contrasts$Contrast <- paste(contrasts$Level1, \"-\", contrasts$Level2)  # Plot ggplot(contrasts, aes(x = Petal.Length, y = Difference, )) +   # Add line and CI band   geom_line(aes(color = Contrast)) +   geom_ribbon(aes(ymin = CI_low, ymax = CI_high, fill = Contrast), alpha = 0.2) +   # Add line at 0, indicating no difference   geom_hline(yintercept = 0, linetype = \"dashed\") +   # Colors   theme_modern()"},{"path":"https://easystats.github.io/modelbased/index.html","id":"create-smart-grids-to-represent-complex-interactions","dir":"","previous_headings":"Examples","what":"Create smart grids to represent complex interactions","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Problem: want graphically represent interaction two continuous variable. top , like express one terms standardized change (.e., standard deviation relative mean). Solution: Create data grid following desired specifications, feed model obtain predictions. Format columns better readability, plot using ggplot. Check-vignette detailed walkthrough visualisation matrices.","code":"# 1. Fit model and get visualization matrix model <- lm(Sepal.Length ~ Petal.Length * Petal.Width, data = iris)  # 2. Create a visualisation matrix with expected Z-score values of Petal.Width vizdata <- insight::get_datagrid(model, by = c(\"Petal.Length\", \"Petal.Width = c(-1, 0, 1)\"))  # 3. Revert from expected SD to actual values vizdata <- unstandardize(vizdata, select = \"Petal.Width\")  # 4. Add predicted relationship from the model vizdata <- modelbased::estimate_expectation(vizdata)  # 5. Express Petal.Width as z-score (\"-1 SD\", \"+2 SD\", etc.) vizdata$Petal.Width <- effectsize::format_standardize(vizdata$Petal.Width, reference = iris$Petal.Width)  # 6. Plot ggplot(iris, aes(x = Petal.Length, y = Sepal.Length)) +   # Add points from original dataset (only shapes 21-25 have a fill aesthetic)   geom_point(aes(fill = Petal.Width), size = 5, shape = 21) +   # Add relationship lines   geom_line(data = vizdata, aes(y = Predicted, color = Petal.Width), linewidth = 1) +   # Improve colors / themes   scale_color_viridis_d(direction = -1) +   scale_fill_viridis_c(guide = \"none\") +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/index.html","id":"generate-predictions-from-your-model-to-compare-it-with-original-data","dir":"","previous_headings":"Examples","what":"Generate predictions from your model to compare it with original data","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Problem: fitted different models, want intuitively visualize compare terms fit quality prediction accuracy, don’t rely abstract indices performance. Solution: can predict response variable different models plot original true response. closest points identity line (diagonal), closest perfect fit. Check-vignette detailed walkthrough predictions.","code":"# Fit model 1 and predict the response variable model1 <- lm(Petal.Length ~ Sepal.Length, data = iris) pred1 <- estimate_expectation(model1) pred1$Petal.Length <- iris$Petal.Length # Add true response  # Print first 5 lines of output head(pred1, n = 5) ## Model-based Predictions ##  ## Sepal.Length | Predicted |   SE |       95% CI | Residuals | Petal.Length ## ------------------------------------------------------------------------- ## 5.10         |      2.38 | 0.10 | [2.19, 2.57] |     -0.98 |         1.40 ## 4.90         |      2.00 | 0.11 | [1.79, 2.22] |     -0.60 |         1.40 ## 4.70         |      1.63 | 0.12 | [1.39, 1.87] |     -0.33 |         1.30 ## 4.60         |      1.45 | 0.13 | [1.19, 1.70] |      0.05 |         1.50 ## 5.00         |      2.19 | 0.10 | [1.99, 2.39] |     -0.79 |         1.40 ##  ## Variable predicted: Petal.Length  # Same for model 2 model2 <- lm(Petal.Length ~ Sepal.Length * Species, data = iris) pred2 <- estimate_expectation(model2) pred2$Petal.Length <- iris$Petal.Length   # Initialize plot for model 1 ggplot(data = pred1, aes(x = Petal.Length, y = Predicted)) +   # with identity line (diagonal) representing perfect predictions   geom_abline(linetype = \"dashed\") +   # Add the actual predicted points of the models   geom_point(aes(color = \"Model 1\")) +   geom_point(data = pred2, aes(color = \"Model 2\")) +   # Aesthetics changes   labs(y = \"Petal.Length (predicted)\", color = NULL) +   scale_color_manual(values = c(\"Model 1\" = \"blue\", \"Model 2\" = \"red\")) +   theme_modern()"},{"path":"https://easystats.github.io/modelbased/index.html","id":"extract-and-format-group-level-random-effects","dir":"","previous_headings":"Examples","what":"Extract and format group-level random effects","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Problem: mixed model like easily access random part, .e., group-level effects (e.g., individuals scores). Solution: can apply estimate_grouplevel mixed model. See vignette information.","code":"library(lme4)  model <- lmer(mpg ~ drat + (1 + drat | cyl), data = mtcars)  random <- estimate_grouplevel(model) random ## Group | Level | Parameter   | Coefficient |   SE |         95% CI ## ----------------------------------------------------------------- ## cyl   | 4     | (Intercept) |       -3.45 | 0.56 | [-4.55, -2.36] ## cyl   | 4     | drat        |        2.24 | 0.36 | [ 1.53,  2.95] ## cyl   | 6     | (Intercept) |        0.13 | 0.84 | [-1.52,  1.78] ## cyl   | 6     | drat        |       -0.09 | 0.54 | [-1.15,  0.98] ## cyl   | 8     | (Intercept) |        3.32 | 0.73 | [ 1.89,  4.74] ## cyl   | 8     | drat        |       -2.15 | 0.47 | [-3.07, -1.23]  plot(random) +   geom_hline(yintercept = 0, linetype = \"dashed\") +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/index.html","id":"estimate-derivative-of-non-linear-relationships-eg-in-gams","dir":"","previous_headings":"Examples","what":"Estimate derivative of non-linear relationships (e.g., in GAMs)","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Problem: model non-linear relationship using polynomials, splines GAMs. want know parts curve significant positive negative trends. Solution: can estimate derivative smooth using estimate_slopes. two plots represent modeled (non-linear) effect estimated model, .e., relationship outcome predictor, well “trend” (slope) relationship given point. can see whenever slope negative, effect 0, vice versa, regions effect significant (.e., positive negative enough confidence) others denote regions relationship rather flat. Check-vignette detailed walkthrough marginal effects.","code":"library(patchwork)  # Fit a non-linear General Additive Model (GAM) model <- mgcv::gam(Sepal.Width ~ s(Petal.Length), data = iris)  # 1. Compute derivatives deriv <- estimate_slopes(model,   trend = \"Petal.Length\",   by = \"Petal.Length\",   length = 200 )  # 2. Visualize predictions and derivative plot(estimate_relation(model, length = 200)) /   plot(deriv) +   geom_hline(yintercept = 0, linetype = \"dashed\")"},{"path":"https://easystats.github.io/modelbased/index.html","id":"describe-the-smooth-term-by-its-linear-parts","dir":"","previous_headings":"Examples","what":"Describe the smooth term by its linear parts","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Problem: model non-linear relationship using polynomials, splines GAMs. want describe terms linear parts: decrease, much, increase, etc. Solution: can apply describe_nonlinear() predicted relationship return different parts increase decrease.","code":"model <- lm(Sepal.Width ~ poly(Petal.Length, 2), data = iris)  # 1. Visualize vizdata <- estimate_relation(model, length = 30)  ggplot(vizdata, aes(x = Petal.Length, y = Predicted)) +   geom_ribbon(aes(ymin = CI_low, ymax = CI_high), alpha = 0.3) +   geom_line() +   # Add original data points   geom_point(data = iris, aes(x = Petal.Length, y = Sepal.Width)) +   # Aesthetics   theme_modern() # 2. Describe smooth line describe_nonlinear(vizdata, x = \"Petal.Length\") ## Start |  End | Length | Change | Slope |   R2 ## --------------------------------------------- ## 1.00  | 4.05 |   0.50 |  -0.84 | -0.28 | 0.05 ## 4.05  | 6.90 |   0.47 |   0.66 |  0.23 | 0.05"},{"path":"https://easystats.github.io/modelbased/index.html","id":"plot-all-posterior-draws-for-bayesian-models-predictions","dir":"","previous_headings":"Examples","what":"Plot all posterior draws for Bayesian models predictions","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"See vignette walkthrough .","code":""},{"path":"https://easystats.github.io/modelbased/index.html","id":"understand-interactions-between-two-continuous-variables","dir":"","previous_headings":"","what":"Understand interactions between two continuous variables","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Also referred Johnson-Neyman intervals, plot shows effect (“slope”) one variable varies depending another variable. useful case complex interactions continuous variables. instance, plot shows effect hp (y-axis) significantly negative wt low (< ~4).","code":"model <- lm(mpg ~ hp * wt, data = mtcars)  slopes <- estimate_slopes(model, trend = \"hp\", by = \"wt\", length = 200)  plot(slopes)"},{"path":"https://easystats.github.io/modelbased/index.html","id":"visualize-predictions-with-random-effects","dir":"","previous_headings":"Understand interactions between two continuous variables","what":"Visualize predictions with random effects","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Aside plotting coefficient random effect (done ), can also visualize predictions model levels, can useful diagnostic see contribute fixed effects. making predictions estimate_relation() setting include_random TRUE. Let’s model reaction time number days sleep deprivation fixed effect participants random intercept.  can see, participant different “intercept” (starting point y-axis), slopes : slope “general” one estimated across participants fixed effect. Let’s address allow slope vary participant .  can see, effect now different participants. Let’s plot, top , “fixed” effect estimated across individual effects.","code":"library(lme4)  model <- lmer(Reaction ~ Days + (1 | Subject), data = sleepstudy)  preds <- estimate_relation(model, include_random = TRUE)  plot(preds, ribbon = list(alpha = 0)) # Make CI ribbon transparent for clarity model <- lmer(Reaction ~ Days + (1 + Days | Subject), data = sleepstudy)  preds <- estimate_relation(model, include_random = TRUE)  plot(preds, ribbon = list(alpha = 0.1)) fixed_pred <- estimate_relation(model) # This time, include_random is FALSE (default)  plot(preds, ribbon = list(alpha = 0)) + # Previous plot   geom_ribbon(data = fixed_pred, aes(x = Days, ymin = CI_low, ymax = CI_high), alpha = 0.4) +   geom_line(data = fixed_pred, aes(x = Days, y = Predicted), linewidth = 2)"},{"path":"https://easystats.github.io/modelbased/index.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Please note modelbased project released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"https://easystats.github.io/modelbased/reference/coffee_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample dataset from a course about analysis of factorial designs — coffee_data","title":"Sample dataset from a course about analysis of factorial designs — coffee_data","text":"sample data set course analysis factorial designs, Mattan S. Ben-Shachar. See following link information: https://github.com/mattansb/Analysis--Factorial-Designs--Psychologists data consists five variables 120 observations: ID: unique identifier participant sex: participant's sex time: time day participant tested (morning, noon, afternoon) coffee: Group indicator, whether participant drank coffee (\"coffee\" \"control\"). alertness: participant's alertness score.","code":""},{"path":"https://easystats.github.io/modelbased/reference/describe_nonlinear.html","id":null,"dir":"Reference","previous_headings":"","what":"Describe the smooth term (for GAMs) or non-linear predictors — describe_nonlinear","title":"Describe the smooth term (for GAMs) or non-linear predictors — describe_nonlinear","text":"function summarises smooth term trend terms linear segments. Using approximate derivative, separates non-linear vector quasi-linear segments (trend either positive negative). segment characterized beginning, end, size (proportion, relative total size) trend (linear regression coefficient) linearity (R2 linear regression).","code":""},{"path":"https://easystats.github.io/modelbased/reference/describe_nonlinear.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Describe the smooth term (for GAMs) or non-linear predictors — describe_nonlinear","text":"","code":"describe_nonlinear(data, ...)  # S3 method for class 'data.frame' describe_nonlinear(data, x = NULL, y = NULL, ...)  estimate_smooth(data, ...)"},{"path":"https://easystats.github.io/modelbased/reference/describe_nonlinear.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Describe the smooth term (for GAMs) or non-linear predictors — describe_nonlinear","text":"data data containing link, instance obtained estimate_relation(). ... arguments passed . x, y name responses variable (y) predicting variable (x).","code":""},{"path":"https://easystats.github.io/modelbased/reference/describe_nonlinear.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Describe the smooth term (for GAMs) or non-linear predictors — describe_nonlinear","text":"data frame linear description non-linear terms.","code":""},{"path":"https://easystats.github.io/modelbased/reference/describe_nonlinear.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Describe the smooth term (for GAMs) or non-linear predictors — describe_nonlinear","text":"","code":"# Create data data <- data.frame(x = rnorm(200)) data$y <- data$x^2 + rnorm(200, 0, 0.5)  model <<- lm(y ~ poly(x, 2), data = data) link_data <- estimate_relation(model, length = 100)  describe_nonlinear(link_data, x = \"x\") #> Start |   End | Length | Change | Slope |   R2 #> ---------------------------------------------- #> -2.61 | -0.06 |   0.47 |  -6.57 | -2.58 | 0.02 #> -0.06 |  2.75 |   0.52 |   7.55 |  2.68 | 0.02"},{"path":"https://easystats.github.io/modelbased/reference/dot-uniroot.all.html","id":null,"dir":"Reference","previous_headings":"","what":"Copied from rootSolve package — .uniroot.all","title":"Copied from rootSolve package — .uniroot.all","text":"Copied rootSolve package","code":""},{"path":"https://easystats.github.io/modelbased/reference/dot-uniroot.all.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Copied from rootSolve package — .uniroot.all","text":"","code":".uniroot.all(   f,   interval,   lower = min(interval),   upper = max(interval),   tol = .Machine$double.eps^0.2,   maxiter = 1000,   n = 100,   ... )"},{"path":"https://easystats.github.io/modelbased/reference/efc.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample dataset from the EFC Survey — efc","title":"Sample dataset from the EFC Survey — efc","text":"Selected variables EUROFAMCARE survey. Useful testing \"real-life\" data sets, including random missing values. data set also value variable label attributes.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_contrasts.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Marginal Contrasts — estimate_contrasts","title":"Estimate Marginal Contrasts — estimate_contrasts","text":"Run contrast analysis estimating differences level factor. See also related functions estimate_means() estimate_slopes().","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_contrasts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Marginal Contrasts — estimate_contrasts","text":"","code":"estimate_contrasts(model, ...)  # Default S3 method estimate_contrasts(   model,   contrast = NULL,   by = NULL,   predict = NULL,   ci = 0.95,   comparison = \"pairwise\",   estimate = NULL,   p_adjust = \"none\",   transform = NULL,   keep_iterations = FALSE,   effectsize = NULL,   iterations = 200,   es_type = \"cohens.d\",   backend = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/modelbased/reference/estimate_contrasts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Marginal Contrasts — estimate_contrasts","text":"model statistical model. ... arguments passed, instance, insight::get_datagrid(), functions emmeans marginaleffects package, process Bayesian models via bayestestR::describe_posterior(). Examples: insight::get_datagrid(): Argument length, digits range can used control (number ) representative values. integer variables, protect_integers modulates whether also treated numerics, .e. values can fractions . marginaleffects: Internally used functions avg_predictions() means contrasts, avg_slope() slopes. Therefore, arguments instance like vcov, equivalence, df, slope even newdata can passed functions. weights argument passed wts argument avg_predictions() avg_slopes(), however, weights can applied estimate \"average\" \"population\" (.e. marginalization options use data grids). arguments, re.form allow.new.levels, may passed predict() (internally used marginaleffects) supported model class. emmeans: Internally used functions emmeans() emtrends(). Additional arguments can passed functions. Bayesian models: Bayesian models, parameters cleaned using describe_posterior(), thus, arguments like, example, centrality, rope_range, test passed function. Especially estimate_contrasts() integer focal predictors, contrasts calculated, use argument integer_as_numeric set maximum number unique values integer predictor treat predictor \"discrete integer\" numeric. first case, contrasts calculated values predictor, latter, contrasts slopes calculated. integer integer_as_numeric unique values, treated numeric. Defaults 5. contrast character vector indicating name variable(s) compute contrasts, optionally including representative values levels contrasts evaluated (e.g., contrast=\"x=c('','b')\"). (focal) predictor variable(s) evaluate desired effect / mean / contrasts. predictors model included collapsed \"averaged\" (effect estimated across ). can character (vector) naming focal predictors, optionally including representative values levels focal predictors evaluated (e.g., = \"x = c(1, 2)\"). estimate \"average\", argument used create \"reference grid\" \"data grid\" representative values focal predictors. case, can also list named elements. See details insight::get_datagrid() learn create data grids predictors interest. predict passed type argument emmeans::emmeans() (backend = \"emmeans\") marginaleffects::avg_predictions() (backend = \"marginaleffects\"). Valid options predict : backend = \"marginaleffects\": predict can \"response\", \"link\", \"inverse_link\" valid type option supported model's class predict() method (e.g., zero-inflation models package glmmTMB, can choose predict = \"zprob\" predict = \"conditional\" etc., see glmmTMB::predict.glmmTMB). default, predict = NULL, appropriate transformation selected, usually returns predictions contrasts response-scale. \"inverse_link\" special option, comparable marginaleffects' invlink(link) option. calculate predictions link scale back-transform response scale. backend = \"emmeans\": predict can \"response\", \"link\", \"mu\", \"unlink\", \"log\". predict = NULL (default), appropriate transformation selected (usually \"response\"). See also vignette. See also section Predictions different scales. ci Confidence Interval (CI) level. Default 0.95 (95%). comparison Specify type contrasts tests carried . backend = \"emmeans\", can one \"pairwise\", \"poly\", \"consec\", \"eff\", \"del.eff\", \"mean_chg\", \"trt.vs.ctrl\", \"dunnett\", \"wtcon\" . See also method argument emmeans::contrast ?emmeans::emmc-functions. backend = \"marginaleffects\", can numeric value, vector, matrix, string equation specifying hypothesis test, string naming comparison method, formula, function. Strings, string equations formula probably common options described . options detailed descriptions options, see also marginaleffects::comparisons website. String: One \"pairwise\", \"reference\", \"sequential\", \"meandev\" \"meanotherdev\", \"poly\", \"helmert\", \"trt_vs_ctrl\". String equation: identify parameters output, either specify term name, \"b1\", \"b2\" etc. indicate rows, e.g.:\"hp = drat\", \"b1 = b2\", \"b1 + b2 + b3 = 0\". Formula: formula like comparison ~ pairs | group, left-hand side indicates type comparison (difference ratio), right-hand side determines pairs estimates compare (reference, sequential, meandev, etc., see string-options). Optionally, comparisons can carried within subsets indicating grouping variable vertical bar ( |). estimate estimate argument determines predictions averaged (\"marginalized\") variables specified contrast (non-focal predictors). controls whether predictions represent \"typical\" individual, \"average\" individual sample, \"average\" individual broader population. \"typical\" (Default): Calculates predictions balanced data grid representing combinations focal predictor levels (specified ). non-focal numeric predictors, uses mean; non-focal categorical predictors, marginalizes (averages) levels. represents \"typical\" observation based data grid useful comparing groups. answers: \"average outcome 'typical' observation?\". default approach estimating marginal means using emmeans package. \"average\": Calculates predictions observation sample averages predictions within group defined focal predictors. reflects sample's actual distribution non-focal predictors, balanced grid. answers: \"predicted value average observation data?\" \"population\": \"Clones\" observation, creating copies possible combinations focal predictor levels. averages predictions across \"counterfactual\" observations (non-observed permutations) within group. extrapolates hypothetical broader population, considering \"\" scenarios. answers: \"predicted response 'average' observation broader possible target population?\" approach entails assumptions likelihood different combinations, can apt generalize. also option used G-computation (Chatton Rohrer 2024). can set default option estimate argument via options(), e.g. options(modelbased_estimate = \"average\") p_adjust p-values adjustment method frequentist multiple comparisons. Can one \"none\" (default), \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"\", \"fdr\", \"tukey\", \"sidak\", \"esarey\" \"holm\". \"esarey\" option specifically case Johnson-Neyman intervals, .e. calling estimate_slopes() two numeric predictors interaction term. Details options can found p-value adjustment section emmeans::test documentation ?stats::p.adjust. transform function applied predictions confidence intervals (back-) transform results, can useful case regression model transformed response variable (e.g., lm(log(y) ~ x)). Bayesian models, function applied individual draws posterior distribution, computing summaries. Can also TRUE, case insight::get_transformation() called determine appropriate transformation-function. Note standard errors returned transformations applied. keep_iterations TRUE, keep iterations (draws) bootstrapped Bayesian models. added additional columns named iter_1, iter_2, . keep_iterations positive number, many columns indicated keep_iterations added output. can reshape long format running bayestestR::reshape_iterations(). effectsize Desired measure standardized effect size, one \"emmeans\", \"marginal\", \"boot\". Default NULL, .e. effect size computed. iterations number bootstrap resamples perform. es_type Specifies type effect-size measure estimate using effectsize = \"boot\". One \"unstandardized\", \"cohens.d\", \"hedges.g\", \"cohens.d.sigma\", \"r\", \"akp.robust.d\". See effect.type argument bootES::bootES details. backend Whether use \"marginaleffects\" (default) \"emmeans\" backend. Results usually similar. major difference found mixed models, backend = \"marginaleffects\" also average across random effects levels, producing \"marginal predictions\" (instead \"conditional predictions\", see Heiss 2022). Another difference backend = \"marginaleffects\" slower backend = \"emmeans\". models, difference negligible. However, particular complex models large data sets fitted glmmTMB can significantly slower. can set default backend via options(), e.g. use options(modelbased_backend = \"emmeans\") use emmeans package options(modelbased_backend = \"marginaleffects\") set marginaleffects default backend. verbose Use FALSE silence messages warnings.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_contrasts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Marginal Contrasts — estimate_contrasts","text":"data frame estimated contrasts.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_contrasts.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate Marginal Contrasts — estimate_contrasts","text":"estimate_slopes(), estimate_means() estimate_contrasts() functions forming group, based marginal estimations (estimations based model). three built emmeans marginaleffects package (depending backend argument), reading documentation (instance emmeans::emmeans(), emmeans::emtrends() website) recommended understand idea behind types procedures. Model-based predictions basis follows. Indeed, first thing understand models can used make predictions (see estimate_link()). corresponds predicted response (\"outcome variable\") given specific predictor values predictors (.e., given specific data configuration). concept reference grid() important direct predictions. Marginal \"means\", obtained via estimate_means(), extension predictions, allowing \"average\" (collapse) predictors, obtain average response value specific predictors configuration. typically used predictors interest factors. Indeed, parameters model usually give intercept value \"effect\" factor level (different intercept). Marginal means can used directly give mean value response variable levels factor. Moreover, can also used control, average predictors, useful case multiple predictors without interactions. Marginal contrasts, obtained via estimate_contrasts(), extension marginal means, allow investigate difference (.e., contrast) marginal means. , , often used get pairwise differences levels factor. works also continuous predictors, instance one also interested whether difference two extremes continuous predictor significant. Finally, marginal effects, obtained via estimate_slopes(), different focus values response variable, model's parameters. idea assess effect predictor specific configuration predictors. relevant case interactions non-linear relationships, effect predictor variable changes depending predictors. Moreover, effects can also \"averaged\" predictors, get instance \"general trend\" predictor different factor levels. Example: imagine following model lm(y ~ condition * x) condition factor 3 levels , B C x continuous variable (like age example). One idea see model performs, compare actual response y one predicted model (using estimate_expectation()). Another idea evaluate average mean condition's levels (using estimate_means()), can useful visualize . Another possibility evaluate difference levels (using estimate_contrasts()). Finally, one also estimate effect x averaged conditions, instead within condition (using [estimate_slopes]).","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_contrasts.html","id":"effect-size","dir":"Reference","previous_headings":"","what":"Effect Size","title":"Estimate Marginal Contrasts — estimate_contrasts","text":"default, estimate_contrasts() reports standardized effect size purpose. one request one, things keep mind. authors emmeans write, \"substantial disagreement among practitioners appropriate sigma use computing effect sizes; , indeed, whether effect-size measure appropriate situations. user completely responsible specifying appropriate parameters (failing ).\" particular, effect size method \"boot\" correct covariates model, probably used just one categorical predictor (however many levels). believe multiple predictors covariates, important re-compute sigma adding back response variance associated variables part contrast. effectsize = \"emmeans\" uses emmeans::eff_size sigma = stats::sigma(model), edf = stats::df.residual(model) method = \"identity\". standardizes using MSE (sigma). believe works contrasts predictors model, covariates. response variance accounted covariates removed SD used standardize. Otherwise, d overestimated. effectsize = \"marginal\" uses following formula compute effect size: d_adj <- difference * (1- R2)/ sigma. standardizes using response SD -groups variance focal factor/contrast removed. allows groups equated covariates, creates appropriate scale standardizing response. effectsize = \"boot\" uses bootstrapping (defaults low value 200) bootES::bootES. Adjusts contrasts, covariates.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_contrasts.html","id":"predictions-and-contrasts-at-meaningful-values-data-grids-","dir":"Reference","previous_headings":"","what":"Predictions and contrasts at meaningful values (data grids)","title":"Estimate Marginal Contrasts — estimate_contrasts","text":"define representative values focal predictors (specified , contrast, trend), can use several methods. values internally generated insight::get_datagrid(), consult documentation details. can directly specify values strings lists , contrast, trend. numeric focal predictors, use examples like = \"gear = c(4, 8)\", = list(gear = c(4, 8)) = \"gear = 5:10\" factor character predictors, use = \"Species = c('setosa', 'virginica')\" = list(Species = c('setosa', 'virginica')) can use \"shortcuts\" within square brackets, = \"Sepal.Width = [sd]\" = \"Sepal.Width = [fivenum]\" numeric focal predictors, representative values specified, length range control number type representative values: length determines many equally spaced values generated. range specifies type values, like \"range\" \"sd\". length range apply numeric focal predictors. multiple numeric predictors, length range can accept multiple elements, one predictor. integer variables, values appear data included data grid, independent length argument. behaviour can changed setting protect_integers = FALSE, treat integer variables numerics (possibly produce fractions). See also vignette examples.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_contrasts.html","id":"predictions-on-different-scales","dir":"Reference","previous_headings":"","what":"Predictions on different scales","title":"Estimate Marginal Contrasts — estimate_contrasts","text":"predict argument allows generate predictions different scales response variable. \"link\" option apply models, usually Gaussian models. \"link\" leave values scale linear predictors. \"response\" (NULL) transform scale response variable. Thus logistic model, \"link\" give estimations expressed log-odds (probabilities logit scale) \"response\" terms probabilities. predict distributional parameters (called \"dpar\" packages), instance using complex formulae brms models, predict argument can take value parameter want estimate, instance \"sigma\", \"kappa\", etc. \"response\" \"inverse_link\" return predictions response scale, however, \"response\" first calculates predictions response scale observation aggregates groups levels defined . \"inverse_link\" first calculates predictions link scale observation, aggregates groups levels defined , finally back-transforms predictions response scale. approaches advantages disadvantages. \"response\" usually produces less biased predictions, confidence intervals might outside reasonable bounds (.e., instance can negative count data). \"inverse_link\" approach robust terms confidence intervals, might produce biased predictions. However, can try set bias_correction = TRUE, adjust bias. particular mixed models, using \"response\" recommended, averaging across random effects groups accurate.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_contrasts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Marginal Contrasts — estimate_contrasts","text":"","code":"# \\dontrun{ # Basic usage model <- lm(Sepal.Width ~ Species, data = iris) estimate_contrasts(model) #> We selected `contrast=c(\"Species\")`. #> Marginal Contrasts Analysis #>  #> Level1     | Level2     | Difference |   SE |         95% CI | t(147) |      p #> ------------------------------------------------------------------------------ #> versicolor | setosa     |      -0.66 | 0.07 | [-0.79, -0.52] |  -9.69 | < .001 #> virginica  | setosa     |      -0.45 | 0.07 | [-0.59, -0.32] |  -6.68 | < .001 #> virginica  | versicolor |       0.20 | 0.07 | [ 0.07,  0.34] |   3.00 |  0.003 #>  #> Variable predicted: Sepal.Width #> Predictors contrasted: Species #> p-values are uncorrected. #>   # Dealing with interactions model <- lm(Sepal.Width ~ Species * Petal.Width, data = iris)  # By default: selects first factor estimate_contrasts(model) #> We selected `contrast=c(\"Species\")`. #> Marginal Contrasts Analysis #>  #> Level1     | Level2     | Difference |   SE |         95% CI | t(144) |      p #> ------------------------------------------------------------------------------ #> versicolor | setosa     |      -1.59 | 0.39 | [-2.37, -0.81] |  -4.04 | < .001 #> virginica  | setosa     |      -1.77 | 0.41 | [-2.59, -0.96] |  -4.29 | < .001 #> virginica  | versicolor |      -0.18 | 0.15 | [-0.47,  0.10] |  -1.27 |  0.205 #>  #> Variable predicted: Sepal.Width #> Predictors contrasted: Species #> Predictors averaged: Petal.Width (1.2) #> p-values are uncorrected. #>   # Can also run contrasts between points of numeric, stratified by \"Species\" estimate_contrasts(model, contrast = \"Petal.Width\", by = \"Species\") #> Marginal Contrasts Analysis #>  #> Level1     | Level2     | Difference |   SE |        95% CI |     t |     p #> --------------------------------------------------------------------------- #> versicolor | setosa     |       0.22 | 0.46 | [-0.69, 1.12] |  0.47 | 0.639 #> virginica  | setosa     |      -0.21 | 0.44 | [-1.06, 0.65] | -0.47 | 0.637 #> virginica  | versicolor |      -0.42 | 0.27 | [-0.95, 0.10] | -1.58 | 0.114 #>  #> Variable predicted: Sepal.Width #> Predictors contrasted: Petal.Width #> Predictors averaged: Petal.Width (1.2) #> p-values are uncorrected. #>   # Or both estimate_contrasts(model, contrast = c(\"Species\", \"Petal.Width\"), length = 2) #> Marginal Contrasts Analysis #>  #> Level1          | Level2          | Difference |   SE |         95% CI | t(144) |      p #> ---------------------------------------------------------------------------------------- #> setosa, 2.5     | setosa, 0.1     |       2.01 | 0.98 | [ 0.08,  3.94] |   2.06 |  0.041 #> versicolor, 0.1 | setosa, 0.1     |      -1.83 | 0.28 | [-2.38, -1.28] |  -6.55 | < .001 #> versicolor, 2.5 | setosa, 0.1     |       0.70 | 0.27 | [ 0.17,  1.23] |   2.61 |  0.010 #> virginica, 0.1  | setosa, 0.1     |      -1.55 | 0.31 | [-2.17, -0.93] |  -4.95 | < .001 #> virginica, 2.5  | setosa, 0.1     |      -0.03 | 0.11 | [-0.25,  0.19] |  -0.29 |  0.773 #> versicolor, 0.1 | setosa, 2.5     |      -3.84 | 0.96 | [-5.73, -1.95] |  -4.01 | < .001 #> versicolor, 2.5 | setosa, 2.5     |      -1.31 | 0.95 | [-3.19,  0.58] |  -1.37 |  0.172 #> virginica, 0.1  | setosa, 2.5     |      -3.56 | 0.97 | [-5.47, -1.65] |  -3.68 | < .001 #> virginica, 2.5  | setosa, 2.5     |      -2.04 | 0.92 | [-3.86, -0.22] |  -2.21 |  0.028 #> versicolor, 2.5 | versicolor, 0.1 |       2.53 | 0.52 | [ 1.50,  3.56] |   4.86 | < .001 #> virginica, 0.1  | versicolor, 0.1 |       0.28 | 0.41 | [-0.52,  1.08] |   0.69 |  0.492 #> virginica, 2.5  | versicolor, 0.1 |       1.80 | 0.28 | [ 1.24,  2.35] |   6.35 | < .001 #> virginica, 0.1  | versicolor, 2.5 |      -2.25 | 0.40 | [-3.04, -1.46] |  -5.64 | < .001 #> virginica, 2.5  | versicolor, 2.5 |      -0.73 | 0.27 | [-1.27, -0.20] |  -2.70 |  0.008 #> virginica, 2.5  | virginica, 0.1  |       1.52 | 0.37 | [ 0.77,  2.26] |   4.04 | < .001 #>  #> Variable predicted: Sepal.Width #> Predictors contrasted: Species, Petal.Width #> p-values are uncorrected. #>   # Or with custom specifications estimate_contrasts(model, contrast = c(\"Species\", \"Petal.Width = c(1, 2)\")) #> Marginal Contrasts Analysis #>  #> Level1        | Level2        | Difference |   SE |         95% CI | t(144) |      p #> ------------------------------------------------------------------------------------ #> setosa, 2     | setosa, 1     |       0.84 | 0.41 | [ 0.03,  1.64] |   2.06 |  0.041 #> versicolor, 1 | setosa, 1     |      -1.63 | 0.32 | [-2.27, -1.00] |  -5.09 | < .001 #> versicolor, 2 | setosa, 1     |      -0.58 | 0.35 | [-1.26,  0.10] |  -1.68 |  0.096 #> virginica, 1  | setosa, 1     |      -1.73 | 0.35 | [-2.43, -1.04] |  -4.93 | < .001 #> virginica, 2  | setosa, 1     |      -1.10 | 0.31 | [-1.72, -0.48] |  -3.52 | < .001 #> versicolor, 1 | setosa, 2     |      -2.47 | 0.72 | [-3.89, -1.05] |  -3.43 | < .001 #> versicolor, 2 | setosa, 2     |      -1.42 | 0.73 | [-2.86,  0.03] |  -1.94 |  0.055 #> virginica, 1  | setosa, 2     |      -2.57 | 0.73 | [-4.02, -1.12] |  -3.50 | < .001 #> virginica, 2  | setosa, 2     |      -1.94 | 0.72 | [-3.35, -0.52] |  -2.71 |  0.008 #> versicolor, 2 | versicolor, 1 |       1.05 | 0.22 | [ 0.62,  1.48] |   4.86 | < .001 #> virginica, 1  | versicolor, 1 |      -0.10 | 0.19 | [-0.47,  0.27] |  -0.54 |  0.589 #> virginica, 2  | versicolor, 1 |       0.53 | 0.09 | [ 0.35,  0.71] |   5.72 | < .001 #> virginica, 1  | versicolor, 2 |      -1.15 | 0.23 | [-1.60, -0.71] |  -5.13 | < .001 #> virginica, 2  | versicolor, 2 |      -0.52 | 0.16 | [-0.84, -0.21] |  -3.31 |  0.001 #> virginica, 2  | virginica, 1  |       0.63 | 0.16 | [ 0.32,  0.94] |   4.04 | < .001 #>  #> Variable predicted: Sepal.Width #> Predictors contrasted: Species, Petal.Width = c(1, 2) #> p-values are uncorrected. #>   # Or modulate it estimate_contrasts(model, by = \"Petal.Width\", length = 4) #> We selected `contrast=c(\"Species\")`. #> Marginal Contrasts Analysis #>  #> Level1     | Level2     | Petal.Width | Difference |   SE |         95% CI #> -------------------------------------------------------------------------- #> versicolor | setosa     |        0.10 |      -1.83 | 0.28 | [-2.38, -1.28] #> virginica  | setosa     |        0.10 |      -1.55 | 0.31 | [-2.17, -0.93] #> virginica  | versicolor |        0.10 |       0.28 | 0.41 | [-0.52,  1.08] #> versicolor | setosa     |        0.90 |      -1.65 | 0.29 | [-2.22, -1.08] #> virginica  | setosa     |        0.90 |      -1.71 | 0.32 | [-2.35, -1.07] #> virginica  | versicolor |        0.90 |      -0.06 | 0.21 | [-0.47,  0.35] #> versicolor | setosa     |        1.70 |      -1.48 | 0.60 | [-2.67, -0.29] #> virginica  | setosa     |        1.70 |      -1.88 | 0.60 | [-3.06, -0.70] #> virginica  | versicolor |        1.70 |      -0.40 | 0.11 | [-0.62, -0.17] #> versicolor | setosa     |        2.50 |      -1.31 | 0.95 | [-3.19,  0.58] #> virginica  | setosa     |        2.50 |      -2.04 | 0.92 | [-3.86, -0.22] #> virginica  | versicolor |        2.50 |      -0.73 | 0.27 | [-1.27, -0.20] #>  #> Level1     | t(144) |      p #> ---------------------------- #> versicolor |  -6.55 | < .001 #> virginica  |  -4.95 | < .001 #> virginica  |   0.69 |  0.492 #> versicolor |  -5.74 | < .001 #> virginica  |  -5.28 | < .001 #> virginica  |  -0.28 |  0.780 #> versicolor |  -2.47 |  0.015 #> virginica  |  -3.14 |  0.002 #> virginica  |  -3.50 | < .001 #> versicolor |  -1.37 |  0.172 #> virginica  |  -2.21 |  0.028 #> virginica  |  -2.70 |  0.008 #>  #> Variable predicted: Sepal.Width #> Predictors contrasted: Species #> p-values are uncorrected. #>   # Standardized differences estimated <- estimate_contrasts(lm(Sepal.Width ~ Species, data = iris)) #> We selected `contrast=c(\"Species\")`. standardize(estimated) #> Marginal Contrasts Analysis (standardized) #>  #> Level1     | Level2     | Difference |   SE |         95% CI | t(147) |      p #> ------------------------------------------------------------------------------ #> versicolor | setosa     |      -1.51 | 0.16 | [-1.82, -1.20] |  -9.69 | < .001 #> virginica  | setosa     |      -1.04 | 0.16 | [-1.35, -0.73] |  -6.68 | < .001 #> virginica  | versicolor |       0.47 | 0.16 | [ 0.16,  0.78] |   3.00 |  0.003 #>  #> Variable predicted: Sepal.Width #> Predictors contrasted: Species #> p-values are uncorrected. #>   # Other models (mixed, Bayesian, ...) data <- iris data$Petal.Length_factor <- ifelse(data$Petal.Length < 4.2, \"A\", \"B\")  model <- lme4::lmer(Sepal.Width ~ Species + (1 | Petal.Length_factor), data = data) estimate_contrasts(model) #> We selected `contrast=c(\"Species\")`. #> Marginal Contrasts Analysis #>  #> Level1     | Level2     | Difference |   SE |         95% CI | t(145) |      p #> ------------------------------------------------------------------------------ #> versicolor | setosa     |      -0.87 | 0.09 | [-1.04, -0.70] | -10.11 | < .001 #> virginica  | setosa     |      -0.80 | 0.11 | [-1.02, -0.58] |  -7.11 | < .001 #> virginica  | versicolor |       0.07 | 0.07 | [-0.07,  0.22] |   1.00 |  0.319 #>  #> Variable predicted: Sepal.Width #> Predictors contrasted: Species #> Predictors averaged: Petal.Length_factor #> p-values are uncorrected. #>   data <- mtcars data$cyl <- as.factor(data$cyl) data$am <- as.factor(data$am)  model <- rstanarm::stan_glm(mpg ~ cyl * wt, data = data, refresh = 0) estimate_contrasts(model) #> We selected `contrast=c(\"cyl\")`. #> Marginal Contrasts Analysis #>  #> Level1 | Level2 | Median |         95% CI |     pd |          ROPE | % in ROPE #> ------------------------------------------------------------------------------ #> 6      | 4      |  -2.23 | [-5.90,  1.34] | 89.40% | [-0.10, 0.10] |     2.13% #> 8      | 4      |  -4.82 | [-8.43, -1.18] | 99.33% | [-0.10, 0.10] |        0% #> 8      | 6      |  -2.55 | [-5.35,  0.21] | 96.70% | [-0.10, 0.10] |     1.08% #>  #> Variable predicted: mpg #> Predictors contrasted: cyl #> Predictors averaged: wt (3.2) #>  estimate_contrasts(model, by = \"wt\", length = 4) #> We selected `contrast=c(\"cyl\")`. #> Marginal Contrasts Analysis #>  #> Level1 | Level2 |   wt | Median |          95% CI |     pd |          ROPE | % in ROPE #> -------------------------------------------------------------------------------------- #> 6      | 4      | 1.51 |  -6.05 | [-14.94,  3.33] | 89.90% | [-0.10, 0.10] |     0.89% #> 8      | 4      | 1.51 | -10.01 | [-15.18, -4.77] |   100% | [-0.10, 0.10] |        0% #> 8      | 6      | 1.51 |  -3.95 | [-14.47,  5.84] | 79.67% | [-0.10, 0.10] |     1.18% #> 6      | 4      | 2.82 |  -3.16 | [ -6.41,  0.25] | 96.53% | [-0.10, 0.10] |     0.95% #> 8      | 4      | 2.82 |  -6.05 | [ -9.35, -2.62] | 99.90% | [-0.10, 0.10] |        0% #> 8      | 6      | 2.82 |  -2.86 | [ -6.63,  0.64] | 94.75% | [-0.10, 0.10] |     1.16% #> 6      | 4      | 4.12 |  -0.22 | [ -8.12,  7.44] | 52.05% | [-0.10, 0.10] |     1.87% #> 8      | 4      | 4.12 |  -2.01 | [ -7.48,  3.29] | 77.53% | [-0.10, 0.10] |     1.95% #> 8      | 6      | 4.12 |  -1.80 | [ -7.61,  4.26] | 73.22% | [-0.10, 0.10] |     2.13% #> 6      | 4      | 5.42 |   2.75 | [-12.82, 17.23] | 63.82% | [-0.10, 0.10] |     0.97% #> 8      | 4      | 5.42 |   1.99 | [ -7.20, 10.88] | 67.45% | [-0.10, 0.10] |     1.61% #> 8      | 6      | 5.42 |  -0.62 | [-13.32, 12.49] | 54.65% | [-0.10, 0.10] |     1.42% #>  #> Variable predicted: mpg #> Predictors contrasted: cyl #>   model <- rstanarm::stan_glm(   Sepal.Width ~ Species + Petal.Width + Petal.Length,   data = iris,   refresh = 0 ) estimate_contrasts(model, by = \"Petal.Length = [sd]\", test = \"bf\") #> We selected `contrast=c(\"Species\")`. #> Marginal Contrasts Analysis #>  #> Level1     | Level2     |   BF | Petal.Length | Median |         95% CI #> ----------------------------------------------------------------------- #> versicolor | setosa     | 1.00 |         1.99 |  -1.73 | [-2.09, -1.38] #> virginica  | setosa     | 1.00 |         1.99 |  -2.15 | [-2.68, -1.64] #> virginica  | versicolor | 1.00 |         1.99 |  -0.42 | [-0.63, -0.21] #> versicolor | setosa     | 1.00 |         3.76 |  -1.73 | [-2.09, -1.38] #> virginica  | setosa     | 1.00 |         3.76 |  -2.15 | [-2.68, -1.64] #> virginica  | versicolor | 1.00 |         3.76 |  -0.42 | [-0.63, -0.21] #> versicolor | setosa     | 1.00 |         5.52 |  -1.73 | [-2.09, -1.38] #> virginica  | setosa     | 1.00 |         5.52 |  -2.15 | [-2.68, -1.64] #> virginica  | versicolor | 1.00 |         5.52 |  -0.42 | [-0.63, -0.21] #>  #> Variable predicted: Sepal.Width #> Predictors contrasted: Species #> Predictors averaged: Petal.Width (1.2) #>  # }"},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":null,"dir":"Reference","previous_headings":"","what":"Model-based predictions — estimate_expectation","title":"Model-based predictions — estimate_expectation","text":"fitting model, useful generate model-based estimates response variables different combinations predictor values. estimates can used make inferences relationships variables, make predictions individual cases, compare predicted values observed data. modelbased package includes 4 \"related\" functions, mostly differ default arguments (particular, data predict): estimate_prediction(data = NULL, predict = \"prediction\", ...) estimate_expectation(data = NULL, predict = \"expectation\", ...) estimate_relation(data = \"grid\", predict = \"expectation\", ...) estimate_link(data = \"grid\", predict = \"link\", ...) based model-based predictions (using insight::get_predicted()), differ terms type predictions make default. instance, estimate_prediction() estimate_expectation() return predictions original data used fit model, estimate_relation() estimate_link() return predictions insight::get_datagrid(). Similarly, estimate_link returns predictions link scale, others return predictions response scale. Note relevance differences depends model family (instance, linear models, estimate_relation equivalent estimate_link(), since difference link-scale response scale). Note can run plot() output functions get visual insights (see plotting examples). See details section details different possibilities.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model-based predictions — estimate_expectation","text":"","code":"estimate_expectation(   model,   data = NULL,   by = NULL,   predict = \"expectation\",   ci = 0.95,   transform = NULL,   iterations = NULL,   keep_iterations = FALSE,   ... )  estimate_link(   model,   data = \"grid\",   by = NULL,   predict = \"link\",   ci = 0.95,   transform = NULL,   iterations = NULL,   keep_iterations = FALSE,   ... )  estimate_prediction(   model,   data = NULL,   by = NULL,   predict = \"prediction\",   ci = 0.95,   transform = NULL,   iterations = NULL,   keep_iterations = FALSE,   ... )  estimate_relation(   model,   data = \"grid\",   by = NULL,   predict = \"expectation\",   ci = 0.95,   transform = NULL,   iterations = NULL,   keep_iterations = FALSE,   ... )"},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model-based predictions — estimate_expectation","text":"model statistical model. data data frame model's predictors estimate response. NULL, model's data used. \"grid\", model matrix obtained (insight::get_datagrid()). predictor variable(s) estimate response. predictors model included set mean value (numeric predictors), reference level (factors) mode (types). argument used create data grid via insight::get_datagrid(), used data argument. Thus, specify data two arguments. predict parameter controls predicted (gets internally passed insight::get_predicted()). cases, need care : changed automatically according different predicting functions (.e., estimate_expectation(), estimate_prediction(), estimate_link() estimate_relation()). time might interested manually changing estimate distributional parameters (called \"dpar\" packages) - instance using complex formulae brms models. predict argument can set parameter want estimate, instance \"sigma\", \"kappa\", etc. Note distinction \"expectation\", \"link\" \"prediction\" apply (directly predicting value distributional parameter), corresponding functions differ default value data argument. ci Confidence Interval (CI) level. Default 0.95 (95%). transform function applied predictions confidence intervals (back-) transform results, can useful case regression model transformed response variable (e.g., lm(log(y) ~ x)). Can also TRUE, case insight::get_transformation() called determine appropriate transformation-function. Note standard errors returned transformations applied. iterations Bayesian models, corresponds number posterior draws. NULL, use draws (one iteration model). frequentist models, NULL, generate bootstrapped draws, bootstrapped CIs computed. Use keep_iterations control many draws included returned output (data frame), can used, instance, plotting. keep_iterations TRUE, keep iterations (draws) bootstrapped Bayesian models. added additional columns named iter_1, iter_2, . keep_iterations positive number, many columns indicated keep_iterations added output. can reshape long format running bayestestR::reshape_iterations(). ... can add additional control arguments insight::get_datagrid() (used data = \"grid\") insight::get_predicted().","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model-based predictions — estimate_expectation","text":"data frame predicted values uncertainty intervals, class \"estimate_predicted\". Methods visualisation_recipe() plot() available.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Model-based predictions — estimate_expectation","text":"functions built top insight::get_predicted() correspond different specifications parameters. may useful read documentation, particular description predict argument additional details difference expected vs. predicted values link vs. response scales. Additional control parameters can used control results insight::get_datagrid() (data = \"grid\") insight::get_predicted() (function used internally compute predictions). plotting, check examples visualisation_recipe(). Also check Vignettes README examples various examples, tutorials usecases.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":"expected-average-values","dir":"Reference","previous_headings":"","what":"Expected (average) values","title":"Model-based predictions — estimate_expectation","text":"important way various types response estimates differ terms quantity estimated meaning uncertainty intervals. major choices expected values uncertainty regression line predicted values uncertainty individual case predictions. Expected values refer fitted regression line - estimated average response value (.e., \"expectation\") individuals specific predictor values. example, linear model y = 2 + 3x + 4z + e, estimated average y individuals x = 1 z = 2 11. expected values, uncertainty intervals refer uncertainty estimated conditional average (might true regression line actually fall)? Uncertainty intervals expected values also called \"confidence intervals\". Expected values uncertainty intervals useful describing relationship variables describing precisely model estimated. generalized linear models, expected values reported one two scales: link scale refers scale fitted regression line, transformation link function. example, logistic regression (logit binomial) model, link scale gives expected log-odds. log-link Poisson model, link scale gives expected log-count. response scale refers original scale response variable (.e., without link function transformation). Expected values link scale back-transformed original response variable metric (e.g., expected probabilities binomial models, expected counts Poisson models).","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":"individual-case-predictions","dir":"Reference","previous_headings":"","what":"Individual case predictions","title":"Model-based predictions — estimate_expectation","text":"contrast expected values, predicted values refer predictions individual cases. Predicted values also called \"posterior predictions\" \"posterior predictive draws\". predicted values, uncertainty intervals refer uncertainty individual response values case (might single case actually fall)? Uncertainty intervals predicted values also called \"prediction intervals\" \"posterior predictive intervals\". Predicted values uncertainty intervals useful forecasting range values might observed new data, making decisions individual cases, checking model predictions reasonable (\"posterior predictive checks\"). Predicted values intervals always scale original response variable (link scale).","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":"functions-for-estimating-predicted-values-and-uncertainty","dir":"Reference","previous_headings":"","what":"Functions for estimating predicted values and uncertainty","title":"Model-based predictions — estimate_expectation","text":"modelbased provides 4 functions generating model-based response estimates uncertainty: estimate_expectation(): Generates expected values (conditional average) response scale. uncertainty interval confidence interval. default, values computed using data used fit model. estimate_link(): Generates expected values (conditional average) link scale. uncertainty interval confidence interval. default, values computed using reference grid spanning observed range predictor values (see insight::get_datagrid()). estimate_prediction(): Generates predicted values (individual cases) response scale. uncertainty interval prediction interval. default, values computed using data used fit model. estimate_relation(): Like estimate_expectation(). Useful visualizing model. Generates expected values (conditional average) response scale. uncertainty interval confidence interval. default, values computed using reference grid spanning observed range predictor values (see insight::get_datagrid()).","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":"data-for-predictions","dir":"Reference","previous_headings":"","what":"Data for predictions","title":"Model-based predictions — estimate_expectation","text":"data = NULL, values estimated using data used fit model. data = \"grid\", values computed using reference grid spanning observed range predictor values insight::get_datagrid(). can useful model visualization. number predictor values used variable can controlled length argument. data can also data frame containing columns names matching model frame (see insight::get_data()). can used generate model predictions specific combinations predictor values.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model-based predictions — estimate_expectation","text":"","code":"library(modelbased)  # Linear Models model <- lm(mpg ~ wt, data = mtcars)  # Get predicted and prediction interval (see insight::get_predicted) estimate_expectation(model) #> Model-based Predictions #>  #> wt   | Predicted |   SE |         95% CI | Residuals #> ---------------------------------------------------- #> 2.62 |     23.28 | 0.63 | [21.99, 24.58] |     -2.28 #> 2.88 |     21.92 | 0.57 | [20.75, 23.09] |     -0.92 #> 2.32 |     24.89 | 0.74 | [23.38, 26.39] |     -2.09 #> 3.21 |     20.10 | 0.54 | [19.00, 21.20] |      1.30 #> 3.44 |     18.90 | 0.55 | [17.77, 20.03] |     -0.20 #> 3.46 |     18.79 | 0.56 | [17.66, 19.93] |     -0.69 #> 3.57 |     18.21 | 0.57 | [17.03, 19.38] |     -3.91 #> 3.19 |     20.24 | 0.54 | [19.14, 21.34] |      4.16 #> 3.15 |     20.45 | 0.54 | [19.35, 21.55] |      2.35 #> 3.44 |     18.90 | 0.55 | [17.77, 20.03] |      0.30 #> 3.44 |     18.90 | 0.55 | [17.77, 20.03] |     -1.10 #> 4.07 |     15.53 | 0.72 | [14.06, 17.00] |      0.87 #> 3.73 |     17.35 | 0.61 | [16.10, 18.60] |     -0.05 #> 3.78 |     17.08 | 0.62 | [15.81, 18.36] |     -1.88 #> 5.25 |      9.23 | 1.26 | [ 6.66, 11.80] |      1.17 #> 5.42 |      8.30 | 1.35 | [ 5.55, 11.05] |      2.10 #> 5.34 |      8.72 | 1.31 | [ 6.05, 11.39] |      5.98 #> 2.20 |     25.53 | 0.78 | [23.93, 27.13] |      6.87 #> 1.61 |     28.65 | 1.05 | [26.52, 30.79] |      1.75 #> 1.83 |     27.48 | 0.94 | [25.55, 29.40] |      6.42 #> 2.46 |     24.11 | 0.68 | [22.72, 25.51] |     -2.61 #> 3.52 |     18.47 | 0.56 | [17.32, 19.63] |     -2.97 #> 3.44 |     18.93 | 0.55 | [17.80, 20.05] |     -3.73 #> 3.84 |     16.76 | 0.64 | [15.45, 18.07] |     -3.46 #> 3.85 |     16.74 | 0.64 | [15.42, 18.05] |      2.46 #> 1.94 |     26.94 | 0.90 | [25.11, 28.77] |      0.36 #> 2.14 |     25.85 | 0.81 | [24.20, 27.50] |      0.15 #> 1.51 |     29.20 | 1.09 | [26.96, 31.43] |      1.20 #> 3.17 |     20.34 | 0.54 | [19.24, 21.44] |     -4.54 #> 2.77 |     22.48 | 0.59 | [21.27, 23.69] |     -2.78 #> 3.57 |     18.21 | 0.57 | [17.03, 19.38] |     -3.21 #> 2.78 |     22.43 | 0.59 | [21.22, 23.64] |     -1.03 #>  #> Variable predicted: mpg #>   # Get expected values with confidence interval pred <- estimate_relation(model) pred #> Model-based Predictions #>  #> wt   | Predicted |   SE |         95% CI #> ---------------------------------------- #> 1.51 |     29.20 | 1.09 | [26.96, 31.43] #> 1.95 |     26.87 | 0.89 | [25.05, 28.69] #> 2.38 |     24.55 | 0.71 | [23.10, 26.01] #> 2.82 |     22.23 | 0.58 | [21.04, 23.42] #> 3.25 |     19.91 | 0.54 | [18.81, 21.01] #> 3.69 |     17.59 | 0.60 | [16.36, 18.81] #> 4.12 |     15.27 | 0.74 | [13.76, 16.77] #> 4.55 |     12.94 | 0.92 | [11.06, 14.82] #> 4.99 |     10.62 | 1.13 | [ 8.32, 12.92] #> 5.42 |      8.30 | 1.35 | [ 5.55, 11.05] #>  #> Variable predicted: mpg #> Predictors modulated: wt #>   # Visualisation (see visualisation_recipe()) plot(pred)   # Standardize predictions pred <- estimate_relation(lm(mpg ~ wt + am, data = mtcars)) z <- standardize(pred, include_response = FALSE) z #> Model-based Predictions (standardized) #>  #> wt    |    am | Predicted |   SE |         95% CI #> ------------------------------------------------- #> -1.74 | -0.81 |     29.22 | 1.91 | [25.31, 33.14] #> -1.30 | -0.81 |     26.89 | 1.60 | [23.62, 30.17] #> -0.85 | -0.81 |     24.57 | 1.30 | [21.90, 27.24] #> -0.41 | -0.81 |     22.24 | 1.03 | [20.13, 24.36] #> 0.03  | -0.81 |     19.92 | 0.82 | [18.24, 21.60] #> 0.48  | -0.81 |     17.59 | 0.71 | [16.13, 19.05] #> 0.92  | -0.81 |     15.27 | 0.76 | [13.71, 16.83] #> 1.37  | -0.81 |     12.94 | 0.94 | [11.01, 14.87] #> 1.81  | -0.81 |     10.62 | 1.20 | [ 8.17, 13.06] #> 2.26  | -0.81 |      8.29 | 1.49 | [ 5.25, 11.33] #> -1.74 |  1.19 |     29.20 | 1.11 | [26.92, 31.48] #> -1.30 |  1.19 |     26.87 | 0.93 | [24.96, 28.78] #> -0.85 |  1.19 |     24.55 | 0.86 | [22.79, 26.31] #> -0.41 |  1.19 |     22.22 | 0.92 | [20.34, 24.09] #> 0.03  |  1.19 |     19.90 | 1.08 | [17.68, 22.11] #> 0.48  |  1.19 |     17.57 | 1.32 | [14.86, 20.27] #> 0.92  |  1.19 |     15.24 | 1.60 | [11.98, 18.51] #> 1.37  |  1.19 |     12.92 | 1.90 | [ 9.04, 16.79] #> 1.81  |  1.19 |     10.59 | 2.21 | [ 6.08, 15.11] #> 2.26  |  1.19 |      8.26 | 2.53 | [ 3.10, 13.43] #>  #> Variable predicted: mpg #> Predictors modulated: wt, am #>  unstandardize(z, include_response = FALSE) #> Model-based Predictions (standardized) #>  #> wt   | am | Predicted |   SE |         95% CI #> --------------------------------------------- #> 1.51 |  0 |     29.22 | 1.91 | [25.31, 33.14] #> 1.95 |  0 |     26.89 | 1.60 | [23.62, 30.17] #> 2.38 |  0 |     24.57 | 1.30 | [21.90, 27.24] #> 2.82 |  0 |     22.24 | 1.03 | [20.13, 24.36] #> 3.25 |  0 |     19.92 | 0.82 | [18.24, 21.60] #> 3.69 |  0 |     17.59 | 0.71 | [16.13, 19.05] #> 4.12 |  0 |     15.27 | 0.76 | [13.71, 16.83] #> 4.55 |  0 |     12.94 | 0.94 | [11.01, 14.87] #> 4.99 |  0 |     10.62 | 1.20 | [ 8.17, 13.06] #> 5.42 |  0 |      8.29 | 1.49 | [ 5.25, 11.33] #> 1.51 |  1 |     29.20 | 1.11 | [26.92, 31.48] #> 1.95 |  1 |     26.87 | 0.93 | [24.96, 28.78] #> 2.38 |  1 |     24.55 | 0.86 | [22.79, 26.31] #> 2.82 |  1 |     22.22 | 0.92 | [20.34, 24.09] #> 3.25 |  1 |     19.90 | 1.08 | [17.68, 22.11] #> 3.69 |  1 |     17.57 | 1.32 | [14.86, 20.27] #> 4.12 |  1 |     15.24 | 1.60 | [11.98, 18.51] #> 4.55 |  1 |     12.92 | 1.90 | [ 9.04, 16.79] #> 4.99 |  1 |     10.59 | 2.21 | [ 6.08, 15.11] #> 5.42 |  1 |      8.26 | 2.53 | [ 3.10, 13.43] #>  #> Variable predicted: mpg #> Predictors modulated: wt, am #>   # Logistic Models model <- glm(vs ~ wt, data = mtcars, family = \"binomial\") estimate_expectation(model) #> Model-based Predictions #>  #> wt   | Predicted |   SE |       95% CI | Residuals #> -------------------------------------------------- #> 2.62 |      0.67 | 0.12 | [0.40, 0.86] |     -0.67 #> 2.88 |      0.56 | 0.12 | [0.33, 0.76] |     -0.56 #> 2.32 |      0.78 | 0.12 | [0.47, 0.94] |      0.22 #> 3.21 |      0.39 | 0.11 | [0.21, 0.61] |      0.61 #> 3.44 |      0.30 | 0.11 | [0.14, 0.53] |     -0.30 #> 3.46 |      0.29 | 0.10 | [0.13, 0.53] |      0.71 #> 3.57 |      0.25 | 0.10 | [0.10, 0.50] |     -0.25 #> 3.19 |      0.41 | 0.11 | [0.22, 0.62] |      0.59 #> 3.15 |      0.42 | 0.11 | [0.24, 0.64] |      0.58 #> 3.44 |      0.30 | 0.11 | [0.14, 0.53] |      0.70 #> 3.44 |      0.30 | 0.11 | [0.14, 0.53] |      0.70 #> 4.07 |      0.11 | 0.08 | [0.02, 0.39] |     -0.11 #> 3.73 |      0.20 | 0.10 | [0.07, 0.46] |     -0.20 #> 3.78 |      0.18 | 0.10 | [0.06, 0.45] |     -0.18 #> 5.25 |      0.01 | 0.02 | [0.00, 0.24] |     -0.01 #> 5.42 |  9.49e-03 | 0.02 | [0.00, 0.23] | -9.49e-03 #> 5.34 |      0.01 | 0.02 | [0.00, 0.23] |     -0.01 #> 2.20 |      0.82 | 0.12 | [0.49, 0.96] |      0.18 #> 1.61 |      0.93 | 0.07 | [0.58, 0.99] |      0.07 #> 1.83 |      0.90 | 0.09 | [0.55, 0.99] |      0.10 #> 2.46 |      0.73 | 0.13 | [0.44, 0.91] |      0.27 #> 3.52 |      0.27 | 0.10 | [0.11, 0.51] |     -0.27 #> 3.44 |      0.30 | 0.11 | [0.14, 0.53] |     -0.30 #> 3.84 |      0.16 | 0.10 | [0.05, 0.43] |     -0.16 #> 3.85 |      0.16 | 0.10 | [0.05, 0.43] |     -0.16 #> 1.94 |      0.88 | 0.10 | [0.54, 0.98] |      0.12 #> 2.14 |      0.84 | 0.11 | [0.50, 0.96] |     -0.84 #> 1.51 |      0.94 | 0.07 | [0.60, 0.99] |      0.06 #> 3.17 |      0.42 | 0.11 | [0.23, 0.63] |     -0.42 #> 2.77 |      0.60 | 0.12 | [0.36, 0.80] |     -0.60 #> 3.57 |      0.25 | 0.10 | [0.10, 0.50] |     -0.25 #> 2.78 |      0.60 | 0.12 | [0.36, 0.80] |      0.40 #>  #> Variable predicted: vs #> Predictions are on the response-scale. #>  estimate_relation(model) #> Model-based Predictions #>  #> wt   | Predicted |   SE |       95% CI #> -------------------------------------- #> 1.51 |      0.94 | 0.07 | [0.60, 0.99] #> 1.95 |      0.88 | 0.10 | [0.53, 0.98] #> 2.38 |      0.76 | 0.12 | [0.46, 0.92] #> 2.82 |      0.58 | 0.12 | [0.35, 0.78] #> 3.25 |      0.38 | 0.11 | [0.20, 0.60] #> 3.69 |      0.21 | 0.10 | [0.07, 0.47] #> 4.12 |      0.10 | 0.08 | [0.02, 0.38] #> 4.55 |      0.05 | 0.05 | [0.01, 0.32] #> 4.99 |      0.02 | 0.03 | [0.00, 0.27] #> 5.42 |  9.49e-03 | 0.02 | [0.00, 0.23] #>  #> Variable predicted: vs #> Predictors modulated: wt #> Predictions are on the response-scale. #>   # Mixed models model <- lme4::lmer(mpg ~ wt + (1 | gear), data = mtcars) estimate_expectation(model) #> Model-based Predictions #>  #> wt   | gear | Predicted |   SE |         95% CI | Residuals #> ----------------------------------------------------------- #> 2.62 | 4.00 |     24.04 | 0.97 | [22.07, 26.02] |     -3.04 #> 2.88 | 4.00 |     22.76 | 0.93 | [20.86, 24.65] |     -1.76 #> 2.32 | 4.00 |     25.56 | 1.04 | [23.42, 27.70] |     -2.76 #> 3.21 | 3.00 |     19.64 | 0.92 | [17.77, 21.52] |      1.76 #> 3.44 | 3.00 |     18.51 | 0.94 | [16.59, 20.42] |      0.19 #> 3.46 | 3.00 |     18.41 | 0.94 | [16.48, 20.33] |     -0.31 #> 3.57 | 3.00 |     17.85 | 0.96 | [15.89, 19.81] |     -3.55 #> 3.19 | 4.00 |     21.17 | 0.91 | [19.30, 23.04] |      3.23 #> 3.15 | 4.00 |     21.37 | 0.91 | [19.50, 23.24] |      1.43 #> 3.44 | 4.00 |     19.91 | 0.94 | [17.99, 21.83] |     -0.71 #> 3.44 | 4.00 |     19.91 | 0.94 | [17.99, 21.83] |     -2.11 #> 4.07 | 3.00 |     15.33 | 1.10 | [13.08, 17.58] |      1.07 #> 3.73 | 3.00 |     17.04 | 0.99 | [15.01, 19.08] |      0.26 #> 3.78 | 3.00 |     16.79 | 1.01 | [14.73, 18.86] |     -1.59 #> 5.25 | 3.00 |      9.37 | 1.64 | [ 6.01, 12.74] |      1.03 #> 5.42 | 3.00 |      8.50 | 1.74 | [ 4.94, 12.06] |      1.90 #> 5.34 | 3.00 |      8.90 | 1.70 | [ 5.42, 12.37] |      5.80 #> 2.20 | 4.00 |     26.16 | 1.08 | [23.94, 28.38] |      6.24 #> 1.61 | 4.00 |     29.11 | 1.32 | [26.40, 31.82] |      1.29 #> 1.83 | 4.00 |     28.00 | 1.23 | [25.49, 30.51] |      5.90 #> 2.46 | 3.00 |     23.42 | 1.00 | [21.37, 25.48] |     -1.92 #> 3.52 | 3.00 |     18.10 | 0.95 | [16.16, 20.05] |     -2.60 #> 3.44 | 3.00 |     18.53 | 0.94 | [16.61, 20.45] |     -3.33 #> 3.84 | 3.00 |     16.49 | 1.02 | [14.39, 18.59] |     -3.19 #> 3.85 | 3.00 |     16.46 | 1.03 | [14.36, 18.56] |      2.74 #> 1.94 | 4.00 |     27.50 | 1.18 | [25.08, 29.92] |     -0.20 #> 2.14 | 5.00 |     24.65 | 1.10 | [22.39, 26.91] |      1.35 #> 1.51 | 5.00 |     27.81 | 1.37 | [25.01, 30.62] |      2.59 #> 3.17 | 5.00 |     19.45 | 0.91 | [17.58, 21.33] |     -3.65 #> 2.77 | 5.00 |     21.47 | 0.94 | [19.55, 23.40] |     -1.77 #> 3.57 | 5.00 |     17.44 | 0.96 | [15.47, 19.40] |     -2.44 #> 2.78 | 4.00 |     23.24 | 0.94 | [21.32, 25.16] |     -1.84 #>  #> Variable predicted: mpg #>  estimate_relation(model) #> Model-based Predictions #>  #> wt   | gear | Predicted |   SE |         95% CI #> ----------------------------------------------- #> 1.51 | 0.00 |     28.56 | 1.37 | [25.75, 31.37] #> 1.95 | 0.00 |     26.36 | 1.18 | [23.95, 28.78] #> 2.38 | 0.00 |     24.17 | 1.03 | [22.07, 26.27] #> 2.82 | 0.00 |     21.98 | 0.93 | [20.07, 23.89] #> 3.25 | 0.00 |     19.79 | 0.92 | [17.91, 21.67] #> 3.69 | 0.00 |     17.59 | 0.98 | [15.58, 19.61] #> 4.12 | 0.00 |     15.40 | 1.12 | [13.12, 17.69] #> 4.55 | 0.00 |     13.21 | 1.30 | [10.55, 15.87] #> 4.99 | 0.00 |     11.02 | 1.51 | [ 7.93, 14.11] #> 5.42 | 0.00 |      8.83 | 1.74 | [ 5.27, 12.39] #>  #> Variable predicted: mpg #> Predictors modulated: wt #>   # Bayesian models # \\donttest{ model <- suppressWarnings(rstanarm::stan_glm(   mpg ~ wt,   data = mtcars, refresh = 0, iter = 200 )) estimate_expectation(model) #> Model-based Predictions #>  #> wt   | Predicted |   SE |         95% CI | Residuals #> ---------------------------------------------------- #> 2.62 |     23.46 | 0.78 | [22.19, 25.03] |     -2.46 #> 2.88 |     22.10 | 0.70 | [20.96, 23.67] |     -1.10 #> 2.32 |     25.06 | 0.91 | [23.52, 26.96] |     -2.26 #> 3.21 |     20.28 | 0.65 | [19.09, 21.84] |      1.12 #> 3.44 |     19.08 | 0.66 | [17.92, 20.61] |     -0.38 #> 3.46 |     18.98 | 0.66 | [17.80, 20.50] |     -0.88 #> 3.57 |     18.39 | 0.68 | [17.17, 19.90] |     -4.09 #> 3.19 |     20.42 | 0.65 | [19.22, 21.93] |      3.98 #> 3.15 |     20.63 | 0.65 | [19.42, 22.15] |      2.17 #> 3.44 |     19.08 | 0.66 | [17.92, 20.61] |      0.12 #> 3.44 |     19.08 | 0.66 | [17.92, 20.61] |     -1.28 #> 4.07 |     15.72 | 0.84 | [14.20, 17.52] |      0.68 #> 3.73 |     17.54 | 0.72 | [16.26, 19.18] |     -0.24 #> 3.78 |     17.27 | 0.73 | [15.97, 18.91] |     -2.07 #> 5.25 |      9.43 | 1.46 | [ 6.81, 12.51] |      0.97 #> 5.42 |      8.50 | 1.57 | [ 5.70, 11.81] |      1.90 #> 5.34 |      8.92 | 1.52 | [ 6.20, 12.16] |      5.78 #> 2.20 |     25.70 | 0.97 | [24.07, 27.76] |      6.70 #> 1.61 |     28.82 | 1.28 | [26.59, 31.47] |      1.58 #> 1.83 |     27.65 | 1.16 | [25.71, 30.10] |      6.25 #> 2.46 |     24.29 | 0.84 | [22.91, 26.01] |     -2.79 #> 3.52 |     18.66 | 0.67 | [17.46, 20.16] |     -3.16 #> 3.44 |     19.11 | 0.66 | [17.95, 20.65] |     -3.91 #> 3.84 |     16.95 | 0.75 | [15.65, 18.57] |     -3.65 #> 3.85 |     16.92 | 0.75 | [15.63, 18.54] |      2.28 #> 1.94 |     27.11 | 1.10 | [25.26, 29.44] |      0.19 #> 2.14 |     26.02 | 1.00 | [24.34, 28.11] |     -0.02 #> 1.51 |     29.36 | 1.34 | [27.00, 32.13] |      1.04 #> 3.17 |     20.52 | 0.65 | [19.33, 22.04] |     -4.72 #> 2.77 |     22.66 | 0.73 | [21.46, 24.23] |     -2.96 #> 3.57 |     18.39 | 0.68 | [17.17, 19.90] |     -3.39 #> 2.78 |     22.60 | 0.73 | [21.42, 24.17] |     -1.20 #>  #> Variable predicted: mpg #>  estimate_relation(model) #> Model-based Predictions #>  #> wt   | Predicted |   SE |         95% CI #> ---------------------------------------- #> 1.51 |     29.36 | 1.34 | [27.00, 32.13] #> 1.95 |     27.04 | 1.10 | [25.20, 29.35] #> 2.38 |     24.73 | 0.88 | [23.26, 26.55] #> 2.82 |     22.41 | 0.72 | [21.27, 23.98] #> 3.25 |     20.09 | 0.65 | [18.91, 21.69] #> 3.69 |     17.77 | 0.70 | [16.55, 19.38] #> 4.12 |     15.46 | 0.86 | [13.91, 17.28] #> 4.55 |     13.13 | 1.07 | [11.29, 15.28] #> 4.99 |     10.82 | 1.31 | [ 8.49, 13.55] #> 5.42 |      8.50 | 1.57 | [ 5.70, 11.81] #>  #> Variable predicted: mpg #> Predictors modulated: wt #>  # }"},{"path":"https://easystats.github.io/modelbased/reference/estimate_grouplevel.html","id":null,"dir":"Reference","previous_headings":"","what":"Group-specific parameters of mixed models random effects — estimate_grouplevel","title":"Group-specific parameters of mixed models random effects — estimate_grouplevel","text":"Extract random parameters individual group context mixed models, commonly referred BLUPs (Best Linear Unbiased Predictors). Can reshaped dimensions original data, can useful add random effects original data.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_grouplevel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Group-specific parameters of mixed models random effects — estimate_grouplevel","text":"","code":"estimate_grouplevel(model, ...)  # Default S3 method estimate_grouplevel(model, type = \"random\", ...)  # S3 method for class 'brmsfit' estimate_grouplevel(   model,   type = \"random\",   dispersion = TRUE,   test = NULL,   diagnostic = NULL,   ... )  reshape_grouplevel(x, indices = \"all\", group = \"all\", ...)"},{"path":"https://easystats.github.io/modelbased/reference/estimate_grouplevel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group-specific parameters of mixed models random effects — estimate_grouplevel","text":"model mixed model random effects. ... arguments passed parameters::model_parameters(). type \"random\" \"total\". \"random\" (default), coefficients correspond conditional estimates  random effects (returned lme4::ranef()). typically correspond deviation individual group fixed effect (assuming random effect also included fixed effect). , coefficient close 0 means participants' effect population-level effect (words, \"norm\"). \"total\", return sum random effect corresponding fixed effects, internally relies coef() method (see ?coef.merMod). Note type = \"total\" yet return uncertainty indices (SE CI) models lme4 glmmTMB, necessary information compute yet available. However, Bayesian models, possible compute . dispersion, test, diagnostic Arguments passed parameters::model_parameters() Bayesian models. default, return significance diagnostic indices (typically useful). x output estimate_grouplevel(). indices list containing indices (.e., columns) extract (e.g., \"Coefficient\"). group list containing random factors select.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_grouplevel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Group-specific parameters of mixed models random effects — estimate_grouplevel","text":"Unlike raw group means, BLUPs apply shrinkage: compromise group estimate population estimate. improves generalizability prevents overfitting.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_grouplevel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Group-specific parameters of mixed models random effects — estimate_grouplevel","text":"","code":"# lme4 model data(mtcars) model <- lme4::lmer(mpg ~ hp + (1 | carb), data = mtcars) random <- estimate_grouplevel(model)  # Show group-specific effects random #> Group | Level | Parameter   | Coefficient |   SE |        95% CI #> ---------------------------------------------------------------- #> carb  | 1     | (Intercept) |        0.41 | 0.84 | [-1.24, 2.05] #> carb  | 2     | (Intercept) |        0.11 | 0.78 | [-1.42, 1.65] #> carb  | 3     | (Intercept) |       -0.32 | 0.94 | [-2.16, 1.51] #> carb  | 4     | (Intercept) |       -0.78 | 0.78 | [-2.31, 0.75] #> carb  | 6     | (Intercept) |        0.09 | 1.00 | [-1.87, 2.05] #> carb  | 8     | (Intercept) |        0.50 | 1.00 | [-1.47, 2.46]  # Visualize random effects plot(random)   # Reshape to wide data so that it matches the original dataframe... reshaped <- reshape_grouplevel(random, indices = c(\"Coefficient\", \"SE\"))  # ...and can be easily combined with the original data alldata <- cbind(mtcars, reshaped)  # Use summary() to remove duplicated rows summary(reshaped) #>   carb carb_Coefficient_Intercept carb_SE_Intercept #> 1    4                -0.77955416         0.7829275 #> 2    1                 0.40506064         0.8390523 #> 3    2                 0.11088289         0.7829275 #> 4    3                -0.32486359         0.9369268 #> 5    6                 0.09296535         1.0007322 #> 6    8                 0.49550886         1.0007322  # overall coefficients estimate_grouplevel(model, type = \"total\") #> Group | Level | Parameter   | Coefficient #> ----------------------------------------- #> carb  | 1     | (Intercept) |       30.18 #> carb  | 2     | (Intercept) |       29.88 #> carb  | 3     | (Intercept) |       29.45 #> carb  | 4     | (Intercept) |       28.99 #> carb  | 6     | (Intercept) |       29.87 #> carb  | 8     | (Intercept) |       30.27"},{"path":"https://easystats.github.io/modelbased/reference/estimate_means.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Marginal Means (Model-based average at each factor level) — estimate_means","title":"Estimate Marginal Means (Model-based average at each factor level) — estimate_means","text":"Estimate average value response variable factor level representative value, respectively values defined \"data grid\" \"reference grid\". plotting, check examples visualisation_recipe(). See also related functions estimate_contrasts() estimate_slopes().","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_means.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Marginal Means (Model-based average at each factor level) — estimate_means","text":"","code":"estimate_means(   model,   by = \"auto\",   predict = NULL,   ci = 0.95,   estimate = NULL,   transform = NULL,   keep_iterations = FALSE,   backend = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/modelbased/reference/estimate_means.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Marginal Means (Model-based average at each factor level) — estimate_means","text":"model statistical model. (focal) predictor variable(s) evaluate desired effect / mean / contrasts. predictors model included collapsed \"averaged\" (effect estimated across ). can character (vector) naming focal predictors, optionally including representative values levels focal predictors evaluated (e.g., = \"x = c(1, 2)\"). estimate \"average\", argument used create \"reference grid\" \"data grid\" representative values focal predictors. case, can also list named elements. See details insight::get_datagrid() learn create data grids predictors interest. predict passed type argument emmeans::emmeans() (backend = \"emmeans\") marginaleffects::avg_predictions() (backend = \"marginaleffects\"). Valid options predict : backend = \"marginaleffects\": predict can \"response\", \"link\", \"inverse_link\" valid type option supported model's class predict() method (e.g., zero-inflation models package glmmTMB, can choose predict = \"zprob\" predict = \"conditional\" etc., see glmmTMB::predict.glmmTMB). default, predict = NULL, appropriate transformation selected, usually returns predictions contrasts response-scale. \"inverse_link\" special option, comparable marginaleffects' invlink(link) option. calculate predictions link scale back-transform response scale. backend = \"emmeans\": predict can \"response\", \"link\", \"mu\", \"unlink\", \"log\". predict = NULL (default), appropriate transformation selected (usually \"response\"). See also vignette. See also section Predictions different scales. ci Confidence Interval (CI) level. Default 0.95 (95%). estimate estimate argument determines predictions averaged (\"marginalized\") variables specified contrast (non-focal predictors). controls whether predictions represent \"typical\" individual, \"average\" individual sample, \"average\" individual broader population. \"typical\" (Default): Calculates predictions balanced data grid representing combinations focal predictor levels (specified ). non-focal numeric predictors, uses mean; non-focal categorical predictors, marginalizes (averages) levels. represents \"typical\" observation based data grid useful comparing groups. answers: \"average outcome 'typical' observation?\". default approach estimating marginal means using emmeans package. \"average\": Calculates predictions observation sample averages predictions within group defined focal predictors. reflects sample's actual distribution non-focal predictors, balanced grid. answers: \"predicted value average observation data?\" \"population\": \"Clones\" observation, creating copies possible combinations focal predictor levels. averages predictions across \"counterfactual\" observations (non-observed permutations) within group. extrapolates hypothetical broader population, considering \"\" scenarios. answers: \"predicted response 'average' observation broader possible target population?\" approach entails assumptions likelihood different combinations, can apt generalize. also option used G-computation (Chatton Rohrer 2024). can set default option estimate argument via options(), e.g. options(modelbased_estimate = \"average\") transform function applied predictions confidence intervals (back-) transform results, can useful case regression model transformed response variable (e.g., lm(log(y) ~ x)). Bayesian models, function applied individual draws posterior distribution, computing summaries. Can also TRUE, case insight::get_transformation() called determine appropriate transformation-function. Note standard errors returned transformations applied. keep_iterations TRUE, keep iterations (draws) bootstrapped Bayesian models. added additional columns named iter_1, iter_2, . keep_iterations positive number, many columns indicated keep_iterations added output. can reshape long format running bayestestR::reshape_iterations(). backend Whether use \"marginaleffects\" (default) \"emmeans\" backend. Results usually similar. major difference found mixed models, backend = \"marginaleffects\" also average across random effects levels, producing \"marginal predictions\" (instead \"conditional predictions\", see Heiss 2022). Another difference backend = \"marginaleffects\" slower backend = \"emmeans\". models, difference negligible. However, particular complex models large data sets fitted glmmTMB can significantly slower. can set default backend via options(), e.g. use options(modelbased_backend = \"emmeans\") use emmeans package options(modelbased_backend = \"marginaleffects\") set marginaleffects default backend. verbose Use FALSE silence messages warnings. ... arguments passed, instance, insight::get_datagrid(), functions emmeans marginaleffects package, process Bayesian models via bayestestR::describe_posterior(). Examples: insight::get_datagrid(): Argument length, digits range can used control (number ) representative values. integer variables, protect_integers modulates whether also treated numerics, .e. values can fractions . marginaleffects: Internally used functions avg_predictions() means contrasts, avg_slope() slopes. Therefore, arguments instance like vcov, equivalence, df, slope even newdata can passed functions. weights argument passed wts argument avg_predictions() avg_slopes(), however, weights can applied estimate \"average\" \"population\" (.e. marginalization options use data grids). arguments, re.form allow.new.levels, may passed predict() (internally used marginaleffects) supported model class. emmeans: Internally used functions emmeans() emtrends(). Additional arguments can passed functions. Bayesian models: Bayesian models, parameters cleaned using describe_posterior(), thus, arguments like, example, centrality, rope_range, test passed function. Especially estimate_contrasts() integer focal predictors, contrasts calculated, use argument integer_as_numeric set maximum number unique values integer predictor treat predictor \"discrete integer\" numeric. first case, contrasts calculated values predictor, latter, contrasts slopes calculated. integer integer_as_numeric unique values, treated numeric. Defaults 5.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_means.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Marginal Means (Model-based average at each factor level) — estimate_means","text":"data frame estimated marginal means.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_means.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate Marginal Means (Model-based average at each factor level) — estimate_means","text":"estimate_slopes(), estimate_means() estimate_contrasts() functions forming group, based marginal estimations (estimations based model). three built emmeans marginaleffects package (depending backend argument), reading documentation (instance emmeans::emmeans(), emmeans::emtrends() website) recommended understand idea behind types procedures. Model-based predictions basis follows. Indeed, first thing understand models can used make predictions (see estimate_link()). corresponds predicted response (\"outcome variable\") given specific predictor values predictors (.e., given specific data configuration). concept reference grid() important direct predictions. Marginal \"means\", obtained via estimate_means(), extension predictions, allowing \"average\" (collapse) predictors, obtain average response value specific predictors configuration. typically used predictors interest factors. Indeed, parameters model usually give intercept value \"effect\" factor level (different intercept). Marginal means can used directly give mean value response variable levels factor. Moreover, can also used control, average predictors, useful case multiple predictors without interactions. Marginal contrasts, obtained via estimate_contrasts(), extension marginal means, allow investigate difference (.e., contrast) marginal means. , , often used get pairwise differences levels factor. works also continuous predictors, instance one also interested whether difference two extremes continuous predictor significant. Finally, marginal effects, obtained via estimate_slopes(), different focus values response variable, model's parameters. idea assess effect predictor specific configuration predictors. relevant case interactions non-linear relationships, effect predictor variable changes depending predictors. Moreover, effects can also \"averaged\" predictors, get instance \"general trend\" predictor different factor levels. Example: imagine following model lm(y ~ condition * x) condition factor 3 levels , B C x continuous variable (like age example). One idea see model performs, compare actual response y one predicted model (using estimate_expectation()). Another idea evaluate average mean condition's levels (using estimate_means()), can useful visualize . Another possibility evaluate difference levels (using estimate_contrasts()). Finally, one also estimate effect x averaged conditions, instead within condition (using [estimate_slopes]).","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_means.html","id":"predictions-and-contrasts-at-meaningful-values-data-grids-","dir":"Reference","previous_headings":"","what":"Predictions and contrasts at meaningful values (data grids)","title":"Estimate Marginal Means (Model-based average at each factor level) — estimate_means","text":"define representative values focal predictors (specified , contrast, trend), can use several methods. values internally generated insight::get_datagrid(), consult documentation details. can directly specify values strings lists , contrast, trend. numeric focal predictors, use examples like = \"gear = c(4, 8)\", = list(gear = c(4, 8)) = \"gear = 5:10\" factor character predictors, use = \"Species = c('setosa', 'virginica')\" = list(Species = c('setosa', 'virginica')) can use \"shortcuts\" within square brackets, = \"Sepal.Width = [sd]\" = \"Sepal.Width = [fivenum]\" numeric focal predictors, representative values specified, length range control number type representative values: length determines many equally spaced values generated. range specifies type values, like \"range\" \"sd\". length range apply numeric focal predictors. multiple numeric predictors, length range can accept multiple elements, one predictor. integer variables, values appear data included data grid, independent length argument. behaviour can changed setting protect_integers = FALSE, treat integer variables numerics (possibly produce fractions). See also vignette examples.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_means.html","id":"predictions-on-different-scales","dir":"Reference","previous_headings":"","what":"Predictions on different scales","title":"Estimate Marginal Means (Model-based average at each factor level) — estimate_means","text":"predict argument allows generate predictions different scales response variable. \"link\" option apply models, usually Gaussian models. \"link\" leave values scale linear predictors. \"response\" (NULL) transform scale response variable. Thus logistic model, \"link\" give estimations expressed log-odds (probabilities logit scale) \"response\" terms probabilities. predict distributional parameters (called \"dpar\" packages), instance using complex formulae brms models, predict argument can take value parameter want estimate, instance \"sigma\", \"kappa\", etc. \"response\" \"inverse_link\" return predictions response scale, however, \"response\" first calculates predictions response scale observation aggregates groups levels defined . \"inverse_link\" first calculates predictions link scale observation, aggregates groups levels defined , finally back-transforms predictions response scale. approaches advantages disadvantages. \"response\" usually produces less biased predictions, confidence intervals might outside reasonable bounds (.e., instance can negative count data). \"inverse_link\" approach robust terms confidence intervals, might produce biased predictions. However, can try set bias_correction = TRUE, adjust bias. particular mixed models, using \"response\" recommended, averaging across random effects groups accurate.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_means.html","id":"global-options-to-customize-estimation-of-marginal-means","dir":"Reference","previous_headings":"","what":"Global Options to Customize Estimation of Marginal Means","title":"Estimate Marginal Means (Model-based average at each factor level) — estimate_means","text":"modelbased_backend: options(modelbased_backend = <string>) set default value backend argument can used set package used default calculate marginal means. Can \"marginalmeans\" \"emmeans\". modelbased_estimate: options(modelbased_estimate = <string>) set default value estimate argument.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_means.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate Marginal Means (Model-based average at each factor level) — estimate_means","text":"Chatton, . Rohrer, J.M. 2024. Causal Cookbook: Recipes Propensity Scores, G-Computation, Doubly Robust Standardization. Advances Methods Practices Psychological Science. 2024;7(1). doi:10.1177/25152459241236149 Dickerman, Barbra ., Miguel . Hernán. 2020. Counterfactual Prediction Causal Inference. European Journal Epidemiology 35 (7): 615–17. doi:10.1007/s10654-020-00659-8 Heiss, . (2022). Marginal conditional effects GLMMs marginaleffects. Andrew Heiss. doi:10.59350/xwnfm-x1827","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_means.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Marginal Means (Model-based average at each factor level) — estimate_means","text":"","code":"library(modelbased)  # Frequentist models # ------------------- model <- lm(Petal.Length ~ Sepal.Width * Species, data = iris)  estimate_means(model) #> We selected `by=c(\"Species\")`. #> Estimated Marginal Means #>  #> Species    | Mean |   SE |       95% CI | t(144) #> ------------------------------------------------ #> setosa     | 1.43 | 0.08 | [1.28, 1.58] |  18.70 #> versicolor | 4.50 | 0.07 | [4.35, 4.65] |  60.64 #> virginica  | 5.61 | 0.06 | [5.50, 5.72] |  99.61 #>  #> Variable predicted: Petal.Length #> Predictors modulated: Species #> Predictors averaged: Sepal.Width (3.1) #>   # the `length` argument is passed to `insight::get_datagrid()` and modulates # the number of representative values to return for numeric predictors estimate_means(model, by = c(\"Species\", \"Sepal.Width\"), length = 2) #> Estimated Marginal Means #>  #> Species    | Sepal.Width | Mean |   SE |       95% CI | t(144) #> -------------------------------------------------------------- #> setosa     |        2.00 | 1.35 | 0.21 | [0.92, 1.77] |   6.28 #> versicolor |        2.00 | 3.61 | 0.15 | [3.33, 3.90] |  24.81 #> virginica  |        2.00 | 4.88 | 0.17 | [4.54, 5.23] |  27.92 #> setosa     |        4.40 | 1.54 | 0.15 | [1.24, 1.84] |  10.19 #> versicolor |        4.40 | 5.63 | 0.29 | [5.05, 6.20] |  19.34 #> virginica  |        4.40 | 6.53 | 0.25 | [6.04, 7.02] |  26.19 #>  #> Variable predicted: Petal.Length #> Predictors modulated: Species, Sepal.Width #>   # an alternative way to setup your data grid is specify the values directly estimate_means(model, by = c(\"Species\", \"Sepal.Width = c(2, 4)\")) #> Estimated Marginal Means #>  #> Species    | Sepal.Width | Mean |   SE |       95% CI | t(144) #> -------------------------------------------------------------- #> setosa     |           2 | 1.35 | 0.21 | [0.92, 1.77] |   6.28 #> versicolor |           2 | 3.61 | 0.15 | [3.33, 3.90] |  24.81 #> virginica  |           2 | 4.88 | 0.17 | [4.54, 5.23] |  27.92 #> setosa     |           4 | 1.51 | 0.10 | [1.31, 1.70] |  15.19 #> versicolor |           4 | 5.29 | 0.22 | [4.85, 5.73] |  23.78 #> virginica  |           4 | 6.26 | 0.18 | [5.89, 6.62] |  34.11 #>  #> Variable predicted: Petal.Length #> Predictors modulated: Species, Sepal.Width = c(2, 4) #>   # or use one of the many predefined \"tokens\" that help you creating a useful # data grid - to learn more about creating data grids, see help in # `?insight::get_datagrid`. estimate_means(model, by = c(\"Species\", \"Sepal.Width = [fivenum]\")) #> Estimated Marginal Means #>  #> Species    | Sepal.Width | Mean |   SE |       95% CI | t(144) #> -------------------------------------------------------------- #> setosa     |        2.00 | 1.35 | 0.21 | [0.92, 1.77] |   6.28 #> versicolor |        2.00 | 3.61 | 0.15 | [3.33, 3.90] |  24.81 #> virginica  |        2.00 | 4.88 | 0.17 | [4.54, 5.23] |  27.92 #> setosa     |        2.80 | 1.41 | 0.11 | [1.20, 1.62] |  13.28 #> versicolor |        2.80 | 4.29 | 0.05 | [4.18, 4.39] |  78.28 #> virginica  |        2.80 | 5.43 | 0.06 | [5.31, 5.56] |  87.55 #> setosa     |        3.00 | 1.43 | 0.08 | [1.26, 1.59] |  17.27 #> versicolor |        3.00 | 4.45 | 0.07 | [4.32, 4.59] |  65.68 #> virginica  |        3.00 | 5.57 | 0.05 | [5.46, 5.68] | 101.89 #> setosa     |        3.30 | 1.45 | 0.06 | [1.34, 1.57] |  25.21 #> versicolor |        3.30 | 4.70 | 0.11 | [4.49, 4.92] |  43.66 #> virginica  |        3.30 | 5.78 | 0.08 | [5.62, 5.93] |  74.17 #> setosa     |        4.40 | 1.54 | 0.15 | [1.24, 1.84] |  10.19 #> versicolor |        4.40 | 5.63 | 0.29 | [5.05, 6.20] |  19.34 #> virginica  |        4.40 | 6.53 | 0.25 | [6.04, 7.02] |  26.19 #>  #> Variable predicted: Petal.Length #> Predictors modulated: Species, Sepal.Width = [fivenum] #>   # \\dontrun{ # same for factors: filter by specific levels estimate_means(model, by = \"Species = c('versicolor', 'setosa')\") #> Estimated Marginal Means #>  #> Species    | Mean |   SE |       95% CI | t(144) #> ------------------------------------------------ #> versicolor | 4.50 | 0.07 | [4.35, 4.65] |  60.64 #> setosa     | 1.43 | 0.08 | [1.28, 1.58] |  18.70 #>  #> Variable predicted: Petal.Length #> Predictors modulated: Species = c('versicolor', 'setosa') #> Predictors averaged: Sepal.Width (3.1) #>  estimate_means(model, by = c(\"Species\", \"Sepal.Width = 0\")) #> Estimated Marginal Means #>  #> Species    | Sepal.Width | Mean |   SE |       95% CI | t(144) #> -------------------------------------------------------------- #> setosa     |           0 | 1.18 | 0.50 | [0.19, 2.17] |   2.36 #> versicolor |           0 | 1.93 | 0.49 | [0.97, 2.90] |   3.96 #> virginica  |           0 | 3.51 | 0.51 | [2.50, 4.52] |   6.88 #>  #> Variable predicted: Petal.Length #> Predictors modulated: Species, Sepal.Width = 0 #>   # estimate marginal average of response at values for numeric predictor estimate_means(model, by = \"Sepal.Width\", length = 5) #> Estimated Marginal Means #>  #> Sepal.Width | Mean |   SE |       95% CI | t(144) #> ------------------------------------------------- #> 2.00        | 3.28 | 0.10 | [3.07, 3.49] |  31.48 #> 2.60        | 3.60 | 0.06 | [3.49, 3.71] |  64.21 #> 3.20        | 3.92 | 0.04 | [3.84, 4.01] |  89.81 #> 3.80        | 4.25 | 0.08 | [4.08, 4.41] |  50.21 #> 4.40        | 4.57 | 0.14 | [4.30, 4.84] |  33.25 #>  #> Variable predicted: Petal.Length #> Predictors modulated: Sepal.Width #> Predictors averaged: Species #>  estimate_means(model, by = \"Sepal.Width = c(2, 4)\") #> Estimated Marginal Means #>  #> Sepal.Width | Mean |   SE |       95% CI | t(144) #> ------------------------------------------------- #> 2           | 3.28 | 0.10 | [3.07, 3.49] |  31.48 #> 4           | 4.35 | 0.10 | [4.15, 4.55] |  42.81 #>  #> Variable predicted: Petal.Length #> Predictors modulated: Sepal.Width = c(2, 4) #> Predictors averaged: Species #>   # or provide the definition of the data grid as list estimate_means(   model,   by = list(Sepal.Width = c(2, 4), Species = c(\"versicolor\", \"setosa\")) ) #> Estimated Marginal Means #>  #> Sepal.Width | Species    | Mean |   SE |       95% CI | t(144) #> -------------------------------------------------------------- #> 2           | versicolor | 3.61 | 0.15 | [3.33, 3.90] |  24.81 #> 4           | versicolor | 5.29 | 0.22 | [4.85, 5.73] |  23.78 #> 2           | setosa     | 1.35 | 0.21 | [0.92, 1.77] |   6.28 #> 4           | setosa     | 1.51 | 0.10 | [1.31, 1.70] |  15.19 #>  #> Variable predicted: Petal.Length #> Predictors modulated: Sepal.Width = c(2, 4), Species = c('versicolor', 'setosa') #>   # Methods that can be applied to it: means <- estimate_means(model, by = c(\"Species\", \"Sepal.Width = 0\"))  plot(means) # which runs visualisation_recipe()  standardize(means) #> Estimated Marginal Means (standardized) #>  #> Species    | Sepal.Width |  Mean |   SE |         95% CI | t(144) #> ----------------------------------------------------------------- #> setosa     |       -7.01 | -1.46 | 0.28 | [-2.02, -0.90] |   2.36 #> versicolor |       -7.01 | -1.03 | 0.28 | [-1.58, -0.49] |   3.96 #> virginica  |       -7.01 | -0.14 | 0.29 | [-0.71,  0.43] |   6.88 #>  #> Variable predicted: Petal.Length #> Predictors modulated: Species, Sepal.Width = 0 #>   # grids for numeric predictors, combine range and length model <- lm(Sepal.Length ~ Sepal.Width * Petal.Length, data = iris)  # create a \"grid\": value range for first numeric predictor, mean +/-1 SD # for remaining numeric predictors. estimate_means(model, c(\"Sepal.Width\", \"Petal.Length\"), range = \"grid\") #> Estimated Marginal Means #>  #> Sepal.Width | Petal.Length | Mean |   SE |       95% CI | t(146) #> ---------------------------------------------------------------- #> 2.00        |         1.99 | 4.23 | 0.13 | [3.98, 4.48] |  33.47 #> 2.27        |         1.99 | 4.42 | 0.10 | [4.21, 4.62] |  42.42 #> 2.53        |         1.99 | 4.60 | 0.08 | [4.44, 4.76] |  55.62 #> 2.80        |         1.99 | 4.79 | 0.06 | [4.66, 4.91] |  76.04 #> 3.07        |         1.99 | 4.97 | 0.05 | [4.88, 5.07] | 105.72 #> 3.33        |         1.99 | 5.16 | 0.04 | [5.08, 5.24] | 129.30 #> 3.60        |         1.99 | 5.34 | 0.05 | [5.25, 5.43] | 116.74 #> 3.87        |         1.99 | 5.53 | 0.06 | [5.41, 5.65] |  90.56 #> 4.13        |         1.99 | 5.71 | 0.08 | [5.56, 5.87] |  71.00 #> 4.40        |         1.99 | 5.90 | 0.10 | [5.70, 6.10] |  57.96 #> 2.00        |         3.76 | 5.23 | 0.08 | [5.07, 5.38] |  67.09 #> 2.27        |         3.76 | 5.38 | 0.06 | [5.26, 5.50] |  88.49 #> 2.53        |         3.76 | 5.52 | 0.05 | [5.43, 5.61] | 122.12 #> 2.80        |         3.76 | 5.67 | 0.03 | [5.61, 5.74] | 169.13 #> 3.07        |         3.76 | 5.82 | 0.03 | [5.76, 5.88] | 190.53 #> 3.33        |         3.76 | 5.97 | 0.04 | [5.90, 6.05] | 155.82 #> 3.60        |         3.76 | 6.12 | 0.05 | [6.02, 6.23] | 117.07 #> 3.87        |         3.76 | 6.27 | 0.07 | [6.14, 6.41] |  91.20 #> 4.13        |         3.76 | 6.42 | 0.09 | [6.25, 6.59] |  74.43 #> 4.40        |         3.76 | 6.57 | 0.10 | [6.36, 6.78] |  62.95 #> 2.00        |         5.52 | 6.22 | 0.12 | [5.98, 6.46] |  51.44 #> 2.27        |         5.52 | 6.34 | 0.09 | [6.15, 6.52] |  69.02 #> 2.53        |         5.52 | 6.45 | 0.06 | [6.32, 6.58] |  99.42 #> 2.80        |         5.52 | 6.56 | 0.04 | [6.47, 6.65] | 148.72 #> 3.07        |         5.52 | 6.67 | 0.04 | [6.59, 6.76] | 163.67 #> 3.33        |         5.52 | 6.79 | 0.06 | [6.67, 6.90] | 117.33 #> 3.60        |         5.52 | 6.90 | 0.08 | [6.74, 7.07] |  82.43 #> 3.87        |         5.52 | 7.01 | 0.11 | [6.79, 7.24] |  62.37 #> 4.13        |         5.52 | 7.13 | 0.14 | [6.85, 7.41] |  50.11 #> 4.40        |         5.52 | 7.24 | 0.17 | [6.90, 7.58] |  41.93 #>  #> Variable predicted: Sepal.Length #> Predictors modulated: Sepal.Width, Petal.Length #>   # range from minimum to maximum spread over four values, # and mean +/- 1 SD (a total of three values) estimate_means(   model,   by = c(\"Sepal.Width\", \"Petal.Length\"),   range = c(\"range\", \"sd\"),   length = c(4, 3) ) #> Estimated Marginal Means #>  #> Sepal.Width | Petal.Length | Mean |   SE |       95% CI | t(146) #> ---------------------------------------------------------------- #> 2.00        |         1.99 | 4.23 | 0.13 | [3.98, 4.48] |  33.47 #> 2.80        |         1.99 | 4.79 | 0.06 | [4.66, 4.91] |  76.04 #> 3.60        |         1.99 | 5.34 | 0.05 | [5.25, 5.43] | 116.74 #> 4.40        |         1.99 | 5.90 | 0.10 | [5.70, 6.10] |  57.96 #> 2.00        |         3.76 | 5.23 | 0.08 | [5.07, 5.38] |  67.09 #> 2.80        |         3.76 | 5.67 | 0.03 | [5.61, 5.74] | 169.13 #> 3.60        |         3.76 | 6.12 | 0.05 | [6.02, 6.23] | 117.07 #> 4.40        |         3.76 | 6.57 | 0.10 | [6.36, 6.78] |  62.95 #> 2.00        |         5.52 | 6.22 | 0.12 | [5.98, 6.46] |  51.44 #> 2.80        |         5.52 | 6.56 | 0.04 | [6.47, 6.65] | 148.72 #> 3.60        |         5.52 | 6.90 | 0.08 | [6.74, 7.07] |  82.43 #> 4.40        |         5.52 | 7.24 | 0.17 | [6.90, 7.58] |  41.93 #>  #> Variable predicted: Sepal.Length #> Predictors modulated: Sepal.Width, Petal.Length #>   data <- iris data$Petal.Length_factor <- ifelse(data$Petal.Length < 4.2, \"A\", \"B\")  model <- lme4::lmer(   Petal.Length ~ Sepal.Width + Species + (1 | Petal.Length_factor),   data = data ) estimate_means(model) #> We selected `by=c(\"Species\")`. #> Estimated Marginal Means #>  #> Species    | Mean |   SE |       95% CI | t(144) #> ------------------------------------------------ #> setosa     | 1.67 | 0.34 | [1.00, 2.35] |   4.88 #> versicolor | 4.27 | 0.34 | [3.61, 4.94] |  12.69 #> virginica  | 5.25 | 0.34 | [4.58, 5.92] |  15.45 #>  #> Variable predicted: Petal.Length #> Predictors modulated: Species #> Predictors averaged: Sepal.Width (3.1), Petal.Length_factor #>  estimate_means(model, by = \"Sepal.Width\", length = 3) #> Estimated Marginal Means #>  #> Sepal.Width | Mean |   SE |       95% CI | t(144) #> ------------------------------------------------- #> 2.00        | 3.40 | 0.35 | [2.72, 4.09] |   9.84 #> 3.20        | 3.78 | 0.33 | [3.12, 4.43] |  11.35 #> 4.40        | 4.15 | 0.35 | [3.45, 4.85] |  11.70 #>  #> Variable predicted: Petal.Length #> Predictors modulated: Sepal.Width #> Predictors averaged: Species, Petal.Length_factor #>  # }"},{"path":"https://easystats.github.io/modelbased/reference/estimate_slopes.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Marginal Effects — estimate_slopes","title":"Estimate Marginal Effects — estimate_slopes","text":"Estimate slopes (.e., coefficient) predictor within different factor levels, alongside numeric variable. words, assess effect predictor specific configurations data. corresponds derivative can useful understand predictor significant role interactions non-linear relationships present. related functions based marginal estimations includes estimate_contrasts() estimate_means(). See Details section , forget also check Vignettes README examples various examples, tutorials use cases.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_slopes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Marginal Effects — estimate_slopes","text":"","code":"estimate_slopes(   model,   trend = NULL,   by = NULL,   predict = NULL,   ci = 0.95,   p_adjust = \"none\",   transform = NULL,   keep_iterations = FALSE,   backend = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/modelbased/reference/estimate_slopes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Marginal Effects — estimate_slopes","text":"model statistical model. trend character indicating name variable compute slopes. get marginal effects specific values, use trend=\"<variable>\" along argument, e.g. =\"<variable>=c(1, 3, 5)\", combination length, instance, =\"<variable>\", length=30. calculate average marginal effects range values, use trend=\"<variable>=seq(1, 3, 0.1)\" (similar) omit variable provided trend argument. (focal) predictor variable(s) evaluate desired effect / mean / contrasts. predictors model included collapsed \"averaged\" (effect estimated across ). can character (vector) naming focal predictors, optionally including representative values levels focal predictors evaluated (e.g., = \"x = c(1, 2)\"). estimate \"average\", argument used create \"reference grid\" \"data grid\" representative values focal predictors. case, can also list named elements. See details insight::get_datagrid() learn create data grids predictors interest. predict passed type argument emmeans::emmeans() (backend = \"emmeans\") marginaleffects::avg_predictions() (backend = \"marginaleffects\"). Valid options predict : backend = \"marginaleffects\": predict can \"response\", \"link\", \"inverse_link\" valid type option supported model's class predict() method (e.g., zero-inflation models package glmmTMB, can choose predict = \"zprob\" predict = \"conditional\" etc., see glmmTMB::predict.glmmTMB). default, predict = NULL, appropriate transformation selected, usually returns predictions contrasts response-scale. \"inverse_link\" special option, comparable marginaleffects' invlink(link) option. calculate predictions link scale back-transform response scale. backend = \"emmeans\": predict can \"response\", \"link\", \"mu\", \"unlink\", \"log\". predict = NULL (default), appropriate transformation selected (usually \"response\"). See also vignette. See also section Predictions different scales. ci Confidence Interval (CI) level. Default 0.95 (95%). p_adjust p-values adjustment method frequentist multiple comparisons. estimate_slopes(), multiple comparison occurs Johnson-Neyman intervals, .e. case interactions two numeric predictors (one specified trend, one ). case, \"esarey\" option recommended, p_adjust can also one \"none\" (default), \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"\", \"fdr\", \"tukey\", \"sidak\", \"holm\". transform function applied predictions confidence intervals (back-) transform results, can useful case regression model transformed response variable (e.g., lm(log(y) ~ x)). Bayesian models, function applied individual draws posterior distribution, computing summaries. Can also TRUE, case insight::get_transformation() called determine appropriate transformation-function. Note standard errors returned transformations applied. keep_iterations TRUE, keep iterations (draws) bootstrapped Bayesian models. added additional columns named iter_1, iter_2, . keep_iterations positive number, many columns indicated keep_iterations added output. can reshape long format running bayestestR::reshape_iterations(). backend Whether use \"marginaleffects\" (default) \"emmeans\" backend. Results usually similar. major difference found mixed models, backend = \"marginaleffects\" also average across random effects levels, producing \"marginal predictions\" (instead \"conditional predictions\", see Heiss 2022). Another difference backend = \"marginaleffects\" slower backend = \"emmeans\". models, difference negligible. However, particular complex models large data sets fitted glmmTMB can significantly slower. can set default backend via options(), e.g. use options(modelbased_backend = \"emmeans\") use emmeans package options(modelbased_backend = \"marginaleffects\") set marginaleffects default backend. verbose Use FALSE silence messages warnings. ... arguments passed, instance, insight::get_datagrid(), functions emmeans marginaleffects package, process Bayesian models via bayestestR::describe_posterior(). Examples: insight::get_datagrid(): Argument length, digits range can used control (number ) representative values. integer variables, protect_integers modulates whether also treated numerics, .e. values can fractions . marginaleffects: Internally used functions avg_predictions() means contrasts, avg_slope() slopes. Therefore, arguments instance like vcov, equivalence, df, slope even newdata can passed functions. weights argument passed wts argument avg_predictions() avg_slopes(), however, weights can applied estimate \"average\" \"population\" (.e. marginalization options use data grids). arguments, re.form allow.new.levels, may passed predict() (internally used marginaleffects) supported model class. emmeans: Internally used functions emmeans() emtrends(). Additional arguments can passed functions. Bayesian models: Bayesian models, parameters cleaned using describe_posterior(), thus, arguments like, example, centrality, rope_range, test passed function. Especially estimate_contrasts() integer focal predictors, contrasts calculated, use argument integer_as_numeric set maximum number unique values integer predictor treat predictor \"discrete integer\" numeric. first case, contrasts calculated values predictor, latter, contrasts slopes calculated. integer integer_as_numeric unique values, treated numeric. Defaults 5.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_slopes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Marginal Effects — estimate_slopes","text":"data.frame class estimate_slopes.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_slopes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate Marginal Effects — estimate_slopes","text":"estimate_slopes(), estimate_means() estimate_contrasts() functions forming group, based marginal estimations (estimations based model). three built emmeans marginaleffects package (depending backend argument), reading documentation (instance emmeans::emmeans(), emmeans::emtrends() website) recommended understand idea behind types procedures. Model-based predictions basis follows. Indeed, first thing understand models can used make predictions (see estimate_link()). corresponds predicted response (\"outcome variable\") given specific predictor values predictors (.e., given specific data configuration). concept reference grid() important direct predictions. Marginal \"means\", obtained via estimate_means(), extension predictions, allowing \"average\" (collapse) predictors, obtain average response value specific predictors configuration. typically used predictors interest factors. Indeed, parameters model usually give intercept value \"effect\" factor level (different intercept). Marginal means can used directly give mean value response variable levels factor. Moreover, can also used control, average predictors, useful case multiple predictors without interactions. Marginal contrasts, obtained via estimate_contrasts(), extension marginal means, allow investigate difference (.e., contrast) marginal means. , , often used get pairwise differences levels factor. works also continuous predictors, instance one also interested whether difference two extremes continuous predictor significant. Finally, marginal effects, obtained via estimate_slopes(), different focus values response variable, model's parameters. idea assess effect predictor specific configuration predictors. relevant case interactions non-linear relationships, effect predictor variable changes depending predictors. Moreover, effects can also \"averaged\" predictors, get instance \"general trend\" predictor different factor levels. Example: imagine following model lm(y ~ condition * x) condition factor 3 levels , B C x continuous variable (like age example). One idea see model performs, compare actual response y one predicted model (using estimate_expectation()). Another idea evaluate average mean condition's levels (using estimate_means()), can useful visualize . Another possibility evaluate difference levels (using estimate_contrasts()). Finally, one also estimate effect x averaged conditions, instead within condition (using [estimate_slopes]).","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_slopes.html","id":"predictions-and-contrasts-at-meaningful-values-data-grids-","dir":"Reference","previous_headings":"","what":"Predictions and contrasts at meaningful values (data grids)","title":"Estimate Marginal Effects — estimate_slopes","text":"define representative values focal predictors (specified , contrast, trend), can use several methods. values internally generated insight::get_datagrid(), consult documentation details. can directly specify values strings lists , contrast, trend. numeric focal predictors, use examples like = \"gear = c(4, 8)\", = list(gear = c(4, 8)) = \"gear = 5:10\" factor character predictors, use = \"Species = c('setosa', 'virginica')\" = list(Species = c('setosa', 'virginica')) can use \"shortcuts\" within square brackets, = \"Sepal.Width = [sd]\" = \"Sepal.Width = [fivenum]\" numeric focal predictors, representative values specified, length range control number type representative values: length determines many equally spaced values generated. range specifies type values, like \"range\" \"sd\". length range apply numeric focal predictors. multiple numeric predictors, length range can accept multiple elements, one predictor. integer variables, values appear data included data grid, independent length argument. behaviour can changed setting protect_integers = FALSE, treat integer variables numerics (possibly produce fractions). See also vignette examples.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_slopes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Marginal Effects — estimate_slopes","text":"","code":"library(ggplot2) # Get an idea of the data ggplot(iris, aes(x = Petal.Length, y = Sepal.Width)) +   geom_point(aes(color = Species)) +   geom_smooth(color = \"black\", se = FALSE) +   geom_smooth(aes(color = Species), linetype = \"dotted\", se = FALSE) +   geom_smooth(aes(color = Species), method = \"lm\", se = FALSE) #> `geom_smooth()` using method = 'loess' and formula = 'y ~ x' #> `geom_smooth()` using method = 'loess' and formula = 'y ~ x' #> `geom_smooth()` using formula = 'y ~ x'   # Model it model <- lm(Sepal.Width ~ Species * Petal.Length, data = iris) # Compute the marginal effect of Petal.Length at each level of Species slopes <- estimate_slopes(model, trend = \"Petal.Length\", by = \"Species\") slopes #> Estimated Marginal Effects #>  #> Species    | Slope |   SE |        95% CI |    t |      p #> --------------------------------------------------------- #> setosa     |  0.39 | 0.26 | [-0.12, 0.90] | 1.49 |  0.136 #> versicolor |  0.37 | 0.10 | [ 0.19, 0.56] | 3.89 | < .001 #> virginica  |  0.23 | 0.08 | [ 0.07, 0.39] | 2.86 |  0.004 #>  #> Marginal effects estimated for Petal.Length #> Type of slope was dY/dX  # \\dontrun{ # Plot it plot(slopes)  standardize(slopes) #> Estimated Marginal Effects (standardized) #>  #> Species    | Slope |   SE |        95% CI |    t |      p #> --------------------------------------------------------- #> setosa     |  0.39 | 0.60 | [-0.28, 2.06] | 1.49 |  0.136 #> versicolor |  0.37 | 0.22 | [ 0.43, 1.29] | 3.89 | < .001 #> virginica  |  0.23 | 0.19 | [ 0.17, 0.91] | 2.86 |  0.004 #>  #> Marginal effects estimated for Petal.Length #> Type of slope was dY/dX  model <- mgcv::gam(Sepal.Width ~ s(Petal.Length), data = iris) slopes <- estimate_slopes(model, by = \"Petal.Length\", length = 50) #> No numeric variable was specified for slope estimation. Selecting `trend #>   = \"Petal.Length\"`. summary(slopes) #> Johnson-Neymann Intervals #>  #> Start |  End | Direction | Confidence      #> ------------------------------------------ #> 1.00  | 1.60 | positive  | Not Significant #> 1.72  | 1.96 | negative  | Not Significant #> 2.08  | 3.05 | negative  | Significant     #> 3.17  | 3.41 | negative  | Not Significant #> 3.53  | 3.65 | positive  | Not Significant #> 3.77  | 4.25 | positive  | Significant     #> 4.37  | 6.18 | positive  | Not Significant #> 6.30  | 6.90 | negative  | Not Significant #>  #> Marginal effects estimated for Petal.Length #> Type of slope was dY/dX plot(slopes)   model <- mgcv::gam(Sepal.Width ~ s(Petal.Length, by = Species), data = iris) slopes <- estimate_slopes(model,   trend = \"Petal.Length\",   by = c(\"Petal.Length\", \"Species\"), length = 20 ) summary(slopes) #> There might be too few data to accurately determine intervals. Consider #>   setting `length = 100` (or larger) in your call to `estimate_slopes()`. #> Johnson-Neymann Intervals #>  #> Group      | Start |  End | Direction | Confidence      #> ------------------------------------------------------- #> setosa     |  1.00 | 1.62 | positive  | Not Significant #> versicolor |  3.17 | 5.04 | positive  | Significant     #> virginica  |  4.73 | 5.66 | positive  | Significant     #> virginica  |  5.97 | 6.90 | positive  | Not Significant #>  #> Marginal effects estimated for Petal.Length #> Type of slope was dY/dX plot(slopes)   # marginal effects, grouped by Species, at different values of Petal.Length estimate_slopes(model,   trend = \"Petal.Length\",   by = c(\"Petal.Length\", \"Species\"), length = 10 ) #> Estimated Marginal Effects #>  #> Petal.Length | Species    | Slope |   SE |        95% CI |    t |      p #> ------------------------------------------------------------------------ #> 1.00         | setosa     |  0.30 | 0.32 | [-0.33, 0.93] | 0.94 |  0.349 #> 1.66         | setosa     |  0.22 | 0.24 | [-0.26, 0.70] | 0.90 |  0.369 #> 3.62         | versicolor |  0.38 | 0.10 | [ 0.19, 0.56] | 3.94 | < .001 #> 4.28         | versicolor |  0.38 | 0.10 | [ 0.19, 0.56] | 3.94 | < .001 #> 4.93         | versicolor |  0.38 | 0.10 | [ 0.19, 0.56] | 3.94 | < .001 #> 4.93         | virginica  |  0.31 | 0.14 | [ 0.04, 0.58] | 2.23 |  0.026 #> 5.59         | virginica  |  0.26 | 0.11 | [ 0.05, 0.47] | 2.42 |  0.016 #> 6.24         | virginica  |  0.12 | 0.14 | [-0.16, 0.40] | 0.86 |  0.392 #> 6.90         | virginica  |  0.05 | 0.22 | [-0.39, 0.49] | 0.21 |  0.835 #>  #> Marginal effects estimated for Petal.Length #> Type of slope was dY/dX  # marginal effects at different values of Petal.Length estimate_slopes(model, trend = \"Petal.Length\", by = \"Petal.Length\", length = 10) #> Estimated Marginal Effects #>  #> Petal.Length |    Slope |   SE |        95% CI |     t |     p #> -------------------------------------------------------------- #> 1.00         |     0.27 | 0.17 | [-0.06, 0.59] |  1.63 | 0.104 #> 1.66         |     0.25 | 0.13 | [-0.01, 0.50] |  1.86 | 0.064 #> 2.31         |     0.14 | 0.12 | [-0.10, 0.39] |  1.16 | 0.247 #> 2.97         |     0.05 | 0.10 | [-0.15, 0.26] |  0.53 | 0.599 #> 3.62         | 5.50e-03 | 0.11 | [-0.20, 0.21] |  0.05 | 0.959 #> 4.28         |    -0.02 | 0.13 | [-0.28, 0.23] | -0.17 | 0.862 #> 4.93         |    -0.02 | 0.17 | [-0.36, 0.32] | -0.11 | 0.912 #> 5.59         |    -0.05 | 0.22 | [-0.48, 0.38] | -0.22 | 0.825 #> 6.24         |    -0.09 | 0.27 | [-0.61, 0.43] | -0.35 | 0.730 #> 6.90         |    -0.12 | 0.31 | [-0.72, 0.48] | -0.40 | 0.689 #>  #> Marginal effects estimated for Petal.Length #> Type of slope was dY/dX  # marginal effects at very specific values of Petal.Length estimate_slopes(model, trend = \"Petal.Length\", by = \"Petal.Length=c(1, 3, 5)\") #> Estimated Marginal Effects #>  #> Petal.Length | Slope |   SE |        95% CI |     t |     p #> ----------------------------------------------------------- #> 1            |  0.27 | 0.17 | [-0.06, 0.59] |  1.63 | 0.104 #> 3            |  0.05 | 0.10 | [-0.15, 0.26] |  0.49 | 0.626 #> 5            | -0.02 | 0.18 | [-0.37, 0.33] | -0.11 | 0.912 #>  #> Marginal effects estimated for Petal.Length #> Type of slope was dY/dX  # average marginal effects of Petal.Length, # just for the trend within a certain range estimate_slopes(model, trend = \"Petal.Length=seq(2, 4, 0.01)\") #> Estimated Marginal Effects #>  #> Slope |   SE |        95% CI |    t |     p #> ------------------------------------------- #> 0.07  | 0.07 | [-0.07, 0.21] | 0.92 | 0.358 #>  #> Marginal effects estimated for Petal.Length #> Type of slope was dY/dX # }"},{"path":"https://easystats.github.io/modelbased/reference/fish.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample data set — fish","title":"Sample data set — fish","text":"sample data set, used tests examples. Useful demonstrating count models (without zero-inflation component). consists nine variables 250 observations.","code":""},{"path":"https://easystats.github.io/modelbased/reference/get_emmeans.html","id":null,"dir":"Reference","previous_headings":"","what":"Consistent API for 'emmeans' and 'marginaleffects' — get_emcontrasts","title":"Consistent API for 'emmeans' and 'marginaleffects' — get_emcontrasts","text":"functions convenient wrappers around emmeans marginaleffects packages. mostly available developers want leverage unified API getting model-based estimates, regular users use estimate_* set functions. get_emmeans(), get_emcontrasts() get_emtrends() functions wrappers around emmeans::emmeans() emmeans::emtrends().","code":""},{"path":"https://easystats.github.io/modelbased/reference/get_emmeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Consistent API for 'emmeans' and 'marginaleffects' — get_emcontrasts","text":"","code":"get_emcontrasts(   model,   contrast = NULL,   by = NULL,   predict = NULL,   comparison = \"pairwise\",   keep_iterations = FALSE,   verbose = TRUE,   ... )  get_emmeans(   model,   by = \"auto\",   predict = NULL,   keep_iterations = FALSE,   verbose = TRUE,   ... )  get_emtrends(   model,   trend = NULL,   by = NULL,   predict = NULL,   keep_iterations = FALSE,   verbose = TRUE,   ... )  get_marginalcontrasts(   model,   contrast = NULL,   by = NULL,   predict = NULL,   ci = 0.95,   comparison = \"pairwise\",   estimate = NULL,   p_adjust = \"none\",   transform = NULL,   keep_iterations = FALSE,   verbose = TRUE,   ... )  get_marginalmeans(   model,   by = \"auto\",   predict = NULL,   ci = 0.95,   estimate = NULL,   transform = NULL,   keep_iterations = FALSE,   verbose = TRUE,   ... )  get_marginaltrends(   model,   trend = NULL,   by = NULL,   predict = NULL,   ci = 0.95,   p_adjust = \"none\",   transform = NULL,   keep_iterations = FALSE,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/modelbased/reference/get_emmeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Consistent API for 'emmeans' and 'marginaleffects' — get_emcontrasts","text":"model statistical model. contrast character vector indicating name variable(s) compute contrasts, optionally including representative values levels contrasts evaluated (e.g., contrast=\"x=c('','b')\"). (focal) predictor variable(s) evaluate desired effect / mean / contrasts. predictors model included collapsed \"averaged\" (effect estimated across ). can character (vector) naming focal predictors, optionally including representative values levels focal predictors evaluated (e.g., = \"x = c(1, 2)\"). estimate \"average\", argument used create \"reference grid\" \"data grid\" representative values focal predictors. case, can also list named elements. See details insight::get_datagrid() learn create data grids predictors interest. predict passed type argument emmeans::emmeans() (backend = \"emmeans\") marginaleffects::avg_predictions() (backend = \"marginaleffects\"). Valid options predict : backend = \"marginaleffects\": predict can \"response\", \"link\", \"inverse_link\" valid type option supported model's class predict() method (e.g., zero-inflation models package glmmTMB, can choose predict = \"zprob\" predict = \"conditional\" etc., see glmmTMB::predict.glmmTMB). default, predict = NULL, appropriate transformation selected, usually returns predictions contrasts response-scale. \"inverse_link\" special option, comparable marginaleffects' invlink(link) option. calculate predictions link scale back-transform response scale. backend = \"emmeans\": predict can \"response\", \"link\", \"mu\", \"unlink\", \"log\". predict = NULL (default), appropriate transformation selected (usually \"response\"). See also vignette. See also section Predictions different scales. comparison Specify type contrasts tests carried . backend = \"emmeans\", can one \"pairwise\", \"poly\", \"consec\", \"eff\", \"del.eff\", \"mean_chg\", \"trt.vs.ctrl\", \"dunnett\", \"wtcon\" . See also method argument emmeans::contrast ?emmeans::emmc-functions. backend = \"marginaleffects\", can numeric value, vector, matrix, string equation specifying hypothesis test, string naming comparison method, formula, function. Strings, string equations formula probably common options described . options detailed descriptions options, see also marginaleffects::comparisons website. String: One \"pairwise\", \"reference\", \"sequential\", \"meandev\" \"meanotherdev\", \"poly\", \"helmert\", \"trt_vs_ctrl\". String equation: identify parameters output, either specify term name, \"b1\", \"b2\" etc. indicate rows, e.g.:\"hp = drat\", \"b1 = b2\", \"b1 + b2 + b3 = 0\". Formula: formula like comparison ~ pairs | group, left-hand side indicates type comparison (difference ratio), right-hand side determines pairs estimates compare (reference, sequential, meandev, etc., see string-options). Optionally, comparisons can carried within subsets indicating grouping variable vertical bar ( |). keep_iterations TRUE, keep iterations (draws) bootstrapped Bayesian models. added additional columns named iter_1, iter_2, . keep_iterations positive number, many columns indicated keep_iterations added output. can reshape long format running bayestestR::reshape_iterations(). verbose Use FALSE silence messages warnings. ... arguments passed, instance, insight::get_datagrid(), functions emmeans marginaleffects package, process Bayesian models via bayestestR::describe_posterior(). Examples: insight::get_datagrid(): Argument length, digits range can used control (number ) representative values. integer variables, protect_integers modulates whether also treated numerics, .e. values can fractions . marginaleffects: Internally used functions avg_predictions() means contrasts, avg_slope() slopes. Therefore, arguments instance like vcov, equivalence, df, slope even newdata can passed functions. weights argument passed wts argument avg_predictions() avg_slopes(), however, weights can applied estimate \"average\" \"population\" (.e. marginalization options use data grids). arguments, re.form allow.new.levels, may passed predict() (internally used marginaleffects) supported model class. emmeans: Internally used functions emmeans() emtrends(). Additional arguments can passed functions. Bayesian models: Bayesian models, parameters cleaned using describe_posterior(), thus, arguments like, example, centrality, rope_range, test passed function. Especially estimate_contrasts() integer focal predictors, contrasts calculated, use argument integer_as_numeric set maximum number unique values integer predictor treat predictor \"discrete integer\" numeric. first case, contrasts calculated values predictor, latter, contrasts slopes calculated. integer integer_as_numeric unique values, treated numeric. Defaults 5. trend character indicating name variable compute slopes. get marginal effects specific values, use trend=\"<variable>\" along argument, e.g. =\"<variable>=c(1, 3, 5)\", combination length, instance, =\"<variable>\", length=30. calculate average marginal effects range values, use trend=\"<variable>=seq(1, 3, 0.1)\" (similar) omit variable provided trend argument. ci Confidence Interval (CI) level. Default 0.95 (95%). estimate estimate argument determines predictions averaged (\"marginalized\") variables specified contrast (non-focal predictors). controls whether predictions represent \"typical\" individual, \"average\" individual sample, \"average\" individual broader population. \"typical\" (Default): Calculates predictions balanced data grid representing combinations focal predictor levels (specified ). non-focal numeric predictors, uses mean; non-focal categorical predictors, marginalizes (averages) levels. represents \"typical\" observation based data grid useful comparing groups. answers: \"average outcome 'typical' observation?\". default approach estimating marginal means using emmeans package. \"average\": Calculates predictions observation sample averages predictions within group defined focal predictors. reflects sample's actual distribution non-focal predictors, balanced grid. answers: \"predicted value average observation data?\" \"population\": \"Clones\" observation, creating copies possible combinations focal predictor levels. averages predictions across \"counterfactual\" observations (non-observed permutations) within group. extrapolates hypothetical broader population, considering \"\" scenarios. answers: \"predicted response 'average' observation broader possible target population?\" approach entails assumptions likelihood different combinations, can apt generalize. also option used G-computation (Chatton Rohrer 2024). can set default option estimate argument via options(), e.g. options(modelbased_estimate = \"average\") p_adjust p-values adjustment method frequentist multiple comparisons. estimate_slopes(), multiple comparison occurs Johnson-Neyman intervals, .e. case interactions two numeric predictors (one specified trend, one ). case, \"esarey\" option recommended, p_adjust can also one \"none\" (default), \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"\", \"fdr\", \"tukey\", \"sidak\", \"holm\". transform function applied predictions confidence intervals (back-) transform results, can useful case regression model transformed response variable (e.g., lm(log(y) ~ x)). Bayesian models, function applied individual draws posterior distribution, computing summaries. Can also TRUE, case insight::get_transformation() called determine appropriate transformation-function. Note standard errors returned transformations applied.","code":""},{"path":"https://easystats.github.io/modelbased/reference/get_emmeans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Consistent API for 'emmeans' and 'marginaleffects' — get_emcontrasts","text":"","code":"# Basic usage model <- lm(Sepal.Width ~ Species, data = iris) get_emcontrasts(model) #> No variable was specified for contrast estimation. Selecting `contrast = #>   \"Species\"`. #>  contrast               estimate     SE  df t.ratio p.value #>  setosa - versicolor       0.658 0.0679 147   9.685  <.0001 #>  setosa - virginica        0.454 0.0679 147   6.683  <.0001 #>  versicolor - virginica   -0.204 0.0679 147  -3.003  0.0088 #>  #> P value adjustment: tukey method for comparing a family of 3 estimates   # \\dontrun{ # Dealing with interactions model <- lm(Sepal.Width ~ Species * Petal.Width, data = iris) # By default: selects first factor get_emcontrasts(model) #> No variable was specified for contrast estimation. Selecting `contrast = #>   \"Species\"`. #>  contrast               estimate    SE  df t.ratio p.value #>  setosa - versicolor       1.590 0.394 144   4.039  0.0003 #>  setosa - virginica        1.774 0.413 144   4.293  0.0001 #>  versicolor - virginica    0.184 0.145 144   1.272  0.4131 #>  #> P value adjustment: tukey method for comparing a family of 3 estimates  # Or both get_emcontrasts(model, contrast = c(\"Species\", \"Petal.Width\"), length = 2) #>  contrast                                              estimate    SE  df #>  setosa Petal.Width0.1 - versicolor Petal.Width0.1       1.8275 0.279 144 #>  setosa Petal.Width0.1 - virginica Petal.Width0.1        1.5479 0.312 144 #>  setosa Petal.Width0.1 - setosa Petal.Width2.5          -2.0093 0.977 144 #>  setosa Petal.Width0.1 - versicolor Petal.Width2.5      -0.7012 0.268 144 #>  setosa Petal.Width0.1 - virginica Petal.Width2.5        0.0325 0.112 144 #>  versicolor Petal.Width0.1 - virginica Petal.Width0.1   -0.2797 0.406 144 #>  versicolor Petal.Width0.1 - setosa Petal.Width2.5      -3.8368 0.957 144 #>  versicolor Petal.Width0.1 - versicolor Petal.Width2.5  -2.5288 0.521 144 #>  versicolor Petal.Width0.1 - virginica Petal.Width2.5   -1.7951 0.282 144 #>  virginica Petal.Width0.1 - setosa Petal.Width2.5       -3.5571 0.967 144 #>  virginica Petal.Width0.1 - versicolor Petal.Width2.5   -2.2491 0.399 144 #>  virginica Petal.Width0.1 - virginica Petal.Width2.5    -1.5154 0.375 144 #>  setosa Petal.Width2.5 - versicolor Petal.Width2.5       1.3080 0.954 144 #>  setosa Petal.Width2.5 - virginica Petal.Width2.5        2.0417 0.922 144 #>  versicolor Petal.Width2.5 - virginica Petal.Width2.5    0.7337 0.272 144 #>  t.ratio p.value #>    6.550  <.0001 #>    4.955  <.0001 #>   -2.057  0.3158 #>   -2.614  0.1005 #>    0.289  0.9997 #>   -0.689  0.9829 #>   -4.009  0.0013 #>   -4.858  <.0001 #>   -6.355  <.0001 #>   -3.678  0.0044 #>   -5.642  <.0001 #>   -4.043  0.0012 #>    1.371  0.7441 #>    2.214  0.2379 #>    2.699  0.0817 #>  #> P value adjustment: tukey method for comparing a family of 6 estimates  # Or with custom specifications get_emcontrasts(model, contrast = c(\"Species\", \"Petal.Width=c(1, 2)\")) #>  contrast                                          estimate     SE  df t.ratio #>  setosa Petal.Width1 - versicolor Petal.Width1        1.633 0.3210 144   5.093 #>  setosa Petal.Width1 - virginica Petal.Width1         1.733 0.3510 144   4.933 #>  setosa Petal.Width1 - setosa Petal.Width2           -0.837 0.4070 144  -2.057 #>  setosa Petal.Width1 - versicolor Petal.Width2        0.579 0.3450 144   1.678 #>  setosa Petal.Width1 - virginica Petal.Width2         1.102 0.3130 144   3.523 #>  versicolor Petal.Width1 - virginica Petal.Width1     0.100 0.1850 144   0.542 #>  versicolor Petal.Width1 - setosa Petal.Width2       -2.470 0.7200 144  -3.431 #>  versicolor Petal.Width1 - versicolor Petal.Width2   -1.054 0.2170 144  -4.858 #>  versicolor Petal.Width1 - virginica Petal.Width2    -0.531 0.0928 144  -5.720 #>  virginica Petal.Width1 - setosa Petal.Width2        -2.570 0.7340 144  -3.501 #>  virginica Petal.Width1 - versicolor Petal.Width2    -1.154 0.2250 144  -5.128 #>  virginica Petal.Width1 - virginica Petal.Width2     -0.631 0.1560 144  -4.043 #>  setosa Petal.Width2 - versicolor Petal.Width2        1.416 0.7310 144   1.937 #>  setosa Petal.Width2 - virginica Petal.Width2         1.939 0.7160 144   2.706 #>  versicolor Petal.Width2 - virginica Petal.Width2     0.523 0.1580 144   3.306 #>  p.value #>   <.0001 #>   <.0001 #>   0.3158 #>   0.5487 #>   0.0074 #>   0.9943 #>   0.0100 #>   <.0001 #>   <.0001 #>   0.0080 #>   <.0001 #>   0.0012 #>   0.3840 #>   0.0802 #>   0.0149 #>  #> P value adjustment: tukey method for comparing a family of 6 estimates  # Or modulate it get_emcontrasts(model, by = \"Petal.Width\", length = 4) #> No variable was specified for contrast estimation. Selecting `contrast = #>   \"Species\"`. #> Petal.Width = 0.1: #>  contrast               estimate    SE  df t.ratio p.value #>  setosa - versicolor      1.8275 0.279 144   6.550  <.0001 #>  setosa - virginica       1.5479 0.312 144   4.955  <.0001 #>  versicolor - virginica  -0.2797 0.406 144  -0.689  0.7703 #>  #> Petal.Width = 0.9: #>  contrast               estimate    SE  df t.ratio p.value #>  setosa - versicolor      1.6544 0.288 144   5.743  <.0001 #>  setosa - virginica       1.7125 0.325 144   5.276  <.0001 #>  versicolor - virginica   0.0581 0.208 144   0.280  0.9577 #>  #> Petal.Width = 1.7: #>  contrast               estimate    SE  df t.ratio p.value #>  setosa - versicolor      1.4812 0.600 144   2.467  0.0390 #>  setosa - virginica       1.8771 0.597 144   3.144  0.0057 #>  versicolor - virginica   0.3959 0.113 144   3.502  0.0018 #>  #> Petal.Width = 2.5: #>  contrast               estimate    SE  df t.ratio p.value #>  setosa - versicolor      1.3080 0.954 144   1.371  0.3587 #>  setosa - virginica       2.0417 0.922 144   2.214  0.0722 #>  versicolor - virginica   0.7337 0.272 144   2.699  0.0212 #>  #> P value adjustment: tukey method for comparing a family of 3 estimates  # } model <- lm(Sepal.Length ~ Species + Petal.Width, data = iris)  # By default, 'by' is set to \"Species\" get_emmeans(model) #> We selected `by = c(\"Species\")`. #>  Species    emmean     SE  df lower.CL upper.CL #>  setosa       5.88 0.1970 146     5.49     6.27 #>  versicolor   5.82 0.0723 146     5.68     5.96 #>  virginica    5.83 0.1740 146     5.49     6.17 #>  #> Confidence level used: 0.95   # \\dontrun{ # Overall mean (close to 'mean(iris$Sepal.Length)') get_emmeans(model, by = NULL) #>  1       emmean     SE  df lower.CL upper.CL #>  overall   5.84 0.0393 146     5.77     5.92 #>  #> Results are averaged over the levels of: Species  #> Confidence level used: 0.95   # One can estimate marginal means at several values of a 'modulate' variable get_emmeans(model, by = \"Petal.Width\", length = 3) #>  Petal.Width emmean     SE  df lower.CL upper.CL #>          0.1   4.84 0.2170 146     4.41     5.26 #>          1.3   5.94 0.0439 146     5.85     6.02 #>          2.5   7.04 0.2550 146     6.53     7.54 #>  #> Results are averaged over the levels of: Species  #> Confidence level used: 0.95   # Interactions model <- lm(Sepal.Width ~ Species * Petal.Length, data = iris)  get_emmeans(model) #> We selected `by = c(\"Species\")`. #>  Species    emmean     SE  df lower.CL upper.CL #>  setosa       4.32 0.5990 144     3.13     5.50 #>  versicolor   2.58 0.0658 144     2.45     2.71 #>  virginica    2.55 0.1540 144     2.25     2.86 #>  #> Confidence level used: 0.95  get_emmeans(model, by = c(\"Species\", \"Petal.Length\"), length = 2) #>  Species    Petal.Length emmean    SE  df lower.CL upper.CL #>  setosa              1.0   3.25 0.128 144    2.995     3.50 #>  versicolor          1.0   1.55 0.317 144    0.924     2.18 #>  virginica           1.0   1.91 0.375 144    1.165     2.65 #>  setosa              6.9   5.54 1.420 144    2.739     8.34 #>  versicolor          6.9   3.76 0.258 144    3.249     4.27 #>  virginica           6.9   3.29 0.119 144    3.055     3.53 #>  #> Confidence level used: 0.95  get_emmeans(model, by = c(\"Species\", \"Petal.Length = c(1, 3, 5)\"), length = 2) #>  Species    Petal.Length emmean     SE  df lower.CL upper.CL #>  setosa                1   3.25 0.1280 144    2.995     3.50 #>  versicolor            1   1.55 0.3170 144    0.924     2.18 #>  virginica             1   1.91 0.3750 144    1.165     2.65 #>  setosa                3   4.02 0.4030 144    3.229     4.82 #>  versicolor            3   2.30 0.1290 144    2.043     2.55 #>  virginica             3   2.38 0.2140 144    1.954     2.80 #>  setosa                5   4.80 0.9220 144    2.979     6.62 #>  versicolor            5   3.05 0.0840 144    2.881     3.21 #>  virginica             5   2.84 0.0636 144    2.719     2.97 #>  #> Confidence level used: 0.95  # } # \\dontrun{ model <- lm(Sepal.Width ~ Species * Petal.Length, data = iris)  get_emtrends(model) #> No numeric variable was specified for slope estimation. Selecting `trend #>   = \"Petal.Length\"`. #>  1       Petal.Length.trend     SE  df lower.CL upper.CL #>  overall              0.332 0.0964 144    0.142    0.523 #>  #> Results are averaged over the levels of: Species  #> Confidence level used: 0.95  get_emtrends(model, by = \"Species\") #> No numeric variable was specified for slope estimation. Selecting `trend #>   = \"Petal.Length\"`. #>  Species    Petal.Length.trend     SE  df lower.CL upper.CL #>  setosa                  0.388 0.2600 144  -0.1264    0.902 #>  versicolor              0.374 0.0961 144   0.1843    0.564 #>  virginica               0.234 0.0819 144   0.0725    0.396 #>  #> Confidence level used: 0.95  get_emtrends(model, by = \"Petal.Length\") #> No numeric variable was specified for slope estimation. Selecting `trend #>   = \"Petal.Length\"`. #>  Petal.Length Petal.Length.trend     SE  df lower.CL upper.CL #>          1.00              0.332 0.0964 144    0.142    0.523 #>          1.66              0.332 0.0964 144    0.142    0.523 #>          2.31              0.332 0.0964 144    0.142    0.523 #>          2.97              0.332 0.0964 144    0.142    0.523 #>          3.62              0.332 0.0964 144    0.142    0.523 #>          4.28              0.332 0.0964 144    0.142    0.523 #>          4.93              0.332 0.0964 144    0.142    0.523 #>          5.59              0.332 0.0964 144    0.142    0.523 #>          6.24              0.332 0.0964 144    0.142    0.523 #>          6.90              0.332 0.0964 144    0.142    0.523 #>  #> Results are averaged over the levels of: Species  #> Confidence level used: 0.95  get_emtrends(model, by = c(\"Species\", \"Petal.Length\")) #> No numeric variable was specified for slope estimation. Selecting `trend #>   = \"Petal.Length\"`. #>  Species    Petal.Length Petal.Length.trend     SE  df lower.CL upper.CL #>  setosa             1.00              0.388 0.2600 144  -0.1264    0.902 #>  versicolor         1.00              0.374 0.0961 144   0.1843    0.564 #>  virginica          1.00              0.234 0.0819 144   0.0725    0.396 #>  setosa             1.66              0.388 0.2600 144  -0.1264    0.902 #>  versicolor         1.66              0.374 0.0961 144   0.1843    0.564 #>  virginica          1.66              0.234 0.0819 144   0.0725    0.396 #>  setosa             2.31              0.388 0.2600 144  -0.1264    0.902 #>  versicolor         2.31              0.374 0.0961 144   0.1843    0.564 #>  virginica          2.31              0.234 0.0819 144   0.0725    0.396 #>  setosa             2.97              0.388 0.2600 144  -0.1264    0.902 #>  versicolor         2.97              0.374 0.0961 144   0.1843    0.564 #>  virginica          2.97              0.234 0.0819 144   0.0725    0.396 #>  setosa             3.62              0.388 0.2600 144  -0.1264    0.902 #>  versicolor         3.62              0.374 0.0961 144   0.1843    0.564 #>  virginica          3.62              0.234 0.0819 144   0.0725    0.396 #>  setosa             4.28              0.388 0.2600 144  -0.1264    0.902 #>  versicolor         4.28              0.374 0.0961 144   0.1843    0.564 #>  virginica          4.28              0.234 0.0819 144   0.0725    0.396 #>  setosa             4.93              0.388 0.2600 144  -0.1264    0.902 #>  versicolor         4.93              0.374 0.0961 144   0.1843    0.564 #>  virginica          4.93              0.234 0.0819 144   0.0725    0.396 #>  setosa             5.59              0.388 0.2600 144  -0.1264    0.902 #>  versicolor         5.59              0.374 0.0961 144   0.1843    0.564 #>  virginica          5.59              0.234 0.0819 144   0.0725    0.396 #>  setosa             6.24              0.388 0.2600 144  -0.1264    0.902 #>  versicolor         6.24              0.374 0.0961 144   0.1843    0.564 #>  virginica          6.24              0.234 0.0819 144   0.0725    0.396 #>  setosa             6.90              0.388 0.2600 144  -0.1264    0.902 #>  versicolor         6.90              0.374 0.0961 144   0.1843    0.564 #>  virginica          6.90              0.234 0.0819 144   0.0725    0.396 #>  #> Confidence level used: 0.95  # }  model <- lm(Petal.Length ~ poly(Sepal.Width, 4), data = iris) get_emtrends(model) #> No numeric variable was specified for slope estimation. Selecting `trend #>   = \"Sepal.Width\"`. #>  1       Sepal.Width.trend    SE  df lower.CL upper.CL #>  overall             -2.67 0.548 145    -3.75    -1.58 #>  #> Confidence level used: 0.95  get_emtrends(model, by = \"Sepal.Width\") #> No numeric variable was specified for slope estimation. Selecting `trend #>   = \"Sepal.Width\"`. #>  Sepal.Width Sepal.Width.trend    SE  df lower.CL upper.CL #>         2.00             7.484 5.420 145   -3.225   18.192 #>         2.27             3.775 2.090 145   -0.357    7.906 #>         2.53             0.834 0.765 145   -0.678    2.346 #>         2.80            -1.337 0.706 145   -2.732    0.058 #>         3.07            -2.700 0.543 145   -3.773   -1.628 #>         3.33            -3.231 0.606 145   -4.430   -2.033 #>         3.60            -2.909 0.838 145   -4.564   -1.254 #>         3.87            -1.705 1.010 145   -3.701    0.290 #>         4.13             0.394 2.390 145   -4.327    5.116 #>         4.40             3.431 5.800 145   -8.028   14.890 #>  #> Confidence level used: 0.95  model <- lm(Sepal.Length ~ Species + Petal.Width, data = iris)  # By default, 'by' is set to \"Species\" get_marginalmeans(model) #> We selected `by=c(\"Species\")`. #>  #>     Species Estimate Std. Error    t Pr(>|t|)     S 2.5 % 97.5 %  Df #>  setosa         5.88     0.1969 29.9   <0.001 210.3  5.49   6.27 146 #>  versicolor     5.82     0.0723 80.5   <0.001 405.6  5.68   5.96 146 #>  virginica      5.83     0.1741 33.5   <0.001 231.4  5.49   6.17 146 #>  #> Type:  response  #>   # Overall mean (close to 'mean(iris$Sepal.Length)') get_marginalmeans(model, by = NULL) #>  #>  Estimate Std. Error   t Pr(>|t|)     S 2.5 % 97.5 %  Df #>      5.84     0.0393 149   <0.001 533.4  5.77   5.92 146 #>  #> Type:  response  #>   # \\dontrun{ # One can estimate marginal means at several values of a 'modulate' variable get_marginalmeans(model, by = \"Petal.Width\", length = 3) #>  #>  Petal.Width Estimate Std. Error     t Pr(>|t|)     S 2.5 % 97.5 %  Df #>          0.1     4.84     0.2167  22.3   <0.001 160.0  4.41   5.26 146 #>          1.3     5.94     0.0439 135.3   <0.001 513.6  5.85   6.02 146 #>          2.5     7.04     0.2552  27.6   <0.001 196.1  6.53   7.54 146 #>  #> Type:  response  #>   # Interactions model <- lm(Sepal.Width ~ Species * Petal.Length, data = iris)  get_marginalmeans(model) #> We selected `by=c(\"Species\")`. #>  #>     Species Estimate Std. Error     t Pr(>|t|)     S 2.5 % 97.5 %  Df #>  setosa         4.32     0.5990  7.21   <0.001  35.0  3.13   5.50 144 #>  versicolor     2.58     0.0658 39.24   <0.001 259.3  2.45   2.71 144 #>  virginica      2.55     0.1535 16.63   <0.001 115.0  2.25   2.86 144 #>  #> Type:  response  #>  get_marginalmeans(model, by = c(\"Species\", \"Petal.Length\"), length = 2) #>  #>     Species Petal.Length Estimate Std. Error     t Pr(>|t|)     S 2.5 % 97.5 % #>  setosa              1.0     3.25      0.128 25.33   <0.001 180.0 2.995   3.50 #>  setosa              6.9     5.54      1.415  3.91   <0.001  12.8 2.739   8.34 #>  versicolor          1.0     1.55      0.317  4.89   <0.001  18.5 0.924   2.18 #>  versicolor          6.9     3.76      0.258 14.58   <0.001  97.7 3.249   4.27 #>  virginica           1.0     1.91      0.375  5.08   <0.001  19.7 1.165   2.65 #>  virginica           6.9     3.29      0.119 27.63   <0.001 195.0 3.055   3.53 #>   Df #>  144 #>  144 #>  144 #>  144 #>  144 #>  144 #>  #> Type:  response  #>  get_marginalmeans(model, by = c(\"Species\", \"Petal.Length = c(1, 3, 5)\"), length = 2) #>  #>     Species Estimate Std. Error     t Pr(>|t|)     S 2.5 % 97.5 %  Df #>  setosa         3.25     0.1282 25.33   <0.001 180.0 2.995   3.50 144 #>  setosa         4.02     0.4026 10.00   <0.001  58.0 3.229   4.82 144 #>  setosa         4.80     0.9216  5.21   <0.001  20.6 2.979   6.62 144 #>  versicolor     1.55     0.3166  4.89   <0.001  18.5 0.924   2.18 144 #>  versicolor     2.30     0.1291 17.80   <0.001 124.5 2.043   2.55 144 #>  versicolor     3.05     0.0840 36.26   <0.001 244.3 2.881   3.21 144 #>  virginica      1.91     0.3753  5.08   <0.001  19.7 1.165   2.65 144 #>  virginica      2.38     0.2137 11.12   <0.001  67.8 1.954   2.80 144 #>  virginica      2.84     0.0636 44.74   <0.001 284.5 2.719   2.97 144 #>  #> Type:  response  #>  # } model <- lm(Sepal.Width ~ Species * Petal.Length, data = iris)  get_marginaltrends(model, trend = \"Petal.Length\", by = \"Species\") #>  #>     Species Estimate Std. Error    z Pr(>|z|)    S   2.5 % 97.5 % #>  setosa        0.388     0.2602 1.49  0.13606  2.9 -0.1221  0.898 #>  versicolor    0.374     0.0963 3.89  < 0.001 13.3  0.1856  0.563 #>  virginica     0.234     0.0819 2.86  0.00421  7.9  0.0739  0.395 #>  #> Term: Petal.Length #> Type:  response  #> Comparison: dY/dX #>  get_marginaltrends(model, trend = \"Petal.Length\", by = \"Petal.Length\") #>  #>  Petal.Length Estimate Std. Error    z Pr(>|z|)    S 2.5 % 97.5 % #>          1.00    0.332     0.0964 3.44   <0.001 10.8 0.143  0.521 #>          1.66    0.332     0.0963 3.45   <0.001 10.8 0.143  0.521 #>          2.31    0.332     0.0963 3.45   <0.001 10.8 0.143  0.521 #>          2.97    0.332     0.0963 3.45   <0.001 10.8 0.143  0.521 #>          3.62    0.332     0.0963 3.45   <0.001 10.8 0.143  0.521 #>          4.28    0.332     0.0963 3.45   <0.001 10.8 0.143  0.521 #>          4.93    0.332     0.0966 3.44   <0.001 10.7 0.143  0.521 #>          5.59    0.332     0.0963 3.45   <0.001 10.8 0.143  0.521 #>          6.24    0.332     0.0963 3.45   <0.001 10.8 0.143  0.521 #>          6.90    0.332     0.0965 3.44   <0.001 10.8 0.143  0.521 #>  #> Term: Petal.Length #> Type:  response  #> Comparison: dY/dX #>  get_marginaltrends(model, trend = \"Petal.Length\", by = c(\"Species\", \"Petal.Length\")) #>  #>     Species Petal.Length Estimate Std. Error    z Pr(>|z|)    S   2.5 % 97.5 % #>  setosa             1.00    0.388     0.2602 1.49  0.13601  2.9 -0.1221  0.898 #>  setosa             1.66    0.388     0.2602 1.49  0.13601  2.9 -0.1221  0.898 #>  versicolor         3.62    0.374     0.0963 3.89  < 0.001 13.3  0.1855  0.563 #>  versicolor         4.28    0.374     0.0963 3.89  < 0.001 13.3  0.1856  0.563 #>  versicolor         4.93    0.374     0.0959 3.90  < 0.001 13.4  0.1863  0.562 #>  virginica          4.93    0.234     0.0819 2.86  0.00421  7.9  0.0739  0.395 #>  virginica          5.59    0.234     0.0819 2.86  0.00420  7.9  0.0739  0.395 #>  virginica          6.24    0.234     0.0819 2.86  0.00422  7.9  0.0738  0.395 #>  virginica          6.90    0.234     0.0819 2.86  0.00420  7.9  0.0739  0.395 #>  #> Term: Petal.Length #> Type:  response  #> Comparison: dY/dX #>"},{"path":"https://easystats.github.io/modelbased/reference/modelbased-options.html","id":null,"dir":"Reference","previous_headings":"","what":"Global options from the modelbased package — modelbased-options","title":"Global options from the modelbased package — modelbased-options","text":"Global options modelbased package","code":""},{"path":"https://easystats.github.io/modelbased/reference/modelbased-options.html","id":"global-options-to-set-defaults-for-function-arguments","dir":"Reference","previous_headings":"","what":"Global options to set defaults for function arguments","title":"Global options from the modelbased package — modelbased-options","text":"calculating marginal means options(modelbased_backend = <string>) set default value backend argument can used set package used default calculate marginal means. Can \"marginaleffects\" \"emmeans\". options(modelbased_estimate = <string>) set default value estimate argument, modulates type target population predictions refer . printing options(modelbased_select = <string>) set default value select argument can used define custom default layout printing. options(modelbased_include_grid = TRUE) set default value include_grid argument can used include data grids output default . options(modelbased_full_labels = FALSE) remove redundant (duplicated) labels rows. plotting options(modelbased_join_dots = <logical>) set default value join_dots. options(modelbased_numeric_as_discrete = <number>) set default value modelbased_numeric_as_discrete argument. Can also FALSE.","code":""},{"path":"https://easystats.github.io/modelbased/reference/modelbased-package.html","id":null,"dir":"Reference","previous_headings":"","what":"modelbased: Estimation of Model-Based Predictions, Contrasts and Means — modelbased-package","title":"modelbased: Estimation of Model-Based Predictions, Contrasts and Means — modelbased-package","text":"modelbased package helping model-based estimations, easily compute marginal means, contrast analysis model predictions.","code":""},{"path":"https://easystats.github.io/modelbased/reference/modelbased-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"modelbased: Estimation of Model-Based Predictions, Contrasts and Means — modelbased-package","text":"modelbased","code":""},{"path":[]},{"path":"https://easystats.github.io/modelbased/reference/modelbased-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"modelbased: Estimation of Model-Based Predictions, Contrasts and Means — modelbased-package","text":"Maintainer: Dominique Makowski officialeasystats@gmail.com (ORCID) Authors: Daniel Lüdecke d.luedecke@uke.de (ORCID) Mattan S. Ben-Shachar matanshm@post.bgu.ac.il (ORCID) Indrajeet Patil patilindrajeet.science@gmail.com (ORCID) Rémi Thériault remi.theriault@mail.mcgill.ca (ORCID)","code":""},{"path":"https://easystats.github.io/modelbased/reference/pool_contrasts.html","id":null,"dir":"Reference","previous_headings":"","what":"Pool contrasts and comparisons from estimate_contrasts() — pool_contrasts","title":"Pool contrasts and comparisons from estimate_contrasts() — pool_contrasts","text":"function \"pools\" (.e. combines) multiple estimate_contrasts objects, returned estimate_contrasts(), similar fashion mice::pool().","code":""},{"path":"https://easystats.github.io/modelbased/reference/pool_contrasts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pool contrasts and comparisons from estimate_contrasts() — pool_contrasts","text":"","code":"pool_contrasts(x, ...)"},{"path":"https://easystats.github.io/modelbased/reference/pool_contrasts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pool contrasts and comparisons from estimate_contrasts() — pool_contrasts","text":"x list estimate_contrasts objects, returned estimate_contrasts(). ... Currently used.","code":""},{"path":"https://easystats.github.io/modelbased/reference/pool_contrasts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pool contrasts and comparisons from estimate_contrasts() — pool_contrasts","text":"data frame pooled comparisons contrasts predictions.","code":""},{"path":"https://easystats.github.io/modelbased/reference/pool_contrasts.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Pool contrasts and comparisons from estimate_contrasts() — pool_contrasts","text":"Averaging parameters follows Rubin's rules (Rubin, 1987, p. 76).","code":""},{"path":"https://easystats.github.io/modelbased/reference/pool_contrasts.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Pool contrasts and comparisons from estimate_contrasts() — pool_contrasts","text":"Rubin, D.B. (1987). Multiple Imputation Nonresponse Surveys. New York: John Wiley Sons.","code":""},{"path":"https://easystats.github.io/modelbased/reference/pool_contrasts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pool contrasts and comparisons from estimate_contrasts() — pool_contrasts","text":"","code":"data(\"nhanes2\", package = \"mice\") imp <- mice::mice(nhanes2, printFlag = FALSE) comparisons <- lapply(1:5, function(i) {   m <- lm(bmi ~ age + hyp + chl, data = mice::complete(imp, action = i))   estimate_contrasts(m, \"age\") }) pool_contrasts(comparisons) #> Marginal Contrasts Analysis #>  #> Level1 | Level2 | Difference |   SE |          95% CI |  t(1) |     p #> --------------------------------------------------------------------- #> 40-59  | 20-39  |      -4.56 | 2.20 | [-32.51, 23.39] | -2.07 | 0.286 #> 60-99  | 20-39  |      -6.49 | 2.70 | [-40.80, 27.81] | -2.40 | 0.251 #> 60-99  | 40-59  |      -1.93 | 2.17 | [-29.55, 25.69] | -0.89 | 0.537 #>  #> Variable predicted: bmi #> Predictors contrasted: age #> Predictors averaged: hyp, chl (2e+02) #> p-values are uncorrected. #>"},{"path":"https://easystats.github.io/modelbased/reference/pool_predictions.html","id":null,"dir":"Reference","previous_headings":"","what":"Pool Predictions and Estimated Marginal Means — pool_predictions","title":"Pool Predictions and Estimated Marginal Means — pool_predictions","text":"function \"pools\" (.e. combines) multiple estimate_means objects, similar fashion mice::pool().","code":""},{"path":"https://easystats.github.io/modelbased/reference/pool_predictions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pool Predictions and Estimated Marginal Means — pool_predictions","text":"","code":"pool_predictions(x, transform = NULL, ...)  pool_slopes(x, transform = NULL, ...)"},{"path":"https://easystats.github.io/modelbased/reference/pool_predictions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pool Predictions and Estimated Marginal Means — pool_predictions","text":"x list estimate_means objects, returned estimate_means(), estimate_predicted objects, returned estimate_relation() related functions. pool_slopes(), must list estimate_slopes objects, returned estimate_slopes(). transform function applied predictions confidence intervals (back-) transform results, can useful case regression model transformed response variable (e.g., lm(log(y) ~ x)). Bayesian models, function applied individual draws posterior distribution, computing summaries. Can also TRUE, case insight::get_transformation() called determine appropriate transformation-function. Note standard errors returned transformations applied. ... Currently used.","code":""},{"path":"https://easystats.github.io/modelbased/reference/pool_predictions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pool Predictions and Estimated Marginal Means — pool_predictions","text":"data frame pooled predictions.","code":""},{"path":"https://easystats.github.io/modelbased/reference/pool_predictions.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Pool Predictions and Estimated Marginal Means — pool_predictions","text":"Averaging parameters follows Rubin's rules (Rubin, 1987, p. 76). Pooling applied predicted values based standard errors calculated estimate_means estimate_predicted objects provided x. objects class estimate_means, predicted values response scale default, standard errors calculated using delta method. , pooling estimates calculating standard errors pooled estimates based ob Rubin's rule carried . back-transformation link-scale predicted values applying Rubin's rule.","code":""},{"path":"https://easystats.github.io/modelbased/reference/pool_predictions.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Pool Predictions and Estimated Marginal Means — pool_predictions","text":"Rubin, D.B. (1987). Multiple Imputation Nonresponse Surveys. New York: John Wiley Sons.","code":""},{"path":"https://easystats.github.io/modelbased/reference/pool_predictions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pool Predictions and Estimated Marginal Means — pool_predictions","text":"","code":"# example for multiple imputed datasets data(\"nhanes2\", package = \"mice\") imp <- mice::mice(nhanes2, printFlag = FALSE)  # estimated marginal means predictions <- lapply(1:5, function(i) {   m <- lm(bmi ~ age + hyp + chl, data = mice::complete(imp, action = i))   estimate_means(m, \"age\") }) pool_predictions(predictions) #> Estimated Marginal Means #>  #> age   |  Mean |   SE |        95% CI |  t(1) #> -------------------------------------------- #> 20-39 | 30.54 | 1.67 | [9.38, 51.71] | 18.33 #> 40-59 | 24.83 | 1.55 | [5.16, 44.50] | 16.04 #> 60-99 | 23.15 | 1.71 | [1.48, 44.82] | 13.58 #>  #> Variable predicted: bmi #> Predictors modulated: age #> Predictors averaged: hyp, chl (1.9e+02) #>   # estimated slopes (marginal effects) slopes <- lapply(1:5, function(i) {   m <- lm(bmi ~ age + hyp + chl, data = mice::complete(imp, action = i))   estimate_slopes(m, \"chl\") }) pool_slopes(slopes) #> Estimated Marginal Effects #>  #> Slope |   SE |       95% CI | t(Inf) |     p #> -------------------------------------------- #> 0.06  | 0.02 | [0.01, 0.10] |   2.59 | 0.010 #>  #> Marginal effects estimated for chl #> Type of slope was dY/dX"},{"path":"https://easystats.github.io/modelbased/reference/print.estimate_contrasts.html","id":null,"dir":"Reference","previous_headings":"","what":"Printing modelbased-objects — print.estimate_contrasts","title":"Printing modelbased-objects — print.estimate_contrasts","text":"print() method modelbased objects. Can used tweak output tables.","code":""},{"path":"https://easystats.github.io/modelbased/reference/print.estimate_contrasts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Printing modelbased-objects — print.estimate_contrasts","text":"","code":"# S3 method for class 'estimate_contrasts' print(x, select = NULL, include_grid = NULL, full_labels = NULL, ...)"},{"path":"https://easystats.github.io/modelbased/reference/print.estimate_contrasts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Printing modelbased-objects — print.estimate_contrasts","text":"x object returned different estimate_*() functions. select Determines columns printed table layout. two options argument: string expression layout pattern select string \"tokens\" enclosed braces. tokens replaced associated columns, selected columns collapsed one column. Following tokens replaced related coefficients statistics: {estimate}, {se}, {ci} ({ci_low} {ci_high}), {p}, {pd} {stars}. token {ci} replaced {ci_low}, {ci_high}. Example: select = \"{estimate}{stars} ({ci})\" possible create multiple columns well. | separates values new cells/columns. Example: select = \"{estimate} ({ci})|{p}\". string indicating pre-defined layout select can one following string values, create one following pre-defined column layouts: \"minimal\": Estimates, confidence intervals numeric p-values, two columns. equivalent select = \"{estimate} ({ci})|{p}\". \"short\": Estimate, standard errors numeric p-values, two columns. equivalent select = \"{estimate} ({se})|{p}\". \"ci\": Estimates confidence intervals, asterisks p-values. equivalent select = \"{estimate} ({ci})\". \"se\": Estimates standard errors, asterisks p-values. equivalent select = \"{estimate} ({se})\". \"ci_p\": Estimates, confidence intervals asterisks p-values. equivalent select = \"{estimate}{stars} ({ci})\". \"se_p\": Estimates, standard errors asterisks p-values. equivalent select = \"{estimate}{stars} ({se})\".. Using select define columns re-order columns remove columns related uncertainty (standard errors, confidence intervals), test statistics, p-values (similar, like pd BF Bayesian models), assumed included intentionally excluded using select. new column order : Parameter columns first, followed \"glue\" columns, followed remaining columns. columns also placed first, add focal_terms attributes x. .e., following columns considers \"parameter columns\" placed first: c(easystats_columns(\"parameter\"), attributes(x)$focal_terms). Note: glue-like syntax still experimental case complex models (like mixed models) may return expected results. include_grid Logical, TRUE, data grid included table output. applies prediction-functions like estimate_relation() estimate_link(). Default NULL, set value based options(modelbased_include_grid), use FALSE option set. full_labels Logical, TRUE (default), labels focal terms shown. FALSE, redundant (duplicated) labels removed rows. Default NULL, set value based options(modelbased_full_labels), use TRUE option set. ... Arguments passed insight::format_table() insight::export_table().","code":""},{"path":"https://easystats.github.io/modelbased/reference/print.estimate_contrasts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Printing modelbased-objects — print.estimate_contrasts","text":"Invisibly returns x.","code":""},{"path":"https://easystats.github.io/modelbased/reference/print.estimate_contrasts.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Printing modelbased-objects — print.estimate_contrasts","text":"Use print_html() print_md() create tables HTML markdown format, respectively.","code":""},{"path":"https://easystats.github.io/modelbased/reference/print.estimate_contrasts.html","id":"global-options-to-customize-tables-when-printing","dir":"Reference","previous_headings":"","what":"Global Options to Customize Tables when Printing","title":"Printing modelbased-objects — print.estimate_contrasts","text":"Columns table layout can customized using options(): modelbased_select: options(modelbased_select = <string>) set default value select argument can used define custom default layout printing. modelbased_include_grid: options(modelbased_include_grid = TRUE) set default value include_grid argument can used include data grids output default . modelbased_full_labels: options(modelbased_full_labels = FALSE) remove redundant (duplicated) labels rows.","code":""},{"path":"https://easystats.github.io/modelbased/reference/print.estimate_contrasts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Printing modelbased-objects — print.estimate_contrasts","text":"","code":"model <- lm(Petal.Length ~ Species, data = iris) out <- estimate_means(model, \"Species\")  # default print(out) #> Estimated Marginal Means #>  #> Species    | Mean |   SE |       95% CI | t(147) #> ------------------------------------------------ #> setosa     | 1.46 | 0.06 | [1.34, 1.58] |  24.02 #> versicolor | 4.26 | 0.06 | [4.14, 4.38] |  70.00 #> virginica  | 5.55 | 0.06 | [5.43, 5.67] |  91.23 #>  #> Variable predicted: Petal.Length #> Predictors modulated: Species #>   # smaller set of columns print(out, select = \"minimal\") #> Estimated Marginal Means #>  #> Species    |         Mean (CI) #> ------------------------------ #> setosa     | 1.46 (1.34, 1.58) #> versicolor | 4.26 (4.14, 4.38) #> virginica  | 5.55 (5.43, 5.67) #>  #> Variable predicted: Petal.Length #> Predictors modulated: Species #>   # remove redundant labels data(efc, package = \"modelbased\") efc <- datawizard::to_factor(efc, c(\"c161sex\", \"c172code\", \"e16sex\")) levels(efc$c172code) <- c(\"low\", \"mid\", \"high\") fit <- lm(neg_c_7 ~ c161sex * c172code * e16sex, data = efc) out <- estimate_means(fit, c(\"c161sex\", \"c172code\", \"e16sex\")) print(out, full_labels = FALSE, select = \"{estimate} ({se})\") #> Estimated Marginal Means #>  #> c161sex | c172code | e16sex |    Mean (SE) #> ------------------------------------------ #> Male    | low      | male   |  9.47 (1.00) #> Female  |          |        | 12.13 (0.48) #> Male    | mid      |        | 12.16 (0.68) #> Female  |          |        | 12.48 (0.35) #> Male    | high     |        | 12.31 (1.07) #> Female  |          |        | 12.37 (0.71) #> Male    | low      | female | 11.92 (0.76) #> Female  |          |        | 12.11 (0.46) #> Male    | mid      |        | 10.93 (0.43) #> Female  |          |        | 11.57 (0.24) #> Male    | high     |        | 11.42 (0.67) #> Female  |          |        | 12.74 (0.44) #>  #> Variable predicted: neg_c_7 #> Predictors modulated: c161sex, c172code, e16sex #>"},{"path":"https://easystats.github.io/modelbased/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. datawizard standardize, unstandardize, visualisation_recipe insight print_html, print_md","code":""},{"path":"https://easystats.github.io/modelbased/reference/smoothing.html","id":null,"dir":"Reference","previous_headings":"","what":"Smoothing a vector or a time series — smoothing","title":"Smoothing a vector or a time series — smoothing","text":"Smoothing vector time series. data.frames, function smooth numeric variables stratified factor levels (.e., smooth within factor level combination).","code":""},{"path":"https://easystats.github.io/modelbased/reference/smoothing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Smoothing a vector or a time series — smoothing","text":"","code":"smoothing(x, method = \"loess\", strength = 0.25, ...)"},{"path":"https://easystats.github.io/modelbased/reference/smoothing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Smoothing a vector or a time series — smoothing","text":"x numeric vector. method Can \"loess\" (default) \"smooth\". loess smoothing can slow. strength argument applies method = \"loess\". Degree smoothing passed span (see loess()). ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/modelbased/reference/smoothing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Smoothing a vector or a time series — smoothing","text":"smoothed vector data frame.","code":""},{"path":"https://easystats.github.io/modelbased/reference/smoothing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Smoothing a vector or a time series — smoothing","text":"","code":"x <- sin(seq(0, 4 * pi, length.out = 100)) + rnorm(100, 0, 0.2) plot(x, type = \"l\") lines(smoothing(x, method = \"smooth\"), type = \"l\", col = \"blue\") lines(smoothing(x, method = \"loess\"), type = \"l\", col = \"red\")   x <- sin(seq(0, 4 * pi, length.out = 10000)) + rnorm(10000, 0, 0.2) plot(x, type = \"l\") lines(smoothing(x, method = \"smooth\"), type = \"l\", col = \"blue\") lines(smoothing(x, method = \"loess\"), type = \"l\", col = \"red\")"},{"path":"https://easystats.github.io/modelbased/reference/visualisation_recipe.estimate_predicted.html","id":null,"dir":"Reference","previous_headings":"","what":"Automated plotting for 'modelbased' objects — visualisation_recipe.estimate_predicted","title":"Automated plotting for 'modelbased' objects — visualisation_recipe.estimate_predicted","text":"'modelbased' objects can visualized using plot() function, internally calls visualisation_recipe() function. See examples information examples create customize plots.","code":""},{"path":"https://easystats.github.io/modelbased/reference/visualisation_recipe.estimate_predicted.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Automated plotting for 'modelbased' objects — visualisation_recipe.estimate_predicted","text":"","code":"# S3 method for class 'estimate_predicted' visualisation_recipe(   x,   show_data = FALSE,   point = NULL,   line = NULL,   pointrange = NULL,   ribbon = NULL,   facet = NULL,   grid = NULL,   join_dots = NULL,   numeric_as_discrete = NULL,   ... )  # S3 method for class 'estimate_slopes' visualisation_recipe(   x,   line = NULL,   pointrange = NULL,   ribbon = NULL,   facet = NULL,   grid = NULL,   ... )  # S3 method for class 'estimate_grouplevel' visualisation_recipe(   x,   line = NULL,   pointrange = NULL,   ribbon = NULL,   facet = NULL,   grid = NULL,   ... )"},{"path":"https://easystats.github.io/modelbased/reference/visualisation_recipe.estimate_predicted.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Automated plotting for 'modelbased' objects — visualisation_recipe.estimate_predicted","text":"x modelbased object. show_data Logical, TRUE, display \"raw\" data background model-based estimation. point, line, pointrange, ribbon, facet, grid Additional aesthetics parameters geoms (see customization example). join_dots Logical, TRUE (default) categorical focal terms , dots (estimates) connected lines, .e. plots combination dots error bars connecting lines. FALSE, dots error bars shown. possible set global default value using options(), e.g. options(modelbased_join_dots = FALSE). numeric_as_discrete Maximum number unique values numeric predictor treat predictor discrete. Defaults 8. Numeric predictors usually mapped continuous color scale, unless unique values. latter case, numeric predictors assumed represent \"categories\", e.g. mean value +/- 1 standard deviation around mean chosen representative values predictor. Use FALSE always use continuous color scales numeric predictors. possible set global default value using options(), e.g. options(modelbased_numeric_as_discrete = 10). ... used.","code":""},{"path":"https://easystats.github.io/modelbased/reference/visualisation_recipe.estimate_predicted.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Automated plotting for 'modelbased' objects — visualisation_recipe.estimate_predicted","text":"plotting works mapping predictors argument x-axis, colors, alpha (transparency) facets. Thus, appearance plot depends order variables specify argument. instance, plots corresponding estimate_relation(model, =c(\"Species\", \"Sepal.Length\")) estimate_relation(model, =c(\"Sepal.Length\", \"Species\")) look different. automated plotting primarily meant convenient visual checks, publication-ready figures, recommend re-creating figures using ggplot2 package directly. two options remove confidence bands errors bars plot. remove error bars, simply set pointrange geom point, e.g. plot(..., pointrange = list(geom = \"point\")). remove confidence bands line geoms, use ribbon = \"none\".","code":""},{"path":"https://easystats.github.io/modelbased/reference/visualisation_recipe.estimate_predicted.html","id":"global-options-to-customize-plots","dir":"Reference","previous_headings":"","what":"Global Options to Customize Plots","title":"Automated plotting for 'modelbased' objects — visualisation_recipe.estimate_predicted","text":"arguments plot() can get global defaults using options(): modelbased_join_dots: options(modelbased_join_dots = <logical>) set default value join_dots. modelbased_numeric_as_discrete: options(modelbased_numeric_as_discrete = <number>) set default value modelbased_numeric_as_discrete argument. Can also FALSE.","code":""},{"path":"https://easystats.github.io/modelbased/reference/visualisation_recipe.estimate_predicted.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Automated plotting for 'modelbased' objects — visualisation_recipe.estimate_predicted","text":"","code":"library(ggplot2) library(see) # ============================================== # estimate_relation, estimate_expectation, ... # ============================================== # Simple Model --------------- x <- estimate_relation(lm(mpg ~ wt, data = mtcars)) layers <- visualisation_recipe(x) layers #> Layer 1 #> -------- #> Geom type: ribbon #> data = [10 x 6] #> aes_string( #>   y = 'Predicted' #>   x = 'wt' #>   ymin = 'CI_low' #>   ymax = 'CI_high' #>   group = '.group' #> ) #> alpha = 0.3333333 #>  #> Layer 2 #> -------- #> Geom type: line #> data = [10 x 6] #> aes_string( #>   y = 'Predicted' #>   x = 'wt' #>   group = '.group' #> ) #>  #> Layer 3 #> -------- #> Geom type: labs #> y = 'Predicted value of mpg' #>  plot(layers)   # visualization_recipe() is called implicitly when you call plot() plot(estimate_relation(lm(mpg ~ qsec, data = mtcars)))   # \\dontrun{ # It can be used in a pipe workflow lm(mpg ~ qsec, data = mtcars) |>   estimate_relation(ci = c(0.5, 0.8, 0.9)) |>   plot()   # Customize aesthetics ----------  plot(x,   point = list(color = \"red\", alpha = 0.6, size = 3),   line = list(color = \"blue\", size = 3),   ribbon = list(fill = \"green\", alpha = 0.7) ) +   theme_minimal() +   labs(title = \"Relationship between MPG and WT\")   # Customize raw data -------------  plot(x, point = list(geom = \"density_2d_filled\"), line = list(color = \"white\")) +   scale_x_continuous(expand = c(0, 0)) +   scale_y_continuous(expand = c(0, 0)) +   theme(legend.position = \"none\")   # Single predictors examples -----------  plot(estimate_relation(lm(Sepal.Length ~ Species, data = iris)))   # 2-ways interaction ------------  # Numeric * numeric x <- estimate_relation(lm(mpg ~ wt * qsec, data = mtcars)) plot(x)   # Numeric * factor x <- estimate_relation(lm(Sepal.Width ~ Sepal.Length * Species, data = iris)) plot(x)   # ============================================== # estimate_means # ============================================== # Simple Model --------------- x <- estimate_means(lm(Sepal.Width ~ Species, data = iris), by = \"Species\") layers <- visualisation_recipe(x) layers #> Layer 1 #> -------- #> Geom type: line #> data = [3 x 8] #> aes_string( #>   y = 'Mean' #>   x = 'Species' #>   group = '.group' #> ) #>  #> Layer 2 #> -------- #> Geom type: pointrange #> data = [3 x 8] #> aes_string( #>   y = 'Mean' #>   x = 'Species' #>   ymin = 'CI_low' #>   ymax = 'CI_high' #>   group = '.group' #> ) #>  #> Layer 3 #> -------- #> Geom type: labs #> y = 'Mean of Sepal.Width' #>  plot(layers)   # Customize aesthetics layers <- visualisation_recipe(x,   point = list(width = 0.03, color = \"red\"),   pointrange = list(size = 2, linewidth = 2),   line = list(linetype = \"dashed\", color = \"blue\") ) plot(layers)   # Two levels --------------- data <- mtcars data$cyl <- as.factor(data$cyl)  model <- lm(mpg ~ cyl * wt, data = data)  x <- estimate_means(model, by = c(\"cyl\", \"wt\")) plot(x)    # GLMs --------------------- data <- data.frame(vs = mtcars$vs, cyl = as.factor(mtcars$cyl)) x <- estimate_means(glm(vs ~ cyl, data = data, family = \"binomial\"), by = c(\"cyl\")) plot(x)  # } # ============================================== # estimate_slopes # ============================================== model <- lm(Sepal.Width ~ Species * Petal.Length, data = iris) x <- estimate_slopes(model, trend = \"Petal.Length\", by = \"Species\")  layers <- visualisation_recipe(x) layers #> Layer 1 #> -------- #> Geom type: hline #> yintercept = 0 #> alpha = 0.5 #> linetype = 'dashed' #>  #> Layer 2 #> -------- #> Geom type: line #> data = [3 x 8] #> aes_string( #>   y = 'Slope' #>   x = 'Species' #>   group = '.group' #> ) #>  #> Layer 3 #> -------- #> Geom type: pointrange #> data = [3 x 8] #> aes_string( #>   y = 'Slope' #>   x = 'Species' #>   ymin = 'CI_low' #>   ymax = 'CI_high' #>   group = '.group' #> ) #>  #> Layer 4 #> -------- #> Geom type: labs #> y = 'Slope of Petal.Length' #>  plot(layers)   # \\dontrun{ # Customize aesthetics and add horizontal line and theme layers <- visualisation_recipe(x, pointrange = list(size = 2, linewidth = 2)) plot(layers) +   geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +   theme_minimal() +   labs(y = \"Effect of Petal.Length\", title = \"Marginal Effects\")   model <- lm(Petal.Length ~ poly(Sepal.Width, 4), data = iris) x <- estimate_slopes(model, trend = \"Sepal.Width\", by = \"Sepal.Width\", length = 20) plot(visualisation_recipe(x))   model <- lm(Petal.Length ~ Species * poly(Sepal.Width, 3), data = iris) x <- estimate_slopes(model, trend = \"Sepal.Width\", by = c(\"Sepal.Width\", \"Species\")) plot(visualisation_recipe(x))  # } # ============================================== # estimate_grouplevel # ============================================== # \\dontrun{ data <- lme4::sleepstudy data <- rbind(data, data) data$Newfactor <- rep(c(\"A\", \"B\", \"C\", \"D\"))  # 1 random intercept model <- lme4::lmer(Reaction ~ Days + (1 | Subject), data = data) x <- estimate_grouplevel(model) layers <- visualisation_recipe(x) layers #> Layer 1 #> -------- #> Geom type: pointrange #> data = [18 x 9] #> aes_string( #>   y = 'Coefficient' #>   x = 'Level' #>   ymin = 'CI_low' #>   ymax = 'CI_high' #>   group = '.group' #> ) #>  #> Layer 2 #> -------- #> Geom type: coord_flip #>  plot(layers)   # 2 random intercepts model <- lme4::lmer(Reaction ~ Days + (1 | Subject) + (1 | Newfactor), data = data) x <- estimate_grouplevel(model) plot(x) +   geom_hline(yintercept = 0, linetype = \"dashed\") +   theme_minimal()  # Note: we need to use hline instead of vline because the axes is flipped  model <- lme4::lmer(Reaction ~ Days + (1 + Days | Subject) + (1 | Newfactor), data = data) x <- estimate_grouplevel(model) plot(x)  # }"},{"path":"https://easystats.github.io/modelbased/reference/zero_crossings.html","id":null,"dir":"Reference","previous_headings":"","what":"Find zero-crossings and inversion points — zero_crossings","title":"Find zero-crossings and inversion points — zero_crossings","text":"Find zero crossings vector, .e., indices numeric variable crosses 0. useful finding points function changes looking zero crossings derivative.","code":""},{"path":"https://easystats.github.io/modelbased/reference/zero_crossings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find zero-crossings and inversion points — zero_crossings","text":"","code":"zero_crossings(x)  find_inversions(x)"},{"path":"https://easystats.github.io/modelbased/reference/zero_crossings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find zero-crossings and inversion points — zero_crossings","text":"x numeric vector.","code":""},{"path":"https://easystats.github.io/modelbased/reference/zero_crossings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find zero-crossings and inversion points — zero_crossings","text":"Vector zero crossings points inversion.","code":""},{"path":[]},{"path":"https://easystats.github.io/modelbased/reference/zero_crossings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find zero-crossings and inversion points — zero_crossings","text":"","code":"x <- sin(seq(0, 4 * pi, length.out = 100)) # plot(x, type = \"b\")  modelbased::zero_crossings(x) #> [1]  1.00000 25.74975 50.50000 75.25025 modelbased::find_inversions(x) #> [1] 12.87478 37.62484 62.37516 87.12522"},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-0100","dir":"Changelog","previous_headings":"","what":"modelbased 0.10.0","title":"modelbased 0.10.0","text":"CRAN release: 2025-03-10","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"breaking-changes-0-10-0","dir":"Changelog","previous_headings":"","what":"Breaking Changes","title":"modelbased 0.10.0","text":"deprecated function visualisation_matrix() removed. Use insight::get_datagrid() instead. \"average\" option argument estimate renamed \"typical\". former \"average\" option still available, now returns marginal means fully averaged across sample.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"changes-0-10-0","dir":"Changelog","previous_headings":"","what":"Changes","title":"modelbased 0.10.0","text":"transform argument now also works estimate_slopes() estimate_contrasts() numeric focal terms. estimate_contrasts() longer calls estimate_slopes() numeric focal terms integers values. case, assumed contrasts values (“levels”) desired, integer variables two five unique values factor-alike. estimate_contrasts: now supports optional standardized effect sizes, one “none” (default), “emmeans”, “bootES” (#227, @rempsyc). predict() argument estimate_means() gets \"inverse_link\" option, calculate predictions link-scale back-transform response scale aggregation groups. estimate_means(), estimate_slopes() estimate_contrasts() get keep_iterations argument, keep posterior draws Bayesian models added columns output. New functions pool_predictions() pool_contrasts(), deal modelbased objects applied imputed data sets. E.g., functions like estimate_means() can run several data sets missing values imputed, multiple results estimate_means() can pooled using pool_predictions(). print() method now explicitly documented gets new options customize output tables. estimate_grouplevel() gets new option, type = \"total\", return sum fixed random effects (similar coef() returns (Bayesian) mixed models). New option \"esarey\" p_adjust argument. \"esarey\" option specifically case Johnson-Neyman intervals, .e. calling estimate_slopes() two numeric predictors interaction term. print_html() print_md() pass ... format-methods (e.g. insight::format_table()), tweak output. show_data argument plot() automatically set FALSE models transformed response variable, predictions back-transformed using transform argument. plot() method gets numeric_as_discrete argument, decide whether numeric predictors treated factor continuous, based unique values numeric predictors. Plots now use probability scale y-axis models whose response scale probabilities (e.g., logistic regression). Improved printing estimate_contrasts() one focal predictors numeric.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"bug-fixes-0-10-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"modelbased 0.10.0","text":"Fixed issue summary() method estimate_slopes(). Fixed issues multivariate response models. Fixed issues plotting ordinal multinomial models. Fixed issues ci argument, ignored Bayesian models. Fixed issues contrasting slopes backend \"emmeans\". Fixed issues estimate_contrasts() filtering numeric values . Fixed issues estimate_grouplevel(). Fixed issue estimate_slopes() models package lme4.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-090","dir":"Changelog","previous_headings":"","what":"modelbased 0.9.0","title":"modelbased 0.9.0","text":"CRAN release: 2025-02-05","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"breaking-changes-0-9-0","dir":"Changelog","previous_headings":"","what":"Breaking Changes","title":"modelbased 0.9.0","text":"default package used estimate_means(), estimate_slopes() estimate_contrasts() now marginaleffects. can set preferred package backend using either backend argument, general setting options(modelbased_backend = \"marginaleffects\") options(modelbased_backend = \"emmeans\"). Deprecated argument function names removed. Argument fixed removed, can fix predictor certain values using argument. Argument transform longer used determine scale predictions. Please use predict instead. Argument transform now used (back-) transform predictions confidence intervals. Argument method estimate_contrasts() renamed comparison. model_*() alias names removed. Use related get_*() functions instead. show_data argument plot() defaults FALSE.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"major-changes-0-9-0","dir":"Changelog","previous_headings":"","what":"Major Changes","title":"modelbased 0.9.0","text":"\"marginaleffects\" backend now fully implemented longer work--progress. can set preferred package backend using either backend argument, general setting options(modelbased_backend = \"marginaleffects\") options(modelbased_backend = \"emmeans\"). estimate_*() functions get predict argument, can used modulate type transformation applied predictions (.e. whether predictions response scale, link scale, etc.). can also used predict auxiliary (distributional) parameters. estimate_means() estimate_contrasts() get estimate argument, specify estimate non-focal terms. results slightly different predicted values, approach answering different question. estimate_contrasts() gains backend argument. defaults \"marginaleffects\", can set \"emmeans\" use features package estimate contrasts pairwise comparisons. estimate_expectation() related functions also get argument, alternative create datagrid data argument. Many functions get verbose argument, silence warnings messages.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"bug-fixes-0-9-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"modelbased 0.9.0","text":"estimate_contrasts() calculate contrasts levels predictor interest converted factor inside model formula. Fixed issue estimate_contrasts() comparsison (formerly: method) \"pairwise\".","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-089","dir":"Changelog","previous_headings":"","what":"modelbased 0.8.9","title":"modelbased 0.8.9","text":"CRAN release: 2024-10-26 Fixed issues related updates easystats packages.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-086","dir":"Changelog","previous_headings":"","what":"modelbased 0.8.6","title":"modelbased 0.8.6","text":"CRAN release: 2023-01-13","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"breaking-changes-0-8-6","dir":"Changelog","previous_headings":"","what":"Breaking Changes","title":"modelbased 0.8.6","text":"minimum needed R version bumped 3.6.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-085","dir":"Changelog","previous_headings":"","what":"modelbased 0.8.5","title":"modelbased 0.8.5","text":"CRAN release: 2022-08-18 Fixed issues printing-methods. Maintenance release fix failing tests CRAN checks.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-081","dir":"Changelog","previous_headings":"","what":"modelbased 0.8.1","title":"modelbased 0.8.1","text":"CRAN release: 2022-05-30 Maintenance release fix failing tests CRAN checks.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-080","dir":"Changelog","previous_headings":"","what":"modelbased 0.8.0","title":"modelbased 0.8.0","text":"CRAN release: 2022-03-31 visualisation_matrix() now become alias (alternative name) get_datagrid() function, implemented insight package.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-072","dir":"Changelog","previous_headings":"","what":"modelbased 0.7.2","title":"modelbased 0.7.2","text":"CRAN release: 2022-02-27 Patch release. update fixes failing tests updating insight package.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-071","dir":"Changelog","previous_headings":"","what":"modelbased 0.7.1","title":"modelbased 0.7.1","text":"CRAN release: 2022-01-13 API changes: levels estimate_contrasts replaced contrast. levels modulate general aggregated . estimate_prediction() deprecated favour estimate_response(). estimate_expectation() now data=NULL default.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-070","dir":"Changelog","previous_headings":"","what":"modelbased 0.7.0","title":"modelbased 0.7.0","text":"CRAN release: 2021-06-06 General overhaul package. Entire refactoring visualisation_matrix(). Option standardizing/unstandardizing predictions, contrasts means now available via standardize() instead via options. Introduction model_emmeans() wrapper easily create emmeans objects. estimate_smooth() transformed describe_nonlinear() made explicit.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-060","dir":"Changelog","previous_headings":"","what":"modelbased 0.6.0","title":"modelbased 0.6.0","text":"CRAN release: 2021-04-12 estimate_link() now transform predictions response scale GLMs. keep previous behaviour, use new estimate_relation() instead. follows change predictions made internally (now relies get_predicted(), details can found ).","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-051","dir":"Changelog","previous_headings":"","what":"modelbased 0.5.1","title":"modelbased 0.5.1","text":"CRAN release: 2021-01-27 Minor improvements.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-030","dir":"Changelog","previous_headings":"","what":"modelbased 0.3.0","title":"modelbased 0.3.0","text":"CRAN release: 2020-09-26","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"breaking-changes-0-3-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"modelbased 0.3.0","text":"Predicted now name predicted column Bayesian models (similarly Frequentist ones), instead centrality index (e.g., Median).","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"new-supported-models-0-3-0","dir":"Changelog","previous_headings":"","what":"New supported models","title":"modelbased 0.3.0","text":"Models package glmmTMB now supported.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"bug-fixes-0-3-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"modelbased 0.3.0","text":"estimate_slope() now gives informative error numeric predictor present.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-020","dir":"Changelog","previous_headings":"","what":"modelbased 0.2.0","title":"modelbased 0.2.0","text":"Partial support formulas. Refactor emmeans wrapping.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-013","dir":"Changelog","previous_headings":"","what":"modelbased 0.1.3","title":"modelbased 0.1.3","text":"Fix CRAN check issues.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-012","dir":"Changelog","previous_headings":"","what":"modelbased 0.1.2","title":"modelbased 0.1.2","text":"CRAN release: 2020-03-12 Minor code changes address changes forthcoming parameters package update.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-011","dir":"Changelog","previous_headings":"","what":"modelbased 0.1.1","title":"modelbased 0.1.1","text":"CRAN release: 2020-01-26 Fix CRAN check issues.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-010","dir":"Changelog","previous_headings":"","what":"modelbased 0.1.0","title":"modelbased 0.1.0","text":"CRAN release: 2020-01-12 Added NEWS.md file track changes package","code":""}]
