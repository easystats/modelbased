[{"path":[]},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others‚Äô private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement dom.makowski@gmail.com. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.1, available https://www.contributor-covenant.org/version/2/1/code_of_conduct.html. Community Impact Guidelines inspired [Mozilla‚Äôs code conduct enforcement ladder][https://github.com/mozilla/inclusion]. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"https://easystats.github.io/modelbased/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contribution Guidelines","title":"Contribution Guidelines","text":"easystats guidelines 0.1.0 people much welcome contribute code, documentation, testing suggestions. package aims beginner-friendly. Even ‚Äôre new open-source way life, new coding github stuff, encourage try submitting pull requests (PRs). ‚Äú‚Äôd like help, ‚Äôm good enough programming yet‚Äù ‚Äôs alright, don‚Äôt worry! can always dig code, documentation tests. always typos fix, docs improve, details add, code lines document, tests add‚Ä¶ Even smaller PRs appreciated. ‚Äú‚Äôd like help, don‚Äôt know start‚Äù can look around issue section find features / ideas / bugs start working . can also open new issue just say ‚Äôre , interested helping . might ideas adapted skills. ‚Äú‚Äôm sure suggestion idea worthwile‚Äù Enough impostor syndrom! suggestions opinions good, even ‚Äôs just thought , ‚Äôs always good receive feedback. ‚Äúwaste time ? get credit?‚Äù Software contributions getting valued academic world, good time collaborate us! Authors substantial contributions added within authors list. ‚Äôre also keen including eventual academic publications. Anyway, starting important! enter whole new world, new fantastic point view‚Ä¶ fork repo, changes submit . work together make best :)","code":""},{"path":"https://easystats.github.io/modelbased/CONTRIBUTING.html","id":"code","dir":"","previous_headings":"","what":"Code","title":"Contribution Guidelines","text":"Please document comment code, purpose step (code line) stated clear understandable way. submitting change, please read R style guide particular easystats convention code-style keep consistency code formatting. Regarding style guide, note exception: put readability clarity everything. Thus, like underscores full names (prefer model_performance modelperf interpret_odds_logistic intoddslog). start code, make sure ‚Äôre dev branch (‚Äúadvanced‚Äù). , can create new branch named feature (e.g., feature_lightsaber) changes. Finally, submit branch merged dev branch. , every now , dev branch merge master, new package version.","code":""},{"path":"https://easystats.github.io/modelbased/CONTRIBUTING.html","id":"checks-to-do-before-submission","dir":"","previous_headings":"","what":"Checks to do before submission","title":"Contribution Guidelines","text":"Make sure documentation (roxygen) good Make sure add tests new functions Run: styler::style_pkg(): Automatic style formatting lintr::lint_package(): Style checks devtools::check(): General checks","code":""},{"path":"https://easystats.github.io/modelbased/CONTRIBUTING.html","id":"useful-materials","dir":"","previous_headings":"","what":"Useful Materials","title":"Contribution Guidelines","text":"Understanding GitHub flow","code":""},{"path":"https://easystats.github.io/modelbased/articles/derivatives.html","id":"the-traditional-approach","dir":"Articles","previous_headings":"","what":"The Traditional Approach","title":"Interpret simple and complex models using the power of Effect Derivatives","text":"Let‚Äôs say interested relationship y x following dataset:  Upon visualizing data, people might say: ‚Äúwell, straightforward thing run correlation analysis‚Äù (might wrong, sake demonstration, push things ). Let‚Äôs : Great, know significant correlation two variables! ü•≥ like know every increase 1 x, much y increase? words, slope relationship? traditional approach fit linear model, assess parameters. Indeed, slope linear relationship predictor outcome actually effects estimated regression correspond . Let‚Äôs fit linear regression model, visualize , describe parameters.  parameters table shows us effect x 12.75. means every increase 1 x, y increases 12.75. Congrats, ‚Äôve answered question!","code":"# Package to fit GAMs library(mgcv)  # Tidyverse library(ggplot2)  # Easystats library(datawizard) library(parameters) library(modelbased) library(report) library(see)  set.seed(333)  # Generate data data <- bayestestR::simulate_correlation(r = 0.85, n = 1000, names = c(\"y\", \"x\"), mean = c(100, 0), sd = c(15, 1))  ggplot(data, aes(x, y)) +   geom_point() rez <- cor.test(data$y, data$x) report::report(rez) > Effect sizes were labelled following Funder's (2019) recommendations. >  > The Pearson's product-moment correlation between data$y and data$x is positive, > statistically significant, and very large (r = 0.85, 95% CI [0.83, 0.87], > t(998) = 50.97, p < .001) model_lm <- lm(y ~ x, data = data)  plot(modelbased::estimate_relation(model_lm)) parameters::parameters(model_lm) > Parameter   | Coefficient |   SE |          95% CI | t(998) |      p > -------------------------------------------------------------------- > (Intercept) |      100.00 | 0.25 | [99.51, 100.49] | 400.00 | < .001 > x           |       12.75 | 0.25 | [12.26,  13.24] |  50.97 | < .001"},{"path":"https://easystats.github.io/modelbased/articles/derivatives.html","id":"gams-can-be-used-for-linear-relationships-too","dir":"Articles","previous_headings":"","what":"GAMs can be used for linear relationships too!","title":"Interpret simple and complex models using the power of Effect Derivatives","text":"new player entered game. might heard General Additive Models, aka GAMs, extend general linear models (GLMs) enabling elegant robust way modelling non-linear relationships. ‚Äôs good curvy relationships simple stuff ! can even use linear links, , general, sure exact shape relationship. GAMs usually penalize wiggly patterns, problems approximating linear relationship, data indicates. GAMs can fitted using mgcv package, change need specify smooth term (s()) variable want estimate (non-necessarily linear) relationship.  Wow, GAM-based modeled relationship near-exactly GLM! GAMs powerful üòé Okay, ‚Äôs cool, ‚Äôs one slight issue. look parameters table, indeed one line ‚Äúsmooth term‚Äù, ‚Ä¶ coefficient! Indeed, GAMs don‚Äôt model straight lines, doesn‚Äôt return value slope. ‚Äôs people consider GAMs complicated discuss statistically, parameters easily interpretable. Owww, issue considering question effect x y üòï ?","code":"model_gam <- mgcv::gam(y ~ s(x), data = data)  plot(modelbased::estimate_relation(model_gam), line = list(color = \"blue\")) parameters::parameters(model_gam) > # Fixed Effects >  > Parameter   | Coefficient |   SE |          95% CI | t(998.00) |      p > ----------------------------------------------------------------------- > (Intercept) |      100.00 | 0.25 | [99.51, 100.49] |    400.00 | < .001 >  > # Smooth Terms >  > Parameter       |       F |   df |      p > ----------------------------------------- > Smooth term (x) | 2598.40 | 1.00 | < .001"},{"path":"https://easystats.github.io/modelbased/articles/derivatives.html","id":"effect-derivatives","dir":"Articles","previous_headings":"","what":"Effect Derivatives","title":"Interpret simple and complex models using the power of Effect Derivatives","text":"Let us introduce another concept likely get popular near future within world regressions. Derivatives. might remember math class high school derivatives basically pattern slope pattern (pattern-ception much).  figure , plot shows non-linear relationship variables, -plot shows 1st order derivative, .e., evolution slope curve. might take bit time mentally wrap head around transformation, get , become easy think terms derivatives. can see derivative peaks slope relationship highest (steepest), decrease reaching 0. zero-crossing derivative means inversion trend; relationship starts negative. Derivatives can computed statistical models, including simple ones linear regressions. look answer , try think imagine derivative plot previously computed linear model look like? know slope 12.75 (parameters analysis). change across course relationship? , straight line, slope constant. slope constant, derivative ‚Ä¶ constant line , right? Let‚Äôs verify . compute derivative, can use estimate_slopes() function, specify want know: trend x course (‚Äú‚Äù) .  plot shows straight horizontal line 12.75, fixed confidence interval (parameter table). expected, definition, linear model models straight line fixed slope. running summary() derivative, obtain summary ‚Äúsegments‚Äù (positive, flat, negative). , one segment, average coefficient corresponds regression parameter. means don‚Äôt really need parameters table. Indeed, information slope can retrieved effect derivative. guess ‚Ä¶ can applied model! GAMs. Lets‚Äô GAM model: Isn‚Äôt amazing, results identical. moral story GAMs can used wide variety contexts, even simple cases, derivatives easy way interpreting . Let‚Äôs jump another example!","code":"deriv <- modelbased::estimate_slopes(model_lm, trend = \"x\", at = \"x\")  plot(deriv) + # add a dashed line at 0 to show absence of effect   geom_hline(yintercept = 0, linetype = \"dashed\") summary(deriv) > Average Marginal Effects >  > Start |  End |     x | Coefficient |   SE |         95% CI | t(998) |      p > ---------------------------------------------------------------------------- > -3.38 | 3.28 | -0.05 |       12.75 | 0.25 | [12.26, 13.24] |  50.97 | < .001 > Marginal effects estimated for x deriv <- modelbased::estimate_slopes(model_gam, trend = \"x\", at = \"x\")  plot(deriv, line = list(color = \"blue\")) +   geom_hline(yintercept = 0, linetype = \"dashed\")  summary(deriv)"},{"path":"https://easystats.github.io/modelbased/articles/derivatives.html","id":"gam-derivatives-lm-a-polynomial-regression-example","dir":"Articles","previous_headings":"","what":"GAM + Derivatives > LM: a polynomial regression example","title":"Interpret simple and complex models using the power of Effect Derivatives","text":"mentioned one GAMs ‚Äúlimitation‚Äù parameters easily interpretable. assuming classes models, GLMs, case. However, common difficult--interpret parameters normal regression models ! Let‚Äôs take case polynomial regression, use model following data:  Let us fit polynomial regression:  look parameters table, also bit unclear coefficient refer . interpret numbers? Trying understand require lot search understanding polynomials work. Ain‚Äôt nobody got time dat‚Äô! Instead, can rely good ol‚Äô derivatives obtain ‚Äúlinear slope‚Äù every point curve.  know bit theory derivatives, won‚Äôt surprised find derivative 2nd order polynomial (x + x^2) actually linear line. can conclude plot slope (significantly, confidence interval cover 0) negative 0, becomes positive. 0 corresponds indeed point inversion curve. Moral story? Derivatives can used easily interpret draw conclusions relationships models parameters straightforward interpret. , ‚Äôve attentive point, might wonder: bother polynomials GAMs can trick? conclusion similar, shows significant effect goes negative positive becomes flat (.e., non-significant) around 0. 3rd-degree-type relationships? works way: , GAM nicely recovered shape relationship. summary, effects derivatives can used easily leverage power GAMs.","code":"data$y2 <- data$x^2 + rnorm(nrow(data), sd = 0.5)  ggplot(data, aes(x, y2)) +   geom_point() model_poly <- lm(y2 ~ poly(x, 2), data = data)  # Length is increased to have a smoother line plot(modelbased::estimate_relation(model_poly, length = 30)) parameters::parameters(model_poly) > Parameter      | Coefficient |   SE |         95% CI | t(997) |      p > ---------------------------------------------------------------------- > (Intercept)    |        1.01 | 0.02 | [ 0.98,  1.04] |  62.32 | < .001 > x [1st degree] |       -1.37 | 0.51 | [-2.38, -0.37] |  -2.68 | 0.007  > x [2nd degree] |       44.82 | 0.51 | [43.82, 45.83] |  87.38 | < .001 deriv <- modelbased::estimate_slopes(model_poly, trend = \"x\", at = \"x\")  plot(deriv) +   geom_hline(yintercept = 0, linetype = \"dashed\") summary(deriv) > Average Marginal Effects >  > Start |  End |     x | Coefficient |   SE |        95% CI | t(997) |      p > --------------------------------------------------------------------------- > -3.38 | 3.28 | -0.05 |       -0.07 | 0.05 | [-0.17, 0.02] |  -1.56 | < .001 > Marginal effects estimated for x model_gam2 <- mgcv::gam(y2 ~ s(x), data = data)  plot(modelbased::estimate_relation(model_gam2, length = 100), line = list(color = \"blue\"))  # Increase precision deriv <- modelbased::estimate_slopes(model_gam2, trend = \"x\", at = \"x\", length = 100)  plot(deriv, line = list(color = \"blue\")) +   geom_hline(yintercept = 0, linetype = \"dashed\")  summary(deriv) data$y3 <- data$x^3 + rnorm(nrow(data), sd = 1)  model_gam3 <- mgcv::gam(y3 ~ s(x), data = data)  plot(modelbased::estimate_relation(model_gam3, length = 100), line = list(color = \"blue\"))  deriv <- modelbased::estimate_slopes(model_gam3, trend = \"x\", at = \"x\", length = 100)  plot(deriv, line = list(color = \"blue\")) +   geom_hline(yintercept = 0, linetype = \"dashed\")"},{"path":"https://easystats.github.io/modelbased/articles/describe_nonlinear.html","id":"estimate_smooth","dir":"Articles","previous_headings":"","what":"estimate_smooth","title":"Model and describe non-linear relationships","text":"Let‚Äôs start creating simple dataset:  Looking nice! Now let‚Äôs model non-linear relationship using polynomial term: Let‚Äôs continue visualising fitted model:  Although visual representation usually recommended, can verbally describe relationship? describe_nonlinear decompose curve linear parts, returning size (percentage curve segment), trend (positive negative). can now say relationship can summarised one negative link positive link, changing point located roughly around 0.","code":"data <- data.frame(x = -50:50) # Generate dataframe with one variable x data$y <- data$x^2 # Add a variable y data$y <- data$y + rnorm(nrow(data), mean = 0, sd = 100) # Add some gaussian noise library(ggplot2) # For plotting library(see) # For nice themes  ggplot(data, aes(x = x, y = y)) +   geom_point() +   see::theme_modern() model <- glm(y ~ poly(x, 2), data = data) library(modelbased)  estim <- estimate_relation(model, length = 50)  ggplot(estim, aes(x = x, y = Predicted)) +   geom_line(color = \"purple\") +   geom_point(data = data, aes(x = x, y = y)) + # Add original data points   see::theme_modern() describe_nonlinear(estim, x = \"x\", y = \"Predicted\") > Start  |   End | Length |   Change |  Slope |       R2 > ------------------------------------------------------ > -50.00 | -1.02 |   0.48 | -2490.97 | -50.86 | 4.90e-07 > -1.02  | 50.00 |   0.50 |  2492.80 |  48.86 | 4.90e-07"},{"path":"https://easystats.github.io/modelbased/articles/describe_nonlinear.html","id":"real-application-effect-of-time-on-memory","dir":"Articles","previous_headings":"","what":"Real application: Effect of time on memory","title":"Model and describe non-linear relationships","text":"download use dataset participants answer questions movie Avengers: Age ultron (combined memory score) days watching theater (delay variable). Let‚Äôs visualize Delay, days, influences Memory score, plotting data points raw loess fit raw data.  Unsurprisingly, forgetting curve appears non-linear, supported literature suggesting 2nd order polynomial curve (Averell Heathcote 2011).","code":"library(datawizard) library(ggplot2) library(see)  # Load the data and filter out outliers df <- read.csv(\"https://raw.githubusercontent.com/DominiqueMakowski/2017being/master/data/data.csv\") df <- data_filter(df, Delay <= 14 & Memory >= 20)   # Plot the density of the point and a loess smooth line ggplot(df, aes(x = Delay, y = Memory)) +   stat_density_2d(geom = \"raster\", aes(fill = ..density..), contour = FALSE) +   geom_jitter(width = 0.2, height = 0.2) +   scale_fill_viridis_c() +   geom_smooth(formula = \"y ~ x\", method = \"loess\", color = \"red\", se = FALSE) +   theme_modern(legend.position = \"none\")"},{"path":"https://easystats.github.io/modelbased/articles/describe_nonlinear.html","id":"modelling-non-linear-curves","dir":"Articles","previous_headings":"","what":"Modelling non-linear curves","title":"Model and describe non-linear relationships","text":"can fit Bayesian linear mixed regression model relationship, adding variables influence curve, familiarity characters movie, language movie, immersion (2D/3D). can visualize link Delay Memory score using estimate_relation.  seems memory score starts decreasing, point stabilizes (even increases, might related factors, discussions movie, watching YouTube reviews ). point change?","code":"library(lme4)  model <- lmer(Memory ~ poly(Delay, 2) * Characters_Familiarity + (1 | Movie_Language) + (1 | Immersion), data = df) library(modelbased)  estim <- estimate_relation(model, at = \"Delay\", ci = c(0.50, 0.69, 0.89, 0.97))  ggplot(estim, aes(x = Delay, y = Predicted)) +   geom_jitter(data = df, aes(y = Memory), width = 0.2, height = 0.2) +   geom_ribbon(aes(ymin = CI_low_0.97, ymax = CI_high_0.97), alpha = 0.2, fill = \"blue\") +   geom_ribbon(aes(ymin = CI_low_0.89, ymax = CI_high_0.89), alpha = 0.2, fill = \"blue\") +   geom_ribbon(aes(ymin = CI_low_0.69, ymax = CI_high_0.69), alpha = 0.2, fill = \"blue\") +   geom_ribbon(aes(ymin = CI_low_0.5, ymax = CI_high_0.5), alpha = 0.2, fill = \"blue\") +   geom_line(color = \"blue\") +   theme_modern(legend.position = \"none\") +   ylab(\"Memory\")"},{"path":"https://easystats.github.io/modelbased/articles/describe_nonlinear.html","id":"describing-smooth","dir":"Articles","previous_headings":"","what":"Describing smooth","title":"Model and describe non-linear relationships","text":"","code":"estimate_smooth(estim, x = \"Delay\") > Start |   End | Length | Change | Slope |   R2 > ---------------------------------------------- > 0.00  |  7.78 |   0.53 | -15.68 | -2.02 | 0.50 > 7.78  | 14.00 |   0.37 |   4.69 |  0.75 | 0.50"},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/estimate_contrasts.html","id":"testing-pairwise-differences","dir":"Articles","previous_headings":"","what":"Testing pairwise differences","title":"Contrast analysis","text":"previous tutorial, computed marginal means 3 different Species levels iris dataset. However, one might also want statistically test differences levels, can achieved contrast analysis. Although procedure much powerful, aim analogous post hoc analysis (pretty much consisting pairwise t-tests), heavily utilized behavioral sciences way follow hypotheses global differences tested ANOVAs specific hypotheses pairwise differences. Let‚Äôs carry contrast analysis simple model previous tutorial:  Contrast analysis can achieved estimate_contrasts function: can conclude pairwise differences statistically significant.","code":"library(ggplot2) library(see) library(modelbased)  model <- lm(Sepal.Width ~ Species, data = iris) means <- estimate_means(model)  ggplot(means, aes(x = Species, y = Mean)) +   geom_line(aes(group = 1)) +   geom_pointrange(aes(color = Species, ymin = CI_low, ymax = CI_high)) +   theme_modern() estimate_contrasts(model) > Marginal Contrasts Analysis >  > Level1     |     Level2 | Difference |         95% CI |   SE | t(147) |      p > ------------------------------------------------------------------------------ > setosa     | versicolor |       0.66 | [ 0.49,  0.82] | 0.07 |   9.69 | < .001 > setosa     |  virginica |       0.45 | [ 0.29,  0.62] | 0.07 |   6.68 | < .001 > versicolor |  virginica |      -0.20 | [-0.37, -0.04] | 0.07 |  -3.00 | 0.003  >  > Marginal contrasts estimated at Species > p-value adjustment method: Holm (1979)"},{"path":"https://easystats.github.io/modelbased/articles/estimate_contrasts.html","id":"complex-model","dir":"Articles","previous_headings":"","what":"Complex model","title":"Contrast analysis","text":", contrast analysis based marginal means, can applied complex models: instance, add Petal.Width model, can see difference versicolor virginica becomes significant (even changes sign). Note can plot simple contrast analysis lighthouse plots help see package:  represent estimated means CI range (black), grey areas show CI range difference (compared point estimate).","code":"model <- lm(Sepal.Width ~ Species * Petal.Width, data = iris) contrasts <- estimate_contrasts(model) contrasts > Marginal Contrasts Analysis >  > Level1     |     Level2 | Difference |        95% CI |   SE | t(144) |      p > ----------------------------------------------------------------------------- > setosa     | versicolor |       1.59 | [ 0.64, 2.54] | 0.39 |   4.04 | < .001 > setosa     |  virginica |       1.77 | [ 0.77, 2.78] | 0.41 |   4.29 | < .001 > versicolor |  virginica |       0.18 | [-0.17, 0.54] | 0.15 |   1.27 | 0.205  >  > Marginal contrasts estimated at Species > p-value adjustment method: Holm (1979) library(see)  plot(contrasts, estimate_means(model)) +   theme_modern()"},{"path":"https://easystats.github.io/modelbased/articles/estimate_contrasts.html","id":"changes-in-difference","dir":"Articles","previous_headings":"","what":"Changes in difference","title":"Contrast analysis","text":"Interestingly, can also see differences modulated another continuous variable. Based model (including interaction Petal.Width), compute contrasts 100 equally-spaced points Petal.Width, visualise.  can see, difference versicolor virginica increases Petal.Width increases.","code":"contrasts <- estimate_contrasts(model, at = \"Petal.Width\", length = 100)  # Create a variable with the two levels concatenated contrasts$Contrast <- paste(contrasts$Level1, \"-\", contrasts$Level2)  # Visualise the changes in the differences ggplot(contrasts, aes(x = Petal.Width, y = Difference)) +   geom_ribbon(aes(fill = Contrast, ymin = CI_low, ymax = CI_high), alpha = 0.2) +   geom_line(aes(colour = Contrast), size = 1) +   geom_hline(yintercept = 0, linetype = \"dashed\") +   theme_modern() +   ylab(\"Difference\")"},{"path":"https://easystats.github.io/modelbased/articles/estimate_contrasts.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Contrast analysis","text":"Contrast analysis can powerful tool interpret understand statistical models.","code":""},{"path":[]},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/estimate_grouplevel.html","id":"population-level-effects","dir":"Articles","previous_headings":"Speed (RT)","what":"Population-level Effects","title":"How to use Mixed models to Estimate Individuals' Scores","text":"reaction time, start removing incorrect responses, since reflective ‚Äúsuccessful‚Äù cognitive process. , plot RT according condition stimulus category.  descriptive visualisation indeed seems suggest people slower accuracy condition compared speed condition. also slight effect frequency. Let‚Äôs verify using modelisation approach. Let‚Äôs unpack formula model. ‚Äôre tying predict rt using different terms. can separated two groups, fixed effects random effects. condition fixed effect means interested estimating ‚Äúgeneral‚Äù effect condition, across subjects items (.e., population level). top effect condition, second ‚Äòfixed‚Äô parameter implicitly specified estimated, intercept (might know, one explicitly remove rt ~ 0 + condition, otherwise added automatically). Let‚Äôs investigate two fixed parameters first: condition factor two levels, parameters easily interpretable. intercept corresponds rt baseline level factor (accuracy), effect condition corresponds change rt intercept speed condition. words, effect condition refers difference two conditions, speed - accuracy. can see, difference significant, people , general, lower rt (sign negative) speed condition. Let‚Äôs visualize marginal means estimated model:  Now, ‚Äôs random effects. formula, specified random intercepts (.e., right part bar | symbol) id (participants) stim. means participant stimulus ‚ÄúIntercept‚Äù parameter (, ‚Äôve seen , corresponds rt accuracy condition). Additionally, ‚Äôve specified random effect (‚Äúrandom slope‚Äù - left side bar) condition participant. means participant effect condition computed. need complex model? Let‚Äôs compare model without specifying random intercepts stimuli. Mmmh, seems simpler model performs lot worse (Bayes Factor lower 1). run compare_performance() learn details, example go ahead keep worse model (simplicity conciseness inspecting random effects later, keep mind real life ‚Äôs surely best thing ).","code":"data_rt <- filter(data, error == 0)  ggplot(data = data_rt, aes(y = rt, condition)) +   geom_violin() model_full <- lmer(rt ~ condition + (1 + condition | id) + (1 | stim),   data = data_rt ) parameters(model_full, effects = \"fixed\") > # Fixed Effects >  > Parameter         | Coefficient |   SE |         95% CI | t(4506) |      p > -------------------------------------------------------------------------- > (Intercept)       |        0.69 | 0.02 | [ 0.65,  0.74] |   30.44 | < .001 > condition [speed] |       -0.16 | 0.02 | [-0.19, -0.12] |   -8.53 | < .001 estimate_means(model_full) %>%   plot(show_data = \"violin\") model <- lmer(rt ~ condition + (1 + condition | id), data = data_rt)  test_performance(model_full, model) > Name       |   Model |       BF | df | df_diff |  Chi2 |      p > --------------------------------------------------------------- > model_full | lmerMod |          |  7 |         |       |        > model      | lmerMod | 6.92e-07 |  6 |   -1.00 | 36.78 | < .001 > Models were detected as nested and are compared in sequential order."},{"path":"https://easystats.github.io/modelbased/articles/estimate_grouplevel.html","id":"group-level-effects","dir":"Articles","previous_headings":"Speed (RT)","what":"Group-level Effects","title":"How to use Mixed models to Estimate Individuals' Scores","text":"‚Äôs nice know, actually get access group-level scores. can use estimate_grouplevel() function retrieve . participant (Level column), numbered 1 17, two rows, corresponding deviation main effect intercept condition effect. can also use reshape_grouplevel() select Coefficient column (skip information uncertainty - real life equally important!) make match original data. resulting table length original dataset can merged : ‚Äôs convenient way re-incorporate random effects data re-use. can see, first row repeated corresponds participant (random effects ). Note can use summary() remove duplicate rows. Let‚Äôs add original data. can also visualize random effects:  Wow! can see, lot -participants variability. random parameters correspond ?","code":"random <- estimate_grouplevel(model) random > Group | Level |      Parameter | Coefficient |   SE |         95% CI > -------------------------------------------------------------------- > id    |     1 |    (Intercept) |       -0.10 | 0.01 | [-0.12, -0.07] > id    |     1 | conditionspeed |        0.09 | 0.02 | [ 0.06,  0.12] > id    |     2 |    (Intercept) |        0.08 | 0.02 | [ 0.04,  0.12] > id    |     2 | conditionspeed |       -0.03 | 0.02 | [-0.07,  0.01] > id    |     3 |    (Intercept) |        0.02 | 0.01 | [ 0.00,  0.05] > id    |     3 | conditionspeed |       -0.02 | 0.02 | [-0.05,  0.01] > id    |     4 |    (Intercept) |       -0.13 | 0.01 | [-0.15, -0.10] > id    |     4 | conditionspeed |        0.08 | 0.02 | [ 0.05,  0.11] > id    |     5 |    (Intercept) |       -0.05 | 0.01 | [-0.08, -0.03] > id    |     5 | conditionspeed |    6.67e-03 | 0.02 | [-0.02,  0.04] > id    |     6 |    (Intercept) |       -0.08 | 0.01 | [-0.10, -0.05] > id    |     6 | conditionspeed |        0.04 | 0.02 | [ 0.01,  0.07] > id    |     7 |    (Intercept) |       -0.09 | 0.01 | [-0.12, -0.07] > id    |     7 | conditionspeed |        0.10 | 0.02 | [ 0.06,  0.13] > id    |     8 |    (Intercept) |        0.21 | 0.01 | [ 0.19,  0.24] > id    |     8 | conditionspeed |       -0.18 | 0.02 | [-0.21, -0.14] > id    |     9 |    (Intercept) |        0.03 | 0.01 | [ 0.00,  0.05] > id    |     9 | conditionspeed |       -0.02 | 0.02 | [-0.05,  0.01] > id    |    10 |    (Intercept) |       -0.10 | 0.01 | [-0.13, -0.08] > id    |    10 | conditionspeed |        0.07 | 0.02 | [ 0.04,  0.10] > id    |    11 |    (Intercept) |       -0.09 | 0.01 | [-0.11, -0.07] > id    |    11 | conditionspeed |        0.07 | 0.02 | [ 0.04,  0.11] > id    |    12 |    (Intercept) |   -6.47e-04 | 0.01 | [-0.03,  0.02] > id    |    12 | conditionspeed |    3.65e-03 | 0.02 | [-0.03,  0.04] > id    |    13 |    (Intercept) |        0.08 | 0.01 | [ 0.05,  0.10] > id    |    13 | conditionspeed |       -0.06 | 0.02 | [-0.09, -0.02] > id    |    14 |    (Intercept) |        0.03 | 0.01 | [ 0.01,  0.06] > id    |    14 | conditionspeed |       -0.03 | 0.02 | [-0.06,  0.00] > id    |    15 |    (Intercept) |        0.09 | 0.01 | [ 0.07,  0.11] > id    |    15 | conditionspeed |       -0.07 | 0.02 | [-0.10, -0.04] > id    |    16 |    (Intercept) |        0.04 | 0.01 | [ 0.02,  0.06] > id    |    16 | conditionspeed |       -0.01 | 0.02 | [-0.05,  0.02] > id    |    17 |    (Intercept) |        0.06 | 0.01 | [ 0.03,  0.08] > id    |    17 | conditionspeed |       -0.05 | 0.02 | [-0.08, -0.02] reshaped <- reshape_grouplevel(random, indices = \"Coefficient\")  head(reshaped) >   id Intercept conditionspeed > 1  1    -0.097          0.094 > 2  1    -0.097          0.094 > 3  1    -0.097          0.094 > 4  1    -0.097          0.094 > 5  1    -0.097          0.094 > 6  1    -0.097          0.094 data_rt <- full_join(data_rt, reshaped, by = \"id\") plot(random) +   theme_lucid()"},{"path":"https://easystats.github.io/modelbased/articles/estimate_grouplevel.html","id":"correlation-with-empirical-scores","dir":"Articles","previous_headings":"Speed (RT)","what":"Correlation with empirical scores","title":"How to use Mixed models to Estimate Individuals' Scores","text":"said random effects group-level (group unit , model, participants) version population-level effects (fixed effects). One important thing note represent deviation fixed effect, coefficient close 0 means participants‚Äô effect population-level effect. words, ‚Äôs ‚Äúnorm‚Äù (note can also obtain group-specific effect corresponding sum fixed random changing type argument). Nevertheless, let‚Äôs compute empirical scores, condition averages participant. group data participant condition, get mean RT, reshape data , participant, two means two columns. , create new dataframe (use - overwrite - keep concise), keep mean RT accuracy condition, difference speed condition (reminds something?). Now, empirical scores compare random effects estimated model? Let‚Äôs merge empirical scores random effects scores. , run summary() reshaped random effects remove duplicate rows (one row per participant, matches format data_sub). Let‚Äôs run correlation model-based scores empirical scores. First thing notice everything significantly strongly correlated!. , empirical scores accuracy condition, corresponding ‚Äúraw‚Äù average RT, correlate almost perfectly model-based counterpart (\\(r_{empirical\\_accuracy/Coefficient\\_Intercept} = 1\\); \\(r_{empirical\\_condition/Coefficient\\_conditionspeed} > .99\\)). ‚Äôs reassuring, means model managed estimate intuitive parameters! Finally, can observe strong negative correlation (even salient model-based indices) RT accuracy condition effect speed condition:  slower accuracy condition, bigger difference speed condition.","code":"data_sub <- aggregate(rt ~ id + condition, data_rt, mean) %>%   reshape_wider(names_from = \"condition\", values_from = \"rt\", names_prefix = \"rt_\")  data_sub <- data.frame(   id = data_sub$id,   empirical_accuracy = data_sub$rt_accuracy,   empirical_condition = data_sub$rt_speed - data_sub$rt_accuracy ) data_sub <- full_join(data_sub, summary(reshaped), by = \"id\") correlation(data_sub) > # Correlation Matrix (pearson-method) >  > Parameter1          |          Parameter2 |     r |         95% CI |  t(15) |         p > --------------------------------------------------------------------------------------- > empirical_accuracy  | empirical_condition | -0.94 | [-0.98, -0.84] | -10.72 | < .001*** > empirical_accuracy  |           Intercept |  1.00 | [ 1.00,  1.00] | 198.45 | < .001*** > empirical_accuracy  |      conditionspeed | -0.98 | [-0.99, -0.93] | -17.37 | < .001*** > empirical_condition |           Intercept | -0.93 | [-0.98, -0.82] | -10.10 | < .001*** > empirical_condition |      conditionspeed |  0.99 | [ 0.98,  1.00] |  29.16 | < .001*** > Intercept           |      conditionspeed | -0.97 | [-0.99, -0.92] | -15.95 | < .001*** >  > p-value adjustment method: Holm (1979) > Observations: 17 ggplot(data_sub, aes(x = Intercept, y = conditionspeed)) +   geom_point() +   geom_smooth(method = \"lm\") +   theme_modern()"},{"path":"https://easystats.github.io/modelbased/articles/estimate_grouplevel.html","id":"accuracy","dir":"Articles","previous_headings":"","what":"Accuracy","title":"How to use Mixed models to Estimate Individuals' Scores","text":"section, take interest accuracy - probability making errors, using logistic models. , use dataset still includes errors (data, data_rt used previous section). fit logistic mixed model predict likelihood making error depending condition. Similarly, specified random intercept random effect condition participants. parameters suggest general, participants indeed make errors speed condition compared accuracy condition. can visualize average probability (.e., marginal means) making errors two conditions.  Similarly, can extract group-level effects, clean (rename columns, otherwise names RT model), merge previous ones.","code":"model <- glmer(error ~ condition + (1 + condition | id),   data = data, family = \"binomial\" )  parameters(model, effects = \"fixed\") > # Fixed Effects >  > Parameter         | Log-Odds |   SE |         95% CI |      z |      p > ---------------------------------------------------------------------- > (Intercept)       |    -2.91 | 0.19 | [-3.28, -2.53] | -15.16 | < .001 > condition [speed] |     1.32 | 0.15 | [ 1.02,  1.61] |   8.73 | < .001 plot(estimate_means(model), show_data = \"none\") random <- estimate_grouplevel(model) random > Group | Level |      Parameter | Coefficient |   SE |         95% CI > -------------------------------------------------------------------- > id    |     1 |    (Intercept) |   -4.68e-03 | 0.28 | [-0.55,  0.54] > id    |     1 | conditionspeed |       -0.32 | 0.30 | [-0.90,  0.26] > id    |     2 |    (Intercept) |       -0.54 | 0.41 | [-1.34,  0.26] > id    |     2 | conditionspeed |        0.11 | 0.36 | [-0.61,  0.82] > id    |     3 |    (Intercept) |       -0.26 | 0.30 | [-0.85,  0.32] > id    |     3 | conditionspeed |        0.22 | 0.30 | [-0.38,  0.81] > id    |     4 |    (Intercept) |       -0.63 | 0.33 | [-1.28,  0.01] > id    |     4 | conditionspeed |        0.21 | 0.32 | [-0.43,  0.84] > id    |     5 |    (Intercept) |       -0.28 | 0.31 | [-0.88,  0.32] > id    |     5 | conditionspeed |       -0.51 | 0.31 | [-1.12,  0.11] > id    |     6 |    (Intercept) |        0.17 | 0.26 | [-0.35,  0.69] > id    |     6 | conditionspeed |       -0.04 | 0.28 | [-0.60,  0.51] > id    |     7 |    (Intercept) |        0.91 | 0.21 | [ 0.49,  1.32] > id    |     7 | conditionspeed |        0.12 | 0.24 | [-0.35,  0.58] > id    |     8 |    (Intercept) |        1.18 | 0.21 | [ 0.77,  1.59] > id    |     8 | conditionspeed |       -0.03 | 0.24 | [-0.50,  0.43] > id    |     9 |    (Intercept) |       -0.24 | 0.30 | [-0.83,  0.35] > id    |     9 | conditionspeed |        0.19 | 0.31 | [-0.41,  0.79] > id    |    10 |    (Intercept) |       -0.20 | 0.29 | [-0.78,  0.37] > id    |    10 | conditionspeed |        0.29 | 0.30 | [-0.30,  0.88] > id    |    11 |    (Intercept) |        0.43 | 0.24 | [-0.05,  0.91] > id    |    11 | conditionspeed |        0.12 | 0.26 | [-0.39,  0.64] > id    |    12 |    (Intercept) |        1.00 | 0.21 | [ 0.59,  1.41] > id    |    12 | conditionspeed |       -0.77 | 0.25 | [-1.25, -0.29] > id    |    13 |    (Intercept) |        0.45 | 0.25 | [-0.04,  0.93] > id    |    13 | conditionspeed |       -0.12 | 0.27 | [-0.65,  0.40] > id    |    14 |    (Intercept) |       -0.32 | 0.31 | [-0.93,  0.29] > id    |    14 | conditionspeed |       -0.12 | 0.32 | [-0.73,  0.50] > id    |    15 |    (Intercept) |       -0.27 | 0.30 | [-0.86,  0.32] > id    |    15 | conditionspeed |        0.18 | 0.31 | [-0.42,  0.78] > id    |    16 |    (Intercept) |        0.21 | 0.26 | [-0.30,  0.73] > id    |    16 | conditionspeed |        0.13 | 0.28 | [-0.42,  0.68] > id    |    17 |    (Intercept) |       -1.16 | 0.38 | [-1.90, -0.42] > id    |    17 | conditionspeed |        0.17 | 0.35 | [-0.52,  0.86] plot(random)"},{"path":[]},{"path":[]},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/estimate_means.html","id":"raw-means","dir":"Articles","previous_headings":"","what":"Raw Means","title":"What are, why use and how to get marginal means","text":"iris dataset, available base R, contains observations 3 types iris flowers (Species variable); Setosa, Versicolor Virginica, different features measured, length width sepals petals. traditional starting point, reporting data, start descriptive statistics. instance, mean Sepal.Width 3 species. can compute means easily grouping observations species, computing mean SD: can also provide plot:  However, raw means might biased, number observations group might different. Moreover, might hidden covariance mediation variables dataset, creating ‚Äúspurious‚Äù influence means. can take influences account calculating means?","code":"library(poorman)  iris %>%   group_by(Species) %>%   summarise(     Mean_Sepal.Width = mean(Sepal.Width),     SD_Sepal.Width = sd(Sepal.Width)   ) > ‚Ä©[38;5;246m# A tibble: 3 √ó 3‚Ä©[39m > ‚Ä©[38;5;246m# Groups:   Species [3]‚Ä©[39m >   Species    Mean_Sepal.Width SD_Sepal.Width >   ‚Ä©[3m‚Ä©[38;5;246m<fct>‚Ä©[39m‚Ä©[23m                 ‚Ä©[3m‚Ä©[38;5;246m<dbl>‚Ä©[39m‚Ä©[23m          ‚Ä©[3m‚Ä©[38;5;246m<dbl>‚Ä©[39m‚Ä©[23m > ‚Ä©[38;5;250m1‚Ä©[39m setosa                 3.43          0.379 > ‚Ä©[38;5;250m2‚Ä©[39m versicolor             2.77          0.314 > ‚Ä©[38;5;250m3‚Ä©[39m virginica              2.97          0.322 library(ggplot2) library(see)  ggplot(iris, aes(x = Species, y = Sepal.Width, fill = Species)) +   geom_violin() +   geom_jitter2(width = 0.05) +   theme_modern()"},{"path":"https://easystats.github.io/modelbased/articles/estimate_means.html","id":"marginal-means","dir":"Articles","previous_headings":"","what":"Marginal Means","title":"What are, why use and how to get marginal means","text":"Another way analysing means actually statistically model , rather simply describe appear data. instance, fit simple Bayesian linear regression modelling relationship Species Sepal.Width. Marginal means basically means extracted statistical model, represent average response variable (, Sepal.Width) level predictor variable (, Species). Note means computed different raw means created . can surmise many spurious influences need worry iris dataset. might case dataset. can now add means, well credible interval (CI) representing uncertainty estimation, overlay previous plot:","code":"library(modelbased)  model <- lm(Sepal.Width ~ Species, data = iris) means <- estimate_means(model) means > Estimated Marginal Means >  > Species    | Mean |   SE |       95% CI > --------------------------------------- > setosa     | 3.43 | 0.05 | [3.33, 3.52] > versicolor | 2.77 | 0.05 | [2.68, 2.86] > virginica  | 2.97 | 0.05 | [2.88, 3.07] >  > Marginal means estimated at Species ggplot(iris, aes(x = Species, y = Sepal.Width, fill = Species)) +   geom_violin() +   geom_jitter2(width = 0.05, alpha = 0.5) +   geom_line(data = means, aes(y = Mean, group = 1), size = 1) +   geom_pointrange(     data = means,     aes(y = Mean, ymin = CI_low, ymax = CI_high),     size = 1,     color = \"white\"   ) +   theme_modern()"},{"path":"https://easystats.github.io/modelbased/articles/estimate_means.html","id":"complex-models","dir":"Articles","previous_headings":"","what":"Complex Models","title":"What are, why use and how to get marginal means","text":"power marginal means resides fact can estimated much complex models. instance, fit model takes account interaction variable, Petal.Width. estimated means ‚Äúadjusted‚Äù (take account) variations components. Now let‚Äôs plot marginal means simple linear model (shown white dots) saw marginal means complex model (shown yellow dots) next , help us notice adjusted means change depending predictors.  ‚Äôs interesting! seems adjusting model petal characteristics, differences Species seems even bigger! differences ‚Äúsignificant‚Äù? ‚Äôs contrast analysis comes play! Click read tutorial contrast analysis.","code":"model <- lm(Sepal.Width ~ Species * Petal.Width, data = iris) means_complex <- estimate_means(model)  means_complex > Estimated Marginal Means >  > Species    | Mean |   SE |       95% CI > --------------------------------------- > setosa     | 4.23 | 0.39 | [3.45, 5.00] > versicolor | 2.64 | 0.05 | [2.54, 2.74] > virginica  | 2.45 | 0.14 | [2.18, 2.72] >  > Marginal means estimated at Species ggplot(iris, aes(x = Species, y = Sepal.Width, fill = Species)) +   geom_violin() +   geom_jitter2(width = 0.05, alpha = 0.5) +   geom_line(data = means, aes(y = Mean, group = 1), size = 1, alpha = 0.25) +   geom_pointrange(     data = means,     aes(y = Mean, ymin = CI_low, ymax = CI_high),     size = 1,     color = \"white\"   ) +   geom_line(data = means_complex, aes(y = Mean, group = 1), size = 1) +   geom_pointrange(     data = means_complex,     aes(y = Mean, ymin = CI_low, ymax = CI_high),     size = 1,     color = \"orange\"   ) +   theme_modern()"},{"path":[]},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/estimate_relation.html","id":"linear-relationship","dir":"Articles","previous_headings":"Simple regression","what":"Linear relationship","title":"Visualize effects and interactions","text":"","code":"library(modelbased)  model <- glm(Sepal.Length ~ Sepal.Width, data = iris)  visualization_data <- estimate_relation(model) head(visualization_data) library(ggplot2) library(see) library(poorman)  visualization_data %>%   ggplot(aes(x = Sepal.Width, y = Predicted)) +   geom_ribbon(aes(ymin = CI_low, ymax = CI_high), alpha = 0.2) +   geom_line() +   see::theme_modern()"},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/estimate_relation.html","id":"non-linear-relationships","dir":"Articles","previous_headings":"More complex regressions","what":"Non-linear relationships","title":"Visualize effects and interactions","text":"Note non-linear relationships can also described linear approximations using describe_nonlinear.","code":""},{"path":"https://easystats.github.io/modelbased/articles/estimate_relation.html","id":"polynomial","dir":"Articles","previous_headings":"More complex regressions > Non-linear relationships","what":"Polynomial","title":"Visualize effects and interactions","text":"","code":"glm(Sepal.Length ~ poly(Sepal.Width, 2), data = iris) %>%   modelbased::estimate_relation(length = 50) %>%   ggplot(aes(x = Sepal.Width, y = Predicted)) +   geom_ribbon(aes(ymin = CI_low, ymax = CI_high), alpha = 0.2) +   geom_line() +   see::theme_modern()"},{"path":"https://easystats.github.io/modelbased/articles/estimate_relation.html","id":"additive-models","dir":"Articles","previous_headings":"More complex regressions > Non-linear relationships","what":"Additive Models","title":"Visualize effects and interactions","text":"","code":"library(mgcv)  mgcv::gam(Sepal.Length ~ s(Sepal.Width), data = iris) %>%   modelbased::estimate_relation(length = 50) %>%   ggplot(aes(x = Sepal.Width, y = Predicted)) +   geom_ribbon(aes(ymin = CI_low, ymax = CI_high), alpha = 0.2) +   geom_line() +   see::theme_modern()"},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/estimate_relation.html","id":"interaction-with-a-factor","dir":"Articles","previous_headings":"Interactions","what":"Interaction with a factor","title":"Visualize effects and interactions","text":"TODO.","code":""},{"path":"https://easystats.github.io/modelbased/articles/estimate_relation.html","id":"interaction-with-another-continuous-variable","dir":"Articles","previous_headings":"Interactions","what":"Interaction with another continuous variable","title":"Visualize effects and interactions","text":"TODO.","code":""},{"path":"https://easystats.github.io/modelbased/articles/estimate_relation.html","id":"supported-models","dir":"Articles","previous_headings":"","what":"Supported Models","title":"Visualize effects and interactions","text":"TODO.","code":""},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/estimate_response.html","id":"prediction-against-original-data","dir":"Articles","previous_headings":"","what":"Prediction against original data","title":"Use a model to make predictions","text":"Generating prediction model can used wide variety reasons, one visualisation. can achieved via estimate_expectation() function visualisation spinoff, estimate_relation(). Let‚Äôs start fitting linear regression. might interested comparing values predicted model actual ‚Äútrue‚Äù values. can done generating predictions: output data frame containing predicted values (median CI posterior distribution) value original data frame (used fitting model). Hence, can simply add original response column (Petal.Length) data plot original predicted data (top identity line, representing perfect relationship).  seems like model perform bad. added information Species model? now plot second observations, based complex model, red overlay previous points:  new model generated much accurate predictions (closer underlying regression line).","code":"model <- lm(Petal.Length ~ Sepal.Length, data = iris) library(modelbased) library(poorman)  pred_data <- estimate_expectation(model) head(pred_data) > Model-based Expectation >  > Sepal.Length | Predicted |   SE |       95% CI | Residuals > ---------------------------------------------------------- > 5.10         |      2.38 | 0.10 | [2.19, 2.57] |     -0.98 > 4.90         |      2.00 | 0.11 | [1.79, 2.22] |     -0.60 > 4.70         |      1.63 | 0.12 | [1.39, 1.87] |     -0.33 > 4.60         |      1.45 | 0.13 | [1.19, 1.70] |      0.05 > 5.00         |      2.19 | 0.10 | [1.99, 2.39] |     -0.79 > 5.40         |      2.93 | 0.08 | [2.78, 3.09] |     -1.23 >  > Variable predicted: Petal.Length library(ggplot2) library(see)  pred_data$Petal.Length <- iris$Petal.Length  pred_data %>%   ggplot(aes(x = Petal.Length, y = Predicted)) +   geom_line(aes(x = Petal.Length, y = Petal.Length), linetype = \"dashed\") +   geom_point() +   ylab(\"Petal.Length (predicted)\") +   theme_modern() model <- lm(Petal.Length ~ Sepal.Length * Species, data = iris)  pred_data$Predicted_2 <- estimate_expectation(model)$Predicted pred_data %>%   ggplot() +   geom_line(aes(x = Petal.Length, y = Petal.Length), linetype = \"dashed\") +   geom_point(aes(x = Petal.Length, y = Predicted), color = \"grey\") +   geom_point(aes(x = Petal.Length, y = Predicted_2), color = \"red\") +   ylab(\"Petal.Length (predicted)\") +   theme_modern()"},{"path":"https://easystats.github.io/modelbased/articles/estimate_response.html","id":"estimating-response-vs--relation","dir":"Articles","previous_headings":"","what":"Estimating response vs. relation","title":"Use a model to make predictions","text":"Rather visualizing predictions made model, often interested visualizing relation. model , relationship response two predictors. can achieved generating predictions data grid model‚Äôs data instead original dataset. visualise relationship response (Petal.Length) predictors (Sepal.Length Species).  However, might notice Credible Interval (CI) bands quite big. estimate_relation() coming . traditional, frequentist, regression, predictions deterministic: always fall regression line. However, Bayesian framework, probabilistic. Hence , predicting response predicting link (.e., regression line uncertainty interval associated line). order facilitate visualization links, added estimate_relation() shortcut estimate_expectation() data = \"grid\" , Bayesian models, predict = \"link\" smoothing default. estimate_expectation() used context generating actual predictions existing new data, whereas estimate_relation() relevant context visualization plotting.","code":"predicted <- estimate_expectation(model, data = \"grid\")  iris %>%   ggplot(aes(x = Sepal.Length)) +   geom_point(aes(y = Petal.Length, color = Species)) +   geom_ribbon(data = predicted, aes(ymin = CI_low, ymax = CI_high, fill = Species), alpha = 0.3) +   geom_line(data = predicted, aes(y = Predicted, color = Species), size = 1) +   theme_modern() predicted <- estimate_relation(model)  iris %>%   ggplot(aes(x = Sepal.Length)) +   geom_point(aes(y = Petal.Length, color = Species)) +   geom_ribbon(data = predicted, aes(ymin = CI_low, ymax = CI_high, fill = Species), alpha = 0.3) +   geom_line(data = predicted, aes(y = Predicted, color = Species), size = 1) +   theme_modern()"},{"path":"https://easystats.github.io/modelbased/articles/estimate_response.html","id":"different-ci-levels","dir":"Articles","previous_headings":"","what":"Different CI levels","title":"Use a model to make predictions","text":"purpose CI bands provide information uncertainty related estimation. Bayesian framework, credible intervals directly related shape posterior distribution. Thus, showing different CI levels (instance, 69%, 89% 99%).","code":"predicted <- estimate_relation(model, ci = c(0.69, .89, 0.99))  iris %>%   ggplot(aes(x = Sepal.Length)) +   geom_point(aes(y = Petal.Length, color = Species)) +   geom_ribbon(data = predicted, aes(ymin = CI_low_0.99, ymax = CI_high_0.99, fill = Species), alpha = 0.2) +   geom_ribbon(data = predicted, aes(ymin = CI_low_0.89, ymax = CI_high_0.89, fill = Species), alpha = 0.3) +   geom_ribbon(data = predicted, aes(ymin = CI_low_0.69, ymax = CI_high_0.69, fill = Species), alpha = 0.3) +   geom_line(data = predicted, aes(y = Predicted, color = Species), size = 1) +   theme_modern()"},{"path":"https://easystats.github.io/modelbased/articles/estimate_response.html","id":"adding-individual-iterations","dir":"Articles","previous_headings":"","what":"Adding individual iterations","title":"Use a model to make predictions","text":"Let‚Äôs now fit model Bayesian framework. Note: ‚Äôre familiar Bayesian framework, recommend starting gentle introduction. refresh seed arguments included reproducibility readability, critical model. Instead (addition ) representing confidence intervals, one can also represent every individual posterior draw, correspond random selection possible links compatible observed data. nice insight ‚Äútrue‚Äù underlying probabilities.  Note also possible obtain similar plots without Bayesian models, bootstrapping predictions. can done setting iterations argument number (e.g., 50).  Animated hypothetical outcome plots can also easily created gganimate:","code":"library(rstanarm)  model <- stan_glm(Petal.Length ~ Sepal.Length * Species,   refresh = 0, seed = 33,   data = iris ) # Keep only 100 draws (keeping all the draws is slower) predicted <- estimate_relation(model, keep_iterations = TRUE, iterations = 100)  # Format draws for plotting iterations <- bayestestR::reshape_iterations(predicted) iterations$group <- paste0(iterations$iter_group, iterations$Species)  iris %>%   ggplot(aes(x = Sepal.Length)) +   geom_point(aes(y = Petal.Length, color = Species)) +   geom_line(data = iterations, aes(y = iter_value, color = Species, group = group), alpha = 0.05) +   geom_line(data = predicted, aes(y = Predicted, color = Species), size = 1) +   theme_modern() model <- lm(Petal.Length ~ Sepal.Length * Species, data = iris)  # Bootstrap with n=50 iterations predicted <- estimate_relation(model, keep_iterations = TRUE, iterations = 50)  # Format draws for plotting iterations <- bayestestR::reshape_iterations(predicted) iterations$group <- paste0(iterations$iter_group, iterations$Species)  p <- iris %>%   ggplot(aes(x = Sepal.Length)) +   geom_point(aes(y = Petal.Length, color = Species)) +   geom_line(data = iterations, aes(y = iter_value, color = Species, group = group), alpha = 0.1) +   geom_line(data = predicted, aes(y = Predicted, color = Species), size = 1) +   theme_modern() p library(gganimate)  p <- iris %>%   ggplot(aes(x = Sepal.Length)) +   geom_point(aes(y = Petal.Length, color = Species)) +   geom_line(data = iterations, aes(y = iter_value, color = Species, group = group)) +   theme_modern() +   transition_states(iter_group, 0, 1) +   shadow_mark(past = TRUE, future = TRUE, alpha = 1 / 20, color = \"grey\")  gganimate::animate(p)"},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/estimate_slopes.html","id":"marginal-effects-over-a-factors-levels","dir":"Articles","previous_headings":"","what":"Marginal effects over a factor‚Äôs levels","title":"Marginal effects and derivatives","text":"Let‚Äôs fit linear model factor interacting continuous predictor visualize .  seems like slope effect roughly similar (direction) across different factor levels. Moreover, interaction significant. However, see removing interaction substantially improve model‚Äôs performance. , sake demonstration, let‚Äôs say want keep maximal effect structure. Although satisfied model performance, imagine interested effect Petal.Length different Species, rather, general trend ‚Äúacross‚Äù different species. need compute marginal effect predictor, corresponds slope averaged (‚Äôs bit complex simple averaging ‚Äôs idea) different factor levels. can see effect Petal.Length, marginalized Species, positive significant.","code":"library(parameters) library(performance) library(modelbased)  model <- lm(Sepal.Length ~ Petal.Length * Species, data = iris)  plot(estimate_relation(model)) parameters(model) > Parameter                           | Coefficient |   SE |         95% CI | t(144) |      p > ------------------------------------------------------------------------------------------- > (Intercept)                         |        4.21 | 0.41 | [ 3.41,  5.02] |  10.34 | < .001 > Petal Length                        |        0.54 | 0.28 | [ 0.00,  1.09] |   1.96 | 0.052  > Species [versicolor]                |       -1.81 | 0.60 | [-2.99, -0.62] |  -3.02 | 0.003  > Species [virginica]                 |       -3.15 | 0.63 | [-4.41, -1.90] |  -4.97 | < .001 > Petal Length √ó Species [versicolor] |        0.29 | 0.30 | [-0.30,  0.87] |   0.97 | 0.334  > Petal Length √ó Species [virginica]  |        0.45 | 0.29 | [-0.12,  1.03] |   1.56 | 0.120 model2 <- lm(Sepal.Length ~ Petal.Length + Species, data = iris)  test_performance(model, model2) > Name   | Model |    BF | df | df_diff | Chi2 |     p > ---------------------------------------------------- > model  |    lm |       |  7 |         |      |       > model2 |    lm | 26.52 |  5 |   -2.00 | 3.47 | 0.177 > Models were detected as nested and are compared in sequential order. slopes <- estimate_slopes(model, trend = \"Petal.Length\")  slopes > Estimated Marginal Effects >  > Coefficient |   SE |       95% CI | t(144) |      p > --------------------------------------------------- > 0.79        | 0.10 | [0.59, 0.99] |   7.69 | < .001 > Marginal effects estimated for Petal.Length"},{"path":"https://easystats.github.io/modelbased/articles/estimate_slopes.html","id":"effects-for-each-factors-levels","dir":"Articles","previous_headings":"","what":"Effects for each factor‚Äôs levels","title":"Marginal effects and derivatives","text":"","code":"slopes <- estimate_slopes(model, trend = \"Petal.Length\", at = \"Species\")  slopes > Estimated Marginal Effects >  > Species    | Coefficient |   SE |        95% CI | t(144) |      p > ----------------------------------------------------------------- > setosa     |        0.54 | 0.28 | [ 0.00, 1.09] |   1.96 | 0.052  > versicolor |        0.83 | 0.10 | [ 0.63, 1.03] |   8.10 | < .001 > virginica  |        1.00 | 0.09 | [ 0.82, 1.17] |  11.43 | < .001 > Marginal effects estimated for Petal.Length plot(slopes)"},{"path":"https://easystats.github.io/modelbased/articles/estimate_slopes.html","id":"interactions-between-two-continuous-variables","dir":"Articles","previous_headings":"","what":"Interactions between two continuous variables","title":"Marginal effects and derivatives","text":"Interactions two continuous variables often straightforward visualize interpret. Thanks model-based approach, one can represent effect one variables function variable. plot, also referred Johnson-Neyman intervals, shows effect (‚Äúslope‚Äù) one variable varies depending another variable. useful case complex interactions continuous variables. instance, plot shows effect hp (y-axis) significantly negative wt low (< ~4).","code":"library(modelbased)  model <- lm(mpg ~ hp * wt, data = mtcars)  slopes <- estimate_slopes(model, trend = \"hp\", at = \"wt\")  plot(slopes)"},{"path":"https://easystats.github.io/modelbased/articles/estimate_slopes.html","id":"describing-and-reporting-non-linear-relationships-e-g--in-gams","dir":"Articles","previous_headings":"","what":"Describing and reporting non-linear relationships (e.g., in GAMs)","title":"Marginal effects and derivatives","text":"Complex problems require modern solutions. General Additive Models (GAMs) powerful class models extend capabilities traditional GLMs. particular, able parsimoniously model possibly non-linear relationship. Let‚Äôs take instance following model:  GAMs nicely models complex relationship two variables (don‚Äôt take account different species course). interpret report manuscript results? can‚Äôt simply paste figure right? Right? Reviewers want statistics, numbers brackets, otherwise doesn‚Äôt look serious . problem GAMs parameters (.e., coefficients), easily interpretable. can see one line corresponding smooth term. ‚Äôs significant, great, mean? run GAM using packages (e.g., rstanarm brms), parameters . ! meaning parameters somewhat disconnected need relationship understanding, another possibility compute marginal linear effect smooth term, .e., ‚Äúderivative‚Äù, using estimate_slopes. plot represents ‚Äúslope‚Äù curve point curve. can see, significant negative trend (Petal.Length = 4), followed significant positive trend (around Petal.Length = 4). Marginal derivatives allow us make inferences point point relationship! Finally, help reporting manuscript, can divide chunks obtain ‚Äúaverage‚Äù linear trend chunk. can conclude Petal.Length shares significantly negative relationship outcome variable 2.01 3.15 (average marginal effect = -0.76, 95% CI [-1.14, -0.37], p < .01) significantly positive 3.74 4.28 (average marginal effect = 0.54, 95% CI [0.14, 0.93], p < .05).","code":"# Fit a non-linear General Additive Model (GAM) model <- mgcv::gam(Sepal.Width ~ s(Petal.Length), data = iris)  plot(estimate_relation(model, length = 50)) parameters::parameters(model) > # Fixed Effects >  > Parameter   | Coefficient |   SE |       95% CI | t(142.33) |      p > -------------------------------------------------------------------- > (Intercept) |        3.06 | 0.03 | [3.01, 3.11] |    118.31 | < .001 >  > # Smooth Terms >  > Parameter                  |     F |   df |      p > -------------------------------------------------- > Smooth term (Petal Length) | 17.52 | 6.67 | < .001 # Compute derivative deriv <- estimate_slopes(model,   trend = \"Petal.Length\",   at = \"Petal.Length\",   length = 100 )  # Visualise plot(deriv) summary(deriv)"},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/modelisation_approach.html","id":"the-empirical-approach-classic","dir":"Articles","previous_headings":"","what":"The Empirical Approach (Classic)","title":"The Modelisation Approach to Statistics","text":"","code":"library(poorman) library(ggplot2) library(emmeans) library(parameters) library(modelbased)"},{"path":"https://easystats.github.io/modelbased/articles/modelisation_approach.html","id":"data-simulation","dir":"Articles","previous_headings":"The Empirical Approach (Classic)","what":"Data Simulation","title":"The Modelisation Approach to Statistics","text":"First run function simulate data. ‚Äôs need understand hows whys, explain everything due time.","code":"generate_data <- function(effect = 5, noise = 0.5) {   data <- data.frame()   n <- 100   for (i in 1:length(effect)) {     participant <- data.frame(Experimental_Variable = c(seq(-3, 3, length = n / 2), seq(-3, 3, length = n / 2)))     participant$RT <- c(participant$Experimental_Variable[1:(n / 2)]**2 - effect[i], (participant$Experimental_Variable[(n / 2 + 1):n] + effect[i])) + rnorm(n, 0, abs(noise[i]))     participant$Condition <- rep(c(\"A\", \"B\"), each = n / 2)     participant$Participant <- paste0(\"S\", i)     data <- rbind(data, participant)   }   data$RT <- (100 + data$RT) * 10   data }  data <- generate_data(effect = rnorm(30, 2, 2), noise = rnorm(30, 0, 0.4)) # # library(rtdists) # # data <- data.frame( #   Participant = paste0(\"S\", speed_acc$id), #   Item = as.numeric(speed_acc$stim), #   Condition = speed_acc$condition, #   Correct = ifelse(as.character(speed_acc$stim_cat) == as.character(speed_acc$response), 1, 0), #   RT = speed_acc$rt * 1000 # )"},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/modelisation_approach.html","id":"anovas","dir":"Articles","previous_headings":"The Empirical Approach (Classic)","what":"ANOVAs","title":"The Modelisation Approach to Statistics","text":"ANOVAs, ‚Äôs groups. Even though people also add continuous variables (creating ANCOVAs, MANOVAs monstrosities), ‚Äôs really ‚Äúspirit‚Äù: ANOVAs made compare groups. take, participant, 20‚Ä¶ : COMPLETE VIGNETTE. can conclude ? Absolutely nothing! need investigate details, instance running post-hoc comparison tests. uninformativeness one reason ANOVA banned psychological science.","code":"data_anova <- data %>%   mutate(Category = case_when(     Experimental_Variable < -1.5 ~ \"Low\",     Experimental_Variable > 1.5 ~ \"High\",     TRUE ~ \"Middle\"   )) %>%   mutate(Category = relevel(as.factor(Category), \"Low\", \"Middle\", \"High\")) %>%   group_by(Participant, Condition, Category) %>%   summarise(RT = mean(RT))  results <- aov(RT ~ Condition * Category + Error(Participant), data = data_anova) parameters(results) > # Participant >  > Parameter | Sum_Squares | df | Mean_Square > ------------------------------------------ > Residuals |       33.32 | 29 |        1.15 >  > # Within >  > Parameter          | Sum_Squares |  df | Mean_Square |     F |      p > --------------------------------------------------------------------- > Condition          |       73.09 |   1 |       73.09 |  0.14 | 0.705  > Category           |    37375.24 |   2 |    18687.62 | 36.84 | < .001 > Condition:Category |    36990.41 |   2 |    18495.20 | 36.46 | < .001 > Residuals          |    73550.75 | 145 |      507.25 |       |        >  > Anova Table (Type 1 tests)"},{"path":"https://easystats.github.io/modelbased/articles/modelisation_approach.html","id":"post-hoc-comparison-tests","dir":"Articles","previous_headings":"The Empirical Approach (Classic)","what":"Post-hoc comparison tests","title":"The Modelisation Approach to Statistics","text":"","code":"posthoc <- model_emmeans(results, at = c(\"Condition\", \"Category\")) %>%   pairs() parameters(posthoc) > contrast            | Coefficient |   SE |           95% CI | t(145) |      p > ----------------------------------------------------------------------------- > A Low - B Low       |       36.83 | 5.82 | [ 25.33,  48.32] |   6.33 | < .001 > A Low - A High      |       -0.23 | 5.82 | [-11.73,  11.26] |  -0.04 | > .999 > A Low - B High      |       -8.54 | 5.82 | [-20.04,   2.95] |  -1.47 | 0.979  > A Low - A Middle    |       46.52 | 5.82 | [ 35.02,  58.01] |   8.00 | < .001 > A Low - B Middle    |       14.18 | 5.82 | [  2.69,  25.67] |   2.44 | 0.491  > B Low - A High      |      -37.06 | 5.82 | [-48.55, -25.56] |  -6.37 | < .001 > B Low - B High      |      -45.37 | 5.82 | [-56.86, -33.87] |  -7.80 | < .001 > B Low - A Middle    |        9.69 | 5.82 | [ -1.80,  21.18] |   1.67 | 0.940  > B Low - B Middle    |      -22.65 | 5.82 | [-34.14, -11.15] |  -3.89 | 0.012  > A High - B High     |       -8.31 | 5.82 | [-19.80,   3.18] |  -1.43 | 0.983  > A High - A Middle   |       46.75 | 5.82 | [ 35.25,  58.24] |   8.04 | < .001 > A High - B Middle   |       14.41 | 5.82 | [  2.92,  25.90] |   2.48 | 0.463  > B High - A Middle   |       55.06 | 5.82 | [ 43.57,  66.55] |   9.47 | < .001 > B High - B Middle   |       22.72 | 5.82 | [ 11.23,  34.21] |   3.91 | 0.012  > A Middle - B Middle |      -32.34 | 5.82 | [-43.83, -20.84] |  -5.56 | < .001 >  > p-value adjustment method: Tukey data_anova %>%   ggplot(aes(x = Category, y = RT, fill = Condition)) +   geom_boxplot() +   see::theme_modern()"},{"path":"https://easystats.github.io/modelbased/articles/modelisation_approach.html","id":"the-modelisation-approach","dir":"Articles","previous_headings":"","what":"The Modelisation Approach","title":"The Modelisation Approach to Statistics","text":"model made parameters, ‚Äòreal‚Äô meaning, opposed indices significance (abstract).","code":""},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/modelisation_approach.html","id":"draw-what-you-want-to-visualize","dir":"Articles","previous_headings":"The Modelisation Approach","what":"1. Draw what you want to visualize","title":"The Modelisation Approach to Statistics","text":"can use geom_smooth(), can fit non-linear relationships empirical way, give us idea shape relationships.","code":"data %>%   group_by(Participant, Condition) %>%   ggplot(aes(x = Experimental_Variable, y = RT, color = Condition)) +   geom_jitter(alpha = 0.4) +   geom_smooth(method = \"loess\", se = FALSE) +   see::theme_modern()"},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/overview_of_vignettes.html","id":"function-overview","dir":"Articles","previous_headings":"","what":"Function Overview","title":"Overview of Vignettes","text":"Function Reference","code":""},{"path":"https://easystats.github.io/modelbased/articles/overview_of_vignettes.html","id":"articles","dir":"Articles","previous_headings":"","what":"Articles","title":"Overview of Vignettes","text":"Interpret simple complex models using power Effect Derivatives Model describe non-linear relationships Contrast analysis use Mixed models Estimate Individuals‚Äô Scores , use get marginal means Visualize effects interactions Use model make predictions Marginal effects derivatives Modelisation Approach Statistics Transformations Data grids","code":""},{"path":"https://easystats.github.io/modelbased/articles/transformations.html","id":"scale-transformations","dir":"Articles","previous_headings":"","what":"Scale Transformations","title":"Transformations","text":"Standardization (also known Z-scoring) refers centering scaling variable expressed terms deviation centrality index. Usually mean SD (0 corresponds mean values represent deviations SD ), indices, median MAD. R, can achieved via standardize() function datawizard package. Normalization rescales variable minimum maximum 0 1. R, can achieved via normalize() function. However, note bit misnomer, doesn‚Äôt actually normalize distribution (.e., make ‚ÄúGaussian‚Äù) data (shown ). Instead, makes range data within expected range [0, 1]. Normalization , fact, special case Rescaling. variable can rescaled new range. R, can achieved via data_rescale() function. Importantly, transformations change scale (.e., ‚Äúunit‚Äù); impact distribution variable. , either impact relationship variables. Let‚Äôs start generating random data creating convenience function check distribution one variable relationship another variable. Transformation:  Transformation:   can see, although unit x changed, scale-transformation impact distribution variable relationship variables. Interpretation (standardized effect sizes) Computation (models can converge efficiently) Interpretation (variable values meaning) Reproducibility (values different meaning depending sample‚Äôs characteristics - transformations depend properties variable like standardization)","code":"datawizard::standardize(c(4, 5, 2, 4, 42)) > [1] -0.43 -0.37 -0.55 -0.43  1.79 > attr(,\"center\") > [1] 11 > attr(,\"scale\") > [1] 17 > attr(,\"robust\") > [1] FALSE > attr(,\"class\") > [1] \"dw_transformer\" \"numeric\" datawizard::normalize(c(4, 5, 2, 4, 42)) > [1] 0.050 0.075 0.000 0.050 1.000 > attr(,\"include_bounds\") > [1] TRUE > attr(,\"flag_bounds\") > [1] TRUE > attr(,\"min_value\") > [1] 2 > attr(,\"vector_length\") > [1] 5 > attr(,\"range_difference\") > [1] 40 > attr(,\"class\") > [1] \"dw_transformer\" \"numeric\" datawizard::rescale(c(4, 5, 2, 4, 42), to = c(-1, 1)) > [1] -0.90 -0.85 -1.00 -0.90  1.00 > attr(,\"min_value\") > [1] 2 > attr(,\"max_value\") > [1] 42 > attr(,\"new_min\") > [1] -1 > attr(,\"new_max\") > [1] 1 > attr(,\"range_difference\") > [1] 40 > attr(,\"to_range\") > [1] -1  1 > attr(,\"class\") > [1] \"dw_transformer\" \"numeric\" library(patchwork)  # Create dataset data <- data.frame(x = bayestestR::distribution_normal(500, mean = 30, sd = 20)) data$y <- data$x^2 + rnorm(500, sd = 100)  # Write convenience function check_transformation <- function(data, x = \"x\", color = \"blue\") {   ggplot(bayestestR::estimate_density(data[[x]]), aes(x = x, y = y)) +     geom_area(fill = color) +     ggtitle(\"Distribution of x\") +     see::theme_modern() +     ggplot(data, aes_string(x = x, y = \"y\")) +     geom_point() +     geom_smooth(color = color, se = FALSE, method = \"loess\", formula = \"y ~ x\") +     ggtitle(\"Relationship with y\") +     see::theme_modern() } check_transformation(data, color = \"blue\") data$x_standardized <- datawizard::standardize(data$x)  check_transformation(data, x = \"x_standardized\", color = \"red\") +   patchwork::plot_annotation(\"After Standardization\") data$x_normalized <- datawizard::normalize(data$x)  check_transformation(data, x = \"x_normalized\", color = \"orange\") +   patchwork::plot_annotation(\"After Normalization\")"},{"path":"https://easystats.github.io/modelbased/articles/transformations.html","id":"shape-transformation","dir":"Articles","previous_headings":"","what":"Shape Transformation","title":"Transformations","text":"http://fmwww.bc.edu/repec/bocode/t/transint.html ‚Äúsee clever trick works nicely. know trick work data, another trick needed, transformation needed?‚Äù ‚ÄúTransformations needed guarantee world works scales happens measured .‚Äù ‚ÄúTransformations appropriate match scientific view variable behaves.‚Äù traditional transformation work best (.e., easily explainable) positively defined data. case variables also negative values, fairly common practice shift scale towards positive range adding minimum. can follows:  now know, ‚Äúscale-transformation‚Äù affect variable‚Äôs distribution shape relationship. beware, next procedures !","code":"data$x_positive <- data$x - min(data$x)  check_transformation(data, \"x_positive\", color = \"yellow\")"},{"path":"https://easystats.github.io/modelbased/articles/transformations.html","id":"pull-the-right-edge-up","dir":"Articles","previous_headings":"Shape Transformation","what":"Pull the right edge ‚Äúup‚Äù","title":"Transformations","text":"following transformations common smaller values inflated lot, larger values less affected. can imagine tightening x-axis, pushing big values right towards left, leaving closer values. result, linear relationship became curved straighten right edge. Square root  Cubic root  Logarithmic","code":"data$x_sqrt <- sqrt(data$x_positive)  check_transformation(data, \"x_sqrt\", color = \"cyan\") data$x_cbrt <- data$x_positive^(1 / 3)  check_transformation(data, \"x_cbrt\", color = \"purple\") data$x_log <- log(1 + data$x_positive)  check_transformation(data, \"x_log\", color = \"maroon\")"},{"path":"https://easystats.github.io/modelbased/articles/transformations.html","id":"bring-the-right-edges-down","dir":"Articles","previous_headings":"Shape Transformation","what":"Bring the right edges ‚Äúdown‚Äù","title":"Transformations","text":"following transformations common bigger number , bigger get. pulled x-axis towards right, ever faster values closer right edge. result, sharply vertical relationships tend smooth lean towards right. Exponential   Square  Cubic  Reciprocal Also know inverse transformation.","code":"data$x_exp <- exp(normalize(data$x_positive))  check_transformation(data, \"x_exp\", color = \"purple\") data$x_exp3 <- exp(3 * normalize(data$x_positive))  check_transformation(data, \"x_exp3\", color = \"pink\") data$x_2 <- data$x_positive^2  check_transformation(data, \"x_2\", color = \"darkblue\") data$x_3 <- data$x_positive^3  check_transformation(data, \"x_3\", color = \"darkgreen\") data$x_reciprocal <- 1 / (1 + data$x_positive)  check_transformation(data, \"x_reciprocal\", color = \"green\")"},{"path":"https://easystats.github.io/modelbased/articles/transformations.html","id":"generalization","dir":"Articles","previous_headings":"Shape Transformation","what":"Generalization","title":"Transformations","text":"Actually, previous shape-transformations part two categories, exponential/log family, power family. Indeed, square root, cubic root, square even inverse values power something.","code":"data$x_reciprocical == (1 + data$x_positive)^(-1) data$x_cbrt == data$x_positive^(1 / 3) data$x_sqrt == data$x_positive^(1 / 2) data$x_2 == data$x_positive^(2) data$x_2 == data$x_positive^(3)"},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/visualisation_matrix.html","id":"simple-linear-regression","dir":"Articles","previous_headings":"","what":"Simple linear regression","title":"Data grids","text":"instance, let‚Äôs fit simple linear model models relationship Sepal.Width Sepal.Length. obvious way representing model plot data points add regression line using geom_smooth function ggplot2:  ‚Äúaccess‚Äù data regression line? One good option select values predictor (Sepal.Length), predict (using base R predict() method now) response (Sepal.Width) using model. Using x y points, can create regression line. Let‚Äôs try visualisation_matrix function modelbased package (note function insight::get_datagrid(), just different name). pass numeric column function, return vector equally spread points (range, .e., minimum maximum, original data). default length 10, can adjust length argument. instance, linear relationships (.e., straight line), two points theory sufficient. Let‚Äôs generate predictions using reference grid predictor. Now x y values, can plot line overlay actual data points:  can see, quite similar previous plot. , can useful?","code":"library(parameters)  model <- lm(Sepal.Width ~ Sepal.Length, data = iris) model_parameters(model) > Parameter    | Coefficient |   SE |        95% CI | t(148) |      p > ------------------------------------------------------------------- > (Intercept)  |        3.42 | 0.25 | [ 2.92, 3.92] |  13.48 | < .001 > Sepal Length |       -0.06 | 0.04 | [-0.15, 0.02] |  -1.44 | 0.152 library(ggplot2) library(see) library(poorman)  ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width)) +   geom_point() +   geom_smooth(method = \"lm\") +   theme_modern() library(modelbased)  visualisation_matrix(iris[\"Sepal.Length\"]) > Visualisation Grid >  > Sepal.Length > ------------ >         4.30 >         4.70 >         5.10 >         5.50 >         5.90 >         6.30 >         6.70 >         7.10 >         7.50 >         7.90 vizdata <- visualisation_matrix(iris[\"Sepal.Length\"], length = 2) vizdata$Predicted <- predict(model, vizdata) vizdata > Visualisation Grid >  > Sepal.Length | Predicted > ------------------------ >         4.30 |      3.15 >         7.90 |      2.93 ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width)) +   geom_point() +   geom_line(data = vizdata, aes(y = Predicted), size = 1, color = \"red\") +   theme_modern()"},{"path":"https://easystats.github.io/modelbased/articles/visualisation_matrix.html","id":"mixed-models","dir":"Articles","previous_headings":"","what":"Mixed models","title":"Data grids","text":"Data grids useful represent complex models. instance, models , negative relationship length width sepals fact biased presence three different species. One way adjusting model grouping structure add random effect mixed model. model , ‚Äúfixed‚Äù effects (parameters interest) adjusted (‚Äúaveraged ‚Äù) random effects. can see, adjusting species, relationship two variables become positive! can represent using procedure , note instead using base R predict() function, using get_predicted(), insight package, robust user-friendly version predict().","code":"library(lme4)  model <- lmer(Sepal.Width ~ Sepal.Length + (1 | Species), data = iris) model_parameters(model) > # Fixed Effects >  > Parameter    | Coefficient |   SE |       95% CI | t(146) |      p > ------------------------------------------------------------------ > (Intercept)  |        1.04 | 0.43 | [0.20, 1.89] |   2.45 | 0.015  > Sepal Length |        0.34 | 0.05 | [0.25, 0.44] |   7.47 | < .001 >  > # Random Effects >  > Parameter               | Coefficient > ------------------------------------- > SD (Intercept: Species) |        0.57 > SD (Residual)           |        0.29 vizdata <- visualisation_matrix(iris[\"Sepal.Length\"]) vizdata$Predicted <- insight::get_predicted(model, vizdata)  ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width)) +   geom_point(aes(color = Species)) +   geom_line(data = vizdata, aes(y = Predicted), size = 1) +   theme_modern()"},{"path":"https://easystats.github.io/modelbased/articles/visualisation_matrix.html","id":"fixed-variables","dir":"Articles","previous_headings":"","what":"Fixed variables","title":"Data grids","text":"way constructing reference grid, .e., providing single column data function, almost equivalent following: However, variables (present dataframe selected ) ‚Äúfixed‚Äù, .e., maintained specific values. useful variables model whose effect interested. default, factors fixed ‚Äúreference‚Äù level numeric variables fixed mean. However, can easily changed:","code":"vizdata <- visualisation_matrix(iris, at = \"Sepal.Length\") vizdata > Visualisation Grid >  > Sepal.Length | Sepal.Width | Petal.Length | Petal.Width | Species > ----------------------------------------------------------------- >         4.30 |        3.06 |         3.76 |        1.20 |  setosa >         4.70 |        3.06 |         3.76 |        1.20 |  setosa >         5.10 |        3.06 |         3.76 |        1.20 |  setosa >         5.50 |        3.06 |         3.76 |        1.20 |  setosa >         5.90 |        3.06 |         3.76 |        1.20 |  setosa >         6.30 |        3.06 |         3.76 |        1.20 |  setosa >         6.70 |        3.06 |         3.76 |        1.20 |  setosa >         7.10 |        3.06 |         3.76 |        1.20 |  setosa >         7.50 |        3.06 |         3.76 |        1.20 |  setosa >         7.90 |        3.06 |         3.76 |        1.20 |  setosa >  > Maintained constant: Sepal.Width, Petal.Length, Petal.Width, Species vizdata <- visualisation_matrix(iris, at = \"Sepal.Length\", numerics = \"min\") vizdata > Visualisation Grid >  > Sepal.Length | Sepal.Width | Petal.Length | Petal.Width | Species > ----------------------------------------------------------------- >         4.30 |           2 |            1 |        0.10 |  setosa >         4.70 |           2 |            1 |        0.10 |  setosa >         5.10 |           2 |            1 |        0.10 |  setosa >         5.50 |           2 |            1 |        0.10 |  setosa >         5.90 |           2 |            1 |        0.10 |  setosa >         6.30 |           2 |            1 |        0.10 |  setosa >         6.70 |           2 |            1 |        0.10 |  setosa >         7.10 |           2 |            1 |        0.10 |  setosa >         7.50 |           2 |            1 |        0.10 |  setosa >         7.90 |           2 |            1 |        0.10 |  setosa >  > Maintained constant: Sepal.Width, Petal.Length, Petal.Width, Species"},{"path":"https://easystats.github.io/modelbased/articles/visualisation_matrix.html","id":"target-variables","dir":"Articles","previous_headings":"","what":"Target variables","title":"Data grids","text":"one target variable selected, visualisation_matrix return combination (.e., unique values crossed together). can useful case interaction numeric variable factor. Let‚Äôs visualise regression line levels Species:","code":"model <- lm(Sepal.Width ~ Sepal.Length * Species, data = iris)  vizdata <- visualisation_matrix(iris, at = c(\"Sepal.Length\", \"Species\"), length = 5) vizdata$Predicted <- insight::get_predicted(model, vizdata) vizdata > Visualisation Grid >  > Sepal.Length |    Species | Sepal.Width | Petal.Length | Petal.Width | Predicted > -------------------------------------------------------------------------------- >         4.30 |     setosa |        3.06 |         3.76 |        1.20 |      2.86 >         5.20 |     setosa |        3.06 |         3.76 |        1.20 |      3.58 >         6.10 |     setosa |        3.06 |         3.76 |        1.20 |      4.30 >         7.00 |     setosa |        3.06 |         3.76 |        1.20 |      5.02 >         7.90 |     setosa |        3.06 |         3.76 |        1.20 |      5.74 >         4.30 | versicolor |        3.06 |         3.76 |        1.20 |      2.25 >         5.20 | versicolor |        3.06 |         3.76 |        1.20 |      2.53 >         6.10 | versicolor |        3.06 |         3.76 |        1.20 |      2.82 >         7.00 | versicolor |        3.06 |         3.76 |        1.20 |      3.11 >         7.90 | versicolor |        3.06 |         3.76 |        1.20 |      3.40 >         4.30 |  virginica |        3.06 |         3.76 |        1.20 |      2.44 >         5.20 |  virginica |        3.06 |         3.76 |        1.20 |      2.65 >         6.10 |  virginica |        3.06 |         3.76 |        1.20 |      2.86 >         7.00 |  virginica |        3.06 |         3.76 |        1.20 |      3.07 >         7.90 |  virginica |        3.06 |         3.76 |        1.20 |      3.28 >  > Maintained constant: Sepal.Width, Petal.Length, Petal.Width ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +   geom_point() +   geom_line(data = vizdata, aes(y = Predicted), size = 1) +   theme_modern()"},{"path":"https://easystats.github.io/modelbased/articles/visualisation_matrix.html","id":"preserve-range","dir":"Articles","previous_headings":"","what":"Preserve range","title":"Data grids","text":"However, generally good practice extend regression lines beyond range original data, case red line. preserve_range option allows remove observations ‚Äúoutside‚Äù original dataset (however, length increased improve precision toward edges):","code":"vizdata <- visualisation_matrix(iris,   at = c(\"Sepal.Length\", \"Species\"),   length = 100,   preserve_range = TRUE )  vizdata$Predicted_Sepal.Width <- insight::get_predicted(model, vizdata)  ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +   geom_point() +   geom_line(data = vizdata, aes(y = Predicted_Sepal.Width), size = 1) +   theme_modern()"},{"path":"https://easystats.github.io/modelbased/articles/visualisation_matrix.html","id":"visualising-an-interaction-between-two-numeric-variables-three-way-interaction","dir":"Articles","previous_headings":"","what":"Visualising an interaction between two numeric variables (three-way interaction)","title":"Data grids","text":"idea can also used visualise interactions two numeric variables, aka nightmare every scientist. One possibility basically represent relationship response one predictor representative values second predictor. case, represent regression line Sepal.Length Petal.Length 5 equally spaced values Petal.Length, get feel interaction. can obtain right reference grid quite easily chaining two visualisation_matrix together follows: ? started generating reference grid containing combinations 10 equally spread values two target variables, creating 10 * 10 = 100 rows. next step reduce Petal.Length set 5 values, without touching variables (.e., keeping 10 values created Petal.Length). achieved using numerics = \"\". can visualise follows:  plot can clear expressing interaction variable terms deviations mean (standardized variable).  Petal.Width increases (becomes yellow), coefficient Petal.Length Sepal.Length increases (slope steep). Although, can guess, fact captures underlying effect species‚Ä¶ ‚Äôll leave discussing meaningfulness models :)","code":"model <- lm(Sepal.Length ~ Petal.Length * Petal.Width, data = iris) model_parameters(model) > Parameter                  | Coefficient |   SE |         95% CI | t(146) |      p > ---------------------------------------------------------------------------------- > (Intercept)                |        4.58 | 0.11 | [ 4.36,  4.80] |  40.89 | < .001 > Petal Length               |        0.44 | 0.07 | [ 0.31,  0.57] |   6.74 | < .001 > Petal Width                |       -1.24 | 0.22 | [-1.67, -0.81] |  -5.65 | < .001 > Petal Length √ó Petal Width |        0.19 | 0.03 | [ 0.12,  0.25] |   5.62 | < .001 vizdata <- iris %>%   visualisation_matrix(c(\"Petal.Length\", \"Petal.Width\"), length = 10) %>%   visualisation_matrix(\"Petal.Width\", length = 5, numerics = \"all\") vizdata$Predicted <- insight::get_predicted(model, vizdata)  iris %>%   ggplot(aes(x = Petal.Length, y = Sepal.Length, color = Petal.Width)) +   geom_point() +   geom_line(data = vizdata, aes(y = Predicted, group = Petal.Width), size = 1) +   scale_color_viridis_c() +   theme_modern() # Express values in an abstract way vizdata$Petal.Width <- effectsize::format_standardize(vizdata$Petal.Width, reference = iris$Petal.Width)  iris %>%   ggplot(aes(x = Petal.Length, y = Sepal.Length)) +   geom_point2(aes(fill = Petal.Width), color = \"white\", shape = 21, size = 5) + # Only shapes from 21 to 25 have a fill aesthetic   geom_line(data = vizdata, aes(y = Predicted, color = Petal.Width), size = 1) +   scale_color_viridis_d(direction = -1) +   scale_fill_viridis_c(guide = \"none\") +   theme_modern()"},{"path":"https://easystats.github.io/modelbased/articles/visualisation_matrix.html","id":"visualization_matrix-also-runs-directly-on-model-objects","dir":"Articles","previous_headings":"","what":"visualization_matrix() also runs directly on model objects","title":"Data grids","text":"illustrate , let‚Äôs set general additive mixed model (GAMM), going specify smooth term (non-linear relationship; specified s() function) random effects structure. One can directly extract visualization matrix model entering entire object function: also skip smooth term interested fixed effects: can also include random effects:","code":"library(gamm4)  model <- gamm4::gamm4(   formula = Petal.Length ~ Petal.Width + s(Sepal.Length),   random = ~ (1 | Species),   data = iris ) visualisation_matrix(model, length = 3, include_random = FALSE) > Visualisation Grid >  > Petal.Width | Sepal.Length > -------------------------- >        0.10 |         4.30 >        1.30 |         4.30 >        2.50 |         4.30 >        0.10 |         6.10 >        1.30 |         6.10 >        2.50 |         6.10 >        0.10 |         7.90 >        1.30 |         7.90 >        2.50 |         7.90 visualisation_matrix(model, length = 3, include_random = FALSE, include_smooth = FALSE) > Visualisation Grid >  > Petal.Width > ----------- >        0.10 >        1.30 >        2.50 >  > Maintained constant: Sepal.Length visualisation_matrix(model, length = 5, include_random = TRUE) > Visualisation Grid >  > Petal.Width | Sepal.Length |    Species > --------------------------------------- >        0.10 |         4.30 |     setosa >        0.10 |         5.20 |     setosa >        1.30 |         5.20 | versicolor >        1.30 |         6.10 | versicolor >        1.30 |         7.00 | versicolor >        1.90 |         5.20 |  virginica >        2.50 |         5.20 |  virginica >        1.90 |         6.10 |  virginica >        2.50 |         6.10 |  virginica >        1.90 |         7.00 |  virginica >        2.50 |         7.00 |  virginica >        1.90 |         7.90 |  virginica >        2.50 |         7.90 |  virginica"},{"path":"https://easystats.github.io/modelbased/articles/visualisation_matrix.html","id":"controlled-standardized-change","dir":"Articles","previous_headings":"","what":"Controlled standardized change","title":"Data grids","text":"Although plot nice, , like standardized changes SD smoother (e.g., increments 1 SD). can achieved first requesting values want, unstandardizing . Let‚Äôs use model , obtain data grid specific values Petal.Width.","code":"vizdata <- lm(Sepal.Length ~ Petal.Length * Petal.Width, data = iris) %>%   visualisation_matrix(at = c(\"Petal.Length\", \"Petal.Width = seq(-3, 3)\")) %>%   unstandardize(vizdata, select = \"Petal.Width\") %>%   estimate_relation(vizdata)  vizdata$Petal.Width <- effectsize::format_standardize(vizdata$Petal.Width, reference = iris$Petal.Width)  # 6. Plot ggplot(iris, aes(x = Petal.Length, y = Sepal.Length)) +   geom_point2(aes(fill = Petal.Width), shape = 21, size = 5) +   geom_line(data = vizdata, aes(y = Predicted, color = Petal.Width), size = 1) +   scale_color_viridis_d(direction = -1) +   scale_fill_viridis_c(guide = \"none\") +   theme_modern()"},{"path":"https://easystats.github.io/modelbased/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Dominique Makowski. Author, maintainer.            @Dom_Makowski Daniel L√ºdecke. Author.            @strengejacke Mattan S. Ben-Shachar. Author.            @mattansb Indrajeet Patil. Author.            @patilindrajeets","code":""},{"path":"https://easystats.github.io/modelbased/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Makowski, D., Ben-Shachar, M. S., Patil, ., & L√ºdecke, D. (2020). Estimation Model-Based Predictions, Contrasts Means. CRAN.","code":"@Article{,   title = {Estimation of Model-Based Predictions, Contrasts and Means.},   author = {Dominique Makowski and Mattan S. Ben-Shachar and Indrajeet Patil and Daniel L√ºdecke},   journal = {CRAN},   year = {2020},   url = {https://github.com/easystats/modelbased}, }"},{"path":"https://easystats.github.io/modelbased/index.html","id":"modelbased-","dir":"","previous_headings":"","what":"Estimation of Model-Based Predictions, Contrasts and Means","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Taking models new heights modelbased package helping model-based estimations, easily compute marginal means, contrast analysis model predictions.","code":""},{"path":"https://easystats.github.io/modelbased/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"modelbased package available CRAN, latest development version available R-universe (rOpenSci). downloaded package, can load using: Tip Instead library(datawizard), use library(easystats). make features easystats-ecosystem available. stay updated, use easystats::install_latest().","code":"library(\"modelbased\")"},{"path":"https://easystats.github.io/modelbased/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Access package documentation, check-vignettes: Visualisation matrix Marginal means Contrast analysis Marginal effects Use model make predictions Describe non-linear curves Interpret models using Effect Derivatives Estimate re-use random effects modelisation approach","code":""},{"path":"https://easystats.github.io/modelbased/index.html","id":"features","dir":"","previous_headings":"","what":"Features","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"package built around 5 main functions: estimate_means(): Estimates average values factor levels estimate_contrasts(): Estimates tests contrasts different factor levels estimate_slopes(): Estimates slopes numeric predictors different factor levels alongside numeric predictor estimate_expectation(): Predict response variable using model functions powered visualisation_matrix() function, smart tool guessing appropriate reference grid.","code":""},{"path":"https://easystats.github.io/modelbased/index.html","id":"create-smart-grids-to-represent-complex-interactions","dir":"","previous_headings":"","what":"Create smart grids to represent complex interactions","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Problem: want graphically represent interaction two continuous variable. top , like express one terms standardized change (.e., standard deviation relative mean). Solution: Create data grid following desired specifications, feed model obtain predictions. Format columns better readability, plot using ggplot. Check-vignette detailed walkthrough visualisation matrices.","code":"library(ggplot2) library(see) library(modelbased)  # 1. Fit model and get visualization matrix model <- lm(Sepal.Length ~ Petal.Length * Petal.Width, data = iris)  # 2. Create a visualisation matrix with expected Z-score values of Petal.Width vizdata <- modelbased::visualisation_matrix(model, at = c(\"Petal.Length\", \"Petal.Width = c(-1, 0, 1)\"))  # 3. Revert from expected SD to actual values vizdata <- unstandardize(vizdata, select = \"Petal.Width\")  # 4. Add predicted relationship from the model vizdata <- modelbased::estimate_expectation(vizdata)  # 5. Express Petal.Width as z-score (\"-1 SD\", \"+2 SD\", etc.) vizdata$Petal.Width <- effectsize::format_standardize(vizdata$Petal.Width, reference = iris$Petal.Width)  # 6. Plot ggplot(iris, aes(x = Petal.Length, y = Sepal.Length)) +   # Add points from original dataset (only shapes 21-25 have a fill aesthetic)   geom_point2(aes(fill = Petal.Width), shape = 21, size = 5) +   # Add relationship lines   geom_line(data = vizdata, aes(y = Predicted, color = Petal.Width), size = 1) +   # Improve colors / themes   scale_color_viridis_d(direction = -1) +   scale_fill_viridis_c(guide = \"none\") +   theme_modern()"},{"path":"https://easystats.github.io/modelbased/index.html","id":"estimate-marginal-means","dir":"","previous_headings":"","what":"Estimate marginal means","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Problem: model factor predictor, parameters return difference levels intercept. want see values factor level. Solution: Estimate model-based means (‚Äúmarginal means‚Äù). can visualize plotting confidence interval original data. Check-vignette detailed walkthrough marginal means.","code":"# 1. The model model <- lm(Sepal.Width ~ Species, data = iris)  # 2. Obtain estimated means means <- estimate_means(model) means ## Estimated Marginal Means ##  ## Species    | Mean |   SE |       95% CI ## --------------------------------------- ## setosa     | 3.43 | 0.05 | [3.33, 3.52] ## versicolor | 2.77 | 0.05 | [2.68, 2.86] ## virginica  | 2.97 | 0.05 | [2.88, 3.07] ##  ## Marginal means estimated at Species  # 3. Plot ggplot(iris, aes(x = Species, y = Sepal.Width)) +   # Add base data   geom_violin(aes(fill = Species), color = \"white\") +   geom_jitter2(width = 0.05, alpha = 0.5) +    # Add pointrange and line from means   geom_line(data = means, aes(y = Mean, group = 1), size = 1) +   geom_pointrange(     data = means,     aes(y = Mean, ymin = CI_low, ymax = CI_high),     size = 1,     color = \"white\"   ) +   # Improve colors   scale_fill_material() +   theme_modern()"},{"path":"https://easystats.github.io/modelbased/index.html","id":"contrast-analysis","dir":"","previous_headings":"","what":"Contrast analysis","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Problem: parameters model return difference factor levels intercept. want see differences levels, post-hoc comparison tests ANOVAs. Solution: Estimate model-based contrasts (‚Äúmarginal contrasts‚Äù). can visualize plotting confidence interval. Check-vignette detailed walkthrough contrast analysis.","code":"# 1. The model model <- lm(Sepal.Width ~ Species, data = iris)  # 2. Estimate marginal contrasts contrasts <- estimate_contrasts(model) contrasts ## Marginal Contrasts Analysis ##  ## Level1     |     Level2 | Difference |         95% CI |   SE | t(147) |      p ## ------------------------------------------------------------------------------ ## setosa     | versicolor |       0.66 | [ 0.49,  0.82] | 0.07 |   9.69 | < .001 ## setosa     |  virginica |       0.45 | [ 0.29,  0.62] | 0.07 |   6.68 | < .001 ## versicolor |  virginica |      -0.20 | [-0.37, -0.04] | 0.07 |  -3.00 | 0.003  ##  ## Marginal contrasts estimated at Species ## p-value adjustment method: Holm (1979)"},{"path":"https://easystats.github.io/modelbased/index.html","id":"check-the-contrasts-at-different-points-of-another-linear-predictor","dir":"","previous_headings":"","what":"Check the contrasts at different points of another linear predictor","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Problem: case interaction factor continuous variable, might interested computing differences factor levels (contrasts) change depending continuous variable. Solution: can estimate marginal contrasts different values continuous variable (modulator), plot differences (significant 95% CI doesn‚Äôt cover 0).","code":"model <- lm(Sepal.Width ~ Species * Petal.Length, data = iris)  estimate_contrasts(model, at = \"Petal.Length\", length = 3) ## Marginal Contrasts Analysis ##  ## Level1     |     Level2 | Petal.Length | Difference |        95% CI |   SE | t(144) |      p ## -------------------------------------------------------------------------------------------- ## setosa     | versicolor |         1.00 |       1.70 | [ 0.87, 2.53] | 0.34 |   4.97 | < .001 ## setosa     | versicolor |         3.95 |       1.74 | [ 0.16, 3.32] | 0.65 |   2.67 | 0.023  ## setosa     | versicolor |         6.90 |       1.78 | [-1.71, 5.26] | 1.44 |   1.24 | 0.304  ## setosa     |  virginica |         1.00 |       1.34 | [ 0.38, 2.30] | 0.40 |   3.38 | 0.002  ## setosa     |  virginica |         3.95 |       1.79 | [ 0.19, 3.40] | 0.66 |   2.70 | 0.023  ## setosa     |  virginica |         6.90 |       2.25 | [-1.19, 5.69] | 1.42 |   1.58 | 0.304  ## versicolor |  virginica |         1.00 |      -0.36 | [-1.55, 0.83] | 0.49 |  -0.73 | 0.468  ## versicolor |  virginica |         3.95 |       0.06 | [-0.30, 0.42] | 0.15 |   0.37 | 0.710  ## versicolor |  virginica |         6.90 |       0.47 | [-0.22, 1.16] | 0.28 |   1.65 | 0.304  ##  ## Marginal contrasts estimated at Species ## p-value adjustment method: Holm (1979) # Recompute contrasts with a higher precision (for a smoother plot) contrasts <- estimate_contrasts(model, at = \"Petal.Length\", length = 20)  # Add Contrast column by concatenating contrasts$Contrast <- paste(contrasts$Level1, \"-\", contrasts$Level2)  # Plot ggplot(contrasts, aes(x = Petal.Length, y = Difference, )) +   # Add line and CI band   geom_line(aes(color = Contrast)) +   geom_ribbon(aes(ymin = CI_low, ymax = CI_high, fill = Contrast), alpha = 0.2) +   # Add line at 0, indicating no difference   geom_hline(yintercept = 0, linetype = \"dashed\") +   # Colors   theme_modern()"},{"path":"https://easystats.github.io/modelbased/index.html","id":"generate-predictions-from-your-model-to-compare-it-with-original-data","dir":"","previous_headings":"","what":"Generate predictions from your model to compare it with original data","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Problem: fitted different models, want intuitively visualize compare terms fit quality prediction accuracy, don‚Äôt rely abstract indices performance. Solution: can predict response variable different models plot original true response. closest points identity line (diagonal), closest perfect fit. Check-vignette detailed walkthrough predictions.","code":"# Fit model 1 and predict the response variable model1 <- lm(Petal.Length ~ Sepal.Length, data = iris) pred1 <- estimate_expectation(model1) pred1$Petal.Length <- iris$Petal.Length # Add true response  # Print first 5 lines of output head(pred1, n = 5) ## Model-based Expectation ##  ## Sepal.Length | Predicted |   SE |       95% CI | Residuals | Petal.Length ## ------------------------------------------------------------------------- ## 5.10         |      2.38 | 0.10 | [2.19, 2.57] |     -0.98 |         1.40 ## 4.90         |      2.00 | 0.11 | [1.79, 2.22] |     -0.60 |         1.40 ## 4.70         |      1.63 | 0.12 | [1.39, 1.87] |     -0.33 |         1.30 ## 4.60         |      1.45 | 0.13 | [1.19, 1.70] |      0.05 |         1.50 ## 5.00         |      2.19 | 0.10 | [1.99, 2.39] |     -0.79 |         1.40 ##  ## Variable predicted: Petal.Length  # Same for model 2 model2 <- lm(Petal.Length ~ Sepal.Length * Species, data = iris) pred2 <- estimate_expectation(model2) pred2$Petal.Length <- iris$Petal.Length   # Initialize plot for model 1 ggplot(data = pred1, aes(x = Petal.Length, y = Predicted)) +   # with identity line (diagonal) representing perfect predictions   geom_abline(linetype = \"dashed\") +   # Add the actual predicted points of the models   geom_point(aes(color = \"Model 1\")) +   geom_point(data = pred2, aes(color = \"Model 2\")) +   # Aesthetics changes   labs(y = \"Petal.Length (predicted)\", color = NULL) +   scale_color_manual(values = c(\"Model 1\" = \"blue\", \"Model 2\" = \"red\")) +   theme_modern()"},{"path":"https://easystats.github.io/modelbased/index.html","id":"extract-and-format-group-level-random-effects","dir":"","previous_headings":"","what":"Extract and format group-level random effects","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Problem: mixed model like easily access random part, .e., group-level effects (e.g., individuals scores). Solution: can apply estimate_grouplevel mixed model. See vignette information.","code":"library(lme4)  model <- lmer(mpg ~ drat + (1 + drat | cyl), data = mtcars)  random <- estimate_grouplevel(model) random ## Group | Level |   Parameter | Coefficient |   SE |         95% CI ## ----------------------------------------------------------------- ## cyl   |     4 | (Intercept) |       -3.45 | 0.56 | [-4.55, -2.36] ## cyl   |     4 |        drat |        2.24 | 0.36 | [ 1.53,  2.95] ## cyl   |     6 | (Intercept) |        0.13 | 0.84 | [-1.52,  1.78] ## cyl   |     6 |        drat |       -0.09 | 0.54 | [-1.15,  0.98] ## cyl   |     8 | (Intercept) |        3.32 | 0.73 | [ 1.89,  4.74] ## cyl   |     8 |        drat |       -2.15 | 0.47 | [-3.07, -1.23]  plot(random)"},{"path":"https://easystats.github.io/modelbased/index.html","id":"estimate-derivative-of-non-linear-relationships-eg-in-gams","dir":"","previous_headings":"","what":"Estimate derivative of non-linear relationships (e.g., in GAMs)","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Problem: model non-linear relationship using polynomials, splines GAMs. want know parts curve significant positive negative trends. Solution: can estimate derivative smooth using estimate_slopes. two plots represent modeled (non-linear) effect estimated model, .e., relationship outcome predictor, well ‚Äútrend‚Äù (slope) relationship given point. can see whenever slope negative, effect 0, vice versa, regions effect significant (.e., positive negative enough confidence) others denote regions relationship rather flat. Check-vignette detailed walkthrough marginal effects.","code":"# Fit a non-linear General Additive Model (GAM) model <- mgcv::gam(Sepal.Width ~ s(Petal.Length), data = iris)  # 1. Compute derivatives deriv <- estimate_slopes(model,   trend = \"Petal.Length\",   at = \"Petal.Length\",   length = 100 )  # 2. Visualize predictions and derivative see::plots(   plot(estimate_relation(model)),   plot(deriv),   n_rows = 2 )"},{"path":"https://easystats.github.io/modelbased/index.html","id":"describe-the-smooth-term-by-its-linear-parts","dir":"","previous_headings":"","what":"Describe the smooth term by its linear parts","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Problem: model non-linear relationship using polynomials, splines GAMs. want describe terms linear parts: decrease, much, increase, etc. Solution: can apply describe_nonlinear predicted relationship return different parts increase decrease. See vignette information.","code":"model <- lm(Sepal.Width ~ poly(Petal.Length, 2), data = iris)  # 1. Visualize vizdata <- estimate_relation(model, length = 30)  ggplot(vizdata, aes(x = Petal.Length, y = Predicted)) +   geom_ribbon(aes(ymin = CI_low, ymax = CI_high), alpha = 0.3) +   geom_line() +   # Add original data points   geom_point(data = iris, aes(x = Petal.Length, y = Sepal.Width)) +   # Aesthetics   theme_modern() # 2. Describe smooth line describe_nonlinear(vizdata, x = \"Petal.Length\") ## Start |  End | Length | Change | Slope |   R2 ## --------------------------------------------- ## 1.00  | 4.05 |   0.50 |  -0.84 | -0.28 | 0.05 ## 4.05  | 6.90 |   0.47 |   0.66 |  0.23 | 0.05"},{"path":"https://easystats.github.io/modelbased/index.html","id":"plot-all-posterior-draws-for-bayesian-models-predictions","dir":"","previous_headings":"","what":"Plot all posterior draws for Bayesian models predictions","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"See vignette walkthrough .","code":""},{"path":"https://easystats.github.io/modelbased/index.html","id":"understand-interactions-between-two-continuous-variables","dir":"","previous_headings":"","what":"Understand interactions between two continuous variables","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Also referred Johnson-Neyman intervals, plot shows effect (‚Äúslope‚Äù) one variable varies depending another variable. useful case complex interactions continuous variables. instance, plot shows effect hp (y-axis) significantly negative wt low (< ~4).","code":"model <- lm(mpg ~ hp * wt, data = mtcars)  slopes <- estimate_slopes(model, trend = \"hp\", at = \"wt\")  plot(slopes)"},{"path":"https://easystats.github.io/modelbased/index.html","id":"visualize-predictions-with-random-effects","dir":"","previous_headings":"","what":"Visualize predictions with random effects","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Aside plotting coefficient random effect (done ), can also visualize predictions model levels, can useful diagnostic see contribute fixed effects. making predictions estimate_relation setting include_random TRUE. Let‚Äôs model reaction time number days sleep deprivation fixed effect participants random intercept.  can see, participant different ‚Äúintercept‚Äù (starting point y-axis), slopes : slope ‚Äúgeneral‚Äù one estimated across participants fixed effect. Let‚Äôs address allow slope vary participant .  can see, effect now different participants. Let‚Äôs plot, top , ‚Äúfixed‚Äù effect estimated across individual effects.","code":"library(lme4)  model <- lmer(Reaction ~ Days + (1 | Subject), data = sleepstudy)  preds <- estimate_relation(model, include_random = TRUE)  plot(preds, ribbon = list(alpha = 0)) # Make CI ribbon transparent for clarity model <- lmer(Reaction ~ Days + (1 + Days | Subject), data = sleepstudy)  preds <- estimate_relation(model, include_random = TRUE)  plot(preds, ribbon = list(alpha = 0.1)) fixed_pred <- estimate_relation(model) # This time, include_random is FALSE (default)  plot(preds, ribbon = list(alpha = 0)) + # Previous plot   geom_ribbon(data = fixed_pred, aes(x = Days, ymin = CI_low, ymax = CI_high), alpha = 0.4) +   geom_line(data = fixed_pred, aes(x = Days, y = Predicted), size = 2)"},{"path":"https://easystats.github.io/modelbased/index.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Please note modelbased project released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"https://easystats.github.io/modelbased/reference/describe_nonlinear.html","id":null,"dir":"Reference","previous_headings":"","what":"Describe the smooth term (for GAMs) or non-linear predictors ‚Äî describe_nonlinear","title":"Describe the smooth term (for GAMs) or non-linear predictors ‚Äî describe_nonlinear","text":"function summarises smooth term trend terms linear segments. Using approximative derivative, separates non-linear vector quasi-linear segments (trend either positive negative). segment characterized beginning, end, size (proportion, relative total size) trend (linear regression coefficient) linearity (R2 linear regression).","code":""},{"path":"https://easystats.github.io/modelbased/reference/describe_nonlinear.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Describe the smooth term (for GAMs) or non-linear predictors ‚Äî describe_nonlinear","text":"","code":"describe_nonlinear(data, ...)  # S3 method for data.frame describe_nonlinear(data, x = NULL, y = NULL, ...)  estimate_smooth(data, ...)"},{"path":"https://easystats.github.io/modelbased/reference/describe_nonlinear.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Describe the smooth term (for GAMs) or non-linear predictors ‚Äî describe_nonlinear","text":"data data containing link, instance obtained estimate_relation(). ... arguments passed . x, y name responses variable (y) predicting variable (x).","code":""},{"path":"https://easystats.github.io/modelbased/reference/describe_nonlinear.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Describe the smooth term (for GAMs) or non-linear predictors ‚Äî describe_nonlinear","text":"dataframe linear description non-linear terms.","code":""},{"path":"https://easystats.github.io/modelbased/reference/describe_nonlinear.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Describe the smooth term (for GAMs) or non-linear predictors ‚Äî describe_nonlinear","text":"","code":"library(modelbased)  # Create data data <- data.frame(x = rnorm(200)) data$y <- data$x^2 + rnorm(200, 0, 0.5)  model <- lm(y ~ poly(x, 2), data = data) link_data <- estimate_relation(model, length = 100) #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now.  describe_nonlinear(link_data, x = \"x\") #> Start |   End | Length | Change | Slope |   R2 #> ---------------------------------------------- #> -2.50 | -0.05 |   0.43 |  -6.19 | -2.52 | 0.18 #> -0.05 |  3.15 |   0.56 |  10.13 |  3.17 | 0.18"},{"path":"https://easystats.github.io/modelbased/reference/dot-uniroot.all.html","id":null,"dir":"Reference","previous_headings":"","what":"Copied from rootSolve package ‚Äî .uniroot.all","title":"Copied from rootSolve package ‚Äî .uniroot.all","text":"Copied rootSolve package","code":""},{"path":"https://easystats.github.io/modelbased/reference/dot-uniroot.all.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Copied from rootSolve package ‚Äî .uniroot.all","text":"","code":".uniroot.all(   f,   interval,   lower = min(interval),   upper = max(interval),   tol = .Machine$double.eps^0.2,   maxiter = 1000,   n = 100,   ... )"},{"path":"https://easystats.github.io/modelbased/reference/estimate_contrasts.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Marginal Contrasts ‚Äî estimate_contrasts","title":"Estimate Marginal Contrasts ‚Äî estimate_contrasts","text":"Run contrast analysis estimating differences level factor. See also related functions estimate_means() estimate_slopes().","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_contrasts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Marginal Contrasts ‚Äî estimate_contrasts","text":"","code":"estimate_contrasts(   model,   contrast = NULL,   at = NULL,   fixed = NULL,   transform = \"none\",   ci = 0.95,   p_adjust = \"holm\",   method = \"pairwise\",   adjust = NULL,   ... )"},{"path":"https://easystats.github.io/modelbased/reference/estimate_contrasts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Marginal Contrasts ‚Äî estimate_contrasts","text":"model statistical model. contrast character vector indicating name variable(s) compute contrasts. predictor variable(s) evaluate desired effect / mean / contrasts. predictors model included collapsed \"averaged\" (effect estimated across ). fixed character vector indicating names predictors \"fixed\" (.e., maintained), estimation made values. transform passed type argument emmeans::emmeans(). See vignette. Can \"none\" (default contrasts), \"response\" (default means), \"mu\", \"unlink\", \"log\". \"none\" leave values scale linear predictors. \"response\" transform scale response variable. Thus logistic model, \"none\" give estimations expressed log-odds (probabilities logit scale) \"response\" terms probabilities. ci Confidence Interval (CI) level. Default 0.95 (95%). p_adjust p-values adjustment method frequentist multiple comparisons. Can one \"holm\" (default), \"tukey\", \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"\", \"fdr\" \"none\". See p-value adjustment section emmeans::test documentation. method Contrast method. See argument emmeans::contrast. adjust Deprecated favour p_adjust. ... arguments passed instance insight::get_datagrid().","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_contrasts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Marginal Contrasts ‚Äî estimate_contrasts","text":"data frame estimated contrasts.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_contrasts.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate Marginal Contrasts ‚Äî estimate_contrasts","text":"See Details section , forget also check Vignettes README examples various examples, tutorials use cases. estimate_slopes(), estimate_means() estimate_contrasts() functions forming group, based marginal estimations (estimations based model). three also built emmeans package, reading documentation (instance emmeans::emmeans() emmeans::emtrends()) recommended understand idea behind types procedures. Model-based predictions basis follows. Indeed, first thing understand models can used make predictions (see estimate_link()). corresponds predicted response (\"outcome variable\") given specific predictor values predictors (.e., given specific data configuration). concept reference grid() important direct predictions. Marginal \"means\", obtained via estimate_means(), extension predictions, allowing \"average\" (collapse) predictors, obtain average response value specific predictors configuration. typically used predictors interest factors. Indeed, parameters model usually give intercept value \"effect\" factor level (different intercept). Marginal means can used directly give mean value response variable levels factor. Moreover, can also used control, average predictors, useful case multiple predictors without interactions. Marginal contrasts, obtained via estimate_contrasts(), extension marginal means, allow investigate difference (.e., contrast) marginal means. , , often used get pairwise differences levels factor. works also continuous predictors, instance one also interested whether difference two extremes continuous predictor significant. Finally, marginal effects, obtained via estimate_slopes(), different focus values response variable, model's parameters. idea assess effect predictor specific configuration predictors. relevant case interactions non-linear relationships, effect predictor variable changes depending predictors. Moreover, effects can also \"averaged\" predictors, get instance \"general trend\" predictor different factor levels. Example: imagine following model lm(y ~ condition * x) condition factor 3 levels , B C x continuous variable (like age example). One idea see model performs, compare actual response y one predicted model (using estimate_response()). Another idea evaluate average mean condition's levels (using estimate_means()), can useful visualize . Another possibility evaluate difference levels (using estimate_contrasts()). Finally, one also estimate effect x averaged conditions, instead within condition (using [estimate_slopes]).","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_contrasts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Marginal Contrasts ‚Äî estimate_contrasts","text":"","code":"# Basic usage model <- lm(Sepal.Width ~ Species, data = iris) estimate_contrasts(model) #> No variable was specified for contrast estimation. Selecting `contrast = \"Species\"`. #> Marginal Contrasts Analysis #>  #> Level1     |     Level2 | Difference |         95% CI |   SE | t(147) |      p #> ------------------------------------------------------------------------------ #> setosa     | versicolor |       0.66 | [ 0.49,  0.82] | 0.07 |   9.69 | < .001 #> setosa     |  virginica |       0.45 | [ 0.29,  0.62] | 0.07 |   6.68 | < .001 #> versicolor |  virginica |      -0.20 | [-0.37, -0.04] | 0.07 |  -3.00 | 0.003  #>  #> Marginal contrasts estimated at Species #> p-value adjustment method: Holm (1979)  # Dealing with interactions model <- lm(Sepal.Width ~ Species * Petal.Width, data = iris)  # By default: selects first factor estimate_contrasts(model) #> No variable was specified for contrast estimation. Selecting `contrast = \"Species\"`. #> NOTE: Results may be misleading due to involvement in interactions #> Marginal Contrasts Analysis #>  #> Level1     |     Level2 | Difference |        95% CI |   SE | t(144) |      p #> ----------------------------------------------------------------------------- #> setosa     | versicolor |       1.59 | [ 0.64, 2.54] | 0.39 |   4.04 | < .001 #> setosa     |  virginica |       1.77 | [ 0.77, 2.78] | 0.41 |   4.29 | < .001 #> versicolor |  virginica |       0.18 | [-0.17, 0.54] | 0.15 |   1.27 | 0.205  #>  #> Marginal contrasts estimated at Species #> p-value adjustment method: Holm (1979)  # Can also run contrasts between points of numeric estimate_contrasts(model, contrast = \"Petal.Width\", length = 4) #> NOTE: Results may be misleading due to involvement in interactions #> Marginal Contrasts Analysis #>  #> Level1         |         Level2 | Difference |         95% CI |   SE | t(144) |      p #> -------------------------------------------------------------------------------------- #> Petal.Width0.1 | Petal.Width0.9 |      -0.67 | [-1.02, -0.33] | 0.13 |  -5.18 | < .001 #> Petal.Width0.1 | Petal.Width1.7 |      -1.35 | [-2.04, -0.65] | 0.26 |  -5.18 | < .001 #> Petal.Width0.1 | Petal.Width2.5 |      -2.02 | [-3.06, -0.98] | 0.39 |  -5.18 | < .001 #> Petal.Width0.9 | Petal.Width1.7 |      -0.67 | [-1.02, -0.33] | 0.13 |  -5.18 | < .001 #> Petal.Width0.9 | Petal.Width2.5 |      -1.35 | [-2.04, -0.65] | 0.26 |  -5.18 | < .001 #> Petal.Width1.7 | Petal.Width2.5 |      -0.67 | [-1.02, -0.33] | 0.13 |  -5.18 | < .001 #>  #> Marginal contrasts estimated at Petal.Width #> p-value adjustment method: Holm (1979)  # Or both estimate_contrasts(model, contrast = c(\"Species\", \"Petal.Width\"), length = 2) #> Marginal Contrasts Analysis #>  #> Level1                    |                    Level2 | Difference |         95% CI |   SE | t(144) |      p #> ------------------------------------------------------------------------------------------------------------ #> setosa Petal.Width0.1     |     setosa Petal.Width2.5 |      -2.01 | [-4.92,  0.91] | 0.98 |  -2.06 | 0.166  #> setosa Petal.Width0.1     | versicolor Petal.Width0.1 |       1.83 | [ 0.99,  2.66] | 0.28 |   6.55 | < .001 #> setosa Petal.Width0.1     | versicolor Petal.Width2.5 |      -0.70 | [-1.50,  0.10] | 0.27 |  -2.61 | 0.059  #> setosa Petal.Width0.1     |  virginica Petal.Width0.1 |       1.55 | [ 0.62,  2.48] | 0.31 |   4.95 | < .001 #> setosa Petal.Width0.1     |  virginica Petal.Width2.5 |       0.03 | [-0.30,  0.37] | 0.11 |   0.29 | 0.984  #> setosa Petal.Width2.5     | versicolor Petal.Width2.5 |       1.31 | [-1.54,  4.16] | 0.95 |   1.37 | 0.517  #> setosa Petal.Width2.5     |  virginica Petal.Width2.5 |       2.04 | [-0.71,  4.79] | 0.92 |   2.21 | 0.142  #> versicolor Petal.Width0.1 |     setosa Petal.Width2.5 |      -3.84 | [-6.69, -0.98] | 0.96 |  -4.01 | < .001 #> versicolor Petal.Width0.1 | versicolor Petal.Width2.5 |      -2.53 | [-4.08, -0.98] | 0.52 |  -4.86 | < .001 #> versicolor Petal.Width0.1 |  virginica Petal.Width0.1 |      -0.28 | [-1.49,  0.93] | 0.41 |  -0.69 | 0.984  #> versicolor Petal.Width0.1 |  virginica Petal.Width2.5 |      -1.80 | [-2.64, -0.95] | 0.28 |  -6.35 | < .001 #> versicolor Petal.Width2.5 |  virginica Petal.Width2.5 |       0.73 | [-0.08,  1.55] | 0.27 |   2.70 | 0.055  #> virginica Petal.Width0.1  |     setosa Petal.Width2.5 |      -3.56 | [-6.44, -0.67] | 0.97 |  -3.68 | 0.003  #> virginica Petal.Width0.1  | versicolor Petal.Width2.5 |      -2.25 | [-3.44, -1.06] | 0.40 |  -5.64 | < .001 #> virginica Petal.Width0.1  |  virginica Petal.Width2.5 |      -1.52 | [-2.63, -0.40] | 0.37 |  -4.04 | < .001 #>  #> Marginal contrasts estimated at Species, Petal.Width #> p-value adjustment method: Holm (1979)  # Or with custom specifications estimate_contrasts(model, contrast = c(\"Species\", \"Petal.Width=c(1, 2)\")) #> Marginal Contrasts Analysis #>  #> Level1                  |                  Level2 | Difference |         95% CI |   SE | t(144) |      p #> -------------------------------------------------------------------------------------------------------- #> setosa Petal.Width1     |     setosa Petal.Width2 |      -0.84 | [-2.05,  0.38] | 0.41 |  -2.06 | 0.166  #> setosa Petal.Width1     | versicolor Petal.Width1 |       1.63 | [ 0.68,  2.59] | 0.32 |   5.09 | < .001 #> setosa Petal.Width1     | versicolor Petal.Width2 |       0.58 | [-0.45,  1.61] | 0.35 |   1.68 | 0.191  #> setosa Petal.Width1     |  virginica Petal.Width1 |       1.73 | [ 0.68,  2.78] | 0.35 |   4.93 | < .001 #> setosa Petal.Width1     |  virginica Petal.Width2 |       1.10 | [ 0.17,  2.04] | 0.31 |   3.52 | 0.005  #> setosa Petal.Width2     | versicolor Petal.Width2 |       1.42 | [-0.77,  3.60] | 0.73 |   1.94 | 0.166  #> setosa Petal.Width2     |  virginica Petal.Width2 |       1.94 | [-0.20,  4.08] | 0.72 |   2.71 | 0.038  #> versicolor Petal.Width1 |     setosa Petal.Width2 |      -2.47 | [-4.62, -0.32] | 0.72 |  -3.43 | 0.005  #> versicolor Petal.Width1 | versicolor Petal.Width2 |      -1.05 | [-1.70, -0.41] | 0.22 |  -4.86 | < .001 #> versicolor Petal.Width1 |  virginica Petal.Width1 |       0.10 | [-0.45,  0.65] | 0.19 |   0.54 | 0.589  #> versicolor Petal.Width1 |  virginica Petal.Width2 |      -0.53 | [-0.81, -0.25] | 0.09 |  -5.72 | < .001 #> versicolor Petal.Width2 |  virginica Petal.Width2 |       0.52 | [ 0.05,  0.99] | 0.16 |   3.31 | 0.007  #> virginica Petal.Width1  |     setosa Petal.Width2 |      -2.57 | [-4.76, -0.38] | 0.73 |  -3.50 | 0.005  #> virginica Petal.Width1  | versicolor Petal.Width2 |      -1.15 | [-1.83, -0.48] | 0.23 |  -5.13 | < .001 #> virginica Petal.Width1  |  virginica Petal.Width2 |      -0.63 | [-1.10, -0.17] | 0.16 |  -4.04 | < .001 #>  #> Marginal contrasts estimated at Species, Petal.Width #> p-value adjustment method: Holm (1979)  # Can fixate the numeric at a specific value estimate_contrasts(model, fixed = \"Petal.Width\") #> No variable was specified for contrast estimation. Selecting `contrast = \"Species\"`. #> Marginal Contrasts Analysis #>  #> Level1     |     Level2 | Petal.Width | Difference |        95% CI |   SE | t(144) |      p #> ------------------------------------------------------------------------------------------- #> setosa     | versicolor |        1.20 |       1.59 | [ 0.64, 2.54] | 0.39 |   4.04 | < .001 #> setosa     |  virginica |        1.20 |       1.77 | [ 0.77, 2.78] | 0.41 |   4.29 | < .001 #> versicolor |  virginica |        1.20 |       0.18 | [-0.17, 0.54] | 0.15 |   1.27 | 0.205  #>  #> Marginal contrasts estimated at Species #> p-value adjustment method: Holm (1979)  # Or modulate it estimate_contrasts(model, at = \"Petal.Width\", length = 4) #> No variable was specified for contrast estimation. Selecting `contrast = \"Species\"`. #> Marginal Contrasts Analysis #>  #> Level1     |     Level2 | Petal.Width | Difference |        95% CI |   SE | t(144) |      p #> ------------------------------------------------------------------------------------------- #> setosa     | versicolor |        0.10 |       1.83 | [ 1.15, 2.50] | 0.28 |   6.55 | < .001 #> setosa     | versicolor |        0.90 |       1.65 | [ 0.96, 2.35] | 0.29 |   5.74 | < .001 #> setosa     | versicolor |        1.70 |       1.48 | [ 0.03, 2.94] | 0.60 |   2.47 | 0.015  #> setosa     | versicolor |        2.50 |       1.31 | [-1.00, 3.62] | 0.95 |   1.37 | 0.172  #> setosa     |  virginica |        0.10 |       1.55 | [ 0.79, 2.30] | 0.31 |   4.95 | < .001 #> setosa     |  virginica |        0.90 |       1.71 | [ 0.93, 2.50] | 0.32 |   5.28 | < .001 #> setosa     |  virginica |        1.70 |       1.88 | [ 0.43, 3.32] | 0.60 |   3.14 | 0.004  #> setosa     |  virginica |        2.50 |       2.04 | [-0.19, 4.28] | 0.92 |   2.21 | 0.057  #> versicolor |  virginica |        0.10 |      -0.28 | [-1.26, 0.70] | 0.41 |  -0.69 | 0.492  #> versicolor |  virginica |        0.90 |       0.06 | [-0.44, 0.56] | 0.21 |   0.28 | 0.780  #> versicolor |  virginica |        1.70 |       0.40 | [ 0.12, 0.67] | 0.11 |   3.50 | 0.002  #> versicolor |  virginica |        2.50 |       0.73 | [ 0.08, 1.39] | 0.27 |   2.70 | 0.023  #>  #> Marginal contrasts estimated at Species #> p-value adjustment method: Holm (1979)  # Standardized differences estimated <- estimate_contrasts(lm(Sepal.Width ~ Species, data = iris)) #> No variable was specified for contrast estimation. Selecting `contrast = \"Species\"`. standardize(estimated) #> Marginal Contrasts Analysis (standardized) #>  #> Level1     |     Level2 | Difference |         95% CI |   SE | t(147) |      p #> ------------------------------------------------------------------------------ #> setosa     | versicolor |       1.51 | [ 1.13,  1.89] | 0.16 |   9.69 | < .001 #> setosa     |  virginica |       1.04 | [ 0.66,  1.42] | 0.16 |   6.68 | < .001 #> versicolor |  virginica |      -0.47 | [-0.85, -0.09] | 0.16 |  -3.00 | 0.003  #>  #> Marginal contrasts estimated at Species #> p-value adjustment method: Holm (1979) # Other models (mixed, Bayesian, ...) data <- iris data$Petal.Length_factor <- ifelse(data$Petal.Length < 4.2, \"A\", \"B\")  model <- lme4::lmer(Sepal.Width ~ Species + (1 | Petal.Length_factor), data = data) estimate_contrasts(model) #> No variable was specified for contrast estimation. Selecting `contrast = \"Species\"`. #> Cannot use mode = \"kenward-roger\" because *pbkrtest* package is not installed #> Cannot use mode = \"satterthwaite\" because *lmerTest* package is not installed #> Marginal Contrasts Analysis #>  #> Level1     |     Level2 | Difference |        95% CI |   SE |  df |     z |      p #> ---------------------------------------------------------------------------------- #> setosa     | versicolor |       0.87 | [ 0.66, 1.08] | 0.09 | Inf | 10.11 | < .001 #> setosa     |  virginica |       0.80 | [ 0.53, 1.07] | 0.11 | Inf |  7.11 | < .001 #> versicolor |  virginica |      -0.07 | [-0.25, 0.10] | 0.07 | Inf | -1.00 | 0.318  #>  #> Marginal contrasts estimated at Species #> p-value adjustment method: Holm (1979) library(rstanarm) #> Loading required package: Rcpp #> This is rstanarm version 2.21.3 #> - See https://mc-stan.org/rstanarm/articles/priors for changes to default priors! #> - Default priors may change, so it's safest to specify priors, even if equivalent to the defaults. #> - For execution on a local, multicore CPU with excess RAM we recommend calling #>   options(mc.cores = parallel::detectCores())  data <- mtcars data$cyl <- as.factor(data$cyl) data$am <- as.factor(data$am) # \\dontrun{ model <- stan_glm(mpg ~ cyl * am, data = data, refresh = 0) estimate_contrasts(model) #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> No variable was specified for contrast estimation. Selecting `contrast = \"cyl\"`. #> NOTE: Results may be misleading due to involvement in interactions #> Marginal Contrasts Analysis #>  #> Level1 | Level2 | Difference |        95% CI |     pd | % in ROPE #> ----------------------------------------------------------------- #> cyl4   |   cyl6 |       5.67 | [2.53,  8.96] |   100% |        0% #> cyl4   |   cyl8 |      10.27 | [6.95, 13.63] |   100% |        0% #> cyl6   |   cyl8 |       4.58 | [1.08,  7.84] | 99.48% |        0% #>  #> Marginal contrasts estimated at cyl estimate_contrasts(model, fixed = \"am\") #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> No variable was specified for contrast estimation. Selecting `contrast = \"cyl\"`. #> Marginal Contrasts Analysis #>  #> Level1 | Level2 | am | Difference |         95% CI |     pd | % in ROPE #> ----------------------------------------------------------------------- #> cyl4   |   cyl6 |  0 |       3.77 | [-1.00,  8.71] | 94.50% |     1.00% #> cyl4   |   cyl8 |  0 |       7.81 | [ 3.79, 11.91] |   100% |        0% #> cyl6   |   cyl8 |  0 |       4.08 | [ 0.30,  7.59] | 98.05% |        0% #>  #> Marginal contrasts estimated at cyl  model <- stan_glm(mpg ~ cyl * wt, data = data, refresh = 0) estimate_contrasts(model) #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> No variable was specified for contrast estimation. Selecting `contrast = \"cyl\"`. #> NOTE: Results may be misleading due to involvement in interactions #> Marginal Contrasts Analysis #>  #> Level1 | Level2 | Difference |        95% CI |     pd | % in ROPE #> ----------------------------------------------------------------- #> cyl4   |   cyl6 |       2.25 | [-1.30, 5.77] | 89.65% |     1.71% #> cyl4   |   cyl8 |       4.76 | [ 1.09, 8.38] | 99.55% |        0% #> cyl6   |   cyl8 |       2.52 | [-0.46, 5.16] | 95.28% |     1.42% #>  #> Marginal contrasts estimated at cyl estimate_contrasts(model, fixed = \"wt\") #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> No variable was specified for contrast estimation. Selecting `contrast = \"cyl\"`. #> Marginal Contrasts Analysis #>  #> Level1 | Level2 |   wt | Difference |        95% CI |     pd | % in ROPE #> ------------------------------------------------------------------------ #> cyl4   |   cyl6 | 3.22 |       2.25 | [-1.30, 5.77] | 89.65% |     1.71% #> cyl4   |   cyl8 | 3.22 |       4.76 | [ 1.09, 8.38] | 99.55% |        0% #> cyl6   |   cyl8 | 3.22 |       2.52 | [-0.46, 5.16] | 95.28% |     1.42% #>  #> Marginal contrasts estimated at cyl estimate_contrasts(model, at = \"wt\", length = 4) #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> No variable was specified for contrast estimation. Selecting `contrast = \"cyl\"`. #> Marginal Contrasts Analysis #>  #> Level1 | Level2 |   wt | Difference |          95% CI |     pd | % in ROPE #> -------------------------------------------------------------------------- #> cyl4   |   cyl6 | 1.51 |       6.01 | [ -3.50, 15.55] | 90.30% |     0.92% #> cyl4   |   cyl8 | 1.51 |       9.92 | [  4.55, 15.13] | 99.98% |        0% #> cyl6   |   cyl8 | 1.51 |       3.89 | [ -6.18, 13.71] | 78.10% |     1.32% #> cyl4   |   cyl6 | 2.82 |       3.16 | [ -0.13,  6.51] | 97.00% |     0.87% #> cyl4   |   cyl8 | 2.82 |       5.99 | [  2.61,  9.22] | 99.90% |        0% #> cyl6   |   cyl8 | 2.82 |       2.86 | [ -0.82,  6.32] | 93.88% |     1.16% #> cyl4   |   cyl6 | 4.12 |       0.29 | [ -7.45,  7.99] | 53.02% |     2.32% #> cyl4   |   cyl8 | 4.12 |       1.95 | [ -3.17,  7.64] | 78.12% |     2.08% #> cyl6   |   cyl8 | 4.12 |       1.75 | [ -4.27,  7.79] | 71.83% |     2.13% #> cyl4   |   cyl6 | 5.42 |      -2.59 | [-17.91, 12.66] | 64.00% |     1.11% #> cyl4   |   cyl8 | 5.42 |      -1.98 | [-10.72,  7.20] | 67.75% |     1.50% #> cyl6   |   cyl8 | 5.42 |       0.78 | [-12.07, 13.76] | 54.57% |     1.58% #>  #> Marginal contrasts estimated at cyl  model <- stan_glm(Sepal.Width ~ Species + Petal.Width + Petal.Length, data = iris, refresh = 0) estimate_contrasts(model, at = \"Petal.Length\", test = \"bf\") #> No variable was specified for contrast estimation. Selecting `contrast = \"Species\"`. #> Warning: Prior not specified! Please provide the original model to get meaningful results. #> Warning: Bayes factors might not be precise. #> For precise Bayes factors, sampling at least 40,000 posterior samples is recommended. #> Marginal Contrasts Analysis #>  #> Level1     |     Level2 | Petal.Length | Difference |       95% CI |   BF #> ------------------------------------------------------------------------- #> setosa     | versicolor |         1.00 |       1.72 | [1.37, 2.07] | 1.00 #> setosa     |  virginica |         1.00 |       2.14 | [1.61, 2.65] | 1.00 #> versicolor |  virginica |         1.00 |       0.41 | [0.21, 0.63] | 1.00 #> setosa     | versicolor |         1.66 |       1.72 | [1.37, 2.07] | 1.00 #> setosa     |  virginica |         1.66 |       2.14 | [1.61, 2.65] | 1.00 #> versicolor |  virginica |         1.66 |       0.41 | [0.21, 0.63] | 1.00 #> setosa     | versicolor |         2.31 |       1.72 | [1.37, 2.07] | 1.00 #> setosa     |  virginica |         2.31 |       2.14 | [1.61, 2.65] | 1.00 #> versicolor |  virginica |         2.31 |       0.41 | [0.21, 0.63] | 1.00 #> setosa     | versicolor |         2.97 |       1.72 | [1.37, 2.07] | 1.00 #> setosa     |  virginica |         2.97 |       2.14 | [1.61, 2.65] | 1.00 #> versicolor |  virginica |         2.97 |       0.41 | [0.21, 0.63] | 1.00 #> setosa     | versicolor |         3.62 |       1.72 | [1.37, 2.07] | 1.00 #> setosa     |  virginica |         3.62 |       2.14 | [1.61, 2.65] | 1.00 #> versicolor |  virginica |         3.62 |       0.41 | [0.21, 0.63] | 1.00 #> setosa     | versicolor |         4.28 |       1.72 | [1.37, 2.07] | 1.00 #> setosa     |  virginica |         4.28 |       2.14 | [1.61, 2.65] | 1.00 #> versicolor |  virginica |         4.28 |       0.41 | [0.21, 0.63] | 1.00 #> setosa     | versicolor |         4.93 |       1.72 | [1.37, 2.07] | 1.00 #> setosa     |  virginica |         4.93 |       2.14 | [1.61, 2.65] | 1.00 #> versicolor |  virginica |         4.93 |       0.41 | [0.21, 0.63] | 1.00 #> setosa     | versicolor |         5.59 |       1.72 | [1.37, 2.07] | 1.00 #> setosa     |  virginica |         5.59 |       2.14 | [1.61, 2.65] | 1.00 #> versicolor |  virginica |         5.59 |       0.41 | [0.21, 0.63] | 1.00 #> setosa     | versicolor |         6.24 |       1.72 | [1.37, 2.07] | 1.00 #> setosa     |  virginica |         6.24 |       2.14 | [1.61, 2.65] | 1.00 #> versicolor |  virginica |         6.24 |       0.41 | [0.21, 0.63] | 1.00 #> setosa     | versicolor |         6.90 |       1.72 | [1.37, 2.07] | 1.00 #> setosa     |  virginica |         6.90 |       2.14 | [1.61, 2.65] | 1.00 #> versicolor |  virginica |         6.90 |       0.41 | [0.21, 0.63] | 1.00 #>  #> Marginal contrasts estimated at Species # }"},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":null,"dir":"Reference","previous_headings":"","what":"Model-based response estimates and uncertainty ‚Äî estimate_expectation","title":"Model-based response estimates and uncertainty ‚Äî estimate_expectation","text":"fitting model, useful generate model-based estimates response variables different combinations predictor values. estimates can used make inferences relationships variables make predictions individual cases. Model-based response estimates uncertainty can generated conditional average response values (regression line expectation) predictions individual cases. See details.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model-based response estimates and uncertainty ‚Äî estimate_expectation","text":"","code":"estimate_expectation(   model,   data = NULL,   ci = 0.95,   keep_iterations = FALSE,   ... )  estimate_response(...)  estimate_link(model, data = \"grid\", ci = 0.95, keep_iterations = FALSE, ...)  estimate_prediction(   model,   data = NULL,   ci = 0.95,   keep_iterations = FALSE,   ... )  estimate_relation(   model,   data = \"grid\",   ci = 0.95,   keep_iterations = FALSE,   ... )"},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model-based response estimates and uncertainty ‚Äî estimate_expectation","text":"model statistical model. data data frame model's predictors estimate response. NULL, model's data used. \"grid\", model matrix obtained (insight::get_datagrid()). ci Confidence Interval (CI) level. Default 0.95 (95%). keep_iterations TRUE, keep iterations (draws) bootstrapped Bayesian models. added additional columns named iter_1, iter_2, .... can reshape long format running reshape_iterations(). ... can add additional control arguments insight::get_datagrid() (used data = \"grid\") insight::get_predicted().","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model-based response estimates and uncertainty ‚Äî estimate_expectation","text":"data frame predicted values uncertainty intervals, class \"estimate_predicted\". Methods visualisation_recipe() plot() available.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Model-based response estimates and uncertainty ‚Äî estimate_expectation","text":"functions built top insight::get_predicted() correspond different specifications parameters. may useful read documentation, particular description predict argument additional details difference expected vs. predicted values link vs. response scales. Additional control parameters can used control results insight::get_datagrid() (data = \"grid\") insight::get_predicted() (function used internally compute predictions). plotting, check examples visualisation_recipe(). Also check Vignettes README examples various examples, tutorials usecases.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":"expected-average-values","dir":"Reference","previous_headings":"","what":"Expected (average) values","title":"Model-based response estimates and uncertainty ‚Äî estimate_expectation","text":"important way various types response estimates differ terms quantity estimated meaning uncertainty intervals. major choices expected values uncertainty regression line predicted values uncertainty individual case predictions. Expected values refer fitted regression line - estimated average response value (.e., \"expectation\") individuals specific predictor values. example, linear model y = 2 + 3x + 4z + e, estimated average y individuals x = 1 z = 2 11. expected values, uncertainty intervals refer uncertainty estimated conditional average (might true regression line actually fall)? Uncertainty intervals expected values also called \"confidence intervals\". Expected values uncertainty intervals useful describing relationship variables describing precisely model estimated. generalized linear models, expected values reported one two scales: link scale refers scale fitted regression line, transformation link function. example, logistic regression (logit binomial) model, link scale gives expected log-odds. log-link Poisson model, link scale gives expected log-count. response scale refers original scale response variable (.e., without link function transformation). Expected values link scale back-transformed original response variable metric (e.g., expected probabilities binomial models, expected counts Poisson models).","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":"individual-case-predictions","dir":"Reference","previous_headings":"","what":"Individual case predictions","title":"Model-based response estimates and uncertainty ‚Äî estimate_expectation","text":"contrast expected values, predicted values refer predictions individual cases. Predicted values also called \"posterior predictions\" \"posterior predictive draws\". predicted values, uncertainty intervals refer uncertainty individual response values case (might single case actually fall)? Uncertainty intervals predicted values also called \"prediction intervals\" \"posterior predictive intervals\". Predicted values uncertainty intervals useful forecasting range values might observed new data, making decisions individual cases, checking model predictions reasonable (\"posterior predictive checks\"). Predicted values intervals always scale original response variable (link scale).","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":"functions-for-estimating-predicted-values-and-uncertainty","dir":"Reference","previous_headings":"","what":"Functions for estimating predicted values and uncertainty","title":"Model-based response estimates and uncertainty ‚Äî estimate_expectation","text":"modelbased provides 4 functions generating model-based response estimates uncertainty: estimate_expectation(): Generates expected values (conditional average) response scale. uncertainty interval confidence interval. default, values computed using data used fit model. estimate_link(): Generates expected values (conditional average) link scale. uncertainty interval confidence interval. default, values computed using reference grid spanning observed range predictor values (see visualisation_matrix()). estimate_prediction(): Generates predicted values (individual cases) response scale. uncertainty interval prediction interval. default, values computed using data used fit model. estimate_relation(): Like estimate_expectation(). Useful visualizing model. Generates expected values (conditional average) response scale. uncertainty interval confidence interval. default, values computed using reference grid spanning observed range predictor values (see visualisation_matrix()). estimate_response() deprecated alias estimate_expectation().","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":"data-for-predictions","dir":"Reference","previous_headings":"","what":"Data for predictions","title":"Model-based response estimates and uncertainty ‚Äî estimate_expectation","text":"data = NULL, values estimated using data used fit model. data = \"grid\", values computed using reference grid spanning observed range predictor values visualisation_matrix(). can useful model visualization. number predictor values used variable can controlled length argument. data can also data frame containing columns names matching model frame (see insight::get_data()). can used generate model predictions specific combinations predictor values.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model-based response estimates and uncertainty ‚Äî estimate_expectation","text":"","code":"library(modelbased)  # Linear Models model <- lm(mpg ~ wt, data = mtcars)  # Get predicted and prediction interval (see insight::get_predicted) estimate_response(model) #> `estimate_response()` is deprecated. #>   Please use `estimate_expectation()` (for conditional expected values) or #>   `estimate_prediction()` (for individual case predictions) instead. #> Model-based Expectation #>  #> wt   | Predicted |   SE |         95% CI | Residuals #> ---------------------------------------------------- #> 2.62 |     23.28 | 0.63 | [21.99, 24.58] |     -2.28 #> 2.88 |     21.92 | 0.57 | [20.75, 23.09] |     -0.92 #> 2.32 |     24.89 | 0.74 | [23.38, 26.39] |     -2.09 #> 3.21 |     20.10 | 0.54 | [19.00, 21.20] |      1.30 #> 3.44 |     18.90 | 0.55 | [17.77, 20.03] |     -0.20 #> 3.46 |     18.79 | 0.56 | [17.66, 19.93] |     -0.69 #> 3.57 |     18.21 | 0.57 | [17.03, 19.38] |     -3.91 #> 3.19 |     20.24 | 0.54 | [19.14, 21.34] |      4.16 #> 3.15 |     20.45 | 0.54 | [19.35, 21.55] |      2.35 #> 3.44 |     18.90 | 0.55 | [17.77, 20.03] |      0.30 #> 3.44 |     18.90 | 0.55 | [17.77, 20.03] |     -1.10 #> 4.07 |     15.53 | 0.72 | [14.06, 17.00] |      0.87 #> 3.73 |     17.35 | 0.61 | [16.10, 18.60] |     -0.05 #> 3.78 |     17.08 | 0.62 | [15.81, 18.36] |     -1.88 #> 5.25 |      9.23 | 1.26 | [ 6.66, 11.80] |      1.17 #> 5.42 |      8.30 | 1.35 | [ 5.55, 11.05] |      2.10 #> 5.34 |      8.72 | 1.31 | [ 6.05, 11.39] |      5.98 #> 2.20 |     25.53 | 0.78 | [23.93, 27.13] |      6.87 #> 1.61 |     28.65 | 1.05 | [26.52, 30.79] |      1.75 #> 1.83 |     27.48 | 0.94 | [25.55, 29.40] |      6.42 #> 2.46 |     24.11 | 0.68 | [22.72, 25.51] |     -2.61 #> 3.52 |     18.47 | 0.56 | [17.32, 19.63] |     -2.97 #> 3.44 |     18.93 | 0.55 | [17.80, 20.05] |     -3.73 #> 3.84 |     16.76 | 0.64 | [15.45, 18.07] |     -3.46 #> 3.85 |     16.74 | 0.64 | [15.42, 18.05] |      2.46 #> 1.94 |     26.94 | 0.90 | [25.11, 28.77] |      0.36 #> 2.14 |     25.85 | 0.81 | [24.20, 27.50] |      0.15 #> 1.51 |     29.20 | 1.09 | [26.96, 31.43] |      1.20 #> 3.17 |     20.34 | 0.54 | [19.24, 21.44] |     -4.54 #> 2.77 |     22.48 | 0.59 | [21.27, 23.69] |     -2.78 #> 3.57 |     18.21 | 0.57 | [17.03, 19.38] |     -3.21 #> 2.78 |     22.43 | 0.59 | [21.22, 23.64] |     -1.03 #>  #> Variable predicted: mpg #>   # Get expected values with confidence interval pred <- estimate_relation(model) pred #> Model-based Expectation #>  #> wt   | Predicted |   SE |         95% CI #> ---------------------------------------- #> 1.51 |     29.20 | 1.09 | [26.96, 31.43] #> 1.95 |     26.88 | 0.89 | [25.06, 28.70] #> 2.38 |     24.55 | 0.71 | [23.10, 26.01] #> 2.82 |     22.23 | 0.58 | [21.04, 23.42] #> 3.25 |     19.91 | 0.54 | [18.81, 21.01] #> 3.69 |     17.59 | 0.60 | [16.36, 18.81] #> 4.12 |     15.26 | 0.74 | [13.76, 16.77] #> 4.55 |     12.94 | 0.92 | [11.06, 14.82] #> 4.99 |     10.62 | 1.13 | [ 8.32, 12.92] #> 5.42 |      8.30 | 1.35 | [ 5.55, 11.05] #>  #> Variable predicted: mpg #> Predictors modulated: wt #>   # Visualisation (see visualisation_recipe()) if (require(\"see\")) {   plot(pred) } #> Loading required package: see   # Standardize predictions pred <- estimate_relation(lm(mpg ~ wt + am, data = mtcars)) z <- standardize(pred, include_response = FALSE) z #> Model-based Expectation (standardized) #>  #> wt    |    am | Predicted |   SE |         95% CI #> ------------------------------------------------- #> -1.74 | -0.81 |     29.22 | 1.91 | [25.31, 33.14] #> -1.30 | -0.81 |     26.90 | 1.60 | [23.62, 30.17] #> -0.85 | -0.81 |     24.57 | 1.30 | [21.90, 27.24] #> -0.41 | -0.81 |     22.24 | 1.03 | [20.13, 24.36] #> 0.03  | -0.81 |     19.92 | 0.82 | [18.24, 21.59] #> 0.48  | -0.81 |     17.59 | 0.71 | [16.13, 19.05] #> 0.92  | -0.81 |     15.27 | 0.76 | [13.71, 16.83] #> 1.37  | -0.81 |     12.94 | 0.94 | [11.01, 14.87] #> 1.81  | -0.81 |     10.61 | 1.20 | [ 8.17, 13.06] #> 2.26  | -0.81 |      8.29 | 1.49 | [ 5.25, 11.33] #> -1.74 | -0.59 |     29.22 | 1.78 | [25.58, 32.86] #> -1.30 | -0.59 |     26.89 | 1.46 | [23.90, 29.89] #> -0.85 | -0.59 |     24.57 | 1.17 | [22.19, 26.95] #> -0.41 | -0.59 |     22.24 | 0.90 | [20.40, 24.08] #> 0.03  | -0.59 |     19.92 | 0.70 | [18.48, 21.35] #> 0.48  | -0.59 |     17.59 | 0.64 | [16.28, 18.90] #> 0.92  | -0.59 |     15.26 | 0.75 | [13.73, 16.80] #> 1.37  | -0.59 |     12.94 | 0.98 | [10.94, 14.93] #> 1.81  | -0.59 |     10.61 | 1.26 | [ 8.04, 13.18] #> 2.26  | -0.59 |      8.29 | 1.56 | [ 5.09, 11.48] #> -1.74 | -0.37 |     29.22 | 1.65 | [25.85, 32.59] #> -1.30 | -0.37 |     26.89 | 1.33 | [24.17, 29.62] #> -0.85 | -0.37 |     24.57 | 1.04 | [22.45, 26.68] #> -0.41 | -0.37 |     22.24 | 0.78 | [20.65, 23.83] #> 0.03  | -0.37 |     19.91 | 0.61 | [18.67, 21.16] #> 0.48  | -0.37 |     17.59 | 0.61 | [16.34, 18.83] #> 0.92  | -0.37 |     15.26 | 0.78 | [13.67, 16.85] #> 1.37  | -0.37 |     12.93 | 1.04 | [10.81, 15.06] #> 1.81  | -0.37 |     10.61 | 1.33 | [ 7.88, 13.34] #> 2.26  | -0.37 |      8.28 | 1.65 | [ 4.91, 11.66] #> -1.74 | -0.15 |     29.21 | 1.53 | [26.10, 32.33] #> -1.30 | -0.15 |     26.89 | 1.21 | [24.41, 29.37] #> -0.85 | -0.15 |     24.56 | 0.92 | [22.68, 26.45] #> -0.41 | -0.15 |     22.24 | 0.68 | [20.85, 23.63] #> 0.03  | -0.15 |     19.91 | 0.56 | [18.77, 21.05] #> 0.48  | -0.15 |     17.58 | 0.63 | [16.30, 18.86] #> 0.92  | -0.15 |     15.26 | 0.84 | [13.54, 16.98] #> 1.37  | -0.15 |     12.93 | 1.12 | [10.64, 15.23] #> 1.81  | -0.15 |     10.61 | 1.43 | [ 7.68, 13.53] #> 2.26  | -0.15 |      8.28 | 1.75 | [ 4.70, 11.86] #> -1.74 |  0.08 |     29.21 | 1.41 | [26.32, 32.10] #> -1.30 |  0.08 |     26.89 | 1.11 | [24.62, 29.15] #> -0.85 |  0.08 |     24.56 | 0.83 | [22.87, 26.25] #> -0.41 |  0.08 |     22.23 | 0.61 | [20.98, 23.49] #> 0.03  |  0.08 |     19.91 | 0.55 | [18.78, 21.04] #> 0.48  |  0.08 |     17.58 | 0.69 | [16.18, 18.98] #> 0.92  |  0.08 |     15.26 | 0.93 | [13.35, 17.16] #> 1.37  |  0.08 |     12.93 | 1.23 | [10.42, 15.44] #> 1.81  |  0.08 |     10.60 | 1.54 | [ 7.46, 13.75] #> 2.26  |  0.08 |      8.28 | 1.86 | [ 4.47, 12.09] #> -1.74 |  0.30 |     29.21 | 1.31 | [26.52, 31.90] #> -1.30 |  0.30 |     26.88 | 1.02 | [24.80, 28.96] #> -0.85 |  0.30 |     24.56 | 0.76 | [23.01, 26.11] #> -0.41 |  0.30 |     22.23 | 0.59 | [21.02, 23.44] #> 0.03  |  0.30 |     19.91 | 0.60 | [18.67, 21.14] #> 0.48  |  0.30 |     17.58 | 0.78 | [15.98, 19.17] #> 0.92  |  0.30 |     15.25 | 1.04 | [13.12, 17.39] #> 1.37  |  0.30 |     12.93 | 1.34 | [10.18, 15.67] #> 1.81  |  0.30 |     10.60 | 1.66 | [ 7.21, 13.99] #> 2.26  |  0.30 |      8.27 | 1.98 | [ 4.22, 12.33] #> -1.74 |  0.52 |     29.21 | 1.23 | [26.69, 31.73] #> -1.30 |  0.52 |     26.88 | 0.95 | [24.93, 28.83] #> -0.85 |  0.52 |     24.55 | 0.73 | [23.07, 26.04] #> -0.41 |  0.52 |     22.23 | 0.62 | [20.96, 23.50] #> 0.03  |  0.52 |     19.90 | 0.69 | [18.49, 21.32] #> 0.48  |  0.52 |     17.58 | 0.90 | [15.74, 19.41] #> 0.92  |  0.52 |     15.25 | 1.17 | [12.86, 17.64] #> 1.37  |  0.52 |     12.92 | 1.47 | [ 9.92, 15.93] #> 1.81  |  0.52 |     10.60 | 1.79 | [ 6.94, 14.25] #> 2.26  |  0.52 |      8.27 | 2.11 | [ 3.95, 12.59] #> -1.74 |  0.74 |     29.20 | 1.17 | [26.81, 31.59] #> -1.30 |  0.74 |     26.88 | 0.91 | [25.01, 28.75] #> -0.85 |  0.74 |     24.55 | 0.73 | [23.05, 26.05] #> -0.41 |  0.74 |     22.23 | 0.69 | [20.81, 23.64] #> 0.03  |  0.74 |     19.90 | 0.81 | [18.25, 21.55] #> 0.48  |  0.74 |     17.57 | 1.03 | [15.47, 19.68] #> 0.92  |  0.74 |     15.25 | 1.30 | [12.58, 17.92] #> 1.37  |  0.74 |     12.92 | 1.61 | [ 9.64, 16.21] #> 1.81  |  0.74 |     10.60 | 1.92 | [ 6.67, 14.53] #> 2.26  |  0.74 |      8.27 | 2.24 | [ 3.68, 12.86] #> -1.74 |  0.97 |     29.20 | 1.13 | [26.89, 31.51] #> -1.30 |  0.97 |     26.88 | 0.91 | [25.02, 28.73] #> -0.85 |  0.97 |     24.55 | 0.78 | [22.95, 26.15] #> -0.41 |  0.97 |     22.22 | 0.79 | [20.60, 23.85] #> 0.03  |  0.97 |     19.90 | 0.94 | [17.97, 21.82] #> 0.48  |  0.97 |     17.57 | 1.17 | [15.17, 19.97] #> 0.92  |  0.97 |     15.25 | 1.45 | [12.28, 18.21] #> 1.37  |  0.97 |     12.92 | 1.75 | [ 9.34, 16.50] #> 1.81  |  0.97 |     10.59 | 2.06 | [ 6.38, 14.81] #> 2.26  |  0.97 |      8.27 | 2.38 | [ 3.39, 13.14] #> -1.74 |  1.19 |     29.20 | 1.11 | [26.92, 31.48] #> -1.30 |  1.19 |     26.87 | 0.93 | [24.96, 28.78] #> -0.85 |  1.19 |     24.55 | 0.86 | [22.79, 26.30] #> -0.41 |  1.19 |     22.22 | 0.92 | [20.35, 24.10] #> 0.03  |  1.19 |     19.89 | 1.08 | [17.68, 22.11] #> 0.48  |  1.19 |     17.57 | 1.32 | [14.86, 20.27] #> 0.92  |  1.19 |     15.24 | 1.60 | [11.97, 18.51] #> 1.37  |  1.19 |     12.92 | 1.90 | [ 9.04, 16.79] #> 1.81  |  1.19 |     10.59 | 2.21 | [ 6.08, 15.10] #> 2.26  |  1.19 |      8.26 | 2.53 | [ 3.10, 13.43] #>  #> Variable predicted: mpg #> Predictors modulated: wt, am #>  unstandardize(z, include_response = FALSE) #> Model-based Expectation (standardized) #>  #> wt   |   am | Predicted |   SE |         95% CI #> ----------------------------------------------- #> 1.51 | 0.00 |     29.22 | 1.91 | [25.31, 33.14] #> 1.95 | 0.00 |     26.90 | 1.60 | [23.62, 30.17] #> 2.38 | 0.00 |     24.57 | 1.30 | [21.90, 27.24] #> 2.82 | 0.00 |     22.24 | 1.03 | [20.13, 24.36] #> 3.25 | 0.00 |     19.92 | 0.82 | [18.24, 21.59] #> 3.69 | 0.00 |     17.59 | 0.71 | [16.13, 19.05] #> 4.12 | 0.00 |     15.27 | 0.76 | [13.71, 16.83] #> 4.55 | 0.00 |     12.94 | 0.94 | [11.01, 14.87] #> 4.99 | 0.00 |     10.61 | 1.20 | [ 8.17, 13.06] #> 5.42 | 0.00 |      8.29 | 1.49 | [ 5.25, 11.33] #> 1.51 | 0.11 |     29.22 | 1.78 | [25.58, 32.86] #> 1.95 | 0.11 |     26.89 | 1.46 | [23.90, 29.89] #> 2.38 | 0.11 |     24.57 | 1.17 | [22.19, 26.95] #> 2.82 | 0.11 |     22.24 | 0.90 | [20.40, 24.08] #> 3.25 | 0.11 |     19.92 | 0.70 | [18.48, 21.35] #> 3.69 | 0.11 |     17.59 | 0.64 | [16.28, 18.90] #> 4.12 | 0.11 |     15.26 | 0.75 | [13.73, 16.80] #> 4.55 | 0.11 |     12.94 | 0.98 | [10.94, 14.93] #> 4.99 | 0.11 |     10.61 | 1.26 | [ 8.04, 13.18] #> 5.42 | 0.11 |      8.29 | 1.56 | [ 5.09, 11.48] #> 1.51 | 0.22 |     29.22 | 1.65 | [25.85, 32.59] #> 1.95 | 0.22 |     26.89 | 1.33 | [24.17, 29.62] #> 2.38 | 0.22 |     24.57 | 1.04 | [22.45, 26.68] #> 2.82 | 0.22 |     22.24 | 0.78 | [20.65, 23.83] #> 3.25 | 0.22 |     19.91 | 0.61 | [18.67, 21.16] #> 3.69 | 0.22 |     17.59 | 0.61 | [16.34, 18.83] #> 4.12 | 0.22 |     15.26 | 0.78 | [13.67, 16.85] #> 4.55 | 0.22 |     12.93 | 1.04 | [10.81, 15.06] #> 4.99 | 0.22 |     10.61 | 1.33 | [ 7.88, 13.34] #> 5.42 | 0.22 |      8.28 | 1.65 | [ 4.91, 11.66] #> 1.51 | 0.33 |     29.21 | 1.53 | [26.10, 32.33] #> 1.95 | 0.33 |     26.89 | 1.21 | [24.41, 29.37] #> 2.38 | 0.33 |     24.56 | 0.92 | [22.68, 26.45] #> 2.82 | 0.33 |     22.24 | 0.68 | [20.85, 23.63] #> 3.25 | 0.33 |     19.91 | 0.56 | [18.77, 21.05] #> 3.69 | 0.33 |     17.58 | 0.63 | [16.30, 18.86] #> 4.12 | 0.33 |     15.26 | 0.84 | [13.54, 16.98] #> 4.55 | 0.33 |     12.93 | 1.12 | [10.64, 15.23] #> 4.99 | 0.33 |     10.61 | 1.43 | [ 7.68, 13.53] #> 5.42 | 0.33 |      8.28 | 1.75 | [ 4.70, 11.86] #> 1.51 | 0.44 |     29.21 | 1.41 | [26.32, 32.10] #> 1.95 | 0.44 |     26.89 | 1.11 | [24.62, 29.15] #> 2.38 | 0.44 |     24.56 | 0.83 | [22.87, 26.25] #> 2.82 | 0.44 |     22.23 | 0.61 | [20.98, 23.49] #> 3.25 | 0.44 |     19.91 | 0.55 | [18.78, 21.04] #> 3.69 | 0.44 |     17.58 | 0.69 | [16.18, 18.98] #> 4.12 | 0.44 |     15.26 | 0.93 | [13.35, 17.16] #> 4.55 | 0.44 |     12.93 | 1.23 | [10.42, 15.44] #> 4.99 | 0.44 |     10.60 | 1.54 | [ 7.46, 13.75] #> 5.42 | 0.44 |      8.28 | 1.86 | [ 4.47, 12.09] #> 1.51 | 0.56 |     29.21 | 1.31 | [26.52, 31.90] #> 1.95 | 0.56 |     26.88 | 1.02 | [24.80, 28.96] #> 2.38 | 0.56 |     24.56 | 0.76 | [23.01, 26.11] #> 2.82 | 0.56 |     22.23 | 0.59 | [21.02, 23.44] #> 3.25 | 0.56 |     19.91 | 0.60 | [18.67, 21.14] #> 3.69 | 0.56 |     17.58 | 0.78 | [15.98, 19.17] #> 4.12 | 0.56 |     15.25 | 1.04 | [13.12, 17.39] #> 4.55 | 0.56 |     12.93 | 1.34 | [10.18, 15.67] #> 4.99 | 0.56 |     10.60 | 1.66 | [ 7.21, 13.99] #> 5.42 | 0.56 |      8.27 | 1.98 | [ 4.22, 12.33] #> 1.51 | 0.67 |     29.21 | 1.23 | [26.69, 31.73] #> 1.95 | 0.67 |     26.88 | 0.95 | [24.93, 28.83] #> 2.38 | 0.67 |     24.55 | 0.73 | [23.07, 26.04] #> 2.82 | 0.67 |     22.23 | 0.62 | [20.96, 23.50] #> 3.25 | 0.67 |     19.90 | 0.69 | [18.49, 21.32] #> 3.69 | 0.67 |     17.58 | 0.90 | [15.74, 19.41] #> 4.12 | 0.67 |     15.25 | 1.17 | [12.86, 17.64] #> 4.55 | 0.67 |     12.92 | 1.47 | [ 9.92, 15.93] #> 4.99 | 0.67 |     10.60 | 1.79 | [ 6.94, 14.25] #> 5.42 | 0.67 |      8.27 | 2.11 | [ 3.95, 12.59] #> 1.51 | 0.78 |     29.20 | 1.17 | [26.81, 31.59] #> 1.95 | 0.78 |     26.88 | 0.91 | [25.01, 28.75] #> 2.38 | 0.78 |     24.55 | 0.73 | [23.05, 26.05] #> 2.82 | 0.78 |     22.23 | 0.69 | [20.81, 23.64] #> 3.25 | 0.78 |     19.90 | 0.81 | [18.25, 21.55] #> 3.69 | 0.78 |     17.57 | 1.03 | [15.47, 19.68] #> 4.12 | 0.78 |     15.25 | 1.30 | [12.58, 17.92] #> 4.55 | 0.78 |     12.92 | 1.61 | [ 9.64, 16.21] #> 4.99 | 0.78 |     10.60 | 1.92 | [ 6.67, 14.53] #> 5.42 | 0.78 |      8.27 | 2.24 | [ 3.68, 12.86] #> 1.51 | 0.89 |     29.20 | 1.13 | [26.89, 31.51] #> 1.95 | 0.89 |     26.88 | 0.91 | [25.02, 28.73] #> 2.38 | 0.89 |     24.55 | 0.78 | [22.95, 26.15] #> 2.82 | 0.89 |     22.22 | 0.79 | [20.60, 23.85] #> 3.25 | 0.89 |     19.90 | 0.94 | [17.97, 21.82] #> 3.69 | 0.89 |     17.57 | 1.17 | [15.17, 19.97] #> 4.12 | 0.89 |     15.25 | 1.45 | [12.28, 18.21] #> 4.55 | 0.89 |     12.92 | 1.75 | [ 9.34, 16.50] #> 4.99 | 0.89 |     10.59 | 2.06 | [ 6.38, 14.81] #> 5.42 | 0.89 |      8.27 | 2.38 | [ 3.39, 13.14] #> 1.51 | 1.00 |     29.20 | 1.11 | [26.92, 31.48] #> 1.95 | 1.00 |     26.87 | 0.93 | [24.96, 28.78] #> 2.38 | 1.00 |     24.55 | 0.86 | [22.79, 26.30] #> 2.82 | 1.00 |     22.22 | 0.92 | [20.35, 24.10] #> 3.25 | 1.00 |     19.89 | 1.08 | [17.68, 22.11] #> 3.69 | 1.00 |     17.57 | 1.32 | [14.86, 20.27] #> 4.12 | 1.00 |     15.24 | 1.60 | [11.97, 18.51] #> 4.55 | 1.00 |     12.92 | 1.90 | [ 9.04, 16.79] #> 4.99 | 1.00 |     10.59 | 2.21 | [ 6.08, 15.10] #> 5.42 | 1.00 |      8.26 | 2.53 | [ 3.10, 13.43] #>  #> Variable predicted: mpg #> Predictors modulated: wt, am #>   # Logistic Models model <- glm(vs ~ wt, data = mtcars, family = \"binomial\") estimate_response(model) #> `estimate_response()` is deprecated. #>   Please use `estimate_expectation()` (for conditional expected values) or #>   `estimate_prediction()` (for individual case predictions) instead. #> Model-based Expectation #>  #> wt   | Predicted |   SE |       95% CI | Residuals #> -------------------------------------------------- #> 2.62 |      0.67 | 0.12 | [0.40, 0.86] |     -0.67 #> 2.88 |      0.56 | 0.12 | [0.33, 0.76] |     -0.56 #> 2.32 |      0.78 | 0.12 | [0.47, 0.94] |      0.22 #> 3.21 |      0.39 | 0.11 | [0.21, 0.61] |      0.61 #> 3.44 |      0.30 | 0.11 | [0.14, 0.53] |     -0.30 #> 3.46 |      0.29 | 0.10 | [0.13, 0.53] |      0.71 #> 3.57 |      0.25 | 0.10 | [0.10, 0.50] |     -0.25 #> 3.19 |      0.41 | 0.11 | [0.22, 0.62] |      0.59 #> 3.15 |      0.42 | 0.11 | [0.24, 0.64] |      0.58 #> 3.44 |      0.30 | 0.11 | [0.14, 0.53] |      0.70 #> 3.44 |      0.30 | 0.11 | [0.14, 0.53] |      0.70 #> 4.07 |      0.11 | 0.08 | [0.02, 0.39] |     -0.11 #> 3.73 |      0.20 | 0.10 | [0.07, 0.46] |     -0.20 #> 3.78 |      0.18 | 0.10 | [0.06, 0.45] |     -0.18 #> 5.25 |      0.01 | 0.02 | [0.00, 0.24] |     -0.01 #> 5.42 |  9.49e-03 | 0.02 | [0.00, 0.23] | -9.49e-03 #> 5.34 |      0.01 | 0.02 | [0.00, 0.23] |     -0.01 #> 2.20 |      0.82 | 0.12 | [0.49, 0.96] |      0.18 #> 1.61 |      0.93 | 0.07 | [0.58, 0.99] |      0.07 #> 1.83 |      0.90 | 0.09 | [0.55, 0.99] |      0.10 #> 2.46 |      0.73 | 0.13 | [0.44, 0.91] |      0.27 #> 3.52 |      0.27 | 0.10 | [0.11, 0.51] |     -0.27 #> 3.44 |      0.30 | 0.11 | [0.14, 0.53] |     -0.30 #> 3.84 |      0.16 | 0.10 | [0.05, 0.43] |     -0.16 #> 3.85 |      0.16 | 0.10 | [0.05, 0.43] |     -0.16 #> 1.94 |      0.88 | 0.10 | [0.54, 0.98] |      0.12 #> 2.14 |      0.84 | 0.11 | [0.50, 0.96] |     -0.84 #> 1.51 |      0.94 | 0.07 | [0.60, 0.99] |      0.06 #> 3.17 |      0.42 | 0.11 | [0.23, 0.63] |     -0.42 #> 2.77 |      0.60 | 0.12 | [0.36, 0.80] |     -0.60 #> 3.57 |      0.25 | 0.10 | [0.10, 0.50] |     -0.25 #> 2.78 |      0.60 | 0.12 | [0.36, 0.80] |      0.40 #>  #> Variable predicted: vs #>  estimate_relation(model) #> Model-based Expectation #>  #> wt   | Predicted |   SE |       95% CI #> -------------------------------------- #> 1.51 |      0.94 | 0.07 | [0.60, 0.99] #> 1.95 |      0.88 | 0.10 | [0.53, 0.98] #> 2.38 |      0.76 | 0.12 | [0.46, 0.92] #> 2.82 |      0.58 | 0.12 | [0.35, 0.78] #> 3.25 |      0.38 | 0.11 | [0.20, 0.60] #> 3.69 |      0.21 | 0.10 | [0.07, 0.47] #> 4.12 |      0.10 | 0.08 | [0.02, 0.38] #> 4.55 |      0.05 | 0.05 | [0.01, 0.32] #> 4.99 |      0.02 | 0.03 | [0.00, 0.27] #> 5.42 |  9.49e-03 | 0.02 | [0.00, 0.23] #>  #> Variable predicted: vs #> Predictors modulated: wt #>   # Mixed models if (require(\"lme4\")) {   model <- lmer(mpg ~ wt + (1 | gear), data = mtcars)   estimate_response(model)   estimate_relation(model) } #> Loading required package: lme4 #> Loading required package: Matrix #> `estimate_response()` is deprecated. #>   Please use `estimate_expectation()` (for conditional expected values) or #>   `estimate_prediction()` (for individual case predictions) instead. #> Model-based Expectation #>  #> wt   | gear | Predicted |   SE |         95% CI #> ----------------------------------------------- #> 1.51 | 0.00 |     28.56 | 1.37 | [25.75, 31.37] #> 1.95 | 0.00 |     26.36 | 1.18 | [23.95, 28.78] #> 2.38 | 0.00 |     24.17 | 1.03 | [22.07, 26.27] #> 2.82 | 0.00 |     21.98 | 0.93 | [20.07, 23.89] #> 3.25 | 0.00 |     19.79 | 0.92 | [17.91, 21.67] #> 3.69 | 0.00 |     17.60 | 0.98 | [15.58, 19.61] #> 4.12 | 0.00 |     15.40 | 1.12 | [13.11, 17.69] #> 4.55 | 0.00 |     13.21 | 1.30 | [10.55, 15.87] #> 4.99 | 0.00 |     11.02 | 1.51 | [ 7.93, 14.11] #> 5.42 | 0.00 |      8.83 | 1.74 | [ 5.27, 12.39] #>  #> Variable predicted: mpg #> Predictors modulated: wt #>   # Bayesian models # \\donttest{ if (require(\"rstanarm\")) {   model <- rstanarm::stan_glm(mpg ~ wt, data = mtcars, refresh = 0, iter = 200)   estimate_response(model)   estimate_relation(model) } #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess #> `estimate_response()` is deprecated. #>   Please use `estimate_expectation()` (for conditional expected values) or #>   `estimate_prediction()` (for individual case predictions) instead. #> Model-based Expectation #>  #> wt   | Predicted |   SE |         95% CI #> ---------------------------------------- #> 1.51 |     29.12 | 1.06 | [27.12, 31.22] #> 1.95 |     26.81 | 0.86 | [25.23, 28.51] #> 2.38 |     24.51 | 0.68 | [23.26, 25.85] #> 2.82 |     22.20 | 0.55 | [21.10, 23.29] #> 3.25 |     19.90 | 0.50 | [18.87, 20.89] #> 3.69 |     17.59 | 0.56 | [16.50, 18.70] #> 4.12 |     15.29 | 0.70 | [13.92, 16.64] #> 4.55 |     12.99 | 0.88 | [11.30, 14.65] #> 4.99 |     10.68 | 1.09 | [ 8.62, 12.75] #> 5.42 |      8.38 | 1.30 | [ 5.94, 10.90] #>  #> Variable predicted: mpg #> Predictors modulated: wt #>  # }"},{"path":"https://easystats.github.io/modelbased/reference/estimate_grouplevel.html","id":null,"dir":"Reference","previous_headings":"","what":"Group-specific parameters of mixed models random effects ‚Äî estimate_grouplevel","title":"Group-specific parameters of mixed models random effects ‚Äî estimate_grouplevel","text":"Extract random parameters individual group context mixed models. Can reshaped dimensions original data, can useful add random effects original data.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_grouplevel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Group-specific parameters of mixed models random effects ‚Äî estimate_grouplevel","text":"","code":"estimate_grouplevel(model, type = \"random\", ...)  reshape_grouplevel(x, indices = \"all\", group = \"all\", ...)"},{"path":"https://easystats.github.io/modelbased/reference/estimate_grouplevel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group-specific parameters of mixed models random effects ‚Äî estimate_grouplevel","text":"model mixed model random effects. type \"random\" (default), coefficients ones estimated natively model (returned , instance, lme4::ranef()). correspond deviation individual group fixed effect. , coefficient close 0 means participants' effect population-level effect (words, \"norm\"). \"total\", return sum random effect corresponding fixed effects. known BLUPs (Best Linear Unbiased Predictions). argument can used reproduce results given lme4::ranef() coef() (see ?coef.merMod). Note BLUPs currently uncertainty indices (SE CI), computable. ... arguments passed methods. x output estimate_grouplevel(). indices list containing indices extract (e.g., \"Coefficient\"). group list containing random factors select.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_grouplevel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Group-specific parameters of mixed models random effects ‚Äî estimate_grouplevel","text":"","code":"# lme4 model if (require(\"lme4\") && require(\"see\")) {   model <- lmer(mpg ~ hp + (1 | carb), data = mtcars)   random <- estimate_grouplevel(model)   random    # Visualize random effects   plot(random)    # Show group-specific effects   estimate_grouplevel(model, deviation = FALSE)    # Reshape to wide data so that it matches the original dataframe...   reshaped <- reshape_grouplevel(random, indices = c(\"Coefficient\", \"SE\"))    # ... and can be easily combined   alldata <- cbind(mtcars, reshaped)    # Use summary() to remove duplicated rows   summary(reshaped)    # Compute BLUPs   estimate_grouplevel(model, type = \"total\") } #> Group | Level |   Parameter | Coefficient #> ----------------------------------------- #> carb  |     1 | (Intercept) |       30.18 #> carb  |     2 | (Intercept) |       29.88 #> carb  |     3 | (Intercept) |       29.45 #> carb  |     4 | (Intercept) |       28.99 #> carb  |     6 | (Intercept) |       29.87 #> carb  |     8 | (Intercept) |       30.27  # Bayesian models # \\donttest{ if (require(\"rstanarm\")) {   model <- rstanarm::stan_lmer(mpg ~ hp + (1 | carb) + (1 | gear), data = mtcars, refresh = 0)   # Broken estimate_grouplevel(model) } #> Warning: There were 3 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems # }"},{"path":"https://easystats.github.io/modelbased/reference/estimate_means.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Marginal Means (Model-based average at each factor level) ‚Äî estimate_means","title":"Estimate Marginal Means (Model-based average at each factor level) ‚Äî estimate_means","text":"Estimate average value response variable factor levels. plotting, check examples visualisation_recipe(). See also related functions estimate_contrasts() estimate_slopes().","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_means.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Marginal Means (Model-based average at each factor level) ‚Äî estimate_means","text":"","code":"estimate_means(   model,   at = \"auto\",   fixed = NULL,   transform = \"response\",   ci = 0.95,   backend = \"emmeans\",   ... )"},{"path":"https://easystats.github.io/modelbased/reference/estimate_means.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Marginal Means (Model-based average at each factor level) ‚Äî estimate_means","text":"model statistical model. predictor variable(s) evaluate desired effect / mean / contrasts. predictors model included collapsed \"averaged\" (effect estimated across ). fixed character vector indicating names predictors \"fixed\" (.e., maintained), estimation made values. transform passed type argument emmeans::emmeans(). See vignette. Can \"none\" (default contrasts), \"response\" (default means), \"mu\", \"unlink\", \"log\". \"none\" leave values scale linear predictors. \"response\" transform scale response variable. Thus logistic model, \"none\" give estimations expressed log-odds (probabilities logit scale) \"response\" terms probabilities. ci Confidence Interval (CI) level. Default 0.95 (95%). backend Whether use 'emmeans' 'marginaleffects' backend. latter experimental features might work. ... arguments passed instance insight::get_datagrid().","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_means.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Marginal Means (Model-based average at each factor level) ‚Äî estimate_means","text":"data frame estimated marginal means.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_means.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate Marginal Means (Model-based average at each factor level) ‚Äî estimate_means","text":"See Details section , forget also check Vignettes README examples various examples, tutorials use cases. estimate_slopes(), estimate_means() estimate_contrasts() functions forming group, based marginal estimations (estimations based model). three also built emmeans package, reading documentation (instance emmeans::emmeans() emmeans::emtrends()) recommended understand idea behind types procedures. Model-based predictions basis follows. Indeed, first thing understand models can used make predictions (see estimate_link()). corresponds predicted response (\"outcome variable\") given specific predictor values predictors (.e., given specific data configuration). concept reference grid() important direct predictions. Marginal \"means\", obtained via estimate_means(), extension predictions, allowing \"average\" (collapse) predictors, obtain average response value specific predictors configuration. typically used predictors interest factors. Indeed, parameters model usually give intercept value \"effect\" factor level (different intercept). Marginal means can used directly give mean value response variable levels factor. Moreover, can also used control, average predictors, useful case multiple predictors without interactions. Marginal contrasts, obtained via estimate_contrasts(), extension marginal means, allow investigate difference (.e., contrast) marginal means. , , often used get pairwise differences levels factor. works also continuous predictors, instance one also interested whether difference two extremes continuous predictor significant. Finally, marginal effects, obtained via estimate_slopes(), different focus values response variable, model's parameters. idea assess effect predictor specific configuration predictors. relevant case interactions non-linear relationships, effect predictor variable changes depending predictors. Moreover, effects can also \"averaged\" predictors, get instance \"general trend\" predictor different factor levels. Example: imagine following model lm(y ~ condition * x) condition factor 3 levels , B C x continuous variable (like age example). One idea see model performs, compare actual response y one predicted model (using estimate_response()). Another idea evaluate average mean condition's levels (using estimate_means()), can useful visualize . Another possibility evaluate difference levels (using estimate_contrasts()). Finally, one also estimate effect x averaged conditions, instead within condition (using [estimate_slopes]).","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_means.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Marginal Means (Model-based average at each factor level) ‚Äî estimate_means","text":"","code":"library(modelbased)  # Frequentist models # ------------------- model <- lm(Petal.Length ~ Sepal.Width * Species, data = iris)  estimate_means(model) #> We selected `at = c(\"Species\")`. #> NOTE: Results may be misleading due to involvement in interactions #> Estimated Marginal Means #>  #> Species    | Mean |   SE |       95% CI #> --------------------------------------- #> setosa     | 1.43 | 0.08 | [1.28, 1.58] #> versicolor | 4.50 | 0.07 | [4.35, 4.65] #> virginica  | 5.61 | 0.06 | [5.50, 5.72] #>  #> Marginal means estimated at Species estimate_means(model, fixed = \"Sepal.Width\") #> We selected `at = c(\"Species\")`. #> Estimated Marginal Means #>  #> Species    | Sepal.Width | Mean |   SE |       95% CI #> ----------------------------------------------------- #> setosa     |        3.06 | 1.43 | 0.08 | [1.28, 1.58] #> versicolor |        3.06 | 4.50 | 0.07 | [4.35, 4.65] #> virginica  |        3.06 | 5.61 | 0.06 | [5.50, 5.72] #>  #> Marginal means estimated at Species estimate_means(model, at = c(\"Species\", \"Sepal.Width\"), length = 2) #> Estimated Marginal Means #>  #> Species    | Sepal.Width | Mean |   SE |       95% CI #> ----------------------------------------------------- #> setosa     |        2.00 | 1.35 | 0.21 | [0.92, 1.77] #> versicolor |        2.00 | 3.61 | 0.15 | [3.33, 3.90] #> virginica  |        2.00 | 4.88 | 0.17 | [4.54, 5.23] #> setosa     |        4.40 | 1.54 | 0.15 | [1.24, 1.84] #> versicolor |        4.40 | 5.63 | 0.29 | [5.05, 6.20] #> virginica  |        4.40 | 6.53 | 0.25 | [6.04, 7.02] #>  #> Marginal means estimated at Species, Sepal.Width estimate_means(model, at = \"Species=c('versicolor', 'setosa')\") #> NOTE: Results may be misleading due to involvement in interactions #> Estimated Marginal Means #>  #> Species    | Mean |   SE |       95% CI #> --------------------------------------- #> versicolor | 4.50 | 0.07 | [4.35, 4.65] #> setosa     | 1.43 | 0.08 | [1.28, 1.58] #>  #> Marginal means estimated at Species estimate_means(model, at = \"Sepal.Width=c(2, 4)\") #> NOTE: Results may be misleading due to involvement in interactions #> Estimated Marginal Means #>  #> Sepal.Width | Mean |   SE |       95% CI #> ---------------------------------------- #> 2.00        | 3.28 | 0.10 | [3.07, 3.49] #> 4.00        | 4.35 | 0.10 | [4.15, 4.55] #>  #> Marginal means estimated at Sepal.Width estimate_means(model, at = c(\"Species\", \"Sepal.Width=0\")) #> Estimated Marginal Means #>  #> Species    | Sepal.Width | Mean |   SE |       95% CI #> ----------------------------------------------------- #> setosa     |        0.00 | 1.18 | 0.50 | [0.19, 2.17] #> versicolor |        0.00 | 1.93 | 0.49 | [0.97, 2.90] #> virginica  |        0.00 | 3.51 | 0.51 | [2.50, 4.52] #>  #> Marginal means estimated at Species, Sepal.Width estimate_means(model, at = \"Sepal.Width\", length = 5) #> NOTE: Results may be misleading due to involvement in interactions #> Estimated Marginal Means #>  #> Sepal.Width | Mean |   SE |       95% CI #> ---------------------------------------- #> 2.00        | 3.28 | 0.10 | [3.07, 3.49] #> 2.60        | 3.60 | 0.06 | [3.49, 3.71] #> 3.20        | 3.92 | 0.04 | [3.84, 4.01] #> 3.80        | 4.25 | 0.08 | [4.08, 4.41] #> 4.40        | 4.57 | 0.14 | [4.30, 4.84] #>  #> Marginal means estimated at Sepal.Width estimate_means(model, at = \"Sepal.Width=c(2, 4)\") #> NOTE: Results may be misleading due to involvement in interactions #> Estimated Marginal Means #>  #> Sepal.Width | Mean |   SE |       95% CI #> ---------------------------------------- #> 2.00        | 3.28 | 0.10 | [3.07, 3.49] #> 4.00        | 4.35 | 0.10 | [4.15, 4.55] #>  #> Marginal means estimated at Sepal.Width  # Methods that can be applied to it: means <- estimate_means(model, fixed = \"Sepal.Width\") #> We selected `at = c(\"Species\")`. plot(means) # which runs visualisation_recipe()   standardize(means) #> Estimated Marginal Means (standardized) #>  #> Species    | Sepal.Width |  Mean |   SE |         95% CI #> -------------------------------------------------------- #> setosa     |        0.00 | -1.32 | 0.04 | [-1.40, -1.23] #> versicolor |        0.00 |  0.42 | 0.04 | [ 0.34,  0.50] #> virginica  |        0.00 |  1.05 | 0.03 | [ 0.99,  1.11] #>  #> Marginal means estimated at Species # \\donttest{ data <- iris data$Petal.Length_factor <- ifelse(data$Petal.Length < 4.2, \"A\", \"B\")  model <- lmer(Petal.Length ~ Sepal.Width + Species + (1 | Petal.Length_factor), data = data) estimate_means(model) #> We selected `at = c(\"Species\")`. #> Cannot use mode = \"kenward-roger\" because *pbkrtest* package is not installed #> Cannot use mode = \"satterthwaite\" because *lmerTest* package is not installed #> Estimated Marginal Means #>  #> Species    | Mean |   SE |       95% CI #> --------------------------------------- #> setosa     | 1.67 | 0.34 | [1.00, 2.34] #> versicolor | 4.27 | 0.34 | [3.61, 4.93] #> virginica  | 5.25 | 0.34 | [4.59, 5.92] #>  #> Marginal means estimated at Species estimate_means(model, at = \"Sepal.Width\", length = 3) #> Cannot use mode = \"kenward-roger\" because *pbkrtest* package is not installed #> Cannot use mode = \"satterthwaite\" because *lmerTest* package is not installed #> Estimated Marginal Means #>  #> Sepal.Width | Mean |   SE |       95% CI #> ---------------------------------------- #> 2.00        | 3.40 | 0.35 | [2.72, 4.08] #> 3.20        | 3.78 | 0.33 | [3.12, 4.43] #> 4.40        | 4.15 | 0.35 | [3.46, 4.85] #>  #> Marginal means estimated at Sepal.Width # }"},{"path":"https://easystats.github.io/modelbased/reference/estimate_slopes.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Marginal Effects ‚Äî estimate_slopes","title":"Estimate Marginal Effects ‚Äî estimate_slopes","text":"Estimate slopes (.e., coefficient) predictor within different factor levels, alongside numeric variable . words, assess effect predictor specific configurations data. related functions based marginal estimations includes estimate_contrasts() estimate_means().","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_slopes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Marginal Effects ‚Äî estimate_slopes","text":"","code":"estimate_slopes(model, trend = NULL, at = NULL, ci = 0.95, ...)"},{"path":"https://easystats.github.io/modelbased/reference/estimate_slopes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Marginal Effects ‚Äî estimate_slopes","text":"model statistical model. trend character indicating name variable compute slopes. predictor variable(s) evaluate desired effect / mean / contrasts. predictors model included collapsed \"averaged\" (effect estimated across ). ci Confidence Interval (CI) level. Default 0.95 (95%). ... arguments passed instance insight::get_datagrid().","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_slopes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Marginal Effects ‚Äî estimate_slopes","text":"data.frame class estimate_slopes.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_slopes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate Marginal Effects ‚Äî estimate_slopes","text":"See Details section , forget also check Vignettes README examples various examples, tutorials use cases. estimate_slopes(), estimate_means() estimate_contrasts() functions forming group, based marginal estimations (estimations based model). three also built emmeans package, reading documentation (instance emmeans::emmeans() emmeans::emtrends()) recommended understand idea behind types procedures. Model-based predictions basis follows. Indeed, first thing understand models can used make predictions (see estimate_link()). corresponds predicted response (\"outcome variable\") given specific predictor values predictors (.e., given specific data configuration). concept reference grid() important direct predictions. Marginal \"means\", obtained via estimate_means(), extension predictions, allowing \"average\" (collapse) predictors, obtain average response value specific predictors configuration. typically used predictors interest factors. Indeed, parameters model usually give intercept value \"effect\" factor level (different intercept). Marginal means can used directly give mean value response variable levels factor. Moreover, can also used control, average predictors, useful case multiple predictors without interactions. Marginal contrasts, obtained via estimate_contrasts(), extension marginal means, allow investigate difference (.e., contrast) marginal means. , , often used get pairwise differences levels factor. works also continuous predictors, instance one also interested whether difference two extremes continuous predictor significant. Finally, marginal effects, obtained via estimate_slopes(), different focus values response variable, model's parameters. idea assess effect predictor specific configuration predictors. relevant case interactions non-linear relationships, effect predictor variable changes depending predictors. Moreover, effects can also \"averaged\" predictors, get instance \"general trend\" predictor different factor levels. Example: imagine following model lm(y ~ condition * x) condition factor 3 levels , B C x continuous variable (like age example). One idea see model performs, compare actual response y one predicted model (using estimate_response()). Another idea evaluate average mean condition's levels (using estimate_means()), can useful visualize . Another possibility evaluate difference levels (using estimate_contrasts()). Finally, one also estimate effect x averaged conditions, instead within condition (using [estimate_slopes]).","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_slopes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Marginal Effects ‚Äî estimate_slopes","text":"","code":"# Get an idea of the data ggplot(iris, aes(x = Petal.Length, y = Sepal.Width)) +   geom_point(aes(color = Species)) +   geom_smooth(color = \"black\", se = FALSE) +   geom_smooth(aes(color = Species), linetype = \"dotted\", se = FALSE) +   geom_smooth(aes(color = Species), method = \"lm\", se = FALSE) #> `geom_smooth()` using method = 'loess' and formula = 'y ~ x' #> `geom_smooth()` using method = 'loess' and formula = 'y ~ x' #> `geom_smooth()` using formula = 'y ~ x'    # Model it model <- lm(Sepal.Width ~ Species * Petal.Length, data = iris) # Compute the marginal effect of Petal.Length at each level of Species slopes <- estimate_slopes(model, trend = \"Petal.Length\", at = \"Species\") slopes #> Estimated Marginal Effects #>  #> Species    | Coefficient |   SE |        95% CI | t(144) |      p #> ----------------------------------------------------------------- #> setosa     |        0.39 | 0.26 | [-0.13, 0.90] |   1.49 | 0.138  #> versicolor |        0.37 | 0.10 | [ 0.18, 0.56] |   3.89 | < .001 #> virginica  |        0.23 | 0.08 | [ 0.07, 0.40] |   2.86 | 0.005  #> Marginal effects estimated for Petal.Length plot(slopes)   standardize(slopes) #> Estimated Marginal Effects (standardized) #>  #> Species    | Coefficient |   SE |        95% CI | t(144) |      p #> ----------------------------------------------------------------- #> setosa     |        0.89 | 0.60 | [-0.29, 2.07] |   1.49 | 0.138  #> versicolor |        0.86 | 0.22 | [ 0.42, 1.29] |   3.89 | < .001 #> virginica  |        0.54 | 0.19 | [ 0.17, 0.91] |   2.86 | 0.005  #> Marginal effects estimated for Petal.Length model <- mgcv::gam(Sepal.Width ~ s(Petal.Length), data = iris) slopes <- estimate_slopes(model, at = \"Petal.Length\", length = 50) #> No numeric variable was specified for slope estimation. Selecting `trend = \"Petal.Length\"`. summary(slopes) #> Average Marginal Effects #>  #> Start |  End | Petal.Length | Coefficient |   SE |         95% CI | t(142.33) |     p #> ------------------------------------------------------------------------------------- #> 1.00  | 1.96 |         1.48 |        0.12 | 0.30 | [-0.47,  0.72] |      0.29 | 0.420 #> 2.08  | 3.05 |         2.57 |       -0.78 | 0.19 | [-1.15, -0.41] |     -4.25 | 0.001 #> 3.17  | 3.65 |         3.41 |       -0.10 | 0.26 | [-0.61,  0.42] |     -0.29 | 0.345 #> 3.77  | 4.25 |         4.01 |        0.54 | 0.20 | [ 0.15,  0.93] |      2.71 | 0.011 #> 4.37  | 6.90 |         5.64 |        0.07 | 0.23 | [-0.39,  0.53] |      0.58 | 0.430 #> Marginal effects estimated for Petal.Length plot(slopes)   model <- mgcv::gam(Sepal.Width ~ s(Petal.Length, by = Species), data = iris) slopes <- estimate_slopes(model,   trend = \"Petal.Length\",   at = c(\"Petal.Length\", \"Species\"), length = 20 ) summary(slopes) #> Average Marginal Effects #>  #> Species    | Start |  End | Petal.Length | Coefficient |   SE |         95% CI | t(143.68) |      p #> --------------------------------------------------------------------------------------------------- #> setosa     |  1.00 | 3.17 |         2.09 |       -0.02 | 0.27 | [-0.56,  0.52] |     -0.08 | 0.412  #> setosa     |  3.48 | 4.11 |         3.79 |       -0.60 | 0.29 | [-1.16, -0.03] |     -2.10 | 0.038  #> setosa     |  4.42 | 6.90 |         5.66 |       -0.76 | 0.65 | [-2.05,  0.52] |     -1.26 | 0.233  #> versicolor |  1.00 | 6.90 |         3.95 |        0.38 | 0.10 | [ 0.19,  0.56] |      3.94 | < .001 #> virginica  |  1.00 | 4.73 |         2.86 |        0.19 | 0.21 | [-0.23,  0.60] |      1.02 | 0.362  #> virginica  |  5.04 | 5.66 |         5.35 |        0.28 | 0.12 | [ 0.05,  0.51] |      2.44 | 0.017  #> virginica  |  5.97 | 6.90 |         6.43 |        0.10 | 0.17 | [-0.24,  0.44] |      0.70 | 0.539  #> Marginal effects estimated for Petal.Length plot(slopes) #> Warning: Using alpha for a discrete variable is not advised."},{"path":"https://easystats.github.io/modelbased/reference/find_inversions.html","id":null,"dir":"Reference","previous_headings":"","what":"Find points of inversion ‚Äî find_inversions","title":"Find points of inversion ‚Äî find_inversions","text":"Find points inversion curve.","code":""},{"path":"https://easystats.github.io/modelbased/reference/find_inversions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find points of inversion ‚Äî find_inversions","text":"","code":"find_inversions(x)"},{"path":"https://easystats.github.io/modelbased/reference/find_inversions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find points of inversion ‚Äî find_inversions","text":"x numeric vector.","code":""},{"path":"https://easystats.github.io/modelbased/reference/find_inversions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find points of inversion ‚Äî find_inversions","text":"Vector inversion points.","code":""},{"path":"https://easystats.github.io/modelbased/reference/find_inversions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find points of inversion ‚Äî find_inversions","text":"","code":"x <- sin(seq(0, 4 * pi, length.out = 100)) plot(x, type = \"b\")  find_inversions(x) #> [1] 12.87478 37.62484 62.37516 87.12522"},{"path":"https://easystats.github.io/modelbased/reference/get_emmeans.html","id":null,"dir":"Reference","previous_headings":"","what":"Easy 'emmeans' and 'emtrends' ‚Äî get_emcontrasts","title":"Easy 'emmeans' and 'emtrends' ‚Äî get_emcontrasts","text":"get_emmeans() function wrapper facilitate usage emmeans::emmeans() emmeans::emtrends(), providing somewhat simpler intuitive API find specifications variables interest. meanly made developers facilitate organization debugging, end-users rather use estimate_*() series functions.","code":""},{"path":"https://easystats.github.io/modelbased/reference/get_emmeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Easy 'emmeans' and 'emtrends' ‚Äî get_emcontrasts","text":"","code":"get_emcontrasts(   model,   contrast = NULL,   at = NULL,   fixed = NULL,   transform = \"none\",   method = \"pairwise\",   ... )  model_emcontrasts(   model,   contrast = NULL,   at = NULL,   fixed = NULL,   transform = \"none\",   method = \"pairwise\",   ... )  get_emmeans(   model,   at = \"auto\",   fixed = NULL,   transform = \"response\",   levels = NULL,   modulate = NULL,   ... )  model_emmeans(   model,   at = \"auto\",   fixed = NULL,   transform = \"response\",   levels = NULL,   modulate = NULL,   ... )  get_emtrends(   model,   trend = NULL,   at = NULL,   fixed = NULL,   levels = NULL,   modulate = NULL,   ... )  model_emtrends(   model,   trend = NULL,   at = NULL,   fixed = NULL,   levels = NULL,   modulate = NULL,   ... )"},{"path":"https://easystats.github.io/modelbased/reference/get_emmeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Easy 'emmeans' and 'emtrends' ‚Äî get_emcontrasts","text":"model statistical model. contrast character vector indicating name variable(s) compute contrasts. predictor variable(s) evaluate desired effect / mean / contrasts. predictors model included collapsed \"averaged\" (effect estimated across ). fixed character vector indicating names predictors \"fixed\" (.e., maintained), estimation made values. transform passed type argument emmeans::emmeans(). See vignette. Can \"none\" (default contrasts), \"response\" (default means), \"mu\", \"unlink\", \"log\". \"none\" leave values scale linear predictors. \"response\" transform scale response variable. Thus logistic model, \"none\" give estimations expressed log-odds (probabilities logit scale) \"response\" terms probabilities. method Contrast method. See argument emmeans::contrast. ... arguments passed instance insight::get_datagrid(). levels, modulate Deprecated, use instead. trend character indicating name variable compute slopes.","code":""},{"path":"https://easystats.github.io/modelbased/reference/get_emmeans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Easy 'emmeans' and 'emtrends' ‚Äî get_emcontrasts","text":"","code":"if (require(\"emmeans\", quietly = TRUE)) {   # Basic usage   model <- lm(Sepal.Width ~ Species, data = iris)   get_emcontrasts(model)    # Dealing with interactions   model <- lm(Sepal.Width ~ Species * Petal.Width, data = iris)   # By default: selects first factor   get_emcontrasts(model)   # Can also run contrasts between points of numeric   get_emcontrasts(model, contrast = \"Petal.Width\", length = 3)   # Or both   get_emcontrasts(model, contrast = c(\"Species\", \"Petal.Width\"), length = 2)   # Or with custom specifications   estimate_contrasts(model, contrast = c(\"Species\", \"Petal.Width=c(1, 2)\"))   # Can fixate the numeric at a specific value   get_emcontrasts(model, fixed = \"Petal.Width\")   # Or modulate it   get_emcontrasts(model, at = \"Petal.Width\", length = 4) } #> No variable was specified for contrast estimation. Selecting `contrast = \"Species\"`. #> No variable was specified for contrast estimation. Selecting `contrast = \"Species\"`. #> NOTE: Results may be misleading due to involvement in interactions #> NOTE: Results may be misleading due to involvement in interactions #> No variable was specified for contrast estimation. Selecting `contrast = \"Species\"`. #> No variable was specified for contrast estimation. Selecting `contrast = \"Species\"`. #> Petal.Width = 0.1: #>  contrast               estimate    SE  df t.ratio p.value #>  setosa - versicolor      1.8275 0.279 144   6.550  <.0001 #>  setosa - virginica       1.5479 0.312 144   4.955  <.0001 #>  versicolor - virginica  -0.2797 0.406 144  -0.689  0.7703 #>  #> Petal.Width = 0.9: #>  contrast               estimate    SE  df t.ratio p.value #>  setosa - versicolor      1.6544 0.288 144   5.743  <.0001 #>  setosa - virginica       1.7125 0.325 144   5.276  <.0001 #>  versicolor - virginica   0.0581 0.208 144   0.280  0.9577 #>  #> Petal.Width = 1.7: #>  contrast               estimate    SE  df t.ratio p.value #>  setosa - versicolor      1.4812 0.600 144   2.467  0.0390 #>  setosa - virginica       1.8771 0.597 144   3.144  0.0057 #>  versicolor - virginica   0.3959 0.113 144   3.502  0.0018 #>  #> Petal.Width = 2.5: #>  contrast               estimate    SE  df t.ratio p.value #>  setosa - versicolor      1.3080 0.954 144   1.371  0.3587 #>  setosa - virginica       2.0417 0.922 144   2.214  0.0722 #>  versicolor - virginica   0.7337 0.272 144   2.699  0.0212 #>  #> P value adjustment: tukey method for comparing a family of 3 estimates  model <- lm(Sepal.Length ~ Species + Petal.Width, data = iris)  if (require(\"emmeans\", quietly = TRUE)) {   # By default, 'at' is set to \"Species\"   get_emmeans(model)    # Overall mean (close to 'mean(iris$Sepal.Length)')   get_emmeans(model, at = NULL)    # One can estimate marginal means at several values of a 'modulate' variable   get_emmeans(model, at = \"Petal.Width\", length = 3)    # Interactions   model <- lm(Sepal.Width ~ Species * Petal.Length, data = iris)    get_emmeans(model)   get_emmeans(model, at = c(\"Species\", \"Petal.Length\"), length = 2)   get_emmeans(model, at = c(\"Species\", \"Petal.Length = c(1, 3, 5)\"), length = 2) } #> We selected `at = c(\"Species\")`. #> We selected `at = c(\"Species\")`. #> NOTE: Results may be misleading due to involvement in interactions #>  Species    Petal.Length emmean     SE  df lower.CL upper.CL #>  setosa                1   3.25 0.1282 144    2.995     3.50 #>  versicolor            1   1.55 0.3166 144    0.924     2.18 #>  virginica             1   1.91 0.3753 144    1.165     2.65 #>  setosa                3   4.02 0.4026 144    3.229     4.82 #>  versicolor            3   2.30 0.1291 144    2.043     2.55 #>  virginica             3   2.38 0.2137 144    1.954     2.80 #>  setosa                5   4.80 0.9216 144    2.979     6.62 #>  versicolor            5   3.05 0.0840 144    2.881     3.21 #>  virginica             5   2.84 0.0636 144    2.719     2.97 #>  #> Confidence level used: 0.95  if (require(\"emmeans\")) {   model <- lm(Sepal.Width ~ Species * Petal.Length, data = iris)    get_emtrends(model)   get_emtrends(model, at = \"Species\")   get_emtrends(model, at = \"Petal.Length\")   get_emtrends(model, at = c(\"Species\", \"Petal.Length\"))    model <- lm(Petal.Length ~ poly(Sepal.Width, 4), data = iris)   get_emtrends(model)   get_emtrends(model, at = \"Sepal.Width\") } #> No numeric variable was specified for slope estimation. Selecting `trend = \"Petal.Length\"`. #> No numeric variable was specified for slope estimation. Selecting `trend = \"Petal.Length\"`. #> No numeric variable was specified for slope estimation. Selecting `trend = \"Petal.Length\"`. #> NOTE: Results may be misleading due to involvement in interactions #> No numeric variable was specified for slope estimation. Selecting `trend = \"Petal.Length\"`. #> No numeric variable was specified for slope estimation. Selecting `trend = \"Sepal.Width\"`. #> No numeric variable was specified for slope estimation. Selecting `trend = \"Sepal.Width\"`. #>  Sepal.Width Sepal.Width.trend    SE  df lower.CL upper.CL #>         2.00             7.484 5.418 145   -3.225   18.192 #>         2.27             3.779 2.093 145   -0.358    7.916 #>         2.53             0.831 0.765 145   -0.681    2.342 #>         2.80            -1.337 0.706 145   -2.732    0.058 #>         3.07            -2.699 0.543 145   -3.772   -1.626 #>         3.33            -3.231 0.607 145   -4.430   -2.032 #>         3.60            -2.909 0.838 145   -4.564   -1.254 #>         3.87            -1.708 1.009 145   -3.702    0.287 #>         4.13             0.398 2.392 145   -4.330    5.125 #>         4.40             3.431 5.798 145   -8.028   14.890 #>  #> Confidence level used: 0.95"},{"path":"https://easystats.github.io/modelbased/reference/get_marginaleffects.html","id":null,"dir":"Reference","previous_headings":"","what":"Easy marginaleffects ‚Äî get_marginaleffects","title":"Easy marginaleffects ‚Äî get_marginaleffects","text":"Modelbased-like API create marginaleffects objects. Work--progress.","code":""},{"path":"https://easystats.github.io/modelbased/reference/get_marginaleffects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Easy marginaleffects ‚Äî get_marginaleffects","text":"","code":"get_marginaleffects(model, trend = NULL, at = NULL, fixed = NULL, ...)"},{"path":"https://easystats.github.io/modelbased/reference/get_marginaleffects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Easy marginaleffects ‚Äî get_marginaleffects","text":"model statistical model. trend character indicating name variable compute slopes. predictor variable(s) evaluate desired effect / mean / contrasts. predictors model included collapsed \"averaged\" (effect estimated across ). fixed character vector indicating names predictors \"fixed\" (.e., maintained), estimation made values. ... arguments passed instance insight::get_datagrid().","code":""},{"path":"https://easystats.github.io/modelbased/reference/get_marginaleffects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Easy marginaleffects ‚Äî get_marginaleffects","text":"","code":"if (require(\"marginaleffects\")) {   model <- lm(Sepal.Width ~ Species * Petal.Length, data = iris)    get_marginaleffects(model, trend = \"Petal.Length\", at = \"Species\")   get_marginaleffects(model, trend = \"Petal.Length\", at = \"Petal.Length\")   get_marginaleffects(model, trend = \"Petal.Length\", at = c(\"Species\", \"Petal.Length\")) } #> Loading required package: marginaleffects #>  #>          Term Estimate Std. Error    z Pr(>|z|)   2.5 % 97.5 %    Species #>  Petal.Length    0.388     0.2602 1.49   0.1360 -0.1220  0.898 setosa     #>  Petal.Length    0.388     0.2602 1.49   0.1360 -0.1220  0.898 setosa     #>  Petal.Length    0.374     0.0961 3.89   <0.001  0.1859  0.563 versicolor #>  Petal.Length    0.374     0.0961 3.89   <0.001  0.1859  0.563 versicolor #>  Petal.Length    0.374     0.0962 3.89   <0.001  0.1859  0.563 versicolor #>  Petal.Length    0.234     0.0819 2.86   0.0042  0.0739  0.395 virginica  #>  Petal.Length    0.234     0.0819 2.86   0.0042  0.0739  0.395 virginica  #>  Petal.Length    0.234     0.0819 2.86   0.0042  0.0739  0.395 virginica  #>  Petal.Length    0.234     0.0819 2.86   0.0042  0.0739  0.395 virginica  #>  Petal.Length #>          1.00 #>          1.66 #>          3.62 #>          4.28 #>          4.93 #>          4.93 #>          5.59 #>          6.24 #>          6.90 #>  #> Columns: rowid, term, estimate, std.error, statistic, p.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, Species, Petal.Length, Sepal.Width  #>"},{"path":"https://easystats.github.io/modelbased/reference/modelbased-package.html","id":null,"dir":"Reference","previous_headings":"","what":"modelbased: Estimation of Model-Based Predictions, Contrasts and Means ‚Äî modelbased-package","title":"modelbased: Estimation of Model-Based Predictions, Contrasts and Means ‚Äî modelbased-package","text":"modelbased package helping model-based estimations, easily compute marginal means, contrast analysis model predictions.","code":""},{"path":"https://easystats.github.io/modelbased/reference/modelbased-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"modelbased: Estimation of Model-Based Predictions, Contrasts and Means ‚Äî modelbased-package","text":"modelbased","code":""},{"path":[]},{"path":"https://easystats.github.io/modelbased/reference/modelbased-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"modelbased: Estimation of Model-Based Predictions, Contrasts and Means ‚Äî modelbased-package","text":"Maintainer: Dominique Makowski dom.makowski@gmail.com (ORCID) (@Dom_Makowski) Authors: Daniel L√ºdecke d.luedecke@uke.de (ORCID) (@strengejacke) Mattan S. Ben-Shachar matanshm@post.bgu.ac.il (ORCID) (@mattansb) Indrajeet Patil patilindrajeet.science@gmail.com (ORCID) (@patilindrajeets)","code":""},{"path":"https://easystats.github.io/modelbased/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages ‚Äî reexports","title":"Objects exported from other packages ‚Äî reexports","text":"objects imported packages. Follow links see documentation. datawizard standardize, unstandardize, visualisation_recipe insight print_md","code":""},{"path":"https://easystats.github.io/modelbased/reference/smoothing.html","id":null,"dir":"Reference","previous_headings":"","what":"Smoothing a vector or a time series ‚Äî smoothing","title":"Smoothing a vector or a time series ‚Äî smoothing","text":"Smoothing vector time series. data.frames, function smooth numeric variables stratified factor levels (.e., smooth within factor level combination).","code":""},{"path":"https://easystats.github.io/modelbased/reference/smoothing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Smoothing a vector or a time series ‚Äî smoothing","text":"","code":"smoothing(x, method = \"loess\", strength = 0.25, ...)"},{"path":"https://easystats.github.io/modelbased/reference/smoothing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Smoothing a vector or a time series ‚Äî smoothing","text":"x numeric vector. method Can \"loess\" (default) \"smooth\". loess smoothing can slow. strength argument applies method = \"loess\". Degree smoothing passed span (see loess()). ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/modelbased/reference/smoothing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Smoothing a vector or a time series ‚Äî smoothing","text":"smoothed vector data frame.","code":""},{"path":"https://easystats.github.io/modelbased/reference/smoothing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Smoothing a vector or a time series ‚Äî smoothing","text":"","code":"x <- sin(seq(0, 4 * pi, length.out = 100)) + rnorm(100, 0, 0.2) plot(x, type = \"l\") lines(smoothing(x, method = \"smooth\"), type = \"l\", col = \"blue\") lines(smoothing(x, method = \"loess\"), type = \"l\", col = \"red\")   x <- sin(seq(0, 4 * pi, length.out = 10000)) + rnorm(10000, 0, 0.2) plot(x, type = \"l\") lines(smoothing(x, method = \"smooth\"), type = \"l\", col = \"blue\") lines(smoothing(x, method = \"loess\"), type = \"l\", col = \"red\")"},{"path":"https://easystats.github.io/modelbased/reference/visualisation_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a reference grid ‚Äî visualisation_matrix","title":"Create a reference grid ‚Äî visualisation_matrix","text":"function alias (another name) insight::get_datagrid() function. arguments apply.","code":""},{"path":"https://easystats.github.io/modelbased/reference/visualisation_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a reference grid ‚Äî visualisation_matrix","text":"","code":"visualisation_matrix(x, ...)  # S3 method for data.frame visualisation_matrix(   x,   at = \"all\",   target = NULL,   factors = \"reference\",   numerics = \"mean\",   preserve_range = FALSE,   reference = x,   ... )  # S3 method for numeric visualisation_matrix(x, ...)  # S3 method for factor visualisation_matrix(x, ...)"},{"path":"https://easystats.github.io/modelbased/reference/visualisation_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a reference grid ‚Äî visualisation_matrix","text":"x object construct reference grid. ... Arguments passed methods (instance, length range control spread numeric variables.). Indicates focal predictors (variables) reference grid values focal predictors represented. specified otherwise, representative values numeric variables predictors evenly distributed minimum maximum, total number length values covering range (see 'Examples'). Possible options : \"\", include variables predictors. character vector one variable predictor names, like c(\"Species\", \"Sepal.Width\"), create grid combinations unique values. factors, use levels, numeric variables, use range length length (evenly spread minimum maximum) character vectors, use unique values. list named elements, indicating focal predictors representative values, e.g. = list(Sepal.Length = c(2, 4), Species = \"setosa\"). string assignments, e.g. = \"Sepal.Length = 2\" = c(\"Sepal.Length = 2\", \"Species = 'setosa'\") - note usage single double quotes assign strings within strings. special handling assignments brackets, .e. values defined inside [ ].numeric variables, value(s) inside brackets either two values, indicating minimum maximum (e.g. = \"Sepal.Length = [0, 5]\"), range length length (evenly spread given minimum maximum) created. two numeric values = \"Sepal.Length = [2,3,4,5]\", case values used representative values. \"token\" creates pre-defined representative values: mean -/+ 1 SD around mean: \"x = [sd]\" median -/+ 1 MAD around median: \"x = [mad]\" Tukey's five number summary (minimum, lower-hinge, median, upper-hinge, maximum): \"x = [fivenum]\" terciles, including minimum maximum: \"x = [terciles]\" terciles, excluding minimum maximum: \"x = [terciles2]\" quartiles, including minimum maximum: \"x = [quartiles]\" quartiles, excluding minimum maximum: \"x = [quartiles2]\" minimum maximum value: \"x = [minmax]\" 0 maximum value: \"x = [zeromax]\" factor variables, value(s) inside brackets indicate one factor levels, like = \"Species = [setosa, versicolor]\". Note: length argument ignored using brackets-tokens. remaining variables specified fixed (see also arguments factors numerics). target Deprecated name. Please use instead. factors Type summary factors. Can \"reference\" (set reference level), \"mode\" (set common level) \"\" keep levels. numerics Type summary numeric values. Can \"\" (duplicate grid unique values), function (\"mean\", \"median\", ...) value (e.g., numerics = 0). preserve_range case combinations numeric variables factors, setting preserve_range = TRUE drop observations value numeric variable originally present range factor level. leads unbalanced grid. Also, want minimum maximum closely match actual ranges, increase length argument. reference reference vector compute mean SD. Used standardizing unstandardizing grid using effectsize::standardize.","code":""},{"path":"https://easystats.github.io/modelbased/reference/visualisation_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a reference grid ‚Äî visualisation_matrix","text":"Reference grid data frame.","code":""},{"path":"https://easystats.github.io/modelbased/reference/visualisation_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a reference grid ‚Äî visualisation_matrix","text":"","code":"library(modelbased)  # Add one row to change the \"mode\" of Species data <- rbind(iris, iris[149, ], make.row.names = FALSE)  # Single variable is of interest; all others are \"fixed\" visualisation_matrix(data, at = \"Sepal.Length\") #> Visualisation Grid #>  #> Sepal.Length | Sepal.Width | Petal.Length | Petal.Width | Species #> ----------------------------------------------------------------- #>         4.30 |        3.06 |         3.77 |        1.21 |  setosa #>         4.70 |        3.06 |         3.77 |        1.21 |  setosa #>         5.10 |        3.06 |         3.77 |        1.21 |  setosa #>         5.50 |        3.06 |         3.77 |        1.21 |  setosa #>         5.90 |        3.06 |         3.77 |        1.21 |  setosa #>         6.30 |        3.06 |         3.77 |        1.21 |  setosa #>         6.70 |        3.06 |         3.77 |        1.21 |  setosa #>         7.10 |        3.06 |         3.77 |        1.21 |  setosa #>         7.50 |        3.06 |         3.77 |        1.21 |  setosa #>         7.90 |        3.06 |         3.77 |        1.21 |  setosa #>  #> Maintained constant: Sepal.Width, Petal.Length, Petal.Width, Species visualisation_matrix(data, at = \"Sepal.Length\", length = 3) #> Visualisation Grid #>  #> Sepal.Length | Sepal.Width | Petal.Length | Petal.Width | Species #> ----------------------------------------------------------------- #>         4.30 |        3.06 |         3.77 |        1.21 |  setosa #>         6.10 |        3.06 |         3.77 |        1.21 |  setosa #>         7.90 |        3.06 |         3.77 |        1.21 |  setosa #>  #> Maintained constant: Sepal.Width, Petal.Length, Petal.Width, Species visualisation_matrix(data, at = \"Sepal.Length\", range = \"ci\", ci = 0.90) #> Visualisation Grid #>  #> Sepal.Length | Sepal.Width | Petal.Length | Petal.Width | Species #> ----------------------------------------------------------------- #>         4.60 |        3.06 |         3.77 |        1.21 |  setosa #>         4.89 |        3.06 |         3.77 |        1.21 |  setosa #>         5.19 |        3.06 |         3.77 |        1.21 |  setosa #>         5.48 |        3.06 |         3.77 |        1.21 |  setosa #>         5.78 |        3.06 |         3.77 |        1.21 |  setosa #>         6.07 |        3.06 |         3.77 |        1.21 |  setosa #>         6.37 |        3.06 |         3.77 |        1.21 |  setosa #>         6.66 |        3.06 |         3.77 |        1.21 |  setosa #>         6.96 |        3.06 |         3.77 |        1.21 |  setosa #>         7.25 |        3.06 |         3.77 |        1.21 |  setosa #>  #> Maintained constant: Sepal.Width, Petal.Length, Petal.Width, Species visualisation_matrix(data, at = \"Sepal.Length\", factors = \"mode\") #> Visualisation Grid #>  #> Sepal.Length | Sepal.Width | Petal.Length | Petal.Width |   Species #> ------------------------------------------------------------------- #>         4.30 |        3.06 |         3.77 |        1.21 | virginica #>         4.70 |        3.06 |         3.77 |        1.21 | virginica #>         5.10 |        3.06 |         3.77 |        1.21 | virginica #>         5.50 |        3.06 |         3.77 |        1.21 | virginica #>         5.90 |        3.06 |         3.77 |        1.21 | virginica #>         6.30 |        3.06 |         3.77 |        1.21 | virginica #>         6.70 |        3.06 |         3.77 |        1.21 | virginica #>         7.10 |        3.06 |         3.77 |        1.21 | virginica #>         7.50 |        3.06 |         3.77 |        1.21 | virginica #>         7.90 |        3.06 |         3.77 |        1.21 | virginica #>  #> Maintained constant: Sepal.Width, Petal.Length, Petal.Width, Species  # Multiple variables are of interest, creating a combination visualisation_matrix(data, at = c(\"Sepal.Length\", \"Species\"), length = 3) #> Visualisation Grid #>  #> Sepal.Length |    Species | Sepal.Width | Petal.Length | Petal.Width #> -------------------------------------------------------------------- #>         4.30 |     setosa |        3.06 |         3.77 |        1.21 #>         6.10 |     setosa |        3.06 |         3.77 |        1.21 #>         7.90 |     setosa |        3.06 |         3.77 |        1.21 #>         4.30 | versicolor |        3.06 |         3.77 |        1.21 #>         6.10 | versicolor |        3.06 |         3.77 |        1.21 #>         7.90 | versicolor |        3.06 |         3.77 |        1.21 #>         4.30 |  virginica |        3.06 |         3.77 |        1.21 #>         6.10 |  virginica |        3.06 |         3.77 |        1.21 #>         7.90 |  virginica |        3.06 |         3.77 |        1.21 #>  #> Maintained constant: Sepal.Width, Petal.Length, Petal.Width visualisation_matrix(data, at = c(1, 3), length = 3) #> Visualisation Grid #>  #> Sepal.Length | Petal.Length | Sepal.Width | Petal.Width | Species #> ----------------------------------------------------------------- #>         4.30 |         1.00 |        3.06 |        1.21 |  setosa #>         6.10 |         1.00 |        3.06 |        1.21 |  setosa #>         7.90 |         1.00 |        3.06 |        1.21 |  setosa #>         4.30 |         3.95 |        3.06 |        1.21 |  setosa #>         6.10 |         3.95 |        3.06 |        1.21 |  setosa #>         7.90 |         3.95 |        3.06 |        1.21 |  setosa #>         4.30 |         6.90 |        3.06 |        1.21 |  setosa #>         6.10 |         6.90 |        3.06 |        1.21 |  setosa #>         7.90 |         6.90 |        3.06 |        1.21 |  setosa #>  #> Maintained constant: Sepal.Width, Petal.Width, Species visualisation_matrix(data, at = c(\"Sepal.Length\", \"Species\"), preserve_range = TRUE) #> Visualisation Grid #>  #> Sepal.Length |    Species | Sepal.Width | Petal.Length | Petal.Width #> -------------------------------------------------------------------- #>         4.30 |     setosa |        3.06 |         3.77 |        1.21 #>         4.70 |     setosa |        3.06 |         3.77 |        1.21 #>         5.10 |     setosa |        3.06 |         3.77 |        1.21 #>         5.50 |     setosa |        3.06 |         3.77 |        1.21 #>         5.10 | versicolor |        3.06 |         3.77 |        1.21 #>         5.50 | versicolor |        3.06 |         3.77 |        1.21 #>         5.90 | versicolor |        3.06 |         3.77 |        1.21 #>         6.30 | versicolor |        3.06 |         3.77 |        1.21 #>         6.70 | versicolor |        3.06 |         3.77 |        1.21 #>         5.10 |  virginica |        3.06 |         3.77 |        1.21 #>         5.50 |  virginica |        3.06 |         3.77 |        1.21 #>         5.90 |  virginica |        3.06 |         3.77 |        1.21 #>         6.30 |  virginica |        3.06 |         3.77 |        1.21 #>         6.70 |  virginica |        3.06 |         3.77 |        1.21 #>         7.10 |  virginica |        3.06 |         3.77 |        1.21 #>         7.50 |  virginica |        3.06 |         3.77 |        1.21 #>         7.90 |  virginica |        3.06 |         3.77 |        1.21 #>  #> Maintained constant: Sepal.Width, Petal.Length, Petal.Width visualisation_matrix(data, at = c(\"Sepal.Length\", \"Species\"), numerics = 0) #> Visualisation Grid #>  #> Sepal.Length |    Species | Sepal.Width | Petal.Length | Petal.Width #> -------------------------------------------------------------------- #>         4.30 |     setosa |           0 |            0 |           0 #>         4.70 |     setosa |           0 |            0 |           0 #>         5.10 |     setosa |           0 |            0 |           0 #>         5.50 |     setosa |           0 |            0 |           0 #>         5.90 |     setosa |           0 |            0 |           0 #>         6.30 |     setosa |           0 |            0 |           0 #>         6.70 |     setosa |           0 |            0 |           0 #>         7.10 |     setosa |           0 |            0 |           0 #>         7.50 |     setosa |           0 |            0 |           0 #>         7.90 |     setosa |           0 |            0 |           0 #>         4.30 | versicolor |           0 |            0 |           0 #>         4.70 | versicolor |           0 |            0 |           0 #>         5.10 | versicolor |           0 |            0 |           0 #>         5.50 | versicolor |           0 |            0 |           0 #>         5.90 | versicolor |           0 |            0 |           0 #>         6.30 | versicolor |           0 |            0 |           0 #>         6.70 | versicolor |           0 |            0 |           0 #>         7.10 | versicolor |           0 |            0 |           0 #>         7.50 | versicolor |           0 |            0 |           0 #>         7.90 | versicolor |           0 |            0 |           0 #>         4.30 |  virginica |           0 |            0 |           0 #>         4.70 |  virginica |           0 |            0 |           0 #>         5.10 |  virginica |           0 |            0 |           0 #>         5.50 |  virginica |           0 |            0 |           0 #>         5.90 |  virginica |           0 |            0 |           0 #>         6.30 |  virginica |           0 |            0 |           0 #>         6.70 |  virginica |           0 |            0 |           0 #>         7.10 |  virginica |           0 |            0 |           0 #>         7.50 |  virginica |           0 |            0 |           0 #>         7.90 |  virginica |           0 |            0 |           0 #>  #> Maintained constant: Sepal.Width, Petal.Length, Petal.Width visualisation_matrix(data, at = c(\"Sepal.Length = 3\", \"Species\")) #> Visualisation Grid #>  #> Sepal.Length |    Species | Sepal.Width | Petal.Length | Petal.Width #> -------------------------------------------------------------------- #>            3 |     setosa |        3.06 |         3.77 |        1.21 #>            3 | versicolor |        3.06 |         3.77 |        1.21 #>            3 |  virginica |        3.06 |         3.77 |        1.21 #>  #> Maintained constant: Sepal.Width, Petal.Length, Petal.Width visualisation_matrix(data, at = c(\"Sepal.Length = c(3, 1)\", \"Species = 'setosa'\")) #> Visualisation Grid #>  #> Sepal.Length | Species | Sepal.Width | Petal.Length | Petal.Width #> ----------------------------------------------------------------- #>            3 |  setosa |        3.06 |         3.77 |        1.21 #>            1 |  setosa |        3.06 |         3.77 |        1.21 #>  #> Maintained constant: Sepal.Width, Petal.Length, Petal.Width  # with list-style at-argument visualisation_matrix(data, at = list(Sepal.Length = c(1, 3), Species = \"setosa\")) #> Visualisation Grid #>  #> Sepal.Length | Species | Sepal.Width | Petal.Length | Petal.Width #> ----------------------------------------------------------------- #>            1 |  setosa |        3.06 |         3.77 |        1.21 #>            3 |  setosa |        3.06 |         3.77 |        1.21 #>  #> Maintained constant: Sepal.Width, Petal.Length, Petal.Width  # Standardize vizdata <- visualisation_matrix(data, at = \"Sepal.Length\") standardize(vizdata) #> Visualisation Grid #>  #> Sepal.Length | Sepal.Width | Petal.Length | Petal.Width | Species #> ----------------------------------------------------------------- #>        -1.87 |           0 |            0 |           0 |  setosa #>        -1.39 |           0 |            0 |           0 |  setosa #>        -0.90 |           0 |            0 |           0 |  setosa #>        -0.42 |           0 |            0 |           0 |  setosa #>         0.07 |           0 |            0 |           0 |  setosa #>         0.55 |           0 |            0 |           0 |  setosa #>         1.03 |           0 |            0 |           0 |  setosa #>         1.52 |           0 |            0 |           0 |  setosa #>         2.00 |           0 |            0 |           0 |  setosa #>         2.49 |           0 |            0 |           0 |  setosa #>  #> Maintained constant: Sepal.Width, Petal.Length, Petal.Width, Species"},{"path":"https://easystats.github.io/modelbased/reference/visualisation_recipe.estimate_predicted.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualisation Recipe for 'modelbased' Objects ‚Äî visualisation_recipe.estimate_grouplevel","title":"Visualisation Recipe for 'modelbased' Objects ‚Äî visualisation_recipe.estimate_grouplevel","text":"Visualisation Recipe 'modelbased' Objects","code":""},{"path":"https://easystats.github.io/modelbased/reference/visualisation_recipe.estimate_predicted.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualisation Recipe for 'modelbased' Objects ‚Äî visualisation_recipe.estimate_grouplevel","text":"","code":"# S3 method for estimate_grouplevel visualisation_recipe(   x,   hline = NULL,   pointrange = NULL,   facet_wrap = NULL,   labs = NULL,   ... )  # S3 method for estimate_means visualisation_recipe(   x,   show_data = \"jitter\",   point = NULL,   jitter = point,   boxplot = NULL,   violin = NULL,   line = NULL,   pointrange = NULL,   labs = NULL,   ... )  # S3 method for estimate_predicted visualisation_recipe(   x,   show_data = \"points\",   point = NULL,   density_2d = NULL,   line = NULL,   ribbon = NULL,   labs = NULL,   ... )  # S3 method for estimate_slopes visualisation_recipe(   x,   hline = NULL,   line = NULL,   pointrange = NULL,   ribbon = NULL,   labs = NULL,   facet_wrap = NULL,   ... )"},{"path":"https://easystats.github.io/modelbased/reference/visualisation_recipe.estimate_predicted.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualisation Recipe for 'modelbased' Objects ‚Äî visualisation_recipe.estimate_grouplevel","text":"x modelbased object. ... arguments passed functions. show_data Display \"raw\" data background model-based estimation. Can set \"none\" remove . input result estimate_means, show_data can \"points\" (jittered observation points), \"boxplot\", \"violin\" combination (see examples). input result estimate_response estimate_relation, show_data can \"points\" (points original data corresponding x y axes), \"density_2d\", \"density_2d_filled\", \"density_2d_polygon\" \"density_2d_raster\". point, jitter, boxplot, violin, pointrange, density_2d, line, hline, ribbon, labs, facet_wrap Additional aesthetics parameters geoms (see customization example).","code":""},{"path":"https://easystats.github.io/modelbased/reference/visualisation_recipe.estimate_predicted.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualisation Recipe for 'modelbased' Objects ‚Äî visualisation_recipe.estimate_grouplevel","text":"","code":"# ============================================== # estimate_grouplevel # ============================================== if (require(\"see\") && require(\"lme4\")) {   data <- lme4::sleepstudy   data <- rbind(data, data)   data$Newfactor <- rep(c(\"A\", \"B\", \"C\", \"D\"))    # 1 random intercept   model <- lmer(Reaction ~ Days + (1 | Subject), data = data)   x <- estimate_grouplevel(model)   layers <- visualisation_recipe(x)   layers   plot(layers) }  # \\donttest{ if (require(\"see\") && require(\"lme4\")) {   # 2 random intercepts   model <- lmer(Reaction ~ Days + (1 | Subject) + (1 | Newfactor), data = data)   x <- estimate_grouplevel(model)   plot(visualisation_recipe(x))     model <- lmer(Reaction ~ Days + (1 + Days | Subject) + (1 | Newfactor), data = data)   x <- estimate_grouplevel(model)   plot(visualisation_recipe(x)) }  # } # ============================================== # estimate_means # ============================================== if (require(\"ggplot2\")) {   # Simple Model ---------------   x <- estimate_means(lm(Sepal.Width ~ Species, data = iris))   layers <- visualisation_recipe(x)   layers   plot(layers) } #> We selected `at = c(\"Species\")`.  # \\donttest{ if (require(\"ggplot2\")) {   # Customize aesthetics   layers <- visualisation_recipe(x,     jitter = list(width = 0.03, color = \"red\"),     line = list(linetype = \"dashed\")   )   plot(layers)    # Customize raw data   plot(visualisation_recipe(x, show_data = c(\"violin\", \"boxplot\", \"jitter\")))    # Two levels ---------------   data <- mtcars   data$cyl <- as.factor(data$cyl)   data$new_factor <- as.factor(rep(c(\"A\", \"B\"), length.out = nrow(mtcars)))    model <- lm(mpg ~ new_factor * cyl * wt, data = data)   x <- estimate_means(model, at = c(\"new_factor\", \"cyl\"))   plot(visualisation_recipe(x))    # Modulations --------------   x <- estimate_means(model, at = c(\"new_factor\", \"wt\"))   plot(visualisation_recipe(x))    x <- estimate_means(model, at = c(\"new_factor\", \"cyl\", \"wt\"))   plot(visualisation_recipe(x))    #'   # GLMs ---------------------   data <- data.frame(vs = mtcars$vs, cyl = as.factor(mtcars$cyl))   x <- estimate_means(glm(vs ~ cyl, data = data, family = \"binomial\"))   plot(visualisation_recipe(x)) } #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> NOTE: Results may be misleading due to involvement in interactions #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> NOTE: Results may be misleading due to involvement in interactions #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> We selected `at = c(\"cyl\")`. #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now.  # } # ============================================== # estimate_relation, estimate_response, ... # ============================================== if (require(\"ggplot2\")) {   # Simple Model ---------------   x <- estimate_relation(lm(mpg ~ wt, data = mtcars))   layers <- visualisation_recipe(x)   layers   plot(layers) }  # \\donttest{ if (require(\"ggplot2\")) {   # Customize aesthetics ----------    layers <- visualisation_recipe(x,     point = list(color = \"red\", alpha = 0.6, size = 3),     line = list(color = \"blue\", size = 3),     ribbon = list(fill = \"green\", alpha = 0.7),     labs = list(subtitle = \"Oh yeah!\")   )   layers   plot(layers)    # Customize raw data -------------    plot(visualisation_recipe(x, show_data = \"none\"))   plot(visualisation_recipe(x, show_data = c(\"density_2d\", \"points\")))   plot(visualisation_recipe(x, show_data = \"density_2d_filled\"))   plot(visualisation_recipe(x, show_data = \"density_2d_polygon\"))   plot(visualisation_recipe(x, show_data = \"density_2d_raster\")) +     scale_x_continuous(expand = c(0, 0)) +     scale_y_continuous(expand = c(0, 0))    # Single predictors examples -----------    plot(estimate_relation(lm(Sepal.Length ~ Sepal.Width, data = iris)))   plot(estimate_relation(lm(Sepal.Length ~ Species, data = iris)))    # 2-ways interaction ------------    # Numeric * numeric   x <- estimate_relation(lm(mpg ~ wt * qsec, data = mtcars))   layers <- visualisation_recipe(x)   plot(layers)    # Numeric * factor   x <- estimate_relation(lm(Sepal.Width ~ Sepal.Length * Species, data = iris))   layers <- visualisation_recipe(x)   plot(layers)    # Factor * numeric   x <- estimate_relation(lm(Sepal.Width ~ Species * Sepal.Length, data = iris))   layers <- visualisation_recipe(x)   plot(layers)    # 3-ways interaction ------------    data <- mtcars   data$vs <- as.factor(data$vs)   data$cyl <- as.factor(data$cyl)   data$new_factor <- as.factor(rep(c(\"A\", \"B\"), length.out = nrow(mtcars)))    # Numeric * numeric * numeric   x <- estimate_relation(lm(mpg ~ wt * qsec * hp, data = data), length = c(5, 3, 20))   layers <- visualisation_recipe(x)   plot(layers)    # Numeric * numeric * factor   x <- estimate_relation(lm(mpg ~ wt * am * vs, data = data))   layers <- visualisation_recipe(x)   plot(layers)    # Numeric * factor * factor   x <- estimate_relation(lm(mpg ~ wt * cyl * new_factor, data = data))   layers <- visualisation_recipe(x)   plot(layers)    # Factor * numeric * numeric   x <- estimate_relation(lm(mpg ~ cyl * qsec * hp, data = data))   layers <- visualisation_recipe(x)   plot(layers) +     scale_size_continuous(range = c(0.2, 1))    # GLMs ---------------------   x <- estimate_relation(glm(vs ~ mpg, data = mtcars, family = \"binomial\"))   plot(visualisation_recipe(x))   plot(visualisation_recipe(x, show_data = \"jitter\", point = list(height = 0.03)))    # Multiple CIs ---------------------   plot(estimate_relation(lm(mpg ~ disp, data = mtcars),     ci = c(.50, .80, .95)   ))   plot(estimate_relation(lm(Sepal.Length ~ Species, data = iris),     ci = c(0.5, 0.7, 0.95)   )) } #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now.   # Bayesian models --------------------- if (require(\"ggplot2\") && require(\"rstanarm\")) {   model <- rstanarm::stan_glm(mpg ~ wt, data = mtcars, refresh = 0)    # Plot individual draws instead of regular ribbon   x <- estimate_relation(model, keep_iterations = 100)   layers <- visualisation_recipe(x, ribbon = list(color = \"red\"))   plot(layers)    model <- rstanarm::stan_glm(Sepal.Width ~ Species * Sepal.Length, data = iris, refresh = 0)   plot(estimate_relation(model, keep_iterations = 100)) }  # } # ============================================== # estimate_slopes # ============================================== if (require(\"ggplot2\")) {   model <- lm(Sepal.Width ~ Species * Petal.Length, data = iris)   x <- estimate_slopes(model, trend = \"Petal.Length\", at = \"Species\")    layers <- visualisation_recipe(x)   layers   plot(layers)    model <- lm(Petal.Length ~ poly(Sepal.Width, 4), data = iris)   x <- estimate_slopes(model, at = \"Sepal.Width\", length = 20)   plot(visualisation_recipe(x))    model <- lm(Petal.Length ~ Species * poly(Sepal.Width, 3), data = iris)   x <- estimate_slopes(model, at = c(\"Sepal.Width\", \"Species\"))   plot(visualisation_recipe(x)) } #> No numeric variable was specified for slope estimation. Selecting `trend = \"Sepal.Width\"`. #> No numeric variable was specified for slope estimation. Selecting `trend = \"Sepal.Width\"`. #> Warning: Using alpha for a discrete variable is not advised.  # \\dontrun{ # TODO: fails with latest emmeans (1.8.0) if (require(\"mgcv\")) {   data <- iris   data$Petal.Length <- data$Petal.Length^2    model <- mgcv::gam(Sepal.Width ~ t2(Petal.Width, Petal.Length), data = data)   x <- estimate_slopes(model, at = c(\"Petal.Width\", \"Petal.Length\"), length = 20)   plot(visualisation_recipe(x))    model <- mgcv::gam(Sepal.Width ~ t2(Petal.Width, Petal.Length, by = Species), data = data)   x <- estimate_slopes(model, at = c(\"Petal.Width\", \"Petal.Length\", \"Species\"), length = 10)   plot(visualisation_recipe(x)) } #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> No numeric variable was specified for slope estimation. Selecting `trend = \"Petal.Width\"`. #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now. #> No numeric variable was specified for slope estimation. Selecting `trend = \"Petal.Width\"`. #> Warning: Could not recover model data from environment. Please make sure your #>   data is available in your workspace. #>   Trying to retrieve data from the model frame now.  # }"},{"path":"https://easystats.github.io/modelbased/reference/zero_crossings.html","id":null,"dir":"Reference","previous_headings":"","what":"Find zero crossings of a vector ‚Äî zero_crossings","title":"Find zero crossings of a vector ‚Äî zero_crossings","text":"Find zero crossings vector, .e., indices numeric variable crosses 0.","code":""},{"path":"https://easystats.github.io/modelbased/reference/zero_crossings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find zero crossings of a vector ‚Äî zero_crossings","text":"","code":"zero_crossings(x)"},{"path":"https://easystats.github.io/modelbased/reference/zero_crossings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find zero crossings of a vector ‚Äî zero_crossings","text":"x numeric vector.","code":""},{"path":"https://easystats.github.io/modelbased/reference/zero_crossings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find zero crossings of a vector ‚Äî zero_crossings","text":"Vector zero crossings.","code":""},{"path":[]},{"path":"https://easystats.github.io/modelbased/reference/zero_crossings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find zero crossings of a vector ‚Äî zero_crossings","text":"","code":"x <- sin(seq(0, 4 * pi, length.out = 100)) plot(x)  zero_crossings(x) #> [1]  1.00000 25.74975 50.50000 75.25025"},{"path":[]},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-086","dir":"Changelog","previous_headings":"","what":"modelbased 0.8.6","title":"modelbased 0.8.6","text":"CRAN release: 2023-01-13","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"breaking-changes-0-8-6","dir":"Changelog","previous_headings":"","what":"Breaking Changes","title":"modelbased 0.8.6","text":"minimum needed R version bumped 3.6.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-085","dir":"Changelog","previous_headings":"","what":"modelbased 0.8.5","title":"modelbased 0.8.5","text":"CRAN release: 2022-08-18 Fixed issues printing-methods. Maintenance release fix failing tests CRAN checks.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-081","dir":"Changelog","previous_headings":"","what":"modelbased 0.8.1","title":"modelbased 0.8.1","text":"CRAN release: 2022-05-30 Maintenance release fix failing tests CRAN checks.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-080","dir":"Changelog","previous_headings":"","what":"modelbased 0.8.0","title":"modelbased 0.8.0","text":"CRAN release: 2022-03-31 visualisation_matrix() now become alias (alternative name) get_datagrid() function, implemented insight package.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-072","dir":"Changelog","previous_headings":"","what":"modelbased 0.7.2","title":"modelbased 0.7.2","text":"CRAN release: 2022-02-27 Patch release. update fixes failing tests updating insight package.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-071","dir":"Changelog","previous_headings":"","what":"modelbased 0.7.1","title":"modelbased 0.7.1","text":"CRAN release: 2022-01-13 API changes: levels estimate_contrasts replaced contrast. levels modulate general aggregated . estimate_prediction() deprecated favour estimate_response(). estimate_expectation() now data=NULL default.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-070","dir":"Changelog","previous_headings":"","what":"modelbased 0.7.0","title":"modelbased 0.7.0","text":"CRAN release: 2021-06-06 General overhaul package. Entire refactoring visualisation_matrix(). Option standardizing/unstandardizing predictions, contrasts means now available via standardize() instead via options. Introduction model_emmeans() wrapper easily create emmeans objects. estimate_smooth() transformed describe_nonlinear() made explicit.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-060","dir":"Changelog","previous_headings":"","what":"modelbased 0.6.0","title":"modelbased 0.6.0","text":"CRAN release: 2021-04-12 estimate_link() now transform predictions response scale GLMs. keep previous behaviour, use new estimate_relation() instead. follows change predictions made internally (now relies get_predicted(), details can found ).","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-051","dir":"Changelog","previous_headings":"","what":"modelbased 0.5.1","title":"modelbased 0.5.1","text":"CRAN release: 2021-01-27 Minor improvements.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-030","dir":"Changelog","previous_headings":"","what":"modelbased 0.3.0","title":"modelbased 0.3.0","text":"CRAN release: 2020-09-26","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"breaking-changes-0-3-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"modelbased 0.3.0","text":"Predicted now name predicted column Bayesian models (similarly Frequentist ones), instead centrality index (e.g., Median).","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"new-supported-models-0-3-0","dir":"Changelog","previous_headings":"","what":"New supported models","title":"modelbased 0.3.0","text":"Models package glmmTMB now supported.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"bug-fixes-0-3-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"modelbased 0.3.0","text":"estimate_slope() now gives informative error numeric predictor present.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-020","dir":"Changelog","previous_headings":"","what":"modelbased 0.2.0","title":"modelbased 0.2.0","text":"Partial support formulas. Refactor emmeans wrapping.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-013","dir":"Changelog","previous_headings":"","what":"modelbased 0.1.3","title":"modelbased 0.1.3","text":"Fix CRAN check issues.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-012","dir":"Changelog","previous_headings":"","what":"modelbased 0.1.2","title":"modelbased 0.1.2","text":"CRAN release: 2020-03-12 Minor code changes address changes forthcoming parameters package update.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-011","dir":"Changelog","previous_headings":"","what":"modelbased 0.1.1","title":"modelbased 0.1.1","text":"CRAN release: 2020-01-26 Fix CRAN check issues.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-010","dir":"Changelog","previous_headings":"","what":"modelbased 0.1.0","title":"modelbased 0.1.0","text":"CRAN release: 2020-01-12 Added NEWS.md file track changes package","code":""}]
