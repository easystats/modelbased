[{"path":[]},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others‚Äô private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement dom.makowski@gmail.com. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://easystats.github.io/modelbased/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.1, available https://www.contributor-covenant.org/version/2/1/code_of_conduct.html. Community Impact Guidelines inspired [Mozilla‚Äôs code conduct enforcement ladder][https://github.com/mozilla/inclusion]. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"https://easystats.github.io/modelbased/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contribution Guidelines","title":"Contribution Guidelines","text":"easystats guidelines 0.1.0 people much welcome contribute code, documentation, testing suggestions. package aims beginner-friendly. Even ‚Äôre new open-source way life, new coding github stuff, encourage try submitting pull requests (PRs). ‚Äú‚Äôd like help, ‚Äôm good enough programming yet‚Äù ‚Äôs alright, don‚Äôt worry! can always dig code, documentation tests. always typos fix, docs improve, details add, code lines document, tests add‚Ä¶ Even smaller PRs appreciated. ‚Äú‚Äôd like help, don‚Äôt know start‚Äù can look around issue section find features / ideas / bugs start working . can also open new issue just say ‚Äôre , interested helping . might ideas adapted skills. ‚Äú‚Äôm sure suggestion idea worthwile‚Äù Enough impostor syndrom! suggestions opinions good, even ‚Äôs just thought , ‚Äôs always good receive feedback. ‚Äúwaste time ? get credit?‚Äù Software contributions getting valued academic world, good time collaborate us! Authors substantial contributions added within authors list. ‚Äôre also keen including eventual academic publications. Anyway, starting important! enter whole new world, new fantastic point view‚Ä¶ fork repo, changes submit . work together make best :)","code":""},{"path":"https://easystats.github.io/modelbased/CONTRIBUTING.html","id":"code","dir":"","previous_headings":"","what":"Code","title":"Contribution Guidelines","text":"Please document comment code, purpose step (code line) stated clear understandable way. submitting change, please read R style guide particular easystats convention code-style keep consistency code formatting. Regarding style guide, note exception: put readability clarity everything. Thus, like underscores full names (prefer model_performance modelperf interpret_odds_logistic intoddslog). start code, make sure ‚Äôre dev branch (‚Äúadvanced‚Äù). , can create new branch named feature (e.g., feature_lightsaber) changes. Finally, submit branch merged dev branch. , every now , dev branch merge master, new package version.","code":""},{"path":"https://easystats.github.io/modelbased/CONTRIBUTING.html","id":"checks-to-do-before-submission","dir":"","previous_headings":"","what":"Checks to do before submission","title":"Contribution Guidelines","text":"Make sure documentation (roxygen) good Make sure add tests new functions Run: styler::style_pkg(): Automatic style formatting lintr::lint_package(): Style checks devtools::check(): General checks","code":""},{"path":"https://easystats.github.io/modelbased/CONTRIBUTING.html","id":"useful-materials","dir":"","previous_headings":"","what":"Useful Materials","title":"Contribution Guidelines","text":"Understanding GitHub flow","code":""},{"path":"https://easystats.github.io/modelbased/SUPPORT.html","id":null,"dir":"","previous_headings":"","what":"Getting help with {modelbased}","title":"Getting help with {modelbased}","text":"Thanks using modelbased. filing issue, places explore pieces put together make process smooth possible. Start making minimal reproducible example using reprex package. haven‚Äôt heard used reprex , ‚Äôre treat! Seriously, reprex make R-question-asking endeavors easier (pretty insane ROI five ten minutes ‚Äôll take learn ‚Äôs ). additional reprex pointers, check Get help! resource used tidyverse team. Armed reprex, next step figure ask: ‚Äôs question: start StackOverflow. people answer questions. ‚Äôs bug: ‚Äôre right place, file issue. ‚Äôre sure: let‚Äôs discuss try figure ! problem bug feature request, can easily return report . opening new issue, sure search issues pull requests make sure bug hasn‚Äôt reported /already fixed development version. default, search pre-populated :issue :open. can edit qualifiers (e.g.¬†:pr, :closed) needed. example, ‚Äôd simply remove :open search issues repo, open closed. Thanks help!","code":""},{"path":"https://easystats.github.io/modelbased/articles/derivatives.html","id":"the-traditional-approach","dir":"Articles","previous_headings":"","what":"The Traditional Approach","title":"Interpret simple and complex models using the power of effect derivatives","text":"Let‚Äôs say interested relationship y x following dataset:  Upon visualizing data, people might say: ‚Äúwell, straightforward thing run correlation analysis‚Äù (might wrong, sake demonstration, push things ). Let‚Äôs start : Great, know significant correlation two variables! ü•≥ like know every increase 1 x, much y increase? words, slope relationship? traditional approach fit linear model, assess parameters. Indeed, slope linear relationship predictor outcome actually effects estimated regression correspond . Let‚Äôs fit linear regression model, visualize , describe parameters.  parameters table shows us effect x 12.75. means every increase 1 x, y increases 12.75. Congrats, ‚Äôve answered question!","code":"# Package to fit GAMs library(mgcv)  # Tidyverse library(ggplot2) library(easystats)  set.seed(333)  # Generate data data <- bayestestR::simulate_correlation(r = 0.85, n = 1000, names = c(\"y\", \"x\"), mean = c(100, 0), sd = c(15, 1))  ggplot(data, aes(x, y)) +   geom_point() rez <- cor.test(data$y, data$x) report::report(rez) > Effect sizes were labelled following Funder's (2019) recommendations. >  > The Pearson's product-moment correlation between data$y and data$x is positive, > statistically significant, and very large (r = 0.85, 95% CI [0.83, 0.87], > t(998) = 50.97, p < .001) model_lm <- lm(y ~ x, data = data)  modelbased::estimate_relation(model_lm) |>   plot() parameters::parameters(model_lm) > Parameter   | Coefficient |   SE |          95% CI | t(998) |      p > -------------------------------------------------------------------- > (Intercept) |      100.00 | 0.25 | [99.51, 100.49] | 400.00 | < .001 > x           |       12.75 | 0.25 | [12.26,  13.24] |  50.97 | < .001"},{"path":"https://easystats.github.io/modelbased/articles/derivatives.html","id":"gams-can-be-used-for-linear-relationships-too","dir":"Articles","previous_headings":"","what":"GAMs can be used for linear relationships too!","title":"Interpret simple and complex models using the power of effect derivatives","text":"new player entered game. might heard General Additive Models, aka GAMs, extend general linear models (GLMs) enabling elegant robust way modelling non-linear relationships. ‚Äôs good curvy relationships simple stuff ! can even use linear links, , general, sure exact shape relationship. GAMs usually penalize wiggly patterns, problems approximating linear relationship, data indicates. GAMs can fitted using mgcv package, change need specify smooth term (s()) variable want estimate (non-necessarily linear) relationship.  Wow, GAM-based modeled relationship near-exactly GLM! GAMs powerful üòé Okay, ‚Äôs cool, ‚Äôs one slight issue. look parameters table, indeed one line ‚Äúsmooth term‚Äù, ‚Ä¶ coefficient! Indeed, GAMs don‚Äôt model straight lines, doesn‚Äôt return value slope. ‚Äôs people consider GAMs complicated discuss statistically, parameters easily interpretable. Owww, issue considering question effect x y üòï ?","code":"model_gam <- mgcv::gam(y ~ s(x), data = data)  modelbased::estimate_relation(model_gam) |>   plot(line = list(color = \"blue\")) parameters::parameters(model_gam) > # Fixed Effects >  > Parameter   | Coefficient |   SE |          95% CI | t(998.00) |      p > ----------------------------------------------------------------------- > (Intercept) |      100.00 | 0.25 | [99.51, 100.49] |    400.00 | < .001 >  > # Smooth Terms >  > Parameter       |       F |   df |      p > ----------------------------------------- > Smooth term (x) | 2598.40 | 1.00 | < .001"},{"path":"https://easystats.github.io/modelbased/articles/derivatives.html","id":"effect-derivatives","dir":"Articles","previous_headings":"","what":"Effect Derivatives","title":"Interpret simple and complex models using the power of effect derivatives","text":"Let us introduce another concept likely get popular near future within world regressions. Derivatives. might remember math class high school derivatives basically pattern slope pattern (pattern-ception much).  figure , plot shows non-linear relationship variables, -plot shows 1st order derivative, .e., evolution slope curve. might take bit time mentally wrap head around transformation, get , become easy think terms derivatives. can see derivative peaks slope relationship highest (steepest), decrease reaching 0. zero-crossing derivative means inversion trend; relationship starts negative. Derivatives can computed statistical models, including simple ones linear regressions. look answer , try think imagine derivative plot previously computed linear model look like? know slope 12.75 (parameters analysis). change across course relationship? , straight line, slope constant. slope constant, derivative ‚Ä¶ constant line , right? Let‚Äôs verify . compute derivative, can use estimate_slopes() function, specify want know: trend x course (‚Äú‚Äù) .  plot shows straight horizontal line 12.75, fixed confidence interval (parameter table). expected, definition, linear model models straight line fixed slope. running summary() derivative, obtain summary ‚Äúsegments‚Äù (positive, flat, negative). , one segment, average coefficient corresponds regression parameter. means don‚Äôt really need parameters table. Indeed, information slope can retrieved effect derivative. guess ‚Ä¶ can applied model! GAMs. Lets‚Äô GAM model:  Isn‚Äôt amazing, results identical. moral story GAMs can used wide variety contexts, even simple cases, derivatives easy way interpreting . Let‚Äôs jump another example!","code":"deriv <- modelbased::estimate_slopes(model_lm, trend = \"x\", by = \"x\")  plot(deriv) + # add a dashed line at 0 to show absence of effect   geom_hline(yintercept = 0, linetype = \"dashed\") summary(deriv) > Average Marginal Effects >  > Start |  End |     x | Slope |   SE |         95% CI |     t |      p > --------------------------------------------------------------------- > -3.38 | 3.28 | -0.05 | 12.75 | 0.25 | [12.26, 13.24] | 50.98 | < .001 >  > Marginal effects estimated for x > Type of slope was dY/dX deriv <- modelbased::estimate_slopes(model_gam, trend = \"x\", by = \"x\")  plot(deriv, line = list(color = \"blue\")) +   geom_hline(yintercept = 0, linetype = \"dashed\") summary(deriv) > Average Marginal Effects >  > Start |  End |     x | Slope |   SE |         95% CI |     t |      p > --------------------------------------------------------------------- > -3.38 | 3.28 | -0.05 | 12.75 | 0.25 | [12.26, 13.24] | 50.97 | < .001 >  > Marginal effects estimated for x > Type of slope was dY/dX"},{"path":"https://easystats.github.io/modelbased/articles/derivatives.html","id":"gam-derivatives-lm-a-polynomial-regression-example","dir":"Articles","previous_headings":"","what":"GAM + Derivatives > LM: a polynomial regression example","title":"Interpret simple and complex models using the power of effect derivatives","text":"mentioned one GAMs ‚Äúlimitation‚Äù parameters easily interpretable. assuming classes models, GLMs, case. However, common difficult--interpret parameters normal regression models ! Let‚Äôs take case polynomial regression, use model following data:  Let us fit polynomial regression:  look parameters table, also bit unclear coefficient refer . interpret numbers? Trying understand require lot search understanding polynomials work. Ain‚Äôt nobody got time dat‚Äô! Instead, can rely good ol‚Äô derivatives obtain ‚Äúlinear slope‚Äù every point curve.  know bit theory derivatives, won‚Äôt surprised find derivative 2nd order polynomial (x + x^2) actually linear line. can conclude plot slope (significantly, confidence interval cover 0) negative 0, becomes positive. 0 corresponds indeed point inversion curve. Moral story? Derivatives can used easily interpret draw conclusions relationships models parameters straightforward interpret. , ‚Äôve attentive point, might wonder: bother polynomials GAMs can trick?   conclusion similar, shows significant effect goes negative positive becomes flat (.e., non-significant) around 0. 3rd-degree-type relationships? works way:   , GAM nicely recovered shape relationship. summary, effects derivatives can used easily leverage power GAMs.","code":"data$y2 <- data$x^2 + rnorm(nrow(data), sd = 0.5)  ggplot(data, aes(x, y2)) +   geom_point() model_poly <- lm(y2 ~ poly(x, 2), data = data)  # Length is increased to have a smoother line modelbased::estimate_relation(model_poly, length = 30) |>   plot() parameters::parameters(model_poly) > Parameter      | Coefficient |   SE |         95% CI | t(997) |      p > ---------------------------------------------------------------------- > (Intercept)    |        1.01 | 0.02 | [ 0.98,  1.04] |  62.32 | < .001 > x [1st degree] |       -1.37 | 0.51 | [-2.38, -0.37] |  -2.68 | 0.007  > x [2nd degree] |       44.82 | 0.51 | [43.82, 45.83] |  87.38 | < .001 deriv <- modelbased::estimate_slopes(model_poly, trend = \"x\", by = \"x\", length = 100)  plot(deriv) +   geom_hline(yintercept = 0, linetype = \"dashed\") summary(deriv) > Average Marginal Effects >  > Start |   End |     x | Slope |   SE |         95% CI |      t |      p > ----------------------------------------------------------------------- > -3.38 | -0.08 | -1.73 | -3.43 | 0.04 | [-3.52, -3.35] | -72.58 | < .001 > -0.01 | -0.01 | -0.01 | -0.01 | 0.02 | [-0.05,  0.02] |  -0.83 |  0.405 > 0.05  |  3.28 |  1.67 |  3.34 | 0.04 | [ 3.25,  3.42] |  70.50 | < .001 >  > Marginal effects estimated for x > Type of slope was dY/dX model_gam2 <- mgcv::gam(y2 ~ s(x), data = data)  plot(modelbased::estimate_relation(model_gam2, length = 100), line = list(color = \"blue\")) # Increase precision deriv <- modelbased::estimate_slopes(model_gam2, trend = \"x\", by = \"x\", length = 100)  plot(deriv, line = list(color = \"blue\")) +   geom_hline(yintercept = 0, linetype = \"dashed\") summary(deriv) > Average Marginal Effects >  > Start |   End |     x | Slope |   SE |         95% CI |      t |      p > ----------------------------------------------------------------------- > -3.38 | -0.08 | -1.73 | -3.25 | 0.20 | [-3.64, -2.86] | -16.62 | < .001 > -0.01 |  0.05 |  0.02 | -0.01 | 0.11 | [-0.23,  0.21] |  -0.08 |  0.449 > 0.12  |  3.28 |  1.70 |  3.39 | 0.20 | [ 3.00,  3.77] |  17.35 | < .001 >  > Marginal effects estimated for x > Type of slope was dY/dX data$y3 <- data$x^3 + rnorm(nrow(data), sd = 1)  model_gam3 <- mgcv::gam(y3 ~ s(x), data = data)  plot(modelbased::estimate_relation(model_gam3, length = 100), line = list(color = \"blue\")) deriv <- modelbased::estimate_slopes(model_gam3, trend = \"x\", by = \"x\", length = 100)  plot(deriv, line = list(color = \"blue\")) +   geom_hline(yintercept = 0, linetype = \"dashed\")"},{"path":"https://easystats.github.io/modelbased/articles/estimate_contrasts.html","id":"testing-pairwise-differences","dir":"Articles","previous_headings":"","what":"Testing pairwise differences","title":"Contrast analysis","text":"previous tutorial, computed marginal means 3 different Species levels iris dataset. However, one might also want statistically test differences levels, can achieved contrast analysis. Although procedure much powerful, aim analogous post hoc analysis (pretty much consisting pairwise t-tests), heavily utilized behavioral sciences way follow hypotheses global differences tested ANOVAs specific hypotheses pairwise differences. Let‚Äôs carry contrast analysis simple model previous tutorial:  Contrast analysis can achieved estimate_contrasts function: can conclude pairwise differences statistically significant.","code":"library(ggplot2) library(modelbased) data(iris)  model <- lm(Sepal.Width ~ Species, data = iris) means <- estimate_means(model, by = \"Species\")  plot(means, point = list(width = 0.1)) +   theme_minimal() estimate_contrasts(model, contrast = \"Species\") > Marginal Contrasts Analysis >  > Level1     | Level2     | Difference |   SE |         95% CI | t(147) |      p > ------------------------------------------------------------------------------ > versicolor | setosa     |      -0.66 | 0.07 | [-0.79, -0.52] |  -9.69 | < .001 > virginica  | setosa     |      -0.45 | 0.07 | [-0.59, -0.32] |  -6.68 | < .001 > virginica  | versicolor |       0.20 | 0.07 | [ 0.07,  0.34] |   3.00 |  0.003 >  > Variable predicted: Sepal.Width > Predictors contrasted: Species > p-values are uncorrected."},{"path":"https://easystats.github.io/modelbased/articles/estimate_contrasts.html","id":"complex-model","dir":"Articles","previous_headings":"","what":"Complex model","title":"Contrast analysis","text":", contrast analysis based marginal means, can applied complex models: instance, add Petal.Width model, can see difference versicolor virginica becomes significant (even changes sign). Note can plot simple contrast analysis lighthouse plots:  represent estimated means CI range (black), grey areas show CI range difference (compared point estimate). One easy way interpret lighthouse plots whole beam goes (.e., upper limit lower limit direction), difference likely significant.","code":"model <- lm(Sepal.Width ~ Species * Petal.Width, data = iris) contrasts <- estimate_contrasts(model, contrast = \"Species\") contrasts > Marginal Contrasts Analysis >  > Level1     | Level2     | Difference |   SE |         95% CI | t(144) |      p > ------------------------------------------------------------------------------ > versicolor | setosa     |      -1.59 | 0.39 | [-2.37, -0.81] |  -4.04 | < .001 > virginica  | setosa     |      -1.77 | 0.41 | [-2.59, -0.96] |  -4.29 | < .001 > virginica  | versicolor |      -0.18 | 0.15 | [-0.47,  0.10] |  -1.27 |  0.205 >  > Variable predicted: Sepal.Width > Predictors contrasted: Species > Predictors averaged: Petal.Width (1.2) > p-values are uncorrected. plot(contrasts, estimate_means(model, by = \"Species\")) +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/articles/estimate_contrasts.html","id":"changes-in-difference","dir":"Articles","previous_headings":"","what":"Changes in difference","title":"Contrast analysis","text":"Interestingly, can also see differences modulated another continuous variable. Based model (including interaction Petal.Width), compute contrasts 100 equally-spaced points Petal.Width, visualise.  can see, difference versicolor virginica increases Petal.Width increases.","code":"contrasts <- estimate_contrasts(   model,   contrast = \"Species\",   by = \"Petal.Width\",   length = 100,   # we use a emmeans here because marginaleffects doesn't   # generate more than 25 rows for pairwise comparisons   backend = \"emmeans\" )  # Create a variable with the two levels concatenated contrasts$Contrast <- paste(contrasts$Level1, \"-\", contrasts$Level2)  # Visualise the changes in the differences ggplot(contrasts, aes(x = Petal.Width, y = Difference)) +   geom_ribbon(aes(fill = Contrast, ymin = CI_low, ymax = CI_high), alpha = 0.2) +   geom_line(aes(colour = Contrast), linewidth = 1) +   geom_hline(yintercept = 0, linetype = \"dashed\") +   theme_minimal() +   ylab(\"Difference\")"},{"path":"https://easystats.github.io/modelbased/articles/estimate_contrasts.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Contrast analysis","text":"Contrast analysis can powerful tool interpret understand statistical models.","code":""},{"path":[]},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/estimate_grouplevel.html","id":"population-level-effects","dir":"Articles","previous_headings":"Speed (RT)","what":"Population-level Effects","title":"How to use Mixed models to Estimate Individuals' Scores","text":"reaction time, start removing incorrect responses, since reflective ‚Äúsuccessful‚Äù cognitive process. , plot RT according condition stimulus category.  descriptive visualisation indeed seems suggest people slower accuracy condition compared speed condition. also slight effect frequency. Let‚Äôs verify using modelisation approach. Let‚Äôs unpack formula model. ‚Äôre tying predict reaction_time using different terms. can separated two groups, fixed effects random effects. condition fixed effect means interested estimating ‚Äúgeneral‚Äù effect condition, across subjects items (.e., population level). top effect condition, second ‚Äòfixed‚Äô parameter implicitly specified estimated, intercept (might know, one explicitly remove reaction_time ~ 0 + condition, otherwise added automatically). Let‚Äôs investigate two fixed parameters first: condition factor two levels, parameters easily interpretable. intercept corresponds reaction_time baseline level factor (accuracy), effect condition corresponds change reaction_time intercept speed condition. words, effect condition refers difference two conditions, speed - accuracy. can see, difference significant, people , general, lower reaction_time (sign negative) speed condition. Let‚Äôs visualize marginal means estimated model:  Now, ‚Äôs random effects. formula, specified random intercepts (.e., right part bar | symbol) id (participants) stim. means participant stimulus ‚ÄúIntercept‚Äù parameter (, ‚Äôve seen , corresponds reaction_time accuracy condition). Additionally, ‚Äôve specified random effect (‚Äúrandom slope‚Äù - left side bar) condition participant. means participant effect condition computed. need complex model? Let‚Äôs compare model without specifying random intercepts stimuli. Mmmh, seems simpler model performs lot worse (Bayes Factor lower 1). run compare_performance() learn details, example go ahead keep worse model (simplicity conciseness inspecting random effects later, keep mind real life ‚Äôs surely best thing ).","code":"library(ggplot2) data_rt <- data_filter(data, error == 0)  ggplot(data = data_rt, aes(y = reaction_time, x = condition, fill = condition)) +   geom_violin() library(lme4) model_full <- lmer(   reaction_time ~ condition + (1 + condition | id) + (1 | stim),   data = data_rt ) parameters(model_full, effects = \"fixed\") > # Fixed Effects >  > Parameter         | Coefficient |   SE |         95% CI | t(4506) |      p > -------------------------------------------------------------------------- > (Intercept)       |        0.69 | 0.02 | [ 0.65,  0.74] |   30.44 | < .001 > condition [speed] |       -0.16 | 0.02 | [-0.19, -0.12] |   -8.53 | < .001 means <- estimate_means(model_full, by = \"condition\", backend = \"marginaleffects\")  plot(means, point = list(alpha = 0.1, width = 0.1)) +   theme_minimal() model <- lmer(reaction_time ~ condition + (condition | id), data = data_rt)  test_performance(model_full, model) > Name       |   Model |      BF | df | df_diff |  Chi2 |      p > -------------------------------------------------------------- > model_full | lmerMod |         |  7 |         |       |        > model      | lmerMod | < 0.001 |  6 |   -1.00 | 36.78 | < .001 > Models were detected as nested (in terms of fixed parameters) and are compared in sequential order."},{"path":"https://easystats.github.io/modelbased/articles/estimate_grouplevel.html","id":"group-level-effects","dir":"Articles","previous_headings":"Speed (RT)","what":"Group-level Effects","title":"How to use Mixed models to Estimate Individuals' Scores","text":"‚Äôs nice know, actually get access group-level scores. can use estimate_grouplevel() function retrieve . participant (Level column), numbered 1 17, two rows, corresponding deviation main effect intercept condition effect. can easily visualize random effects:  Note: need use hline effectively add vline 0 coordinates flipped plot. can also use reshape_grouplevel() select Coefficient column (skip information uncertainty - real life equally important!) make match original data. resulting table length original dataset can merged : ‚Äôs convenient way re-incorporate random effects data re-use. can see, first row repeated corresponds participant (random effects ). Note can use summary() remove duplicate rows. Let‚Äôs add original data. Wow! can see, lot -participants variability. random parameters correspond ?","code":"random <- estimate_grouplevel(model) random > Group | Level | Parameter      | Coefficient |   SE |         95% CI > -------------------------------------------------------------------- > id    | 1     | (Intercept)    |       -0.10 | 0.01 | [-0.12, -0.07] > id    | 1     | conditionspeed |        0.09 | 0.02 | [ 0.06,  0.12] > id    | 2     | (Intercept)    |        0.08 | 0.02 | [ 0.04,  0.12] > id    | 2     | conditionspeed |       -0.03 | 0.02 | [-0.07,  0.01] > id    | 3     | (Intercept)    |        0.02 | 0.01 | [ 0.00,  0.05] > id    | 3     | conditionspeed |       -0.02 | 0.02 | [-0.05,  0.01] > id    | 4     | (Intercept)    |       -0.13 | 0.01 | [-0.15, -0.10] > id    | 4     | conditionspeed |        0.08 | 0.02 | [ 0.05,  0.11] > id    | 5     | (Intercept)    |       -0.05 | 0.01 | [-0.08, -0.03] > id    | 5     | conditionspeed |    6.67e-03 | 0.02 | [-0.02,  0.04] > id    | 6     | (Intercept)    |       -0.08 | 0.01 | [-0.10, -0.05] > id    | 6     | conditionspeed |        0.04 | 0.02 | [ 0.01,  0.07] > id    | 7     | (Intercept)    |       -0.09 | 0.01 | [-0.12, -0.07] > id    | 7     | conditionspeed |        0.10 | 0.02 | [ 0.06,  0.13] > id    | 8     | (Intercept)    |        0.21 | 0.01 | [ 0.19,  0.24] > id    | 8     | conditionspeed |       -0.18 | 0.02 | [-0.21, -0.14] > id    | 9     | (Intercept)    |        0.03 | 0.01 | [ 0.00,  0.05] > id    | 9     | conditionspeed |       -0.02 | 0.02 | [-0.05,  0.01] > id    | 10    | (Intercept)    |       -0.10 | 0.01 | [-0.13, -0.08] > id    | 10    | conditionspeed |        0.07 | 0.02 | [ 0.04,  0.10] > id    | 11    | (Intercept)    |       -0.09 | 0.01 | [-0.11, -0.07] > id    | 11    | conditionspeed |        0.07 | 0.02 | [ 0.04,  0.11] > id    | 12    | (Intercept)    |   -6.47e-04 | 0.01 | [-0.03,  0.02] > id    | 12    | conditionspeed |    3.65e-03 | 0.02 | [-0.03,  0.04] > id    | 13    | (Intercept)    |        0.08 | 0.01 | [ 0.05,  0.10] > id    | 13    | conditionspeed |       -0.06 | 0.02 | [-0.09, -0.02] > id    | 14    | (Intercept)    |        0.03 | 0.01 | [ 0.01,  0.06] > id    | 14    | conditionspeed |       -0.03 | 0.02 | [-0.06,  0.00] > id    | 15    | (Intercept)    |        0.09 | 0.01 | [ 0.07,  0.11] > id    | 15    | conditionspeed |       -0.07 | 0.02 | [-0.10, -0.04] > id    | 16    | (Intercept)    |        0.04 | 0.01 | [ 0.02,  0.06] > id    | 16    | conditionspeed |       -0.01 | 0.02 | [-0.05,  0.02] > id    | 17    | (Intercept)    |        0.06 | 0.01 | [ 0.03,  0.08] > id    | 17    | conditionspeed |       -0.05 | 0.02 | [-0.08, -0.02] plot(random) +   geom_hline(yintercept = 0, linetype = \"dashed\") +   theme_lucid() reshaped <- reshape_grouplevel(random, indices = \"Coefficient\")  head(reshaped) >   id Intercept conditionspeed > 1  1    -0.097          0.094 > 2  1    -0.097          0.094 > 3  1    -0.097          0.094 > 4  1    -0.097          0.094 > 5  1    -0.097          0.094 > 6  1    -0.097          0.094 data_rt <- data_join(data_rt, reshaped, join = \"full\", by = \"id\")"},{"path":"https://easystats.github.io/modelbased/articles/estimate_grouplevel.html","id":"correlation-with-empirical-scores","dir":"Articles","previous_headings":"Speed (RT)","what":"Correlation with empirical scores","title":"How to use Mixed models to Estimate Individuals' Scores","text":"said random effects group-level (group unit , model, participants) version population-level effects (fixed effects). One important thing note represent deviation fixed effect, coefficient close 0 means participants‚Äô effect population-level effect. words, ‚Äôs ‚Äúnorm‚Äù (note can also obtain group-specific effect corresponding sum fixed random changing type argument). Nevertheless, let‚Äôs compute empirical scores, condition averages participant. group data participant condition, get mean RT, reshape data , participant, two means two columns. , create new dataframe (use - overwrite - keep concise), keep mean RT accuracy condition, difference speed condition (reminds something?). Now, empirical scores compare random effects estimated model? Let‚Äôs merge empirical scores random effects scores. , run summary() reshaped random effects remove duplicate rows (one row per participant, matches format data_sub). can now reshape random effects format data_sub merge . Let‚Äôs run correlation model-based scores empirical scores.  First thing notice everything significantly strongly correlated!. , empirical scores accuracy condition, corresponding ‚Äúraw‚Äù average RT, correlate almost perfectly model-based counterpart (r_{empirical\\_accuracy/Coefficient\\_Intercept} = 1; r_{empirical\\_condition/Coefficient\\_conditionspeed} > .99). ‚Äôs reassuring, means model managed estimate intuitive parameters! Finally, can observe strong negative correlation (even salient model-based indices) RT accuracy condition effect speed condition:  slower accuracy condition, bigger difference speed condition.","code":"data_sub <- aggregate(reaction_time ~ id + condition, data_rt, mean) data_sub <- data_rt |>   data_summary(reaction_time = mean(reaction_time), by = c(\"id\", \"condition\")) |>   reshape_wider(     names_from = \"condition\", values_from = \"reaction_time\", names_prefix = \"empirical_\"   ) |>   data_modify(empirical_speed = empirical_accuracy - empirical_speed) data_sub >    id empirical_accuracy empirical_speed > 1   1               0.59           0.053 > 2   2               0.77           0.165 > 3   3               0.72           0.175 > 4   4               0.56           0.086 > 5   5               0.64           0.165 > 6   6               0.62           0.130 > 7   7               0.59           0.042 > 8   8               0.91           0.353 > 9   9               0.72           0.174 > 10 10               0.59           0.089 > 11 11               0.60           0.078 > 12 12               0.69           0.153 > 13 13               0.77           0.214 > 14 14               0.72           0.195 > 15 15               0.78           0.229 > 16 16               0.73           0.164 > 17 17               0.75           0.206 data_sub <- data_join(data_sub, summary(reshaped), by = \"id\") data_sub >    id empirical_accuracy empirical_speed Intercept conditionspeed > 1   1               0.59           0.053  -0.09676         0.0941 > 2   2               0.77           0.165   0.07896        -0.0324 > 3   3               0.72           0.175   0.02481        -0.0176 > 4   4               0.56           0.086  -0.12699         0.0784 > 5   5               0.64           0.165  -0.05216         0.0067 > 6   6               0.62           0.130  -0.07711         0.0372 > 7   7               0.59           0.042  -0.09326         0.0973 > 8   8               0.91           0.353   0.21236        -0.1785 > 9   9               0.72           0.174   0.02704        -0.0173 > 10 10               0.59           0.089  -0.10344         0.0711 > 11 11               0.60           0.078  -0.08936         0.0749 > 12 12               0.69           0.153  -0.00065         0.0036 > 13 13               0.77           0.214   0.07838        -0.0564 > 14 14               0.72           0.195   0.03066        -0.0324 > 15 15               0.78           0.229   0.09098        -0.0690 > 16 16               0.73           0.164   0.04005        -0.0143 > 17 17               0.75           0.206   0.05650        -0.0454 correlation(data_sub) |>   summary(redundant = TRUE) |>   cor_sort() |>   plot() ggplot(data_sub, aes(x = Intercept, y = conditionspeed)) +   geom_point() +   geom_smooth(method = \"lm\") +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/articles/estimate_grouplevel.html","id":"reliability","dir":"Articles","previous_headings":"Speed (RT)","what":"Reliability","title":"How to use Mixed models to Estimate Individuals' Scores","text":"Extracting random effects also useful compute reliability given paradigm. key idea compare inter-individual variability random effects intra-individual variability data (Williams et al., 2020). , first need compute variability (SD) point-estimates across participants. , compute average variability (SE) random effects within participants, add previous table. reliability ratio -participants variability within-participants variability. estimate varies -participants compared within participants, reliable . Reliability values 1 suggest higher variability participants within participants, good sign reliability estimates.","code":"reliability <- random |>   data_summary(sd_between = sd(Coefficient), by = \"Parameter\") reliability > Parameter      | sd_between > --------------------------- > (Intercept)    |       0.09 > conditionspeed |       0.07 reliability <- random |>   data_summary(sd_within = mean(SE), by = \"Parameter\") |>   data_join(reliability) reliability > Parameter      | sd_within | sd_between > --------------------------------------- > (Intercept)    |      0.01 |       0.09 > conditionspeed |      0.02 |       0.07 reliability |>   data_modify(reliability = sd_between / sd_within) > Parameter      | sd_within | sd_between | reliability > ----------------------------------------------------- > (Intercept)    |      0.01 |       0.09 |        7.24 > conditionspeed |      0.02 |       0.07 |        4.39"},{"path":"https://easystats.github.io/modelbased/articles/estimate_grouplevel.html","id":"accuracy","dir":"Articles","previous_headings":"","what":"Accuracy","title":"How to use Mixed models to Estimate Individuals' Scores","text":"section, take interest accuracy - probability making errors, using logistic models. , use dataset still includes errors (data, data_rt used previous section). fit logistic mixed model predict likelihood making error depending condition. Similarly, specified random intercept random effect condition participants. parameters suggest general, participants indeed make errors speed condition compared accuracy condition. can visualize average probability (.e., marginal means) making errors two conditions.  Similarly, can extract group-level effects, clean (rename columns, otherwise names RT model), merge previous ones.","code":"model <- glmer(   error ~ condition + (1 + condition | id),   data = data,   family = \"binomial\" )  parameters(model, effects = \"fixed\") > # Fixed Effects >  > Parameter         | Log-Odds |   SE |         95% CI |      z |      p > ---------------------------------------------------------------------- > (Intercept)       |    -2.91 | 0.19 | [-3.28, -2.53] | -15.16 | < .001 > condition [speed] |     1.32 | 0.15 | [ 1.02,  1.61] |   8.73 | < .001 plot(estimate_means(model, by = \"condition\"), show_data = FALSE) random <- estimate_grouplevel(model)  plot(random)"},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/estimate_means.html","id":"raw-means","dir":"Articles","previous_headings":"","what":"Raw Means","title":"What are, why use and how to get marginal means","text":"iris dataset, available base R, contains observations three types iris flowers (Species variable); Setosa, Versicolor Virginica, different features measured, length width sepals petals. traditional starting point, reporting data, start descriptive statistics. instance, mean Sepal.Width three species. can compute means easily grouping observations species, computing mean standard deviation (SD): can also visualize plot:  However, raw means might biased, number observations group might different. Moreover, might hidden covariance mediation variables dataset, creating ‚Äúspurious‚Äù influence (confounding) means. can take influences account calculating means?","code":"library(easystats)  iris |>   data_group(\"Species\") |>   describe_distribution(select = \"Sepal.Width\") > # Species=setosa >  > Variable    | Mean |   SD |  IQR |        Range | Skewness | Kurtosis |  n | n_Missing > -------------------------------------------------------------------------------------- > Sepal.Width | 3.43 | 0.38 | 0.52 | [2.30, 4.40] |     0.04 |     0.95 | 50 |         0 >  > # Species=versicolor >  > Variable    | Mean |   SD |  IQR |        Range | Skewness | Kurtosis |  n | n_Missing > -------------------------------------------------------------------------------------- > Sepal.Width | 2.77 | 0.31 | 0.50 | [2.00, 3.40] |    -0.36 |    -0.37 | 50 |         0 >  > # Species=virginica >  > Variable    | Mean |   SD |  IQR |        Range | Skewness | Kurtosis |  n | n_Missing > -------------------------------------------------------------------------------------- > Sepal.Width | 2.97 | 0.32 | 0.40 | [2.20, 3.80] |     0.37 |     0.71 | 50 |         0 library(ggplot2) ggplot(iris, aes(x = Species, y = Sepal.Width, fill = Species)) +   geom_violin() +   geom_jitter(width = 0.05) +   theme_modern()"},{"path":"https://easystats.github.io/modelbased/articles/estimate_means.html","id":"marginal-means","dir":"Articles","previous_headings":"","what":"Marginal Means","title":"What are, why use and how to get marginal means","text":"Another way analysing means actually statistically model , rather simply describe appear data. instance, fit simple Bayesian linear regression modelling relationship Species Sepal.Width. Marginal means basically means extracted statistical model, represent average response variable (, Sepal.Width) level predictor variable (, Species). Note means computed different raw means created . can surmise many spurious influences need worry iris dataset. might case dataset. can now add means, well credible interval (CI) representing uncertainty estimation, overlay previous plot:  Note modelbased provides automated plotting capabilities quick visual checks:","code":"library(modelbased) model <- lm(Sepal.Width ~ Species, data = iris) means <- estimate_means(model, by = \"Species\") means > Estimated Marginal Means >  > Species    | Mean |   SE |       95% CI | t(147) > ------------------------------------------------ > setosa     | 3.43 | 0.05 | [3.33, 3.52] |  71.36 > versicolor | 2.77 | 0.05 | [2.68, 2.86] |  57.66 > virginica  | 2.97 | 0.05 | [2.88, 3.07] |  61.91 >  > Variable predicted: Sepal.Width > Predictors modulated: Species p <- ggplot(iris, aes(x = Species, y = Sepal.Width, fill = Species)) +   geom_violin() +   geom_jitter(width = 0.05) +   geom_line(data = means, aes(y = Mean, group = 1)) +   geom_pointrange(     data = means,     aes(y = Mean, ymin = CI_low, ymax = CI_high),     size = 1,     color = \"white\"   ) +   theme_minimal() p plot(means)"},{"path":"https://easystats.github.io/modelbased/articles/estimate_means.html","id":"complex-models","dir":"Articles","previous_headings":"","what":"Complex Models","title":"What are, why use and how to get marginal means","text":"power marginal means resides fact can estimated much complex models. instance, fit model takes account interaction variable, Petal.Width. estimated means ‚Äúadjusted‚Äù (take account) variations components. Now let‚Äôs add previous plot marginal means complex model (shown purple) next , help us notice adjusted means change depending predictors.  ‚Äôs interesting! seems adjusting (‚Äúcontrolling ‚Äù) model petal characteristics, differences Species seem magnified! differences ‚Äúsignificant‚Äù? ‚Äôs contrast analysis comes play! Click read tutorial contrast analysis.","code":"model <- lm(Sepal.Width ~ Species + Petal.Width, data = iris) means_complex <- estimate_means(model, by = \"Species\")  means_complex > Estimated Marginal Means >  > Species    | Mean |   SE |       95% CI | t(146) > ------------------------------------------------ > setosa     | 4.17 | 0.12 | [3.93, 4.42] |  33.89 > versicolor | 2.67 | 0.05 | [2.58, 2.76] |  59.07 > virginica  | 2.33 | 0.11 | [2.11, 2.54] |  21.39 >  > Variable predicted: Sepal.Width > Predictors modulated: Species > Predictors averaged: Petal.Width (1.2) p +   geom_line(data = means_complex, aes(y = Mean, group = 1), color = \"purple\") +   geom_pointrange(     data = means_complex,     aes(y = Mean, ymin = CI_low, ymax = CI_high),     size = 1,     color = \"purple\"   )"},{"path":[]},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/estimate_relation.html","id":"linear-relationship","dir":"Articles","previous_headings":"Simple regression","what":"Linear relationship","title":"Visualize effects and interactions","text":"","code":"library(modelbased)  model <- lm(Sepal.Length ~ Sepal.Width, data = iris)  visualization_data <- estimate_relation(model) head(visualization_data) > Model-based Predictions >  > Sepal.Width | Predicted |   SE |       95% CI > --------------------------------------------- > 2.00        |      6.08 | 0.18 | [5.73, 6.43] > 2.27        |      6.02 | 0.14 | [5.74, 6.30] > 2.53        |      5.96 | 0.11 | [5.75, 6.17] > 2.80        |      5.90 | 0.08 | [5.75, 6.06] > 3.07        |      5.84 | 0.07 | [5.71, 5.97] > 3.33        |      5.78 | 0.08 | [5.62, 5.94] >  > Variable predicted: Sepal.Length > Predictors modulated: Sepal.Width library(ggplot2) plot(visualization_data, line = list(color = \"red\")) +   theme_minimal()"},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/estimate_relation.html","id":"polynomial","dir":"Articles","previous_headings":"More complex regressions","what":"Polynomial","title":"Visualize effects and interactions","text":"","code":"lm(Sepal.Length ~ poly(Sepal.Width, 2), data = iris) |>   modelbased::estimate_relation(length = 50) |>   plot()"},{"path":"https://easystats.github.io/modelbased/articles/estimate_relation.html","id":"additive-models","dir":"Articles","previous_headings":"More complex regressions","what":"Additive Models","title":"Visualize effects and interactions","text":"","code":"library(mgcv) > Loading required package: nlme > This is mgcv 1.9-1. For overview type 'help(\"mgcv-package\")'. mgcv::gam(Sepal.Length ~ s(Sepal.Width), data = iris) |>   modelbased::estimate_relation(length = 50) |>   plot()"},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/estimate_response.html","id":"prediction-against-original-data","dir":"Articles","previous_headings":"","what":"Prediction against original data","title":"Use a model to make predictions","text":"Generating prediction model can used wide variety reasons, one visualisation. can achieved via estimate_expectation() function visualisation spinoff, estimate_relation(). Let‚Äôs start fitting linear regression. might interested comparing values predicted model actual ‚Äútrue‚Äù values. can done generating predictions: output data frame containing predicted values (median CI posterior distribution) value original data frame (used fitting model). Hence, can simply add original response column (Petal.Length) data plot original predicted data (top identity line, representing perfect relationship).  seems like model perform bad. added information Species model? now plot second observations, based complex model, red overlay previous points:  new model generated much accurate predictions (closer underlying regression line).","code":"library(modelbased)  model <- lm(Petal.Length ~ Sepal.Length, data = iris) pred_data <- estimate_expectation(model) head(pred_data) > Model-based Predictions >  > Sepal.Length | Predicted |   SE |       95% CI | Residuals > ---------------------------------------------------------- > 5.10         |      2.38 | 0.10 | [2.19, 2.57] |     -0.98 > 4.90         |      2.00 | 0.11 | [1.79, 2.22] |     -0.60 > 4.70         |      1.63 | 0.12 | [1.39, 1.87] |     -0.33 > 4.60         |      1.45 | 0.13 | [1.19, 1.70] |      0.05 > 5.00         |      2.19 | 0.10 | [1.99, 2.39] |     -0.79 > 5.40         |      2.93 | 0.08 | [2.78, 3.09] |     -1.23 >  > Variable predicted: Petal.Length library(ggplot2)  pred_data$Petal.Length <- iris$Petal.Length  pred_data |>   ggplot(aes(x = Petal.Length, y = Predicted)) +   geom_line(aes(x = Petal.Length, y = Petal.Length), linetype = \"dashed\") +   geom_point() +   ylab(\"Petal.Length (predicted)\") +   theme_minimal() model <- lm(Petal.Length ~ Sepal.Length * Species, data = iris)  pred_data$Predicted_2 <- estimate_expectation(model)$Predicted pred_data |>   ggplot() +   geom_line(aes(x = Petal.Length, y = Petal.Length), linetype = \"dashed\") +   geom_point(aes(x = Petal.Length, y = Predicted), color = \"grey\") +   geom_point(aes(x = Petal.Length, y = Predicted_2), color = \"red\") +   ylab(\"Petal.Length (predicted)\") +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/articles/estimate_response.html","id":"estimating-response-vs--relation","dir":"Articles","previous_headings":"","what":"Estimating response vs. relation","title":"Use a model to make predictions","text":"Rather visualizing predictions made model, often interested visualizing relation. model , relationship response two predictors. can achieved generating predictions data grid model‚Äôs data instead original dataset. visualise relationship response (Petal.Length) predictors (Sepal.Length Species).  However, might notice Credible Interval (CI) bands quite big. estimate_relation() coming . traditional, frequentist, regression, predictions deterministic: always fall regression line. However, Bayesian framework, probabilistic. Hence , predicting response predicting link (.e., regression line uncertainty interval associated line). order facilitate visualization links, added estimate_relation() shortcut estimate_expectation() data = \"grid\" , Bayesian models, predict = \"link\" smoothing default. estimate_expectation() used context generating actual predictions existing new data, whereas estimate_relation() relevant context visualization plotting.","code":"predicted <- estimate_expectation(model, data = \"grid\")  iris |>   ggplot(aes(x = Sepal.Length)) +   geom_point(aes(y = Petal.Length, color = Species)) +   geom_ribbon(data = predicted, aes(ymin = CI_low, ymax = CI_high, fill = Species), alpha = 0.3) +   geom_line(data = predicted, aes(y = Predicted, color = Species), linewidth = 1) +   theme_minimal() predicted <- estimate_relation(model)  iris |>   ggplot(aes(x = Sepal.Length)) +   geom_point(aes(y = Petal.Length, color = Species)) +   geom_ribbon(data = predicted, aes(ymin = CI_low, ymax = CI_high, fill = Species), alpha = 0.3) +   geom_line(data = predicted, aes(y = Predicted, color = Species), linewidth = 1) +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/articles/estimate_response.html","id":"different-ci-levels","dir":"Articles","previous_headings":"","what":"Different CI levels","title":"Use a model to make predictions","text":"purpose CI bands provide information uncertainty related estimation. Bayesian framework, credible intervals directly related shape posterior distribution. Thus, showing different CI levels (instance, 69%, 89% 99%).","code":"predicted <- estimate_relation(model, ci = c(0.69, .89, 0.99))  iris |>   ggplot(aes(x = Sepal.Length)) +   geom_point(aes(y = Petal.Length, color = Species)) +   geom_ribbon(data = predicted, aes(ymin = CI_low_0.99, ymax = CI_high_0.99, fill = Species), alpha = 0.2) +   geom_ribbon(data = predicted, aes(ymin = CI_low_0.89, ymax = CI_high_0.89, fill = Species), alpha = 0.3) +   geom_ribbon(data = predicted, aes(ymin = CI_low_0.69, ymax = CI_high_0.69, fill = Species), alpha = 0.3) +   geom_line(data = predicted, aes(y = Predicted, color = Species), linewidth = 1) +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/articles/estimate_response.html","id":"adding-individual-iterations","dir":"Articles","previous_headings":"","what":"Adding individual iterations","title":"Use a model to make predictions","text":"Let‚Äôs now fit model Bayesian framework. Note: ‚Äôre familiar Bayesian framework, recommend starting gentle introduction. refresh seed arguments included reproducibility readability, critical model. Instead (addition ) representing confidence intervals, one can also represent every individual posterior draw, correspond random selection possible links compatible observed data. nice insight ‚Äútrue‚Äù underlying probabilities.  Note also possible obtain similar plots without Bayesian models, bootstrapping predictions. can done setting iterations argument number (e.g., 50).","code":"library(rstanarm)  model <- stan_glm(Petal.Length ~ Sepal.Length * Species,   refresh = 0, seed = 3,   data = iris ) # Keep only 100 draws (keeping all the draws is slower) predicted <- estimate_relation(model, keep_iterations = TRUE, iterations = 100)  # Format draws for plotting iterations <- bayestestR::reshape_iterations(predicted) iterations$group <- paste0(iterations$iter_group, iterations$Species)  iris |>   ggplot(aes(x = Sepal.Length)) +   geom_point(aes(y = Petal.Length, color = Species)) +   geom_line(data = iterations, aes(y = iter_value, color = Species, group = group), alpha = 0.1) +   geom_line(data = predicted, aes(y = Predicted, color = Species), linewidth = 1) +   theme_minimal() model <- lm(Petal.Length ~ Sepal.Length * Species, data = iris)  # Bootstrap with n=50 iterations predicted <- estimate_relation(model, keep_iterations = TRUE, iterations = 50)  # Format draws for plotting iterations <- bayestestR::reshape_iterations(predicted) iterations$group <- paste0(iterations$iter_group, iterations$Species)  p <- iris |>   ggplot(aes(x = Sepal.Length)) +   geom_point(aes(y = Petal.Length, color = Species)) +   geom_line(data = iterations, aes(y = iter_value, color = Species, group = group), alpha = 0.1) +   geom_line(data = predicted, aes(y = Predicted, color = Species), linewidth = 1) +   theme_minimal() p"},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/estimate_slopes.html","id":"marginal-effects-over-a-factors-levels","dir":"Articles","previous_headings":"","what":"Marginal effects over a factor‚Äôs levels","title":"Estimate marginal effects","text":"Let‚Äôs fit linear model factor interacting continuous predictor visualize .  seems like slope effect roughly similar (direction) across different factor levels. Moreover, interaction significant. However, see removing interaction substantially improve model‚Äôs performance. , sake demonstration, let‚Äôs say want keep maximal effect structure. Although satisfied model performance, imagine interested effect Petal.Length different Species, rather, general trend ‚Äúacross‚Äù different species. need compute marginal effect predictor, corresponds slope averaged (‚Äôs bit complex simple averaging ‚Äôs idea) different factor levels. can see effect Petal.Length, marginalized Species, positive significant.","code":"library(ggplot2) library(parameters) library(performance) library(modelbased)  model <- lm(Sepal.Length ~ Petal.Length * Species, data = iris)  estimate_relation(model) |>   plot() parameters(model) > Parameter                           | Coefficient |   SE |         95% CI > ------------------------------------------------------------------------- > (Intercept)                         |        4.21 | 0.41 | [ 3.41,  5.02] > Petal Length                        |        0.54 | 0.28 | [ 0.00,  1.09] > Species [versicolor]                |       -1.81 | 0.60 | [-2.99, -0.62] > Species [virginica]                 |       -3.15 | 0.63 | [-4.41, -1.90] > Petal Length √ó Species [versicolor] |        0.29 | 0.30 | [-0.30,  0.87] > Petal Length √ó Species [virginica]  |        0.45 | 0.29 | [-0.12,  1.03] >  > Parameter                           | t(144) |      p > ----------------------------------------------------- > (Intercept)                         |  10.34 | < .001 > Petal Length                        |   1.96 | 0.052  > Species [versicolor]                |  -3.02 | 0.003  > Species [virginica]                 |  -4.97 | < .001 > Petal Length √ó Species [versicolor] |   0.97 | 0.334  > Petal Length √ó Species [virginica]  |   1.56 | 0.120 model2 <- lm(Sepal.Length ~ Petal.Length + Species, data = iris)  test_performance(model, model2) > Name   | Model |    BF | df | df_diff | Chi2 |     p > ---------------------------------------------------- > model  |    lm |       |  7 |         |      |       > model2 |    lm | 26.52 |  5 |   -2.00 | 3.47 | 0.177 > Models were detected as nested (in terms of fixed parameters) and are compared in sequential order. slopes <- estimate_slopes(model, trend = \"Petal.Length\")  slopes > Estimated Marginal Effects >  > Slope |   SE |       95% CI |    t |      p > ------------------------------------------- > 0.79  | 0.10 | [0.59, 0.99] | 7.69 | < .001 >  > Marginal effects estimated for Petal.Length > Type of slope was dY/dX"},{"path":"https://easystats.github.io/modelbased/articles/estimate_slopes.html","id":"effects-for-each-factors-levels","dir":"Articles","previous_headings":"","what":"Effects for each factor‚Äôs levels","title":"Estimate marginal effects","text":"","code":"slopes <- estimate_slopes(model, trend = \"Petal.Length\", by = \"Species\")  slopes > Estimated Marginal Effects >  > Species    | Slope |   SE |        95% CI |     t |      p > ---------------------------------------------------------- > setosa     |  0.54 | 0.28 | [ 0.00, 1.08] |  1.96 |  0.050 > versicolor |  0.83 | 0.10 | [ 0.63, 1.03] |  8.10 | < .001 > virginica  |  1.00 | 0.09 | [ 0.83, 1.17] | 11.43 | < .001 >  > Marginal effects estimated for Petal.Length > Type of slope was dY/dX plot(slopes)"},{"path":"https://easystats.github.io/modelbased/articles/estimate_slopes.html","id":"interactions-between-two-continuous-variables","dir":"Articles","previous_headings":"","what":"Interactions between two continuous variables","title":"Estimate marginal effects","text":"Interactions two continuous variables often straightforward visualize interpret. Thanks model-based approach, one can represent effect one variables function variable. plot, also referred Johnson-Neyman intervals, shows effect (‚Äúslope‚Äù) one variable varies depending another variable. useful case complex interactions continuous variables. instance, plot shows effect hp (y-axis) significantly negative wt low (< ~4).","code":"model <- lm(mpg ~ hp * wt, data = mtcars)  slopes <- estimate_slopes(model, trend = \"hp\", by = \"wt\")  plot(slopes) +   geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/articles/estimate_slopes.html","id":"describing-and-reporting-non-linear-relationships-e-g--in-gams","dir":"Articles","previous_headings":"","what":"Describing and reporting non-linear relationships (e.g., in GAMs)","title":"Estimate marginal effects","text":"Complex problems require modern solutions. General Additive Models (GAMs) powerful class models extend capabilities traditional GLMs. particular, able parsimoniously model possibly non-linear relationship. Let‚Äôs take instance following model:  GAMs nicely models complex relationship two variables (don‚Äôt take account different species course). interpret report manuscript results? can‚Äôt simply paste figure right? Right? Reviewers want statistics, numbers brackets, otherwise doesn‚Äôt look serious . problem GAMs parameters (.e., coefficients), easily interpretable. can see one line corresponding smooth term. ‚Äôs significant, great, mean? run GAM using packages (e.g., rstanarm brms), parameters . ! meaning parameters somewhat disconnected need relationship understanding, another possibility compute marginal linear effect smooth term, .e., ‚Äúderivative‚Äù, using estimate_slopes.  plot represents ‚Äúslope‚Äù curve point curve. can see, significant negative trend (Petal.Length = 4), followed significant positive trend (around Petal.Length = 4). Marginal derivatives allow us make inferences point point relationship! Finally, help reporting manuscript, can divide chunks obtain ‚Äúaverage‚Äù linear trend chunk. can conclude Petal.Length shares significantly negative relationship outcome variable 2.01 3.15 (average marginal effect = -0.76, 95% CI [-1.14, -0.37], p < .01) significantly positive 3.74 4.28 (average marginal effect = 0.54, 95% CI [0.14, 0.93], p < .05).","code":"# Fit a non-linear General Additive Model (GAM) model <- mgcv::gam(Sepal.Width ~ s(Petal.Length), data = iris)  estimate_relation(model, length = 50) |>   plot() parameters::parameters(model) > # Fixed Effects >  > Parameter   | Coefficient |   SE |       95% CI | t(142.33) |      p > -------------------------------------------------------------------- > (Intercept) |        3.06 | 0.03 | [3.01, 3.11] |    118.31 | < .001 >  > # Smooth Terms >  > Parameter                  |     F |   df |      p > -------------------------------------------------- > Smooth term (Petal Length) | 17.52 | 6.67 | < .001 # Compute derivative deriv <- estimate_slopes(model,   trend = \"Petal.Length\",   by = \"Petal.Length\",   length = 100 )  # Visualise plot(deriv) +   geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +   theme_minimal() summary(deriv)"},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/modelisation_approach.html","id":"the-empirical-approach-classic","dir":"Articles","previous_headings":"","what":"The Empirical Approach (Classic)","title":"The Modelisation Approach","text":"","code":"library(easystats) library(emmeans) library(ggplot2)"},{"path":"https://easystats.github.io/modelbased/articles/modelisation_approach.html","id":"data-simulation","dir":"Articles","previous_headings":"The Empirical Approach (Classic)","what":"Data Simulation","title":"The Modelisation Approach","text":"First run function simulate data. ‚Äôs need understand hows whys, explain everything due time.","code":"generate_data <- function(effect = 5, noise = 0.5) {   data <- data.frame()   n <- 100   for (i in 1:length(effect)) {     participant <- data.frame(Experimental_Variable = c(seq(-3, 3, length = n / 2), seq(-3, 3, length = n / 2)))     participant$RT <- c(participant$Experimental_Variable[1:(n / 2)]**2 - effect[i], (participant$Experimental_Variable[(n / 2 + 1):n] + effect[i])) + rnorm(n, 0, abs(noise[i]))     participant$Condition <- rep(c(\"A\", \"B\"), each = n / 2)     participant$Participant <- paste0(\"S\", i)     data <- rbind(data, participant)   }   data$RT <- (100 + data$RT) * 10   data }  data <- generate_data(effect = rnorm(30, 2, 2), noise = rnorm(30, 0, 0.4)) # # library(rtdists) # # data <- data.frame( #   Participant = paste0(\"S\", speed_acc$id), #   Item = as.numeric(speed_acc$stim), #   Condition = speed_acc$condition, #   Correct = ifelse(as.character(speed_acc$stim_cat) == as.character(speed_acc$response), 1, 0), #   RT = speed_acc$rt * 1000 # )"},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/modelisation_approach.html","id":"anovas","dir":"Articles","previous_headings":"The Empirical Approach (Classic)","what":"ANOVAs","title":"The Modelisation Approach","text":"ANOVAs, ‚Äôs groups. Even though people also add continuous variables (creating ANCOVAs, MANOVAs monstrosities), ‚Äôs really ‚Äúspirit‚Äù: ANOVAs made compare groups. take, participant, 20‚Ä¶ can conclude ? Absolutely nothing! need investigate details, instance running post-hoc comparison tests. uninformativeness one reason ANOVA banned psychological science.","code":"data_anova <- data data_anova$Category <- recode_into(   Experimental_Variable < -1.5 ~ \"Low\",   Experimental_Variable > 1.5 ~ \"High\",   default = \"Middle\",   data = data_anova ) data_anova$Category <- factor(data_anova$Category, levels = c(\"Low\", \"Middle\", \"High\"))  data_anova <<- data_anova |>   data_group(c(\"Participant\", \"Condition\", \"Category\")) |>   data_summary(RT = mean(RT))  results <- aov(RT ~ Condition * Category + Error(Participant), data = data_anova) parameters(results) > # Participant >  > Parameter | Sum_Squares | df | Mean_Square > ------------------------------------------ > Residuals |       33.32 | 29 |        1.15 >  > # Within >  > Parameter          | Sum_Squares |  df | Mean_Square |     F |      p > --------------------------------------------------------------------- > Condition          |       73.09 |   1 |       73.09 |  0.14 | 0.705  > Category           |    37375.24 |   2 |    18687.62 | 36.84 | < .001 > Condition:Category |    36990.41 |   2 |    18495.20 | 36.46 | < .001 > Residuals          |    73550.75 | 145 |      507.25 |       |        >  > Anova Table (Type 1 tests)"},{"path":"https://easystats.github.io/modelbased/articles/modelisation_approach.html","id":"post-hoc-comparison-tests","dir":"Articles","previous_headings":"The Empirical Approach (Classic)","what":"Post-hoc comparison tests","title":"The Modelisation Approach","text":"","code":"posthoc <- get_emmeans(results, by = c(\"Condition\", \"Category\")) |>   pairs() parameters(posthoc) > contrast            | Coefficient |   SE |           95% CI | t(145) |      p > ----------------------------------------------------------------------------- > A Low - B Low       |       36.83 | 5.82 | [ 25.33,  48.32] |   6.33 | < .001 > A Low - A Middle    |       46.52 | 5.82 | [ 35.02,  58.01] |   8.00 | < .001 > A Low - B Middle    |       14.18 | 5.82 | [  2.69,  25.67] |   2.44 | 0.491  > A Low - A High      |       -0.23 | 5.82 | [-11.73,  11.26] |  -0.04 | > .999 > A Low - B High      |       -8.54 | 5.82 | [-20.04,   2.95] |  -1.47 | 0.979  > B Low - A Middle    |        9.69 | 5.82 | [ -1.80,  21.18] |   1.67 | 0.940  > B Low - B Middle    |      -22.65 | 5.82 | [-34.14, -11.15] |  -3.89 | 0.012  > B Low - A High      |      -37.06 | 5.82 | [-48.55, -25.56] |  -6.37 | < .001 > B Low - B High      |      -45.37 | 5.82 | [-56.86, -33.87] |  -7.80 | < .001 > A Middle - B Middle |      -32.34 | 5.82 | [-43.83, -20.84] |  -5.56 | < .001 > A Middle - A High   |      -46.75 | 5.82 | [-58.24, -35.25] |  -8.04 | < .001 > A Middle - B High   |      -55.06 | 5.82 | [-66.55, -43.57] |  -9.47 | < .001 > B Middle - A High   |      -14.41 | 5.82 | [-25.90,  -2.92] |  -2.48 | 0.463  > B Middle - B High   |      -22.72 | 5.82 | [-34.21, -11.23] |  -3.91 | 0.012  > A High - B High     |       -8.31 | 5.82 | [-19.80,   3.18] |  -1.43 | 0.983  >  > p-value adjustment method: Tukey data_anova |>   ggplot(aes(x = Category, y = RT, fill = Condition)) +   geom_boxplot() +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/articles/modelisation_approach.html","id":"the-modelisation-approach","dir":"Articles","previous_headings":"","what":"The Modelisation Approach","title":"The Modelisation Approach","text":"model made parameters, ‚Äòreal‚Äô meaning, opposed indices significance (abstract).","code":""},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/modelisation_approach.html","id":"draw-what-you-want-to-visualize","dir":"Articles","previous_headings":"The Modelisation Approach","what":"1. Draw what you want to visualize","title":"The Modelisation Approach","text":"can use geom_smooth(), can fit non-linear relationships empirical way, give us idea shape relationships.","code":"data |>   data_group(c(\"Participant\", \"Condition\")) |>   ggplot(aes(x = Experimental_Variable, y = RT, color = Condition)) +   geom_jitter(alpha = 0.4) +   geom_smooth(method = \"loess\", se = FALSE) +   theme_minimal()"},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://easystats.github.io/modelbased/articles/overview_of_vignettes.html","id":"function-overview","dir":"Articles","previous_headings":"","what":"Function Overview","title":"Overview of Vignettes","text":"Function Documentation","code":""},{"path":"https://easystats.github.io/modelbased/articles/overview_of_vignettes.html","id":"articles","dir":"Articles","previous_headings":"","what":"Articles","title":"Overview of Vignettes","text":"Data grids , use get marginal means Contrast analysis Marginal effects derivatives Use model make predictions Interpret simple complex models using power Effect Derivatives use Mixed models Estimate Individuals‚Äô Scores Visualize effects interactions Modelisation Approach Statistics","code":""},{"path":"https://easystats.github.io/modelbased/articles/visualisation_matrix.html","id":"simple-linear-regression","dir":"Articles","previous_headings":"","what":"Simple linear regression","title":"Data grids","text":"instance, let‚Äôs fit simple linear model models relationship Sepal.Width Sepal.Length. obvious way representing model plot data points add regression line using geom_smooth function ggplot2:  ‚Äúaccess‚Äù data regression line? One good option select values predictor (Sepal.Length), predict (using base R predict() method now) response (Sepal.Width) using model. Using x y points, can create regression line. Let‚Äôs try get_datagrid() function insight package. pass numeric column function, return vector equally spread points (range, .e., minimum maximum, original data). default length 10, can adjust length argument. instance, linear relationships (.e., straight line), two points theory sufficient. Let‚Äôs generate predictions using reference grid predictor. Now x y values, can plot line overlay actual data points:  can see, quite similar previous plot. , can useful?","code":"library(easystats) library(ggplot2)  model <- lm(Sepal.Width ~ Sepal.Length, data = iris) parameters(model) > Parameter    | Coefficient |   SE |        95% CI | t(148) |      p > ------------------------------------------------------------------- > (Intercept)  |        3.42 | 0.25 | [ 2.92, 3.92] |  13.48 | < .001 > Sepal Length |       -0.06 | 0.04 | [-0.15, 0.02] |  -1.44 | 0.152 ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width)) +   geom_point() +   geom_smooth(method = \"lm\") +   theme_minimal() get_datagrid(iris[\"Sepal.Length\"]) > Visualisation Grid >  > Sepal.Length > ------------ > 4.30         > 4.70         > 5.10         > 5.50         > 5.90         > 6.30         > 6.70         > 7.10         > 7.50         > 7.90 vizdata <- get_datagrid(iris[\"Sepal.Length\"], length = 2) vizdata$Predicted <- predict(model, vizdata) vizdata > Visualisation Grid >  > Sepal.Length | Predicted > ------------------------ > 4.30         |      3.15 > 7.90         |      2.93 ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width)) +   geom_point() +   geom_line(data = vizdata, aes(y = Predicted), linewidth = 1, color = \"red\") +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/articles/visualisation_matrix.html","id":"mixed-models","dir":"Articles","previous_headings":"","what":"Mixed models","title":"Data grids","text":"Data grids useful represent complex models. instance, models , negative relationship length width sepals fact biased presence three different species. One way adjusting model grouping structure add random effect mixed model. model , ‚Äúfixed‚Äù effects (parameters interest) adjusted (‚Äúaveraged ‚Äù) random effects. can see, adjusting species, relationship two variables become positive! can represent using procedure , note instead using base R predict() function, using get_predicted(), insight package, robust user-friendly version predict().","code":"library(lme4)  model <- lmer(Sepal.Width ~ Sepal.Length + (1 | Species), data = iris) parameters(model) > # Fixed Effects >  > Parameter    | Coefficient |   SE |       95% CI | t(146) |      p > ------------------------------------------------------------------ > (Intercept)  |        1.04 | 0.43 | [0.20, 1.89] |   2.45 | 0.015  > Sepal Length |        0.34 | 0.05 | [0.25, 0.44] |   7.47 | < .001 >  > # Random Effects >  > Parameter               | Coefficient > ------------------------------------- > SD (Intercept: Species) |        0.57 > SD (Residual)           |        0.29 vizdata <- get_datagrid(iris[\"Sepal.Length\"]) vizdata$Predicted <- get_predicted(model, vizdata)  ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width)) +   geom_point(aes(color = Species)) +   geom_line(data = vizdata, aes(y = Predicted), linewidth = 1) +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/articles/visualisation_matrix.html","id":"fixed-variables","dir":"Articles","previous_headings":"","what":"Fixed variables","title":"Data grids","text":"way constructing reference grid, .e., providing single column data function, almost equivalent following: However, variables (present dataframe selected ) ‚Äúfixed‚Äù, .e., maintained specific values. useful variables model whose effect interested. default, factors fixed ‚Äúreference‚Äù level numeric variables fixed mean. However, can easily changed:","code":"vizdata <- get_datagrid(iris, by = \"Sepal.Length\") vizdata > Visualisation Grid >  > Sepal.Length | Sepal.Width | Petal.Length | Petal.Width | Species > ----------------------------------------------------------------- > 4.30         |        3.06 |         3.76 |        1.20 | setosa  > 4.70         |        3.06 |         3.76 |        1.20 | setosa  > 5.10         |        3.06 |         3.76 |        1.20 | setosa  > 5.50         |        3.06 |         3.76 |        1.20 | setosa  > 5.90         |        3.06 |         3.76 |        1.20 | setosa  > 6.30         |        3.06 |         3.76 |        1.20 | setosa  > 6.70         |        3.06 |         3.76 |        1.20 | setosa  > 7.10         |        3.06 |         3.76 |        1.20 | setosa  > 7.50         |        3.06 |         3.76 |        1.20 | setosa  > 7.90         |        3.06 |         3.76 |        1.20 | setosa  >  > Maintained constant: Sepal.Width, Petal.Length, Petal.Width, Species vizdata <- get_datagrid(iris, by = \"Sepal.Length\", numerics = \"min\") vizdata > Visualisation Grid >  > Sepal.Length | Sepal.Width | Petal.Length | Petal.Width | Species > ----------------------------------------------------------------- > 4.30         |           2 |            1 |        0.10 | setosa  > 4.70         |           2 |            1 |        0.10 | setosa  > 5.10         |           2 |            1 |        0.10 | setosa  > 5.50         |           2 |            1 |        0.10 | setosa  > 5.90         |           2 |            1 |        0.10 | setosa  > 6.30         |           2 |            1 |        0.10 | setosa  > 6.70         |           2 |            1 |        0.10 | setosa  > 7.10         |           2 |            1 |        0.10 | setosa  > 7.50         |           2 |            1 |        0.10 | setosa  > 7.90         |           2 |            1 |        0.10 | setosa  >  > Maintained constant: Sepal.Width, Petal.Length, Petal.Width, Species"},{"path":"https://easystats.github.io/modelbased/articles/visualisation_matrix.html","id":"target-variables","dir":"Articles","previous_headings":"","what":"Target variables","title":"Data grids","text":"one target variable selected, get_datagrid() return combination (.e., unique values crossed together). can useful case interaction numeric variable factor. Let‚Äôs visualise regression line levels Species:","code":"model <- lm(Sepal.Width ~ Sepal.Length * Species, data = iris)  vizdata <- get_datagrid(iris, by = c(\"Sepal.Length\", \"Species\"), length = 5) vizdata$Predicted <- get_predicted(model, vizdata) vizdata > Visualisation Grid >  > Sepal.Length | Species    | Sepal.Width | Petal.Length | Petal.Width | Predicted > -------------------------------------------------------------------------------- > 4.30         | setosa     |        3.06 |         3.76 |        1.20 |      2.86 > 5.20         | setosa     |        3.06 |         3.76 |        1.20 |      3.58 > 6.10         | setosa     |        3.06 |         3.76 |        1.20 |      4.30 > 7.00         | setosa     |        3.06 |         3.76 |        1.20 |      5.02 > 7.90         | setosa     |        3.06 |         3.76 |        1.20 |      5.74 > 4.30         | versicolor |        3.06 |         3.76 |        1.20 |      2.25 > 5.20         | versicolor |        3.06 |         3.76 |        1.20 |      2.53 > 6.10         | versicolor |        3.06 |         3.76 |        1.20 |      2.82 > 7.00         | versicolor |        3.06 |         3.76 |        1.20 |      3.11 > 7.90         | versicolor |        3.06 |         3.76 |        1.20 |      3.40 > 4.30         | virginica  |        3.06 |         3.76 |        1.20 |      2.44 > 5.20         | virginica  |        3.06 |         3.76 |        1.20 |      2.65 > 6.10         | virginica  |        3.06 |         3.76 |        1.20 |      2.86 > 7.00         | virginica  |        3.06 |         3.76 |        1.20 |      3.07 > 7.90         | virginica  |        3.06 |         3.76 |        1.20 |      3.28 >  > Maintained constant: Sepal.Width, Petal.Length, Petal.Width ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +   geom_point() +   geom_line(data = vizdata, aes(y = Predicted), linewidth = 1) +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/articles/visualisation_matrix.html","id":"preserve-range","dir":"Articles","previous_headings":"","what":"Preserve range","title":"Data grids","text":"However, generally good practice extend regression lines beyond range original data, case red line. preserve_range option allows remove observations ‚Äúoutside‚Äù original dataset (however, length increased improve precision toward edges):","code":"vizdata <- get_datagrid(iris,   by = c(\"Sepal.Length\", \"Species\"),   length = 100,   preserve_range = TRUE )  vizdata$Predicted_Sepal.Width <- get_predicted(model, vizdata)  ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +   geom_point() +   geom_line(data = vizdata, aes(y = Predicted_Sepal.Width), linewidth = 1) +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/articles/visualisation_matrix.html","id":"visualising-an-interaction-between-two-numeric-variables-three-way-interaction","dir":"Articles","previous_headings":"","what":"Visualising an interaction between two numeric variables (three-way interaction)","title":"Data grids","text":"idea can also used visualise interactions two numeric variables, aka nightmare every scientist. One possibility basically represent relationship response one predictor representative values second predictor. case, represent regression line Sepal.Length Petal.Length 5 equally spaced values Petal.Length, get feel interaction. can obtain right reference grid quite easily chaining two data grids together follows: ? started generating reference grid containing combinations 10 equally spread values two target variables, creating 10 * 10 = 100 rows. next step reduce Petal.Length set 5 values, without touching variables (.e., keeping 10 values created Petal.Length). achieved using numerics = \"\". can visualise follows:  plot can clear expressing interaction variable terms deviations mean (standardized variable).  Petal.Width increases (becomes yellow), coefficient Petal.Length Sepal.Length increases (slope steep). Although, can guess, fact captures underlying effect species‚Ä¶ ‚Äôll leave discussing meaningfulness models :)","code":"model <- lm(Sepal.Length ~ Petal.Length * Petal.Width, data = iris) parameters(model) > Parameter                  | Coefficient |   SE |         95% CI | t(146) |      p > ---------------------------------------------------------------------------------- > (Intercept)                |        4.58 | 0.11 | [ 4.36,  4.80] |  40.89 | < .001 > Petal Length               |        0.44 | 0.07 | [ 0.31,  0.57] |   6.74 | < .001 > Petal Width                |       -1.24 | 0.22 | [-1.67, -0.81] |  -5.65 | < .001 > Petal Length √ó Petal Width |        0.19 | 0.03 | [ 0.12,  0.25] |   5.62 | < .001 vizdata <- iris |>   get_datagrid(c(\"Petal.Length\", \"Petal.Width\"), length = 10) |>   get_datagrid(\"Petal.Width\", length = 5, numerics = \"all\") vizdata$Predicted <- get_predicted(model, vizdata)  iris |>   ggplot(aes(x = Petal.Length, y = Sepal.Length, color = Petal.Width)) +   geom_point() +   geom_line(data = vizdata, aes(y = Predicted, group = Petal.Width), linewidth = 1) +   scale_color_viridis_c() +   theme_minimal() # Express values in an abstract way vizdata$Petal.Width <- effectsize::format_standardize(   vizdata$Petal.Width,   reference = iris$Petal.Width )  ggplot(iris, aes(x = Petal.Length, y = Sepal.Length)) +   # Only shapes from 21 to 25 have a fill aesthetic   geom_point2(aes(fill = Petal.Width), color = \"white\", shape = 21, size = 5) +   geom_line(data = vizdata, aes(y = Predicted, color = Petal.Width), linewidth = 1) +   scale_color_viridis_d(direction = -1) +   scale_fill_viridis_c(guide = \"none\") +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/articles/visualisation_matrix.html","id":"get_datagrid-also-runs-directly-on-model-objects","dir":"Articles","previous_headings":"","what":"get_datagrid() also runs directly on model objects","title":"Data grids","text":"illustrate , let‚Äôs set general additive mixed model (GAMM), going specify smooth term (non-linear relationship; specified s() function) random effects structure. One can directly extract visualization matrix model entering entire object function: also skip smooth term interested fixed effects: can also include random effects:","code":"library(gamm4)  model <- gamm4::gamm4(   formula = Petal.Length ~ Petal.Width + s(Sepal.Length),   random = ~ (1 | Species),   data = iris ) get_datagrid(model, length = 3, include_random = FALSE) > Visualisation Grid >  > Petal.Width | Sepal.Length > -------------------------- > 0.10        |         4.30 > 1.30        |         4.30 > 2.50        |         4.30 > 0.10        |         6.10 > 1.30        |         6.10 > 2.50        |         6.10 > 0.10        |         7.90 > 1.30        |         7.90 > 2.50        |         7.90 get_datagrid(model, length = 3, include_random = FALSE, include_smooth = FALSE) > Visualisation Grid >  > Petal.Width > ----------- > 0.10        > 1.30        > 2.50        >  > Maintained constant: Sepal.Length get_datagrid(model, length = 5, include_random = TRUE) > Visualisation Grid >  > Petal.Width | Sepal.Length | Species    > --------------------------------------- > 0.10        |         4.30 | setosa     > 0.10        |         5.20 | setosa     > 1.30        |         5.20 | versicolor > 1.30        |         6.10 | versicolor > 1.30        |         7.00 | versicolor > 1.90        |         5.20 | virginica  > 2.50        |         5.20 | virginica  > 1.90        |         6.10 | virginica  > 2.50        |         6.10 | virginica  > 1.90        |         7.00 | virginica  > 2.50        |         7.00 | virginica  > 1.90        |         7.90 | virginica  > 2.50        |         7.90 | virginica"},{"path":"https://easystats.github.io/modelbased/articles/visualisation_matrix.html","id":"controlled-standardized-change","dir":"Articles","previous_headings":"","what":"Controlled standardized change","title":"Data grids","text":"Although plot nice, , like standardized changes SD smoother (e.g., increments 1 SD). can achieved first requesting values want, unstandardizing . Let‚Äôs use model , obtain data grid specific values Petal.Width.","code":"vizdata <- lm(Sepal.Length ~ Petal.Length * Petal.Width, data = iris) |>   get_datagrid(by = c(\"Petal.Length\", \"Petal.Width = seq(-3, 3)\")) |>   unstandardize(vizdata, select = \"Petal.Width\") |>   estimate_relation(vizdata)  vizdata$Petal.Width <- effectsize::format_standardize(vizdata$Petal.Width, reference = iris$Petal.Width)  # 6. Plot ggplot(iris, aes(x = Petal.Length, y = Sepal.Length)) +   geom_point2(aes(fill = Petal.Width), shape = 21, size = 5) +   geom_line(data = vizdata, aes(y = Predicted, color = Petal.Width), linewidth = 1) +   scale_color_viridis_d(direction = -1) +   scale_fill_viridis_c(guide = \"none\") +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Dominique Makowski. Author, maintainer. Daniel L√ºdecke. Author. Mattan S. Ben-Shachar. Author. Indrajeet Patil. Author.","code":""},{"path":"https://easystats.github.io/modelbased/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Makowski, D., Ben-Shachar, M. S., Patil, ., & L√ºdecke, D. (2020). Estimation Model-Based Predictions, Contrasts Means. CRAN.","code":"@Article{,   title = {Estimation of Model-Based Predictions, Contrasts and Means.},   author = {Dominique Makowski and Mattan S. Ben-Shachar and Indrajeet Patil and Daniel L√ºdecke},   journal = {CRAN},   year = {2020},   url = {https://github.com/easystats/modelbased}, }"},{"path":"https://easystats.github.io/modelbased/index.html","id":"modelbased-","dir":"","previous_headings":"","what":"Estimation of Model-Based Predictions, Contrasts and Means","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Make models modelbased package helping model-based estimations, easily compute marginal means, contrast analysis model predictions.","code":""},{"path":"https://easystats.github.io/modelbased/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"modelbased package available CRAN, latest development version available R-universe (rOpenSci). downloaded package, can load using: [!TIP] Instead library(modelbased), use library(easystats), make features easystats-ecosystem available. can also use easystats::install_latest() stay updated.","code":"library(\"modelbased\")"},{"path":"https://easystats.github.io/modelbased/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Access package documentation, check-vignettes: Data grids , use get marginal means Contrast analysis Marginal effects derivatives Use model make predictions Interpret simple complex models using power effect derivatives use mixed models estimate individuals‚Äô scores Visualize effects interactions modelisation approach statistics","code":""},{"path":"https://easystats.github.io/modelbased/index.html","id":"features","dir":"","previous_headings":"","what":"Features","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"core idea behind modelbased package statistical models often contain lot insights get simply looking model parameters. many cases, like models multiple interactions, non-linear effects, non-standard families, complex random effect structures, parameters can hard interpret. modelbased package comes . give simply example, imagine interested effect 3 conditions , B C variable Y. simple linear model Y ~ Condition give 3 parameters: intercept (average value Y condition ), relative effect condition B C. like also get average value Y conditions . Many people compute average ‚Äúhand‚Äù (.e., empirical average) directly averaging observed data groups. know estimated average (can much relevant, e.g., adjust variables model) contained model, can get easily running estimate_means()? modelbased package built around 4 main functions: estimate_means(): Estimates average values factor levels estimate_contrasts(): Estimates tests contrasts different factor levels estimate_slopes(): Estimates slopes numeric predictors different factor levels alongside numeric predictor estimate_prediction(): Make predictions using model functions based important statistical concepts, like data grids, predictions marginal effects, leverages packages like emmeans marginaleffects. recommend reading get deeper understanding hidden power models.","code":""},{"path":[]},{"path":"https://easystats.github.io/modelbased/index.html","id":"estimate-marginal-means","dir":"","previous_headings":"Examples","what":"Estimate marginal means","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Problem: model factor predictor, parameters return difference levels intercept. want see values factor level. Solution: Estimate model-based means (‚Äúmarginal means‚Äù). can visualize plotting confidence interval original data. Check-function documentation vignette detailed walkthrough marginal means.","code":"library(modelbased) library(ggplot2)  # 1. The model model <- lm(Sepal.Width ~ Species, data = iris)  # 2. Obtain estimated means means <- estimate_means(model, by = \"Species\") means ## Estimated Marginal Means ##  ## Species    | Mean |   SE |       95% CI | t(147) ## ------------------------------------------------ ## setosa     | 3.43 | 0.05 | [3.33, 3.52] |  71.36 ## versicolor | 2.77 | 0.05 | [2.68, 2.86] |  57.66 ## virginica  | 2.97 | 0.05 | [2.88, 3.07] |  61.91 ##  ## Variable predicted: Sepal.Width ## Predictors modulated: Species  # 3. Custom plot ggplot(iris, aes(x = Species, y = Sepal.Width)) +   # Add base data   geom_violin(aes(fill = Species), color = \"white\") +   geom_jitter(width = 0.1, height = 0, alpha = 0.5, size = 3) +   # Add pointrange and line for means   geom_line(data = means, aes(y = Mean, group = 1), linewidth = 1) +   geom_pointrange(     data = means,     aes(y = Mean, ymin = CI_low, ymax = CI_high),     size = 1,     color = \"white\"   ) +   # Improve colors   scale_fill_manual(values = c(\"pink\", \"lightblue\", \"lightgreen\")) +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/index.html","id":"contrast-analysis","dir":"","previous_headings":"Examples","what":"Contrast analysis","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Problem: parameters model return difference factor levels intercept. want see differences levels, post-hoc comparison tests ANOVAs. Solution: Estimate model-based contrasts (‚Äúmarginal contrasts‚Äù). can visualize plotting confidence interval. Check-vignette detailed walkthrough contrast analysis.","code":"# 1. The model model <- lm(Sepal.Width ~ Species, data = iris)  # 2. Estimate marginal contrasts contrasts <- estimate_contrasts(model, contrast = \"Species\") contrasts ## Marginal Contrasts Analysis ##  ## Level1     | Level2     | Difference |   SE |         95% CI | t(147) |      p ## ------------------------------------------------------------------------------ ## versicolor | setosa     |      -0.66 | 0.07 | [-0.79, -0.52] |  -9.69 | < .001 ## virginica  | setosa     |      -0.45 | 0.07 | [-0.59, -0.32] |  -6.68 | < .001 ## virginica  | versicolor |       0.20 | 0.07 | [ 0.07,  0.34] |   3.00 |  0.003 ##  ## Variable predicted: Sepal.Width ## Predictors contrasted: Species ## p-values are uncorrected."},{"path":"https://easystats.github.io/modelbased/index.html","id":"check-the-contrasts-at-different-points-of-another-linear-predictor","dir":"","previous_headings":"Examples","what":"Check the contrasts at different points of another linear predictor","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Problem: case interaction factor continuous variable, might interested computing differences factor levels (contrasts) change depending continuous variable. Solution: can estimate marginal contrasts different values continuous variable (modulator), plot differences (significant 95% CI doesn‚Äôt cover 0).","code":"model <- lm(Sepal.Width ~ Species * Petal.Length, data = iris) difference <- estimate_contrasts(   model,   contrast = \"Species\",   by = \"Petal.Length\",   length = 3 ) # no line break for table print(difference, table_width = Inf) ## Marginal Contrasts Analysis ##  ## Level1     | Level2     | Petal.Length | Difference |   SE |         95% CI | t(144) |      p ## --------------------------------------------------------------------------------------------- ## versicolor | setosa     | 1.00         |      -1.70 | 0.34 | [-2.37, -1.02] |  -4.97 | < .001 ## versicolor | setosa     | 3.95         |      -1.74 | 0.65 | [-3.03, -0.45] |  -2.67 |  0.008 ## versicolor | setosa     | 6.90         |      -1.78 | 1.44 | [-4.62,  1.06] |  -1.24 |  0.218 ## virginica  | setosa     | 1.00         |      -1.34 | 0.40 | [-2.13, -0.56] |  -3.38 | < .001 ## virginica  | setosa     | 3.95         |      -1.79 | 0.66 | [-3.11, -0.48] |  -2.70 |  0.008 ## virginica  | setosa     | 6.90         |      -2.25 | 1.42 | [-5.06,  0.56] |  -1.58 |  0.116 ## virginica  | versicolor | 1.00         |       0.36 | 0.49 | [-0.61,  1.33] |   0.73 |  0.468 ## virginica  | versicolor | 3.95         |      -0.06 | 0.15 | [-0.35,  0.24] |  -0.37 |  0.710 ## virginica  | versicolor | 6.90         |      -0.47 | 0.28 | [-1.03,  0.09] |  -1.65 |  0.101 ##  ## Variable predicted: Sepal.Width ## Predictors contrasted: Species ## p-values are uncorrected. # Recompute contrasts with a higher precision (for a smoother plot) contrasts <- estimate_contrasts(   model,   contrast = \"Species\",   by = \"Petal.Length\",   length = 20,   # we use a emmeans here because marginaleffects doesn't   # generate more than 25 rows for pairwise comparisons   backend = \"emmeans\" )  # Add Contrast column by concatenating contrasts$Contrast <- paste(contrasts$Level1, \"-\", contrasts$Level2)  # Plot ggplot(contrasts, aes(x = Petal.Length, y = Difference, )) +   # Add line and CI band   geom_line(aes(color = Contrast)) +   geom_ribbon(aes(ymin = CI_low, ymax = CI_high, fill = Contrast), alpha = 0.2) +   # Add line at 0, indicating no difference   geom_hline(yintercept = 0, linetype = \"dashed\") +   # Colors   theme_modern()"},{"path":"https://easystats.github.io/modelbased/index.html","id":"create-smart-grids-to-represent-complex-interactions","dir":"","previous_headings":"Examples","what":"Create smart grids to represent complex interactions","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Problem: want graphically represent interaction two continuous variable. top , like express one terms standardized change (.e., standard deviation relative mean). Solution: Create data grid following desired specifications, feed model obtain predictions. Format columns better readability, plot using ggplot. Check-vignette detailed walkthrough visualisation matrices.","code":"# 1. Fit model and get visualization matrix model <- lm(Sepal.Length ~ Petal.Length * Petal.Width, data = iris)  # 2. Create a visualisation matrix with expected Z-score values of Petal.Width vizdata <- insight::get_datagrid(model, by = c(\"Petal.Length\", \"Petal.Width = c(-1, 0, 1)\"))  # 3. Revert from expected SD to actual values vizdata <- unstandardize(vizdata, select = \"Petal.Width\")  # 4. Add predicted relationship from the model vizdata <- modelbased::estimate_expectation(vizdata)  # 5. Express Petal.Width as z-score (\"-1 SD\", \"+2 SD\", etc.) vizdata$Petal.Width <- effectsize::format_standardize(vizdata$Petal.Width, reference = iris$Petal.Width)  # 6. Plot ggplot(iris, aes(x = Petal.Length, y = Sepal.Length)) +   # Add points from original dataset (only shapes 21-25 have a fill aesthetic)   geom_point(aes(fill = Petal.Width), size = 5, shape = 21) +   # Add relationship lines   geom_line(data = vizdata, aes(y = Predicted, color = Petal.Width), linewidth = 1) +   # Improve colors / themes   scale_color_viridis_d(direction = -1) +   scale_fill_viridis_c(guide = \"none\") +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/index.html","id":"generate-predictions-from-your-model-to-compare-it-with-original-data","dir":"","previous_headings":"Examples","what":"Generate predictions from your model to compare it with original data","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Problem: fitted different models, want intuitively visualize compare terms fit quality prediction accuracy, don‚Äôt rely abstract indices performance. Solution: can predict response variable different models plot original true response. closest points identity line (diagonal), closest perfect fit. Check-vignette detailed walkthrough predictions.","code":"# Fit model 1 and predict the response variable model1 <- lm(Petal.Length ~ Sepal.Length, data = iris) pred1 <- estimate_expectation(model1) pred1$Petal.Length <- iris$Petal.Length # Add true response  # Print first 5 lines of output head(pred1, n = 5) ## Model-based Predictions ##  ## Sepal.Length | Predicted |   SE |       95% CI | Residuals | Petal.Length ## ------------------------------------------------------------------------- ## 5.10         |      2.38 | 0.10 | [2.19, 2.57] |     -0.98 |         1.40 ## 4.90         |      2.00 | 0.11 | [1.79, 2.22] |     -0.60 |         1.40 ## 4.70         |      1.63 | 0.12 | [1.39, 1.87] |     -0.33 |         1.30 ## 4.60         |      1.45 | 0.13 | [1.19, 1.70] |      0.05 |         1.50 ## 5.00         |      2.19 | 0.10 | [1.99, 2.39] |     -0.79 |         1.40 ##  ## Variable predicted: Petal.Length  # Same for model 2 model2 <- lm(Petal.Length ~ Sepal.Length * Species, data = iris) pred2 <- estimate_expectation(model2) pred2$Petal.Length <- iris$Petal.Length   # Initialize plot for model 1 ggplot(data = pred1, aes(x = Petal.Length, y = Predicted)) +   # with identity line (diagonal) representing perfect predictions   geom_abline(linetype = \"dashed\") +   # Add the actual predicted points of the models   geom_point(aes(color = \"Model 1\")) +   geom_point(data = pred2, aes(color = \"Model 2\")) +   # Aesthetics changes   labs(y = \"Petal.Length (predicted)\", color = NULL) +   scale_color_manual(values = c(\"Model 1\" = \"blue\", \"Model 2\" = \"red\")) +   theme_modern()"},{"path":"https://easystats.github.io/modelbased/index.html","id":"extract-and-format-group-level-random-effects","dir":"","previous_headings":"Examples","what":"Extract and format group-level random effects","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Problem: mixed model like easily access random part, .e., group-level effects (e.g., individuals scores). Solution: can apply estimate_grouplevel mixed model. See vignette information.","code":"library(lme4)  model <- lmer(mpg ~ drat + (1 + drat | cyl), data = mtcars)  random <- estimate_grouplevel(model) random ## Group | Level | Parameter   | Coefficient |   SE |         95% CI ## ----------------------------------------------------------------- ## cyl   | 4     | (Intercept) |       -3.45 | 0.56 | [-4.55, -2.36] ## cyl   | 4     | drat        |        2.24 | 0.36 | [ 1.53,  2.95] ## cyl   | 6     | (Intercept) |        0.13 | 0.84 | [-1.52,  1.78] ## cyl   | 6     | drat        |       -0.09 | 0.54 | [-1.15,  0.98] ## cyl   | 8     | (Intercept) |        3.32 | 0.73 | [ 1.89,  4.74] ## cyl   | 8     | drat        |       -2.15 | 0.47 | [-3.07, -1.23]  plot(random) +   geom_hline(yintercept = 0, linetype = \"dashed\") +   theme_minimal()"},{"path":"https://easystats.github.io/modelbased/index.html","id":"estimate-derivative-of-non-linear-relationships-eg-in-gams","dir":"","previous_headings":"Examples","what":"Estimate derivative of non-linear relationships (e.g., in GAMs)","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Problem: model non-linear relationship using polynomials, splines GAMs. want know parts curve significant positive negative trends. Solution: can estimate derivative smooth using estimate_slopes. two plots represent modeled (non-linear) effect estimated model, .e., relationship outcome predictor, well ‚Äútrend‚Äù (slope) relationship given point. can see whenever slope negative, effect 0, vice versa, regions effect significant (.e., positive negative enough confidence) others denote regions relationship rather flat. Check-vignette detailed walkthrough marginal effects.","code":"library(patchwork)  # Fit a non-linear General Additive Model (GAM) model <- mgcv::gam(Sepal.Width ~ s(Petal.Length), data = iris)  # 1. Compute derivatives deriv <- estimate_slopes(model,   trend = \"Petal.Length\",   by = \"Petal.Length\",   length = 100 )  # 2. Visualize predictions and derivative plot(estimate_relation(model, length = 100)) /   plot(deriv) +   geom_hline(yintercept = 0, linetype = \"dashed\")"},{"path":"https://easystats.github.io/modelbased/index.html","id":"describe-the-smooth-term-by-its-linear-parts","dir":"","previous_headings":"Examples","what":"Describe the smooth term by its linear parts","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Problem: model non-linear relationship using polynomials, splines GAMs. want describe terms linear parts: decrease, much, increase, etc. Solution: can apply describe_nonlinear() predicted relationship return different parts increase decrease.","code":"model <- lm(Sepal.Width ~ poly(Petal.Length, 2), data = iris)  # 1. Visualize vizdata <- estimate_relation(model, length = 30)  ggplot(vizdata, aes(x = Petal.Length, y = Predicted)) +   geom_ribbon(aes(ymin = CI_low, ymax = CI_high), alpha = 0.3) +   geom_line() +   # Add original data points   geom_point(data = iris, aes(x = Petal.Length, y = Sepal.Width)) +   # Aesthetics   theme_modern() # 2. Describe smooth line describe_nonlinear(vizdata, x = \"Petal.Length\") ## Start |  End | Length | Change | Slope |   R2 ## --------------------------------------------- ## 1.00  | 4.05 |   0.50 |  -0.84 | -0.28 | 0.05 ## 4.05  | 6.90 |   0.47 |   0.66 |  0.23 | 0.05"},{"path":"https://easystats.github.io/modelbased/index.html","id":"plot-all-posterior-draws-for-bayesian-models-predictions","dir":"","previous_headings":"Examples","what":"Plot all posterior draws for Bayesian models predictions","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"See vignette walkthrough .","code":""},{"path":"https://easystats.github.io/modelbased/index.html","id":"visualize-predictions-with-random-effects","dir":"","previous_headings":"Examples","what":"Visualize predictions with random effects","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Aside plotting coefficient random effect (done ), can also visualize predictions model levels, can useful diagnostic see contribute fixed effects. making predictions estimate_relation() setting include_random TRUE. Let‚Äôs model reaction time number days sleep deprivation fixed effect participants random intercept.  can see, participant different ‚Äúintercept‚Äù (starting point y-axis), slopes : slope ‚Äúgeneral‚Äù one estimated across participants fixed effect. Let‚Äôs address allow slope vary participant .  can see, effect now different participants. Let‚Äôs plot, top , ‚Äúfixed‚Äù effect estimated across individual effects.","code":"library(lme4)  model <- lmer(Reaction ~ Days + (1 | Subject), data = sleepstudy)  preds <- estimate_relation(model, include_random = TRUE)  plot(preds, ribbon = list(alpha = 0)) # Make CI ribbon transparent for clarity model <- lmer(Reaction ~ Days + (1 + Days | Subject), data = sleepstudy)  preds <- estimate_relation(model, include_random = TRUE)  plot(preds, ribbon = list(alpha = 0.1)) fixed_pred <- estimate_relation(model) # This time, include_random is FALSE (default)  plot(preds, ribbon = list(alpha = 0)) + # Previous plot   geom_ribbon(data = fixed_pred, aes(x = Days, ymin = CI_low, ymax = CI_high), alpha = 0.4) +   geom_line(data = fixed_pred, aes(x = Days, y = Predicted), linewidth = 2)"},{"path":"https://easystats.github.io/modelbased/index.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Estimation of Model-Based Predictions, Contrasts and Means","text":"Please note modelbased project released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"https://easystats.github.io/modelbased/reference/coffee_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample dataset from a course about analysis of factorial designs ‚Äî coffee_data","title":"Sample dataset from a course about analysis of factorial designs ‚Äî coffee_data","text":"sample data set course analysis factorial designs, Mattan S. Ben-Shachar. See following link information: https://github.com/mattansb/Analysis--Factorial-Designs--Psychologists data consists five variables 120 observations: ID: unique identifier participant sex: participant's sex time: time day participant tested (morning, noon, afternoon) coffee: Group indicator, whether participant drank coffee (\"coffee\" \"control\"). alertness: participant's alertness score.","code":""},{"path":"https://easystats.github.io/modelbased/reference/describe_nonlinear.html","id":null,"dir":"Reference","previous_headings":"","what":"Describe the smooth term (for GAMs) or non-linear predictors ‚Äî describe_nonlinear","title":"Describe the smooth term (for GAMs) or non-linear predictors ‚Äî describe_nonlinear","text":"function summarises smooth term trend terms linear segments. Using approximate derivative, separates non-linear vector quasi-linear segments (trend either positive negative). segment characterized beginning, end, size (proportion, relative total size) trend (linear regression coefficient) linearity (R2 linear regression).","code":""},{"path":"https://easystats.github.io/modelbased/reference/describe_nonlinear.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Describe the smooth term (for GAMs) or non-linear predictors ‚Äî describe_nonlinear","text":"","code":"describe_nonlinear(data, ...)  # S3 method for class 'data.frame' describe_nonlinear(data, x = NULL, y = NULL, ...)  estimate_smooth(data, ...)"},{"path":"https://easystats.github.io/modelbased/reference/describe_nonlinear.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Describe the smooth term (for GAMs) or non-linear predictors ‚Äî describe_nonlinear","text":"data data containing link, instance obtained estimate_relation(). ... arguments passed . x, y name responses variable (y) predicting variable (x).","code":""},{"path":"https://easystats.github.io/modelbased/reference/describe_nonlinear.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Describe the smooth term (for GAMs) or non-linear predictors ‚Äî describe_nonlinear","text":"data frame linear description non-linear terms.","code":""},{"path":"https://easystats.github.io/modelbased/reference/describe_nonlinear.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Describe the smooth term (for GAMs) or non-linear predictors ‚Äî describe_nonlinear","text":"","code":"# Create data data <- data.frame(x = rnorm(200)) data$y <- data$x^2 + rnorm(200, 0, 0.5)  model <<- lm(y ~ poly(x, 2), data = data) link_data <- estimate_relation(model, length = 100)  describe_nonlinear(link_data, x = \"x\") #> Start |   End | Length | Change | Slope |   R2 #> ---------------------------------------------- #> -2.61 | -0.06 |   0.47 |  -6.57 | -2.58 | 0.02 #> -0.06 |  2.76 |   0.52 |   7.55 |  2.68 | 0.02"},{"path":"https://easystats.github.io/modelbased/reference/dot-uniroot.all.html","id":null,"dir":"Reference","previous_headings":"","what":"Copied from rootSolve package ‚Äî .uniroot.all","title":"Copied from rootSolve package ‚Äî .uniroot.all","text":"Copied rootSolve package","code":""},{"path":"https://easystats.github.io/modelbased/reference/dot-uniroot.all.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Copied from rootSolve package ‚Äî .uniroot.all","text":"","code":".uniroot.all(   f,   interval,   lower = min(interval),   upper = max(interval),   tol = .Machine$double.eps^0.2,   maxiter = 1000,   n = 100,   ... )"},{"path":"https://easystats.github.io/modelbased/reference/efc.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample dataset from the EFC Survey ‚Äî efc","title":"Sample dataset from the EFC Survey ‚Äî efc","text":"Selected variables EUROFAMCARE survey. Useful testing \"real-life\" data sets, including random missing values. data set also value variable label attributes.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_contrasts.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Marginal Contrasts ‚Äî estimate_contrasts","title":"Estimate Marginal Contrasts ‚Äî estimate_contrasts","text":"Run contrast analysis estimating differences level factor. See also related functions estimate_means() estimate_slopes().","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_contrasts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Marginal Contrasts ‚Äî estimate_contrasts","text":"","code":"estimate_contrasts(   model,   contrast = NULL,   by = NULL,   predict = NULL,   ci = 0.95,   p_adjust = \"none\",   comparison = \"pairwise\",   marginalize = \"average\",   backend = getOption(\"modelbased_backend\", \"marginaleffects\"),   transform = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/modelbased/reference/estimate_contrasts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Marginal Contrasts ‚Äî estimate_contrasts","text":"model statistical model. contrast character vector indicating name variable(s) compute contrasts. (focal) predictor variable(s) evaluate desired effect / mean / contrasts. predictors model included collapsed \"averaged\" (effect estimated across ). argument used create \"reference grid\" \"data grid\" representative values focal predictors. can character (vector) naming focal predictors (optionally, representative values levels), list named elements. See details insight::get_datagrid() learn create data grids predictors interest. predict passed type argument emmeans::emmeans() (backend = \"emmeans\") marginaleffects::avg_predictions() (backend = \"marginaleffects\"). emmeans, see also vignette. Valid options `predict‚Äú : backend = \"emmeans\": predict can \"response\", \"link\", \"mu\", \"unlink\", \"log\". predict = NULL (default), appropriate transformation selected (usually \"response\"). backend = \"marginaleffects\": predict can \"response\", \"link\" valid type option supported model's class predict() method (e.g., zero-inflation models package glmmTMB, can choose predict = \"zprob\" predict = \"conditional\" etc., see glmmTMB::predict.glmmTMB). default, predict = NULL, appropriate transformation selected, usually returns predictions contrasts response-scale. \"link\" leave values scale linear predictors. \"response\" (NULL) transform scale response variable. Thus logistic model, \"link\" give estimations expressed log-odds (probabilities logit scale) \"response\" terms probabilities. predict distributional parameters (called \"dpar\" packages), instance using complex formulae brms models, predict argument can take value parameter want estimate, instance \"sigma\", \"kappa\", etc. ci Confidence Interval (CI) level. Default 0.95 (95%). p_adjust p-values adjustment method frequentist multiple comparisons. Can one \"none\" (default), \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"\", \"fdr\", \"tukey\" \"holm\". See p-value adjustment section emmeans::test documentation ?stats::p.adjust. comparison Specify type contrasts tests carried . backend = \"emmeans\", can one \"pairwise\", \"poly\", \"consec\", \"eff\", \"del.eff\", \"mean_chg\", \"trt.vs.ctrl\", \"dunnett\", \"wtcon\" . See also method argument emmeans::contrast ?emmeans::emmc-functions. backend = \"marginaleffects\", can numeric value, vector, matrix, string equation specifying hypothesis test, string naming comparison method, formula, function. Strings, string equations formula probably common options described . options detailed descriptions options, see also marginaleffects::comparisons website. String: One \"pairwise\", \"reference\", \"sequential\", \"meandev\" \"meanotherdev\", \"poly\", \"helmert\", \"trt_vs_ctrl\". String equation: identify parameters output, either specify term name, \"b1\", \"b2\" etc. indicate rows, e.g.:\"hp = drat\", \"b1 = b2\", \"b1 + b2 + b3 = 0\". Formula: formula like comparison ~ pairs | group, left-hand side indicates type comparison (difference ratio), right-hand side determines pairs estimates compare (reference, sequential, meandev, etc., see string-options). Optionally, comparisons can carried within subsets indicating grouping variable vertical bar ( |). marginalize Character string, indicating type marginalization. dictates predictions \"averaged\" non-focal predictors, .e. variables specified contrast. \"average\" (default): Takes mean value non-focal numeric predictors marginalizes factor levels non-focal terms, computes kind \"weighted average\" values terms hold constant. predictions good representation sample, possible values levels non-focal predictors considered. answers question, \"predicted value 'average' observation data?\". refers randomly picking subject sample result get average. approach one taken default emmeans package. \"population\": Non-focal predictors marginalized observations sample, sample replicated multiple times produce \"counterfactuals\" takes average predicted values (aggregated/grouped focal terms). can considered extrapolation hypothetical target population. Counterfactual predictions useful, insofar results can also transferred contexts (Dickerman Hernan, 2020). answers question, \"predicted response value 'average' observation broader target population?\". refer actual data observed sample, also \"\" data, data different sample. words, distinction marginalization types resides whether prediction made : specific \"individual\" sample (.e., specific combination predictor values): obtained using estimate_relation() prediction functions. average individual sample: obtained estimate_means(..., marginalize = \"average\") broader, hypothetical target population: obtained estimate_means(..., marginalize = \"population\") backend Whether use \"emmeans\" \"marginaleffects\" backend. Results usually similar. major difference found mixed models, backend = \"marginaleffects\" also average across random effects levels, producing \"marginal predictions\" (instead \"conditional predictions\", see Heiss 2022). can set default backend via options(), e.g. use options(modelbased_backend = \"emmeans\") use emmeans package options(modelbased_backend = \"marginaleffects\") set marginaleffects default backend. transform Deprecated, please use predict instead. verbose Use FALSE silence messages warnings. ... arguments passed, instance, insight::get_datagrid(), functions emmeans marginaleffects package, process Bayesian models via bayestestR::describe_posterior(). Examples: insight::get_datagrid(): Argument length range can used control (number ) representative values. marginaleffects: Internally used functions avg_predictions() means contrasts, avg_slope() slopes. Therefore, arguments instance like vcov, transform, equivalence slope can passed functions. emmeans: Internally used functions emmeans() emtrends(). Additional arguments can passed functions. Bayesian models: Bayesian models, parameters cleaned using describe_posterior(), thus, arguments like, example, centrality, rope_range, test passed function.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_contrasts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Marginal Contrasts ‚Äî estimate_contrasts","text":"data frame estimated contrasts.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_contrasts.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate Marginal Contrasts ‚Äî estimate_contrasts","text":"estimate_slopes(), estimate_means() estimate_contrasts() functions forming group, based marginal estimations (estimations based model). three built emmeans marginaleffects package (depending backend argument), reading documentation (instance emmeans::emmeans(), emmeans::emtrends() website) recommended understand idea behind types procedures. Model-based predictions basis follows. Indeed, first thing understand models can used make predictions (see estimate_link()). corresponds predicted response (\"outcome variable\") given specific predictor values predictors (.e., given specific data configuration). concept reference grid() important direct predictions. Marginal \"means\", obtained via estimate_means(), extension predictions, allowing \"average\" (collapse) predictors, obtain average response value specific predictors configuration. typically used predictors interest factors. Indeed, parameters model usually give intercept value \"effect\" factor level (different intercept). Marginal means can used directly give mean value response variable levels factor. Moreover, can also used control, average predictors, useful case multiple predictors without interactions. Marginal contrasts, obtained via estimate_contrasts(), extension marginal means, allow investigate difference (.e., contrast) marginal means. , , often used get pairwise differences levels factor. works also continuous predictors, instance one also interested whether difference two extremes continuous predictor significant. Finally, marginal effects, obtained via estimate_slopes(), different focus values response variable, model's parameters. idea assess effect predictor specific configuration predictors. relevant case interactions non-linear relationships, effect predictor variable changes depending predictors. Moreover, effects can also \"averaged\" predictors, get instance \"general trend\" predictor different factor levels. Example: imagine following model lm(y ~ condition * x) condition factor 3 levels , B C x continuous variable (like age example). One idea see model performs, compare actual response y one predicted model (using estimate_expectation()). Another idea evaluate average mean condition's levels (using estimate_means()), can useful visualize . Another possibility evaluate difference levels (using estimate_contrasts()). Finally, one also estimate effect x averaged conditions, instead within condition (using [estimate_slopes]).","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_contrasts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Marginal Contrasts ‚Äî estimate_contrasts","text":"","code":"# \\dontrun{ options(marginaleffects_safe = FALSE) # Basic usage model <- lm(Sepal.Width ~ Species, data = iris) estimate_contrasts(model) #> We selected `contrast=c(\"Species\")`. #> Marginal Contrasts Analysis #>  #> Level1     | Level2     | Difference |   SE |         95% CI | t(147) |      p #> ------------------------------------------------------------------------------ #> versicolor | setosa     |      -0.66 | 0.07 | [-0.79, -0.52] |  -9.69 | < .001 #> virginica  | setosa     |      -0.45 | 0.07 | [-0.59, -0.32] |  -6.68 | < .001 #> virginica  | versicolor |       0.20 | 0.07 | [ 0.07,  0.34] |   3.00 |  0.003 #>  #> Variable predicted: Sepal.Width #> Predictors contrasted: Species #> p-values are uncorrected. #>   # Dealing with interactions model <- lm(Sepal.Width ~ Species * Petal.Width, data = iris)  # By default: selects first factor estimate_contrasts(model) #> We selected `contrast=c(\"Species\")`. #> Marginal Contrasts Analysis #>  #> Level1     | Level2     | Difference |   SE |         95% CI | t(144) |      p #> ------------------------------------------------------------------------------ #> versicolor | setosa     |      -1.59 | 0.39 | [-2.37, -0.81] |  -4.04 | < .001 #> virginica  | setosa     |      -1.77 | 0.41 | [-2.59, -0.96] |  -4.29 | < .001 #> virginica  | versicolor |      -0.18 | 0.15 | [-0.47,  0.10] |  -1.27 |  0.205 #>  #> Variable predicted: Sepal.Width #> Predictors contrasted: Species #> Predictors averaged: Petal.Width (1.2) #> p-values are uncorrected. #>   # Can also run contrasts between points of numeric, stratified by \"Species\" estimate_contrasts(model, contrast = \"Petal.Width\", by = \"Species\", length = 4) #> Marginal Contrasts Analysis #>  #> Level1     | Level2     | Difference |   SE |        95% CI |     t |     p #> --------------------------------------------------------------------------- #> versicolor | setosa     |       0.22 | 0.46 | [-0.69, 1.12] |  0.47 | 0.639 #> virginica  | setosa     |      -0.21 | 0.44 | [-1.06, 0.65] | -0.47 | 0.637 #> virginica  | versicolor |      -0.42 | 0.27 | [-0.95, 0.10] | -1.58 | 0.114 #>  #> Variable predicted: Sepal.Width #> Predictors contrasted: Petal.Width #> Predictors averaged: Petal.Width (1.2) #> p-values are uncorrected. #>   # Or both estimate_contrasts(model, contrast = c(\"Species\", \"Petal.Width\"), length = 2) #> Marginal Contrasts Analysis #>  #> Level1          | Level2          | Difference |   SE |         95% CI | t(144) |      p #> ---------------------------------------------------------------------------------------- #> setosa, 2.5     | setosa, 0.1     |       2.01 | 0.98 | [ 0.08,  3.94] |   2.06 |  0.041 #> versicolor, 0.1 | setosa, 0.1     |      -1.83 | 0.28 | [-2.38, -1.28] |  -6.55 | < .001 #> versicolor, 2.5 | setosa, 0.1     |       0.70 | 0.27 | [ 0.17,  1.23] |   2.61 |  0.010 #> virginica, 0.1  | setosa, 0.1     |      -1.55 | 0.31 | [-2.17, -0.93] |  -4.95 | < .001 #> virginica, 2.5  | setosa, 0.1     |      -0.03 | 0.11 | [-0.25,  0.19] |  -0.29 |  0.773 #> versicolor, 0.1 | setosa, 2.5     |      -3.84 | 0.96 | [-5.73, -1.95] |  -4.01 | < .001 #> versicolor, 2.5 | setosa, 2.5     |      -1.31 | 0.95 | [-3.19,  0.58] |  -1.37 |  0.172 #> virginica, 0.1  | setosa, 2.5     |      -3.56 | 0.97 | [-5.47, -1.65] |  -3.68 | < .001 #> virginica, 2.5  | setosa, 2.5     |      -2.04 | 0.92 | [-3.86, -0.22] |  -2.21 |  0.028 #> versicolor, 2.5 | versicolor, 0.1 |       2.53 | 0.52 | [ 1.50,  3.56] |   4.86 | < .001 #> virginica, 0.1  | versicolor, 0.1 |       0.28 | 0.41 | [-0.52,  1.08] |   0.69 |  0.492 #> virginica, 2.5  | versicolor, 0.1 |       1.80 | 0.28 | [ 1.24,  2.35] |   6.35 | < .001 #> virginica, 0.1  | versicolor, 2.5 |      -2.25 | 0.40 | [-3.04, -1.46] |  -5.64 | < .001 #> virginica, 2.5  | versicolor, 2.5 |      -0.73 | 0.27 | [-1.27, -0.20] |  -2.70 |  0.008 #> virginica, 2.5  | virginica, 0.1  |       1.52 | 0.37 | [ 0.77,  2.26] |   4.04 | < .001 #>  #> Variable predicted: Sepal.Width #> Predictors contrasted: Species, Petal.Width #> p-values are uncorrected. #>   # Or with custom specifications estimate_contrasts(model, contrast = c(\"Species\", \"Petal.Width=c(1, 2)\")) #> Marginal Contrasts Analysis #>  #> Level1        | Level2        | Difference |   SE |         95% CI | t(144) |      p #> ------------------------------------------------------------------------------------ #> setosa, 2     | setosa, 1     |       0.84 | 0.41 | [ 0.03,  1.64] |   2.06 |  0.041 #> versicolor, 1 | setosa, 1     |      -1.63 | 0.32 | [-2.27, -1.00] |  -5.09 | < .001 #> versicolor, 2 | setosa, 1     |      -0.58 | 0.35 | [-1.26,  0.10] |  -1.68 |  0.096 #> virginica, 1  | setosa, 1     |      -1.73 | 0.35 | [-2.43, -1.04] |  -4.93 | < .001 #> virginica, 2  | setosa, 1     |      -1.10 | 0.31 | [-1.72, -0.48] |  -3.52 | < .001 #> versicolor, 1 | setosa, 2     |      -2.47 | 0.72 | [-3.89, -1.05] |  -3.43 | < .001 #> versicolor, 2 | setosa, 2     |      -1.42 | 0.73 | [-2.86,  0.03] |  -1.94 |  0.055 #> virginica, 1  | setosa, 2     |      -2.57 | 0.73 | [-4.02, -1.12] |  -3.50 | < .001 #> virginica, 2  | setosa, 2     |      -1.94 | 0.72 | [-3.35, -0.52] |  -2.71 |  0.008 #> versicolor, 2 | versicolor, 1 |       1.05 | 0.22 | [ 0.62,  1.48] |   4.86 | < .001 #> virginica, 1  | versicolor, 1 |      -0.10 | 0.19 | [-0.47,  0.27] |  -0.54 |  0.589 #> virginica, 2  | versicolor, 1 |       0.53 | 0.09 | [ 0.35,  0.71] |   5.72 | < .001 #> virginica, 1  | versicolor, 2 |      -1.15 | 0.23 | [-1.60, -0.71] |  -5.13 | < .001 #> virginica, 2  | versicolor, 2 |      -0.52 | 0.16 | [-0.84, -0.21] |  -3.31 |  0.001 #> virginica, 2  | virginica, 1  |       0.63 | 0.16 | [ 0.32,  0.94] |   4.04 | < .001 #>  #> Variable predicted: Sepal.Width #> Predictors contrasted: Species, Petal.Width=c(1, 2) #> p-values are uncorrected. #>   # Or modulate it estimate_contrasts(model, by = \"Petal.Width\", length = 4) #> We selected `contrast=c(\"Species\")`. #> Marginal Contrasts Analysis #>  #> Level1     | Level2     | Petal.Width | Difference |   SE |         95% CI #> -------------------------------------------------------------------------- #> versicolor | setosa     |        0.10 |      -1.83 | 0.28 | [-2.38, -1.28] #> virginica  | setosa     |        0.10 |      -1.55 | 0.31 | [-2.17, -0.93] #> virginica  | versicolor |        0.10 |       0.28 | 0.41 | [-0.52,  1.08] #> versicolor | setosa     |        0.90 |      -1.65 | 0.29 | [-2.22, -1.08] #> virginica  | setosa     |        0.90 |      -1.71 | 0.32 | [-2.35, -1.07] #> virginica  | versicolor |        0.90 |      -0.06 | 0.21 | [-0.47,  0.35] #> versicolor | setosa     |        1.70 |      -1.48 | 0.60 | [-2.67, -0.29] #> virginica  | setosa     |        1.70 |      -1.88 | 0.60 | [-3.06, -0.70] #> virginica  | versicolor |        1.70 |      -0.40 | 0.11 | [-0.62, -0.17] #> versicolor | setosa     |        2.50 |      -1.31 | 0.95 | [-3.19,  0.58] #> virginica  | setosa     |        2.50 |      -2.04 | 0.92 | [-3.86, -0.22] #> virginica  | versicolor |        2.50 |      -0.73 | 0.27 | [-1.27, -0.20] #>  #> Level1     | t(144) |      p #> ---------------------------- #> versicolor |  -6.55 | < .001 #> virginica  |  -4.95 | < .001 #> virginica  |   0.69 |  0.492 #> versicolor |  -5.74 | < .001 #> virginica  |  -5.28 | < .001 #> virginica  |  -0.28 |  0.780 #> versicolor |  -2.47 |  0.015 #> virginica  |  -3.14 |  0.002 #> virginica  |  -3.50 | < .001 #> versicolor |  -1.37 |  0.172 #> virginica  |  -2.21 |  0.028 #> virginica  |  -2.70 |  0.008 #>  #> Variable predicted: Sepal.Width #> Predictors contrasted: Species #> p-values are uncorrected. #>   # Standardized differences estimated <- estimate_contrasts(lm(Sepal.Width ~ Species, data = iris)) #> We selected `contrast=c(\"Species\")`. standardize(estimated) #> Marginal Contrasts Analysis (standardized) #>  #> Level1     | Level2     | Difference |   SE |         95% CI | t(147) |      p #> ------------------------------------------------------------------------------ #> versicolor | setosa     |      -1.51 | 0.16 | [-1.82, -1.20] |  -9.69 | < .001 #> virginica  | setosa     |      -1.04 | 0.16 | [-1.35, -0.73] |  -6.68 | < .001 #> virginica  | versicolor |       0.47 | 0.16 | [ 0.16,  0.78] |   3.00 |  0.003 #>  #> Variable predicted: Sepal.Width #> Predictors contrasted: Species #> p-values are uncorrected. #>   # Other models (mixed, Bayesian, ...) data <- iris data$Petal.Length_factor <- ifelse(data$Petal.Length < 4.2, \"A\", \"B\")  model <- lme4::lmer(Sepal.Width ~ Species + (1 | Petal.Length_factor), data = data) estimate_contrasts(model) #> We selected `contrast=c(\"Species\")`. #> Marginal Contrasts Analysis #>  #> Level1     | Level2     | Difference |   SE |         95% CI | t(145) |      p #> ------------------------------------------------------------------------------ #> versicolor | setosa     |      -0.87 | 0.09 | [-1.04, -0.70] | -10.11 | < .001 #> virginica  | setosa     |      -0.80 | 0.11 | [-1.02, -0.58] |  -7.11 | < .001 #> virginica  | versicolor |       0.07 | 0.07 | [-0.07,  0.22] |   1.00 |  0.319 #>  #> Variable predicted: Sepal.Width #> Predictors contrasted: Species #> Predictors averaged: Petal.Length_factor #> p-values are uncorrected. #>   data <- mtcars data$cyl <- as.factor(data$cyl) data$am <- as.factor(data$am)  model <- rstanarm::stan_glm(mpg ~ cyl * wt, data = data, refresh = 0) estimate_contrasts(model) #> We selected `contrast=c(\"cyl\")`. #> Marginal Contrasts Analysis #>  #> Level1 | Level2 | Median |         95% CI |     pd |          ROPE | % in ROPE #> ------------------------------------------------------------------------------ #> 6      | 4      |  -2.23 | [-5.90,  1.34] | 89.40% | [-0.10, 0.10] |     2.13% #> 8      | 4      |  -4.82 | [-8.43, -1.18] | 99.33% | [-0.10, 0.10] |        0% #> 8      | 6      |  -2.55 | [-5.35,  0.21] | 96.70% | [-0.10, 0.10] |     1.08% #>  #> Variable predicted: mpg #> Predictors contrasted: cyl #> Predictors averaged: wt (3.2) #>  estimate_contrasts(model, by = \"wt\", length = 4) #> We selected `contrast=c(\"cyl\")`. #> Marginal Contrasts Analysis #>  #> Level1 | Level2 |   wt | Median |          95% CI |     pd |          ROPE | % in ROPE #> -------------------------------------------------------------------------------------- #> 6      | 4      | 1.51 |  -6.05 | [-14.94,  3.33] | 89.88% | [-0.10, 0.10] |     0.89% #> 8      | 4      | 1.51 | -10.01 | [-15.18, -4.76] | 99.98% | [-0.10, 0.10] |        0% #> 8      | 6      | 1.51 |  -3.95 | [-14.47,  5.84] | 79.66% | [-0.10, 0.10] |     1.18% #> 6      | 4      | 2.82 |  -3.16 | [ -6.41,  0.25] | 96.50% | [-0.10, 0.10] |     0.92% #> 8      | 4      | 2.82 |  -6.05 | [ -9.35, -2.62] | 99.88% | [-0.10, 0.10] |        0% #> 8      | 6      | 2.82 |  -2.86 | [ -6.63,  0.65] | 94.70% | [-0.10, 0.10] |     1.16% #> 6      | 4      | 4.12 |  -0.22 | [ -8.12,  7.44] | 52.04% | [-0.10, 0.10] |     1.92% #> 8      | 4      | 4.12 |  -2.01 | [ -7.47,  3.29] | 77.51% | [-0.10, 0.10] |     1.97% #> 8      | 6      | 4.12 |  -1.80 | [ -7.61,  4.26] | 73.21% | [-0.10, 0.10] |     2.13% #> 6      | 4      | 5.42 |   2.76 | [-12.82, 17.23] | 63.83% | [-0.10, 0.10] |     0.97% #> 8      | 4      | 5.42 |   1.99 | [ -7.20, 10.88] | 67.46% | [-0.10, 0.10] |     1.61% #> 8      | 6      | 5.42 |  -0.62 | [-13.32, 12.49] | 54.64% | [-0.10, 0.10] |     1.42% #>  #> Variable predicted: mpg #> Predictors contrasted: cyl #>   model <- rstanarm::stan_glm(   Sepal.Width ~ Species + Petal.Width + Petal.Length,   data = iris,   refresh = 0 ) estimate_contrasts(model, by = \"Petal.Length = [sd]\", test = \"bf\") #> We selected `contrast=c(\"Species\")`. #> Marginal Contrasts Analysis #>  #> Level1     | Level2     |   BF | Median |         95% CI #> -------------------------------------------------------- #> versicolor | setosa     | 1.00 |  -1.73 | [-2.09, -1.38] #> virginica  | setosa     | 1.00 |  -2.15 | [-2.68, -1.64] #> virginica  | versicolor | 1.00 |  -0.42 | [-0.63, -0.21] #>  #> Variable predicted: Sepal.Width #> Predictors contrasted: Species #> Predictors averaged: Petal.Width (1.2), Petal.Length (3.8) #>  # }"},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":null,"dir":"Reference","previous_headings":"","what":"Model-based predictions ‚Äî estimate_expectation","title":"Model-based predictions ‚Äî estimate_expectation","text":"fitting model, useful generate model-based estimates response variables different combinations predictor values. estimates can used make inferences relationships variables, make predictions individual cases, compare predicted values observed data. modelbased package includes 4 \"related\" functions, mostly differ default arguments (particular, data predict): estimate_prediction(data = NULL, predict = \"prediction\", ...) estimate_expectation(data = NULL, predict = \"expectation\", ...) estimate_relation(data = \"grid\", predict = \"expectation\", ...) estimate_link(data = \"grid\", predict = \"link\", ...) based model-based predictions (using insight::get_predicted()), differ terms type predictions make default. instance, estimate_prediction() estimate_expectation() return predictions original data used fit model, estimate_relation() estimate_link() return predictions insight::get_datagrid(). Similarly, estimate_link returns predictions link scale, others return predictions response scale. Note relevance differences depends model family (instance, linear models, estimate_relation equivalent estimate_link(), since difference link-scale response scale). Note can run plot() output functions get visual insights (see plotting examples). See details section details different possibilities.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model-based predictions ‚Äî estimate_expectation","text":"","code":"estimate_expectation(   model,   data = NULL,   by = NULL,   predict = \"expectation\",   ci = 0.95,   keep_iterations = FALSE,   ... )  estimate_link(   model,   data = \"grid\",   by = NULL,   predict = \"link\",   ci = 0.95,   keep_iterations = FALSE,   ... )  estimate_prediction(   model,   data = NULL,   by = NULL,   predict = \"prediction\",   ci = 0.95,   keep_iterations = FALSE,   ... )  estimate_relation(   model,   data = \"grid\",   by = NULL,   predict = \"expectation\",   ci = 0.95,   keep_iterations = FALSE,   ... )"},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model-based predictions ‚Äî estimate_expectation","text":"model statistical model. data data frame model's predictors estimate response. NULL, model's data used. \"grid\", model matrix obtained (insight::get_datagrid()). predictor variable(s) estimate response. predictors model included set mean value (numeric predictors), reference level (factors) mode (types). argument used create data grid via insight::get_datagrid(), used data argument. Thus, specify data two arguments. predict parameter controls predicted (gets internally passed insight::get_predicted()). cases, need care : changed automatically according different predicting functions (.e., estimate_expectation(), estimate_prediction(), estimate_link() estimate_relation()). time might interested manually changing estimate distributional parameters (called \"dpar\" packages) - instance using complex formulae brms models. predict argument can set parameter want estimate, instance \"sigma\", \"kappa\", etc. Note distinction \"expectation\", \"link\" \"prediction\" apply (directly predicting value distributional parameter), corresponding functions differ default value data argument. ci Confidence Interval (CI) level. Default 0.95 (95%). keep_iterations TRUE, keep iterations (draws) bootstrapped Bayesian models. added additional columns named iter_1, iter_2, .... can reshape long format running reshape_iterations(). ... can add additional control arguments insight::get_datagrid() (used data = \"grid\") insight::get_predicted().","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model-based predictions ‚Äî estimate_expectation","text":"data frame predicted values uncertainty intervals, class \"estimate_predicted\". Methods visualisation_recipe() plot() available.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Model-based predictions ‚Äî estimate_expectation","text":"functions built top insight::get_predicted() correspond different specifications parameters. may useful read documentation, particular description predict argument additional details difference expected vs. predicted values link vs. response scales. Additional control parameters can used control results insight::get_datagrid() (data = \"grid\") insight::get_predicted() (function used internally compute predictions). plotting, check examples visualisation_recipe(). Also check Vignettes README examples various examples, tutorials usecases.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":"expected-average-values","dir":"Reference","previous_headings":"","what":"Expected (average) values","title":"Model-based predictions ‚Äî estimate_expectation","text":"important way various types response estimates differ terms quantity estimated meaning uncertainty intervals. major choices expected values uncertainty regression line predicted values uncertainty individual case predictions. Expected values refer fitted regression line - estimated average response value (.e., \"expectation\") individuals specific predictor values. example, linear model y = 2 + 3x + 4z + e, estimated average y individuals x = 1 z = 2 11. expected values, uncertainty intervals refer uncertainty estimated conditional average (might true regression line actually fall)? Uncertainty intervals expected values also called \"confidence intervals\". Expected values uncertainty intervals useful describing relationship variables describing precisely model estimated. generalized linear models, expected values reported one two scales: link scale refers scale fitted regression line, transformation link function. example, logistic regression (logit binomial) model, link scale gives expected log-odds. log-link Poisson model, link scale gives expected log-count. response scale refers original scale response variable (.e., without link function transformation). Expected values link scale back-transformed original response variable metric (e.g., expected probabilities binomial models, expected counts Poisson models).","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":"individual-case-predictions","dir":"Reference","previous_headings":"","what":"Individual case predictions","title":"Model-based predictions ‚Äî estimate_expectation","text":"contrast expected values, predicted values refer predictions individual cases. Predicted values also called \"posterior predictions\" \"posterior predictive draws\". predicted values, uncertainty intervals refer uncertainty individual response values case (might single case actually fall)? Uncertainty intervals predicted values also called \"prediction intervals\" \"posterior predictive intervals\". Predicted values uncertainty intervals useful forecasting range values might observed new data, making decisions individual cases, checking model predictions reasonable (\"posterior predictive checks\"). Predicted values intervals always scale original response variable (link scale).","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":"functions-for-estimating-predicted-values-and-uncertainty","dir":"Reference","previous_headings":"","what":"Functions for estimating predicted values and uncertainty","title":"Model-based predictions ‚Äî estimate_expectation","text":"modelbased provides 4 functions generating model-based response estimates uncertainty: estimate_expectation(): Generates expected values (conditional average) response scale. uncertainty interval confidence interval. default, values computed using data used fit model. estimate_link(): Generates expected values (conditional average) link scale. uncertainty interval confidence interval. default, values computed using reference grid spanning observed range predictor values (see insight::get_datagrid()). estimate_prediction(): Generates predicted values (individual cases) response scale. uncertainty interval prediction interval. default, values computed using data used fit model. estimate_relation(): Like estimate_expectation(). Useful visualizing model. Generates expected values (conditional average) response scale. uncertainty interval confidence interval. default, values computed using reference grid spanning observed range predictor values (see insight::get_datagrid()).","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":"data-for-predictions","dir":"Reference","previous_headings":"","what":"Data for predictions","title":"Model-based predictions ‚Äî estimate_expectation","text":"data = NULL, values estimated using data used fit model. data = \"grid\", values computed using reference grid spanning observed range predictor values insight::get_datagrid(). can useful model visualization. number predictor values used variable can controlled length argument. data can also data frame containing columns names matching model frame (see insight::get_data()). can used generate model predictions specific combinations predictor values.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_expectation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model-based predictions ‚Äî estimate_expectation","text":"","code":"library(modelbased)  # Linear Models model <- lm(mpg ~ wt, data = mtcars)  # Get predicted and prediction interval (see insight::get_predicted) estimate_expectation(model) #> Model-based Predictions #>  #> wt   | Predicted |   SE |         95% CI | Residuals #> ---------------------------------------------------- #> 2.62 |     23.28 | 0.63 | [21.99, 24.58] |     -2.28 #> 2.88 |     21.92 | 0.57 | [20.75, 23.09] |     -0.92 #> 2.32 |     24.89 | 0.74 | [23.38, 26.39] |     -2.09 #> 3.21 |     20.10 | 0.54 | [19.00, 21.20] |      1.30 #> 3.44 |     18.90 | 0.55 | [17.77, 20.03] |     -0.20 #> 3.46 |     18.79 | 0.56 | [17.66, 19.93] |     -0.69 #> 3.57 |     18.21 | 0.57 | [17.03, 19.38] |     -3.91 #> 3.19 |     20.24 | 0.54 | [19.14, 21.34] |      4.16 #> 3.15 |     20.45 | 0.54 | [19.35, 21.55] |      2.35 #> 3.44 |     18.90 | 0.55 | [17.77, 20.03] |      0.30 #> 3.44 |     18.90 | 0.55 | [17.77, 20.03] |     -1.10 #> 4.07 |     15.53 | 0.72 | [14.06, 17.00] |      0.87 #> 3.73 |     17.35 | 0.61 | [16.10, 18.60] |     -0.05 #> 3.78 |     17.08 | 0.62 | [15.81, 18.36] |     -1.88 #> 5.25 |      9.23 | 1.26 | [ 6.66, 11.80] |      1.17 #> 5.42 |      8.30 | 1.35 | [ 5.55, 11.05] |      2.10 #> 5.34 |      8.72 | 1.31 | [ 6.05, 11.39] |      5.98 #> 2.20 |     25.53 | 0.78 | [23.93, 27.13] |      6.87 #> 1.61 |     28.65 | 1.05 | [26.52, 30.79] |      1.75 #> 1.83 |     27.48 | 0.94 | [25.55, 29.40] |      6.42 #> 2.46 |     24.11 | 0.68 | [22.72, 25.51] |     -2.61 #> 3.52 |     18.47 | 0.56 | [17.32, 19.63] |     -2.97 #> 3.44 |     18.93 | 0.55 | [17.80, 20.05] |     -3.73 #> 3.84 |     16.76 | 0.64 | [15.45, 18.07] |     -3.46 #> 3.85 |     16.74 | 0.64 | [15.42, 18.05] |      2.46 #> 1.94 |     26.94 | 0.90 | [25.11, 28.77] |      0.36 #> 2.14 |     25.85 | 0.81 | [24.20, 27.50] |      0.15 #> 1.51 |     29.20 | 1.09 | [26.96, 31.43] |      1.20 #> 3.17 |     20.34 | 0.54 | [19.24, 21.44] |     -4.54 #> 2.77 |     22.48 | 0.59 | [21.27, 23.69] |     -2.78 #> 3.57 |     18.21 | 0.57 | [17.03, 19.38] |     -3.21 #> 2.78 |     22.43 | 0.59 | [21.22, 23.64] |     -1.03 #>  #> Variable predicted: mpg #>   # Get expected values with confidence interval pred <- estimate_relation(model) pred #> Model-based Predictions #>  #> wt   | Predicted |   SE |         95% CI #> ---------------------------------------- #> 1.51 |     29.20 | 1.09 | [26.96, 31.43] #> 1.95 |     26.88 | 0.89 | [25.06, 28.70] #> 2.38 |     24.55 | 0.71 | [23.10, 26.01] #> 2.82 |     22.23 | 0.58 | [21.04, 23.42] #> 3.25 |     19.91 | 0.54 | [18.81, 21.01] #> 3.69 |     17.59 | 0.60 | [16.36, 18.81] #> 4.12 |     15.26 | 0.74 | [13.76, 16.77] #> 4.55 |     12.94 | 0.92 | [11.06, 14.82] #> 4.99 |     10.62 | 1.13 | [ 8.32, 12.92] #> 5.42 |      8.30 | 1.35 | [ 5.55, 11.05] #>  #> Variable predicted: mpg #> Predictors modulated: wt #>   # Visualisation (see visualisation_recipe()) plot(pred)   # Standardize predictions pred <- estimate_relation(lm(mpg ~ wt + am, data = mtcars)) z <- standardize(pred, include_response = FALSE) z #> Model-based Predictions (standardized) #>  #> wt    |    am | Predicted |   SE |         95% CI #> ------------------------------------------------- #> -1.74 | -0.81 |     29.22 | 1.91 | [25.31, 33.14] #> -1.30 | -0.81 |     26.90 | 1.60 | [23.62, 30.17] #> -0.85 | -0.81 |     24.57 | 1.30 | [21.90, 27.24] #> -0.41 | -0.81 |     22.24 | 1.03 | [20.13, 24.36] #> 0.03  | -0.81 |     19.92 | 0.82 | [18.24, 21.59] #> 0.48  | -0.81 |     17.59 | 0.71 | [16.13, 19.05] #> 0.92  | -0.81 |     15.27 | 0.76 | [13.71, 16.83] #> 1.37  | -0.81 |     12.94 | 0.94 | [11.01, 14.87] #> 1.81  | -0.81 |     10.61 | 1.20 | [ 8.17, 13.06] #> 2.26  | -0.81 |      8.29 | 1.49 | [ 5.25, 11.33] #> -1.74 | -0.59 |     29.22 | 1.78 | [25.58, 32.86] #> -1.30 | -0.59 |     26.89 | 1.46 | [23.90, 29.89] #> -0.85 | -0.59 |     24.57 | 1.17 | [22.19, 26.95] #> -0.41 | -0.59 |     22.24 | 0.90 | [20.40, 24.08] #> 0.03  | -0.59 |     19.92 | 0.70 | [18.48, 21.35] #> 0.48  | -0.59 |     17.59 | 0.64 | [16.28, 18.90] #> 0.92  | -0.59 |     15.26 | 0.75 | [13.73, 16.80] #> 1.37  | -0.59 |     12.94 | 0.98 | [10.94, 14.93] #> 1.81  | -0.59 |     10.61 | 1.26 | [ 8.04, 13.18] #> 2.26  | -0.59 |      8.29 | 1.56 | [ 5.09, 11.48] #> -1.74 | -0.37 |     29.22 | 1.65 | [25.85, 32.59] #> -1.30 | -0.37 |     26.89 | 1.33 | [24.17, 29.62] #> -0.85 | -0.37 |     24.57 | 1.04 | [22.45, 26.68] #> -0.41 | -0.37 |     22.24 | 0.78 | [20.65, 23.83] #> 0.03  | -0.37 |     19.91 | 0.61 | [18.67, 21.16] #> 0.48  | -0.37 |     17.59 | 0.61 | [16.34, 18.83] #> 0.92  | -0.37 |     15.26 | 0.78 | [13.67, 16.85] #> 1.37  | -0.37 |     12.93 | 1.04 | [10.81, 15.06] #> 1.81  | -0.37 |     10.61 | 1.33 | [ 7.88, 13.34] #> 2.26  | -0.37 |      8.28 | 1.65 | [ 4.91, 11.66] #> -1.74 | -0.15 |     29.21 | 1.53 | [26.10, 32.33] #> -1.30 | -0.15 |     26.89 | 1.21 | [24.41, 29.37] #> -0.85 | -0.15 |     24.56 | 0.92 | [22.68, 26.45] #> -0.41 | -0.15 |     22.24 | 0.68 | [20.85, 23.63] #> 0.03  | -0.15 |     19.91 | 0.56 | [18.77, 21.05] #> 0.48  | -0.15 |     17.58 | 0.63 | [16.30, 18.86] #> 0.92  | -0.15 |     15.26 | 0.84 | [13.54, 16.98] #> 1.37  | -0.15 |     12.93 | 1.12 | [10.64, 15.23] #> 1.81  | -0.15 |     10.61 | 1.43 | [ 7.68, 13.53] #> 2.26  | -0.15 |      8.28 | 1.75 | [ 4.70, 11.86] #> -1.74 |  0.08 |     29.21 | 1.41 | [26.32, 32.10] #> -1.30 |  0.08 |     26.89 | 1.11 | [24.62, 29.15] #> -0.85 |  0.08 |     24.56 | 0.83 | [22.87, 26.25] #> -0.41 |  0.08 |     22.23 | 0.61 | [20.98, 23.49] #> 0.03  |  0.08 |     19.91 | 0.55 | [18.78, 21.04] #> 0.48  |  0.08 |     17.58 | 0.69 | [16.18, 18.98] #> 0.92  |  0.08 |     15.26 | 0.93 | [13.35, 17.16] #> 1.37  |  0.08 |     12.93 | 1.23 | [10.42, 15.44] #> 1.81  |  0.08 |     10.60 | 1.54 | [ 7.46, 13.75] #> 2.26  |  0.08 |      8.28 | 1.86 | [ 4.47, 12.09] #> -1.74 |  0.30 |     29.21 | 1.31 | [26.52, 31.90] #> -1.30 |  0.30 |     26.88 | 1.02 | [24.80, 28.96] #> -0.85 |  0.30 |     24.56 | 0.76 | [23.01, 26.11] #> -0.41 |  0.30 |     22.23 | 0.59 | [21.02, 23.44] #> 0.03  |  0.30 |     19.91 | 0.60 | [18.67, 21.14] #> 0.48  |  0.30 |     17.58 | 0.78 | [15.98, 19.17] #> 0.92  |  0.30 |     15.25 | 1.04 | [13.12, 17.39] #> 1.37  |  0.30 |     12.93 | 1.34 | [10.18, 15.67] #> 1.81  |  0.30 |     10.60 | 1.66 | [ 7.21, 13.99] #> 2.26  |  0.30 |      8.27 | 1.98 | [ 4.22, 12.33] #> -1.74 |  0.52 |     29.21 | 1.23 | [26.69, 31.73] #> -1.30 |  0.52 |     26.88 | 0.95 | [24.93, 28.83] #> -0.85 |  0.52 |     24.55 | 0.73 | [23.07, 26.04] #> -0.41 |  0.52 |     22.23 | 0.62 | [20.96, 23.50] #> 0.03  |  0.52 |     19.90 | 0.69 | [18.49, 21.32] #> 0.48  |  0.52 |     17.58 | 0.90 | [15.74, 19.41] #> 0.92  |  0.52 |     15.25 | 1.17 | [12.86, 17.64] #> 1.37  |  0.52 |     12.92 | 1.47 | [ 9.92, 15.93] #> 1.81  |  0.52 |     10.60 | 1.79 | [ 6.94, 14.25] #> 2.26  |  0.52 |      8.27 | 2.11 | [ 3.95, 12.59] #> -1.74 |  0.74 |     29.20 | 1.17 | [26.81, 31.59] #> -1.30 |  0.74 |     26.88 | 0.91 | [25.01, 28.75] #> -0.85 |  0.74 |     24.55 | 0.73 | [23.05, 26.05] #> -0.41 |  0.74 |     22.23 | 0.69 | [20.81, 23.64] #> 0.03  |  0.74 |     19.90 | 0.81 | [18.25, 21.55] #> 0.48  |  0.74 |     17.57 | 1.03 | [15.47, 19.68] #> 0.92  |  0.74 |     15.25 | 1.30 | [12.58, 17.92] #> 1.37  |  0.74 |     12.92 | 1.61 | [ 9.64, 16.21] #> 1.81  |  0.74 |     10.60 | 1.92 | [ 6.67, 14.53] #> 2.26  |  0.74 |      8.27 | 2.24 | [ 3.68, 12.86] #> -1.74 |  0.97 |     29.20 | 1.13 | [26.89, 31.51] #> -1.30 |  0.97 |     26.88 | 0.91 | [25.02, 28.73] #> -0.85 |  0.97 |     24.55 | 0.78 | [22.95, 26.15] #> -0.41 |  0.97 |     22.22 | 0.79 | [20.60, 23.85] #> 0.03  |  0.97 |     19.90 | 0.94 | [17.97, 21.82] #> 0.48  |  0.97 |     17.57 | 1.17 | [15.17, 19.97] #> 0.92  |  0.97 |     15.25 | 1.45 | [12.28, 18.21] #> 1.37  |  0.97 |     12.92 | 1.75 | [ 9.34, 16.50] #> 1.81  |  0.97 |     10.59 | 2.06 | [ 6.38, 14.81] #> 2.26  |  0.97 |      8.27 | 2.38 | [ 3.39, 13.14] #> -1.74 |  1.19 |     29.20 | 1.11 | [26.92, 31.48] #> -1.30 |  1.19 |     26.87 | 0.93 | [24.96, 28.78] #> -0.85 |  1.19 |     24.55 | 0.86 | [22.79, 26.30] #> -0.41 |  1.19 |     22.22 | 0.92 | [20.35, 24.10] #> 0.03  |  1.19 |     19.89 | 1.08 | [17.68, 22.11] #> 0.48  |  1.19 |     17.57 | 1.32 | [14.86, 20.27] #> 0.92  |  1.19 |     15.24 | 1.60 | [11.97, 18.51] #> 1.37  |  1.19 |     12.92 | 1.90 | [ 9.04, 16.79] #> 1.81  |  1.19 |     10.59 | 2.21 | [ 6.08, 15.10] #> 2.26  |  1.19 |      8.26 | 2.53 | [ 3.10, 13.43] #>  #> Variable predicted: mpg #> Predictors modulated: wt, am #>  unstandardize(z, include_response = FALSE) #> Model-based Predictions (standardized) #>  #> wt   |   am | Predicted |   SE |         95% CI #> ----------------------------------------------- #> 1.51 | 0.00 |     29.22 | 1.91 | [25.31, 33.14] #> 1.95 | 0.00 |     26.90 | 1.60 | [23.62, 30.17] #> 2.38 | 0.00 |     24.57 | 1.30 | [21.90, 27.24] #> 2.82 | 0.00 |     22.24 | 1.03 | [20.13, 24.36] #> 3.25 | 0.00 |     19.92 | 0.82 | [18.24, 21.59] #> 3.69 | 0.00 |     17.59 | 0.71 | [16.13, 19.05] #> 4.12 | 0.00 |     15.27 | 0.76 | [13.71, 16.83] #> 4.55 | 0.00 |     12.94 | 0.94 | [11.01, 14.87] #> 4.99 | 0.00 |     10.61 | 1.20 | [ 8.17, 13.06] #> 5.42 | 0.00 |      8.29 | 1.49 | [ 5.25, 11.33] #> 1.51 | 0.11 |     29.22 | 1.78 | [25.58, 32.86] #> 1.95 | 0.11 |     26.89 | 1.46 | [23.90, 29.89] #> 2.38 | 0.11 |     24.57 | 1.17 | [22.19, 26.95] #> 2.82 | 0.11 |     22.24 | 0.90 | [20.40, 24.08] #> 3.25 | 0.11 |     19.92 | 0.70 | [18.48, 21.35] #> 3.69 | 0.11 |     17.59 | 0.64 | [16.28, 18.90] #> 4.12 | 0.11 |     15.26 | 0.75 | [13.73, 16.80] #> 4.55 | 0.11 |     12.94 | 0.98 | [10.94, 14.93] #> 4.99 | 0.11 |     10.61 | 1.26 | [ 8.04, 13.18] #> 5.42 | 0.11 |      8.29 | 1.56 | [ 5.09, 11.48] #> 1.51 | 0.22 |     29.22 | 1.65 | [25.85, 32.59] #> 1.95 | 0.22 |     26.89 | 1.33 | [24.17, 29.62] #> 2.38 | 0.22 |     24.57 | 1.04 | [22.45, 26.68] #> 2.82 | 0.22 |     22.24 | 0.78 | [20.65, 23.83] #> 3.25 | 0.22 |     19.91 | 0.61 | [18.67, 21.16] #> 3.69 | 0.22 |     17.59 | 0.61 | [16.34, 18.83] #> 4.12 | 0.22 |     15.26 | 0.78 | [13.67, 16.85] #> 4.55 | 0.22 |     12.93 | 1.04 | [10.81, 15.06] #> 4.99 | 0.22 |     10.61 | 1.33 | [ 7.88, 13.34] #> 5.42 | 0.22 |      8.28 | 1.65 | [ 4.91, 11.66] #> 1.51 | 0.33 |     29.21 | 1.53 | [26.10, 32.33] #> 1.95 | 0.33 |     26.89 | 1.21 | [24.41, 29.37] #> 2.38 | 0.33 |     24.56 | 0.92 | [22.68, 26.45] #> 2.82 | 0.33 |     22.24 | 0.68 | [20.85, 23.63] #> 3.25 | 0.33 |     19.91 | 0.56 | [18.77, 21.05] #> 3.69 | 0.33 |     17.58 | 0.63 | [16.30, 18.86] #> 4.12 | 0.33 |     15.26 | 0.84 | [13.54, 16.98] #> 4.55 | 0.33 |     12.93 | 1.12 | [10.64, 15.23] #> 4.99 | 0.33 |     10.61 | 1.43 | [ 7.68, 13.53] #> 5.42 | 0.33 |      8.28 | 1.75 | [ 4.70, 11.86] #> 1.51 | 0.44 |     29.21 | 1.41 | [26.32, 32.10] #> 1.95 | 0.44 |     26.89 | 1.11 | [24.62, 29.15] #> 2.38 | 0.44 |     24.56 | 0.83 | [22.87, 26.25] #> 2.82 | 0.44 |     22.23 | 0.61 | [20.98, 23.49] #> 3.25 | 0.44 |     19.91 | 0.55 | [18.78, 21.04] #> 3.69 | 0.44 |     17.58 | 0.69 | [16.18, 18.98] #> 4.12 | 0.44 |     15.26 | 0.93 | [13.35, 17.16] #> 4.55 | 0.44 |     12.93 | 1.23 | [10.42, 15.44] #> 4.99 | 0.44 |     10.60 | 1.54 | [ 7.46, 13.75] #> 5.42 | 0.44 |      8.28 | 1.86 | [ 4.47, 12.09] #> 1.51 | 0.56 |     29.21 | 1.31 | [26.52, 31.90] #> 1.95 | 0.56 |     26.88 | 1.02 | [24.80, 28.96] #> 2.38 | 0.56 |     24.56 | 0.76 | [23.01, 26.11] #> 2.82 | 0.56 |     22.23 | 0.59 | [21.02, 23.44] #> 3.25 | 0.56 |     19.91 | 0.60 | [18.67, 21.14] #> 3.69 | 0.56 |     17.58 | 0.78 | [15.98, 19.17] #> 4.12 | 0.56 |     15.25 | 1.04 | [13.12, 17.39] #> 4.55 | 0.56 |     12.93 | 1.34 | [10.18, 15.67] #> 4.99 | 0.56 |     10.60 | 1.66 | [ 7.21, 13.99] #> 5.42 | 0.56 |      8.27 | 1.98 | [ 4.22, 12.33] #> 1.51 | 0.67 |     29.21 | 1.23 | [26.69, 31.73] #> 1.95 | 0.67 |     26.88 | 0.95 | [24.93, 28.83] #> 2.38 | 0.67 |     24.55 | 0.73 | [23.07, 26.04] #> 2.82 | 0.67 |     22.23 | 0.62 | [20.96, 23.50] #> 3.25 | 0.67 |     19.90 | 0.69 | [18.49, 21.32] #> 3.69 | 0.67 |     17.58 | 0.90 | [15.74, 19.41] #> 4.12 | 0.67 |     15.25 | 1.17 | [12.86, 17.64] #> 4.55 | 0.67 |     12.92 | 1.47 | [ 9.92, 15.93] #> 4.99 | 0.67 |     10.60 | 1.79 | [ 6.94, 14.25] #> 5.42 | 0.67 |      8.27 | 2.11 | [ 3.95, 12.59] #> 1.51 | 0.78 |     29.20 | 1.17 | [26.81, 31.59] #> 1.95 | 0.78 |     26.88 | 0.91 | [25.01, 28.75] #> 2.38 | 0.78 |     24.55 | 0.73 | [23.05, 26.05] #> 2.82 | 0.78 |     22.23 | 0.69 | [20.81, 23.64] #> 3.25 | 0.78 |     19.90 | 0.81 | [18.25, 21.55] #> 3.69 | 0.78 |     17.57 | 1.03 | [15.47, 19.68] #> 4.12 | 0.78 |     15.25 | 1.30 | [12.58, 17.92] #> 4.55 | 0.78 |     12.92 | 1.61 | [ 9.64, 16.21] #> 4.99 | 0.78 |     10.60 | 1.92 | [ 6.67, 14.53] #> 5.42 | 0.78 |      8.27 | 2.24 | [ 3.68, 12.86] #> 1.51 | 0.89 |     29.20 | 1.13 | [26.89, 31.51] #> 1.95 | 0.89 |     26.88 | 0.91 | [25.02, 28.73] #> 2.38 | 0.89 |     24.55 | 0.78 | [22.95, 26.15] #> 2.82 | 0.89 |     22.22 | 0.79 | [20.60, 23.85] #> 3.25 | 0.89 |     19.90 | 0.94 | [17.97, 21.82] #> 3.69 | 0.89 |     17.57 | 1.17 | [15.17, 19.97] #> 4.12 | 0.89 |     15.25 | 1.45 | [12.28, 18.21] #> 4.55 | 0.89 |     12.92 | 1.75 | [ 9.34, 16.50] #> 4.99 | 0.89 |     10.59 | 2.06 | [ 6.38, 14.81] #> 5.42 | 0.89 |      8.27 | 2.38 | [ 3.39, 13.14] #> 1.51 | 1.00 |     29.20 | 1.11 | [26.92, 31.48] #> 1.95 | 1.00 |     26.87 | 0.93 | [24.96, 28.78] #> 2.38 | 1.00 |     24.55 | 0.86 | [22.79, 26.30] #> 2.82 | 1.00 |     22.22 | 0.92 | [20.35, 24.10] #> 3.25 | 1.00 |     19.89 | 1.08 | [17.68, 22.11] #> 3.69 | 1.00 |     17.57 | 1.32 | [14.86, 20.27] #> 4.12 | 1.00 |     15.24 | 1.60 | [11.97, 18.51] #> 4.55 | 1.00 |     12.92 | 1.90 | [ 9.04, 16.79] #> 4.99 | 1.00 |     10.59 | 2.21 | [ 6.08, 15.10] #> 5.42 | 1.00 |      8.26 | 2.53 | [ 3.10, 13.43] #>  #> Variable predicted: mpg #> Predictors modulated: wt, am #>   # Logistic Models model <- glm(vs ~ wt, data = mtcars, family = \"binomial\") estimate_expectation(model) #> Model-based Predictions #>  #> wt   | Predicted |   SE |       95% CI | Residuals #> -------------------------------------------------- #> 2.62 |      0.67 | 0.12 | [0.40, 0.86] |     -0.67 #> 2.88 |      0.56 | 0.12 | [0.33, 0.76] |     -0.56 #> 2.32 |      0.78 | 0.12 | [0.47, 0.94] |      0.22 #> 3.21 |      0.39 | 0.11 | [0.21, 0.61] |      0.61 #> 3.44 |      0.30 | 0.11 | [0.14, 0.53] |     -0.30 #> 3.46 |      0.29 | 0.10 | [0.13, 0.53] |      0.71 #> 3.57 |      0.25 | 0.10 | [0.10, 0.50] |     -0.25 #> 3.19 |      0.41 | 0.11 | [0.22, 0.62] |      0.59 #> 3.15 |      0.42 | 0.11 | [0.24, 0.64] |      0.58 #> 3.44 |      0.30 | 0.11 | [0.14, 0.53] |      0.70 #> 3.44 |      0.30 | 0.11 | [0.14, 0.53] |      0.70 #> 4.07 |      0.11 | 0.08 | [0.02, 0.39] |     -0.11 #> 3.73 |      0.20 | 0.10 | [0.07, 0.46] |     -0.20 #> 3.78 |      0.18 | 0.10 | [0.06, 0.45] |     -0.18 #> 5.25 |      0.01 | 0.02 | [0.00, 0.24] |     -0.01 #> 5.42 |  9.49e-03 | 0.02 | [0.00, 0.23] | -9.49e-03 #> 5.34 |      0.01 | 0.02 | [0.00, 0.23] |     -0.01 #> 2.20 |      0.82 | 0.12 | [0.49, 0.96] |      0.18 #> 1.61 |      0.93 | 0.07 | [0.58, 0.99] |      0.07 #> 1.83 |      0.90 | 0.09 | [0.55, 0.99] |      0.10 #> 2.46 |      0.73 | 0.13 | [0.44, 0.91] |      0.27 #> 3.52 |      0.27 | 0.10 | [0.11, 0.51] |     -0.27 #> 3.44 |      0.30 | 0.11 | [0.14, 0.53] |     -0.30 #> 3.84 |      0.16 | 0.10 | [0.05, 0.43] |     -0.16 #> 3.85 |      0.16 | 0.10 | [0.05, 0.43] |     -0.16 #> 1.94 |      0.88 | 0.10 | [0.54, 0.98] |      0.12 #> 2.14 |      0.84 | 0.11 | [0.50, 0.96] |     -0.84 #> 1.51 |      0.94 | 0.07 | [0.60, 0.99] |      0.06 #> 3.17 |      0.42 | 0.11 | [0.23, 0.63] |     -0.42 #> 2.77 |      0.60 | 0.12 | [0.36, 0.80] |     -0.60 #> 3.57 |      0.25 | 0.10 | [0.10, 0.50] |     -0.25 #> 2.78 |      0.60 | 0.12 | [0.36, 0.80] |      0.40 #>  #> Variable predicted: vs #> Predictions are on the response-scale. #>  estimate_relation(model) #> Model-based Predictions #>  #> wt   | Predicted |   SE |       95% CI #> -------------------------------------- #> 1.51 |      0.94 | 0.07 | [0.60, 0.99] #> 1.95 |      0.88 | 0.10 | [0.53, 0.98] #> 2.38 |      0.76 | 0.12 | [0.46, 0.92] #> 2.82 |      0.58 | 0.12 | [0.35, 0.78] #> 3.25 |      0.38 | 0.11 | [0.20, 0.60] #> 3.69 |      0.21 | 0.10 | [0.07, 0.47] #> 4.12 |      0.10 | 0.08 | [0.02, 0.38] #> 4.55 |      0.05 | 0.05 | [0.01, 0.32] #> 4.99 |      0.02 | 0.03 | [0.00, 0.27] #> 5.42 |  9.49e-03 | 0.02 | [0.00, 0.23] #>  #> Variable predicted: vs #> Predictors modulated: wt #> Predictions are on the response-scale. #>   # Mixed models model <- lme4::lmer(mpg ~ wt + (1 | gear), data = mtcars) estimate_expectation(model) #> Model-based Predictions #>  #> wt   | gear | Predicted |   SE |         95% CI | Residuals #> ----------------------------------------------------------- #> 2.62 | 4.00 |     24.04 | 0.97 | [22.07, 26.02] |     -3.04 #> 2.88 | 4.00 |     22.76 | 0.93 | [20.86, 24.65] |     -1.76 #> 2.32 | 4.00 |     25.56 | 1.04 | [23.42, 27.70] |     -2.76 #> 3.21 | 3.00 |     19.64 | 0.92 | [17.77, 21.52] |      1.76 #> 3.44 | 3.00 |     18.51 | 0.94 | [16.59, 20.42] |      0.19 #> 3.46 | 3.00 |     18.41 | 0.94 | [16.48, 20.33] |     -0.31 #> 3.57 | 3.00 |     17.85 | 0.96 | [15.89, 19.81] |     -3.55 #> 3.19 | 4.00 |     21.17 | 0.91 | [19.30, 23.04] |      3.23 #> 3.15 | 4.00 |     21.37 | 0.91 | [19.50, 23.24] |      1.43 #> 3.44 | 4.00 |     19.91 | 0.94 | [17.99, 21.83] |     -0.71 #> 3.44 | 4.00 |     19.91 | 0.94 | [17.99, 21.83] |     -2.11 #> 4.07 | 3.00 |     15.33 | 1.10 | [13.08, 17.58] |      1.07 #> 3.73 | 3.00 |     17.04 | 0.99 | [15.01, 19.08] |      0.26 #> 3.78 | 3.00 |     16.79 | 1.01 | [14.73, 18.86] |     -1.59 #> 5.25 | 3.00 |      9.37 | 1.64 | [ 6.01, 12.74] |      1.03 #> 5.42 | 3.00 |      8.50 | 1.74 | [ 4.94, 12.06] |      1.90 #> 5.34 | 3.00 |      8.90 | 1.70 | [ 5.42, 12.37] |      5.80 #> 2.20 | 4.00 |     26.16 | 1.08 | [23.94, 28.38] |      6.24 #> 1.61 | 4.00 |     29.11 | 1.32 | [26.40, 31.82] |      1.29 #> 1.83 | 4.00 |     28.00 | 1.23 | [25.49, 30.51] |      5.90 #> 2.46 | 3.00 |     23.42 | 1.00 | [21.37, 25.48] |     -1.92 #> 3.52 | 3.00 |     18.10 | 0.95 | [16.16, 20.05] |     -2.60 #> 3.44 | 3.00 |     18.53 | 0.94 | [16.61, 20.45] |     -3.33 #> 3.84 | 3.00 |     16.49 | 1.02 | [14.39, 18.59] |     -3.19 #> 3.85 | 3.00 |     16.46 | 1.03 | [14.36, 18.56] |      2.74 #> 1.94 | 4.00 |     27.50 | 1.18 | [25.08, 29.92] |     -0.20 #> 2.14 | 5.00 |     24.65 | 1.10 | [22.39, 26.91] |      1.35 #> 1.51 | 5.00 |     27.81 | 1.37 | [25.01, 30.62] |      2.59 #> 3.17 | 5.00 |     19.45 | 0.91 | [17.58, 21.33] |     -3.65 #> 2.77 | 5.00 |     21.47 | 0.94 | [19.55, 23.40] |     -1.77 #> 3.57 | 5.00 |     17.44 | 0.96 | [15.47, 19.40] |     -2.44 #> 2.78 | 4.00 |     23.24 | 0.94 | [21.32, 25.16] |     -1.84 #>  #> Variable predicted: mpg #>  estimate_relation(model) #> Model-based Predictions #>  #> wt   | gear | Predicted |   SE |         95% CI #> ----------------------------------------------- #> 1.51 | 0.00 |     28.56 | 1.37 | [25.75, 31.37] #> 1.95 | 0.00 |     26.36 | 1.18 | [23.95, 28.78] #> 2.38 | 0.00 |     24.17 | 1.03 | [22.07, 26.27] #> 2.82 | 0.00 |     21.98 | 0.93 | [20.07, 23.89] #> 3.25 | 0.00 |     19.79 | 0.92 | [17.91, 21.67] #> 3.69 | 0.00 |     17.60 | 0.98 | [15.58, 19.61] #> 4.12 | 0.00 |     15.40 | 1.12 | [13.11, 17.69] #> 4.55 | 0.00 |     13.21 | 1.30 | [10.55, 15.87] #> 4.99 | 0.00 |     11.02 | 1.51 | [ 7.93, 14.11] #> 5.42 | 0.00 |      8.83 | 1.74 | [ 5.27, 12.39] #>  #> Variable predicted: mpg #> Predictors modulated: wt #>   # Bayesian models # \\donttest{ model <- suppressWarnings(rstanarm::stan_glm(   mpg ~ wt,   data = mtcars, refresh = 0, iter = 200 )) estimate_expectation(model) #> Model-based Predictions #>  #> wt   | Predicted |   SE |         95% CI | Residuals #> ---------------------------------------------------- #> 2.62 |     23.46 | 0.78 | [22.19, 25.03] |     -2.46 #> 2.88 |     22.10 | 0.70 | [20.96, 23.67] |     -1.10 #> 2.32 |     25.06 | 0.91 | [23.52, 26.96] |     -2.26 #> 3.21 |     20.28 | 0.65 | [19.09, 21.84] |      1.12 #> 3.44 |     19.08 | 0.66 | [17.92, 20.61] |     -0.38 #> 3.46 |     18.98 | 0.66 | [17.80, 20.50] |     -0.88 #> 3.57 |     18.39 | 0.68 | [17.17, 19.90] |     -4.09 #> 3.19 |     20.42 | 0.65 | [19.22, 21.93] |      3.98 #> 3.15 |     20.63 | 0.65 | [19.42, 22.15] |      2.17 #> 3.44 |     19.08 | 0.66 | [17.92, 20.61] |      0.12 #> 3.44 |     19.08 | 0.66 | [17.92, 20.61] |     -1.28 #> 4.07 |     15.72 | 0.84 | [14.20, 17.52] |      0.68 #> 3.73 |     17.54 | 0.72 | [16.26, 19.18] |     -0.24 #> 3.78 |     17.27 | 0.73 | [15.97, 18.91] |     -2.07 #> 5.25 |      9.43 | 1.46 | [ 6.81, 12.51] |      0.97 #> 5.42 |      8.50 | 1.57 | [ 5.70, 11.81] |      1.90 #> 5.34 |      8.92 | 1.52 | [ 6.20, 12.16] |      5.78 #> 2.20 |     25.70 | 0.97 | [24.07, 27.76] |      6.70 #> 1.61 |     28.82 | 1.28 | [26.59, 31.47] |      1.58 #> 1.83 |     27.65 | 1.16 | [25.71, 30.10] |      6.25 #> 2.46 |     24.29 | 0.84 | [22.91, 26.01] |     -2.79 #> 3.52 |     18.66 | 0.67 | [17.46, 20.16] |     -3.16 #> 3.44 |     19.11 | 0.66 | [17.95, 20.65] |     -3.91 #> 3.84 |     16.95 | 0.75 | [15.65, 18.57] |     -3.65 #> 3.85 |     16.92 | 0.75 | [15.63, 18.54] |      2.28 #> 1.94 |     27.11 | 1.10 | [25.26, 29.44] |      0.19 #> 2.14 |     26.02 | 1.00 | [24.34, 28.11] |     -0.02 #> 1.51 |     29.36 | 1.34 | [27.00, 32.13] |      1.04 #> 3.17 |     20.52 | 0.65 | [19.33, 22.04] |     -4.72 #> 2.77 |     22.66 | 0.73 | [21.46, 24.23] |     -2.96 #> 3.57 |     18.39 | 0.68 | [17.17, 19.90] |     -3.39 #> 2.78 |     22.60 | 0.73 | [21.42, 24.17] |     -1.20 #>  #> Variable predicted: mpg #>  estimate_relation(model) #> Model-based Predictions #>  #> wt   | Predicted |   SE |         95% CI #> ---------------------------------------- #> 1.51 |     29.36 | 1.34 | [27.00, 32.13] #> 1.95 |     27.05 | 1.10 | [25.20, 29.36] #> 2.38 |     24.73 | 0.88 | [23.26, 26.55] #> 2.82 |     22.41 | 0.72 | [21.27, 23.98] #> 3.25 |     20.09 | 0.65 | [18.90, 21.69] #> 3.69 |     17.77 | 0.70 | [16.55, 19.38] #> 4.12 |     15.45 | 0.86 | [13.91, 17.28] #> 4.55 |     13.13 | 1.07 | [11.29, 15.28] #> 4.99 |     10.82 | 1.31 | [ 8.49, 13.55] #> 5.42 |      8.50 | 1.57 | [ 5.70, 11.81] #>  #> Variable predicted: mpg #> Predictors modulated: wt #>  # }"},{"path":"https://easystats.github.io/modelbased/reference/estimate_grouplevel.html","id":null,"dir":"Reference","previous_headings":"","what":"Group-specific parameters of mixed models random effects ‚Äî estimate_grouplevel","title":"Group-specific parameters of mixed models random effects ‚Äî estimate_grouplevel","text":"Extract random parameters individual group context mixed models. Can reshaped dimensions original data, can useful add random effects original data.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_grouplevel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Group-specific parameters of mixed models random effects ‚Äî estimate_grouplevel","text":"","code":"estimate_grouplevel(model, type = \"random\", ...)  reshape_grouplevel(x, indices = \"all\", group = \"all\", ...)"},{"path":"https://easystats.github.io/modelbased/reference/estimate_grouplevel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group-specific parameters of mixed models random effects ‚Äî estimate_grouplevel","text":"model mixed model random effects. type \"random\" (default), coefficients ones estimated natively model (returned , instance, lme4::ranef()). correspond deviation individual group fixed effect. , coefficient close 0 means participants' effect population-level effect (words, \"norm\"). \"total\", return sum random effect corresponding fixed effects. known BLUPs (Best Linear Unbiased Predictions). argument can used reproduce results given lme4::ranef() coef() (see ?coef.merMod). Note BLUPs currently uncertainty indices (SE CI), computable. ... arguments passed methods. x output estimate_grouplevel(). indices list containing indices extract (e.g., \"Coefficient\"). group list containing random factors select.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_grouplevel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Group-specific parameters of mixed models random effects ‚Äî estimate_grouplevel","text":"","code":"# lme4 model data(mtcars) model <- lme4::lmer(mpg ~ hp + (1 | carb), data = mtcars) random <- estimate_grouplevel(model) random #> Group | Level | Parameter   | Coefficient |   SE |        95% CI #> ---------------------------------------------------------------- #> carb  | 1     | (Intercept) |        0.41 | 0.84 | [-1.24, 2.05] #> carb  | 2     | (Intercept) |        0.11 | 0.78 | [-1.42, 1.65] #> carb  | 3     | (Intercept) |       -0.32 | 0.94 | [-2.16, 1.51] #> carb  | 4     | (Intercept) |       -0.78 | 0.78 | [-2.31, 0.75] #> carb  | 6     | (Intercept) |        0.09 | 1.00 | [-1.87, 2.05] #> carb  | 8     | (Intercept) |        0.50 | 1.00 | [-1.47, 2.46]  # Visualize random effects plot(random)   # Show group-specific effects estimate_grouplevel(model, deviation = FALSE) #> Group | Level | Parameter   | Coefficient |   SE |        95% CI #> ---------------------------------------------------------------- #> carb  | 1     | (Intercept) |        0.41 | 0.84 | [-1.24, 2.05] #> carb  | 2     | (Intercept) |        0.11 | 0.78 | [-1.42, 1.65] #> carb  | 3     | (Intercept) |       -0.32 | 0.94 | [-2.16, 1.51] #> carb  | 4     | (Intercept) |       -0.78 | 0.78 | [-2.31, 0.75] #> carb  | 6     | (Intercept) |        0.09 | 1.00 | [-1.87, 2.05] #> carb  | 8     | (Intercept) |        0.50 | 1.00 | [-1.47, 2.46]  # Reshape to wide data so that it matches the original dataframe... reshaped <- reshape_grouplevel(random, indices = c(\"Coefficient\", \"SE\"))  # ... and can be easily combined alldata <- cbind(mtcars, reshaped)  # Use summary() to remove duplicated rows summary(reshaped) #>   carb carb_Coefficient_Intercept carb_SE_Intercept #> 1    4                -0.77955416         0.7829275 #> 2    1                 0.40506064         0.8390523 #> 3    2                 0.11088289         0.7829275 #> 4    3                -0.32486359         0.9369268 #> 5    6                 0.09296535         1.0007322 #> 6    8                 0.49550886         1.0007322  # Compute BLUPs estimate_grouplevel(model, type = \"total\") #> Group | Level | Parameter   | Coefficient #> ----------------------------------------- #> carb  | 1     | (Intercept) |       30.18 #> carb  | 2     | (Intercept) |       29.88 #> carb  | 3     | (Intercept) |       29.45 #> carb  | 4     | (Intercept) |       28.99 #> carb  | 6     | (Intercept) |       29.87 #> carb  | 8     | (Intercept) |       30.27"},{"path":"https://easystats.github.io/modelbased/reference/estimate_means.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Marginal Means (Model-based average at each factor level) ‚Äî estimate_means","title":"Estimate Marginal Means (Model-based average at each factor level) ‚Äî estimate_means","text":"Estimate average value response variable factor level representative value, respectively values defined \"data grid\" \"reference grid\". plotting, check examples visualisation_recipe(). See also related functions estimate_contrasts() estimate_slopes().","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_means.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Marginal Means (Model-based average at each factor level) ‚Äî estimate_means","text":"","code":"estimate_means(   model,   by = \"auto\",   predict = NULL,   ci = 0.95,   marginalize = \"average\",   backend = getOption(\"modelbased_backend\", \"marginaleffects\"),   transform = NULL,   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/modelbased/reference/estimate_means.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Marginal Means (Model-based average at each factor level) ‚Äî estimate_means","text":"model statistical model. (focal) predictor variable(s) evaluate desired effect / mean / contrasts. predictors model included collapsed \"averaged\" (effect estimated across ). argument used create \"reference grid\" \"data grid\" representative values focal predictors. can character (vector) naming focal predictors (optionally, representative values levels), list named elements. See details insight::get_datagrid() learn create data grids predictors interest. predict passed type argument emmeans::emmeans() (backend = \"emmeans\") marginaleffects::avg_predictions() (backend = \"marginaleffects\"). emmeans, see also vignette. Valid options `predict‚Äú : backend = \"emmeans\": predict can \"response\", \"link\", \"mu\", \"unlink\", \"log\". predict = NULL (default), appropriate transformation selected (usually \"response\"). backend = \"marginaleffects\": predict can \"response\", \"link\" valid type option supported model's class predict() method (e.g., zero-inflation models package glmmTMB, can choose predict = \"zprob\" predict = \"conditional\" etc., see glmmTMB::predict.glmmTMB). default, predict = NULL, appropriate transformation selected, usually returns predictions contrasts response-scale. \"link\" leave values scale linear predictors. \"response\" (NULL) transform scale response variable. Thus logistic model, \"link\" give estimations expressed log-odds (probabilities logit scale) \"response\" terms probabilities. predict distributional parameters (called \"dpar\" packages), instance using complex formulae brms models, predict argument can take value parameter want estimate, instance \"sigma\", \"kappa\", etc. ci Confidence Interval (CI) level. Default 0.95 (95%). marginalize Character string, indicating type marginalization. dictates predictions \"averaged\" non-focal predictors, .e. variables specified contrast. \"average\" (default): Takes mean value non-focal numeric predictors marginalizes factor levels non-focal terms, computes kind \"weighted average\" values terms hold constant. predictions good representation sample, possible values levels non-focal predictors considered. answers question, \"predicted value 'average' observation data?\". refers randomly picking subject sample result get average. approach one taken default emmeans package. \"population\": Non-focal predictors marginalized observations sample, sample replicated multiple times produce \"counterfactuals\" takes average predicted values (aggregated/grouped focal terms). can considered extrapolation hypothetical target population. Counterfactual predictions useful, insofar results can also transferred contexts (Dickerman Hernan, 2020). answers question, \"predicted response value 'average' observation broader target population?\". refer actual data observed sample, also \"\" data, data different sample. words, distinction marginalization types resides whether prediction made : specific \"individual\" sample (.e., specific combination predictor values): obtained using estimate_relation() prediction functions. average individual sample: obtained estimate_means(..., marginalize = \"average\") broader, hypothetical target population: obtained estimate_means(..., marginalize = \"population\") backend Whether use \"emmeans\" \"marginaleffects\" backend. Results usually similar. major difference found mixed models, backend = \"marginaleffects\" also average across random effects levels, producing \"marginal predictions\" (instead \"conditional predictions\", see Heiss 2022). can set default backend via options(), e.g. use options(modelbased_backend = \"emmeans\") use emmeans package options(modelbased_backend = \"marginaleffects\") set marginaleffects default backend. transform Deprecated, please use predict instead. verbose Use FALSE silence messages warnings. ... arguments passed, instance, insight::get_datagrid(), functions emmeans marginaleffects package, process Bayesian models via bayestestR::describe_posterior(). Examples: insight::get_datagrid(): Argument length range can used control (number ) representative values. marginaleffects: Internally used functions avg_predictions() means contrasts, avg_slope() slopes. Therefore, arguments instance like vcov, transform, equivalence slope can passed functions. emmeans: Internally used functions emmeans() emtrends(). Additional arguments can passed functions. Bayesian models: Bayesian models, parameters cleaned using describe_posterior(), thus, arguments like, example, centrality, rope_range, test passed function.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_means.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Marginal Means (Model-based average at each factor level) ‚Äî estimate_means","text":"data frame estimated marginal means.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_means.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate Marginal Means (Model-based average at each factor level) ‚Äî estimate_means","text":"estimate_slopes(), estimate_means() estimate_contrasts() functions forming group, based marginal estimations (estimations based model). three built emmeans marginaleffects package (depending backend argument), reading documentation (instance emmeans::emmeans(), emmeans::emtrends() website) recommended understand idea behind types procedures. Model-based predictions basis follows. Indeed, first thing understand models can used make predictions (see estimate_link()). corresponds predicted response (\"outcome variable\") given specific predictor values predictors (.e., given specific data configuration). concept reference grid() important direct predictions. Marginal \"means\", obtained via estimate_means(), extension predictions, allowing \"average\" (collapse) predictors, obtain average response value specific predictors configuration. typically used predictors interest factors. Indeed, parameters model usually give intercept value \"effect\" factor level (different intercept). Marginal means can used directly give mean value response variable levels factor. Moreover, can also used control, average predictors, useful case multiple predictors without interactions. Marginal contrasts, obtained via estimate_contrasts(), extension marginal means, allow investigate difference (.e., contrast) marginal means. , , often used get pairwise differences levels factor. works also continuous predictors, instance one also interested whether difference two extremes continuous predictor significant. Finally, marginal effects, obtained via estimate_slopes(), different focus values response variable, model's parameters. idea assess effect predictor specific configuration predictors. relevant case interactions non-linear relationships, effect predictor variable changes depending predictors. Moreover, effects can also \"averaged\" predictors, get instance \"general trend\" predictor different factor levels. Example: imagine following model lm(y ~ condition * x) condition factor 3 levels , B C x continuous variable (like age example). One idea see model performs, compare actual response y one predicted model (using estimate_expectation()). Another idea evaluate average mean condition's levels (using estimate_means()), can useful visualize . Another possibility evaluate difference levels (using estimate_contrasts()). Finally, one also estimate effect x averaged conditions, instead within condition (using [estimate_slopes]).","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_means.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate Marginal Means (Model-based average at each factor level) ‚Äî estimate_means","text":"Dickerman, Barbra ., Miguel . Hern√°n. 2020. Counterfactual Prediction Causal Inference. European Journal Epidemiology 35 (7): 615‚Äì17. doi:10.1007/s10654-020-00659-8 Heiss, . (2022). Marginal conditional effects GLMMs marginaleffects. Andrew Heiss. doi:10.59350/xwnfm-x1827","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_means.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Marginal Means (Model-based average at each factor level) ‚Äî estimate_means","text":"","code":"library(modelbased)  # Frequentist models # ------------------- model <- lm(Petal.Length ~ Sepal.Width * Species, data = iris)  estimate_means(model) #> We selected `by=c(\"Species\")`. #> Estimated Marginal Means #>  #> Species    | Mean |   SE |       95% CI | t(144) #> ------------------------------------------------ #> setosa     | 1.43 | 0.08 | [1.28, 1.58] |  18.70 #> versicolor | 4.50 | 0.07 | [4.35, 4.65] |  60.64 #> virginica  | 5.61 | 0.06 | [5.50, 5.72] |  99.61 #>  #> Variable predicted: Petal.Length #> Predictors modulated: Species #> Predictors averaged: Sepal.Width (3.1) #>   # the `length` argument is passed to `insight::get_datagrid()` and modulates # the number of representative values to return for numeric predictors estimate_means(model, by = c(\"Species\", \"Sepal.Width\"), length = 2) #> Estimated Marginal Means #>  #> Species    | Sepal.Width | Mean |   SE |       95% CI | t(144) #> -------------------------------------------------------------- #> setosa     |        2.00 | 1.35 | 0.21 | [0.92, 1.77] |   6.28 #> versicolor |        2.00 | 3.61 | 0.15 | [3.33, 3.90] |  24.81 #> virginica  |        2.00 | 4.88 | 0.17 | [4.54, 5.23] |  27.92 #> setosa     |        4.40 | 1.54 | 0.15 | [1.24, 1.84] |  10.19 #> versicolor |        4.40 | 5.63 | 0.29 | [5.05, 6.20] |  19.34 #> virginica  |        4.40 | 6.53 | 0.25 | [6.04, 7.02] |  26.19 #>  #> Variable predicted: Petal.Length #> Predictors modulated: Species, Sepal.Width #>   # an alternative way to setup your data grid is specify the values directly estimate_means(model, by = c(\"Species\", \"Sepal.Width = c(2, 4)\")) #> Estimated Marginal Means #>  #> Species    | Sepal.Width | Mean |   SE |       95% CI | t(144) #> -------------------------------------------------------------- #> setosa     |           2 | 1.35 | 0.21 | [0.92, 1.77] |   6.28 #> versicolor |           2 | 3.61 | 0.15 | [3.33, 3.90] |  24.81 #> virginica  |           2 | 4.88 | 0.17 | [4.54, 5.23] |  27.92 #> setosa     |           4 | 1.51 | 0.10 | [1.31, 1.70] |  15.19 #> versicolor |           4 | 5.29 | 0.22 | [4.85, 5.73] |  23.78 #> virginica  |           4 | 6.26 | 0.18 | [5.89, 6.62] |  34.11 #>  #> Variable predicted: Petal.Length #> Predictors modulated: Species, Sepal.Width = c(2, 4) #>   # or use one of the many predefined \"tokens\" that help you creating a useful # data grid - to learn more about creating data grids, see help in # `?insight::get_datagrid`. estimate_means(model, by = c(\"Species\", \"Sepal.Width = [fivenum]\")) #> Estimated Marginal Means #>  #> Species    | Sepal.Width | Mean |   SE |       95% CI | t(144) #> -------------------------------------------------------------- #> setosa     |        2.00 | 1.35 | 0.21 | [0.92, 1.77] |   6.28 #> versicolor |        2.00 | 3.61 | 0.15 | [3.33, 3.90] |  24.81 #> virginica  |        2.00 | 4.88 | 0.17 | [4.54, 5.23] |  27.92 #> setosa     |        2.80 | 1.41 | 0.11 | [1.20, 1.62] |  13.28 #> versicolor |        2.80 | 4.29 | 0.05 | [4.18, 4.39] |  78.28 #> virginica  |        2.80 | 5.43 | 0.06 | [5.31, 5.56] |  87.55 #> setosa     |        3.00 | 1.43 | 0.08 | [1.26, 1.59] |  17.27 #> versicolor |        3.00 | 4.45 | 0.07 | [4.32, 4.59] |  65.68 #> virginica  |        3.00 | 5.57 | 0.05 | [5.46, 5.68] | 101.89 #> setosa     |        3.30 | 1.45 | 0.06 | [1.34, 1.57] |  25.21 #> versicolor |        3.30 | 4.70 | 0.11 | [4.49, 4.92] |  43.66 #> virginica  |        3.30 | 5.78 | 0.08 | [5.62, 5.93] |  74.17 #> setosa     |        4.40 | 1.54 | 0.15 | [1.24, 1.84] |  10.19 #> versicolor |        4.40 | 5.63 | 0.29 | [5.05, 6.20] |  19.34 #> virginica  |        4.40 | 6.53 | 0.25 | [6.04, 7.02] |  26.19 #>  #> Variable predicted: Petal.Length #> Predictors modulated: Species, Sepal.Width = [fivenum] #>   # \\dontrun{ # same for factors: filter by specific levels estimate_means(model, by = \"Species=c('versicolor', 'setosa')\") #> Estimated Marginal Means #>  #> Species    | Mean |   SE |       95% CI | t(144) #> ------------------------------------------------ #> versicolor | 4.50 | 0.07 | [4.35, 4.65] |  60.64 #> setosa     | 1.43 | 0.08 | [1.28, 1.58] |  18.70 #>  #> Variable predicted: Petal.Length #> Predictors modulated: Species=c('versicolor', 'setosa') #> Predictors averaged: Sepal.Width (3.1) #>  estimate_means(model, by = c(\"Species\", \"Sepal.Width=0\")) #> Estimated Marginal Means #>  #> Species    | Sepal.Width | Mean |   SE |       95% CI | t(144) #> -------------------------------------------------------------- #> setosa     |           0 | 1.18 | 0.50 | [0.19, 2.17] |   2.36 #> versicolor |           0 | 1.93 | 0.49 | [0.97, 2.90] |   3.96 #> virginica  |           0 | 3.51 | 0.51 | [2.50, 4.52] |   6.88 #>  #> Variable predicted: Petal.Length #> Predictors modulated: Species, Sepal.Width=0 #>   # estimate marginal average of response at values for numeric predictor estimate_means(model, by = \"Sepal.Width\", length = 5) #> Estimated Marginal Means #>  #> Sepal.Width | Mean |   SE |       95% CI | t(144) #> ------------------------------------------------- #> 2.00        | 3.28 | 0.10 | [3.07, 3.49] |  31.48 #> 2.60        | 3.60 | 0.06 | [3.49, 3.71] |  64.21 #> 3.20        | 3.92 | 0.04 | [3.84, 4.01] |  89.81 #> 3.80        | 4.25 | 0.08 | [4.08, 4.41] |  50.21 #> 4.40        | 4.57 | 0.14 | [4.30, 4.84] |  33.25 #>  #> Variable predicted: Petal.Length #> Predictors modulated: Sepal.Width #> Predictors averaged: Species #>  estimate_means(model, by = \"Sepal.Width=c(2, 4)\") #> Estimated Marginal Means #>  #> Sepal.Width | Mean |   SE |       95% CI | t(144) #> ------------------------------------------------- #> 2           | 3.28 | 0.10 | [3.07, 3.49] |  31.48 #> 4           | 4.35 | 0.10 | [4.15, 4.55] |  42.81 #>  #> Variable predicted: Petal.Length #> Predictors modulated: Sepal.Width=c(2, 4) #> Predictors averaged: Species #>   # or provide the definition of the data grid as list estimate_means(   model,   by = list(Sepal.Width = c(2, 4), Species = c(\"versicolor\", \"setosa\")) ) #> Estimated Marginal Means #>  #> Sepal.Width | Species    | Mean |   SE |       95% CI | t(144) #> -------------------------------------------------------------- #> 2           | versicolor | 3.61 | 0.15 | [3.33, 3.90] |  24.81 #> 4           | versicolor | 5.29 | 0.22 | [4.85, 5.73] |  23.78 #> 2           | setosa     | 1.35 | 0.21 | [0.92, 1.77] |   6.28 #> 4           | setosa     | 1.51 | 0.10 | [1.31, 1.70] |  15.19 #>  #> Variable predicted: Petal.Length #> Predictors modulated: Sepal.Width = c(2, 4), Species = c('versicolor', 'setosa') #>   # Methods that can be applied to it: means <- estimate_means(model, by = c(\"Species\", \"Sepal.Width=0\"))  plot(means) # which runs visualisation_recipe()  standardize(means) #> Estimated Marginal Means (standardized) #>  #> Species    | Sepal.Width |  Mean |   SE |         95% CI | t(144) #> ----------------------------------------------------------------- #> setosa     |       -7.01 | -1.46 | 0.28 | [-2.02, -0.90] |   2.36 #> versicolor |       -7.01 | -1.03 | 0.28 | [-1.58, -0.49] |   3.96 #> virginica  |       -7.01 | -0.14 | 0.29 | [-0.71,  0.43] |   6.88 #>  #> Variable predicted: Petal.Length #> Predictors modulated: Species, Sepal.Width=0 #>   data <- iris data$Petal.Length_factor <- ifelse(data$Petal.Length < 4.2, \"A\", \"B\")  model <- lme4::lmer(   Petal.Length ~ Sepal.Width + Species + (1 | Petal.Length_factor),   data = data ) estimate_means(model) #> We selected `by=c(\"Species\")`. #> Estimated Marginal Means #>  #> Species    | Mean |   SE |       95% CI | t(144) #> ------------------------------------------------ #> setosa     | 1.67 | 0.34 | [1.00, 2.35] |   4.88 #> versicolor | 4.27 | 0.34 | [3.61, 4.94] |  12.69 #> virginica  | 5.25 | 0.34 | [4.58, 5.92] |  15.45 #>  #> Variable predicted: Petal.Length #> Predictors modulated: Species #> Predictors averaged: Sepal.Width (3.1), Petal.Length_factor #>  estimate_means(model, by = \"Sepal.Width\", length = 3) #> Estimated Marginal Means #>  #> Sepal.Width | Mean |   SE |       95% CI | t(144) #> ------------------------------------------------- #> 2.00        | 3.40 | 0.35 | [2.72, 4.09] |   9.84 #> 3.20        | 3.78 | 0.33 | [3.12, 4.43] |  11.35 #> 4.40        | 4.15 | 0.35 | [3.45, 4.85] |  11.70 #>  #> Variable predicted: Petal.Length #> Predictors modulated: Sepal.Width #> Predictors averaged: Species, Petal.Length_factor #>  # }"},{"path":"https://easystats.github.io/modelbased/reference/estimate_slopes.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Marginal Effects ‚Äî estimate_slopes","title":"Estimate Marginal Effects ‚Äî estimate_slopes","text":"Estimate slopes (.e., coefficient) predictor within different factor levels, alongside numeric variable. words, assess effect predictor specific configurations data. corresponds derivative can useful understand predictor significant role interactions non-linear relationships present. related functions based marginal estimations includes estimate_contrasts() estimate_means(). See Details section , forget also check Vignettes README examples various examples, tutorials use cases.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_slopes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Marginal Effects ‚Äî estimate_slopes","text":"","code":"estimate_slopes(   model,   trend = NULL,   by = NULL,   ci = 0.95,   backend = getOption(\"modelbased_backend\", \"marginaleffects\"),   verbose = TRUE,   ... )"},{"path":"https://easystats.github.io/modelbased/reference/estimate_slopes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Marginal Effects ‚Äî estimate_slopes","text":"model statistical model. trend character indicating name variable compute slopes. (focal) predictor variable(s) evaluate desired effect / mean / contrasts. predictors model included collapsed \"averaged\" (effect estimated across ). argument used create \"reference grid\" \"data grid\" representative values focal predictors. can character (vector) naming focal predictors (optionally, representative values levels), list named elements. See details insight::get_datagrid() learn create data grids predictors interest. ci Confidence Interval (CI) level. Default 0.95 (95%). backend Whether use \"emmeans\" \"marginaleffects\" backend. Results usually similar. major difference found mixed models, backend = \"marginaleffects\" also average across random effects levels, producing \"marginal predictions\" (instead \"conditional predictions\", see Heiss 2022). can set default backend via options(), e.g. use options(modelbased_backend = \"emmeans\") use emmeans package options(modelbased_backend = \"marginaleffects\") set marginaleffects default backend. verbose Use FALSE silence messages warnings. ... arguments passed, instance, insight::get_datagrid(), functions emmeans marginaleffects package, process Bayesian models via bayestestR::describe_posterior(). Examples: insight::get_datagrid(): Argument length range can used control (number ) representative values. marginaleffects: Internally used functions avg_predictions() means contrasts, avg_slope() slopes. Therefore, arguments instance like vcov, transform, equivalence slope can passed functions. emmeans: Internally used functions emmeans() emtrends(). Additional arguments can passed functions. Bayesian models: Bayesian models, parameters cleaned using describe_posterior(), thus, arguments like, example, centrality, rope_range, test passed function.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_slopes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Marginal Effects ‚Äî estimate_slopes","text":"data.frame class estimate_slopes.","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_slopes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate Marginal Effects ‚Äî estimate_slopes","text":"estimate_slopes(), estimate_means() estimate_contrasts() functions forming group, based marginal estimations (estimations based model). three built emmeans marginaleffects package (depending backend argument), reading documentation (instance emmeans::emmeans(), emmeans::emtrends() website) recommended understand idea behind types procedures. Model-based predictions basis follows. Indeed, first thing understand models can used make predictions (see estimate_link()). corresponds predicted response (\"outcome variable\") given specific predictor values predictors (.e., given specific data configuration). concept reference grid() important direct predictions. Marginal \"means\", obtained via estimate_means(), extension predictions, allowing \"average\" (collapse) predictors, obtain average response value specific predictors configuration. typically used predictors interest factors. Indeed, parameters model usually give intercept value \"effect\" factor level (different intercept). Marginal means can used directly give mean value response variable levels factor. Moreover, can also used control, average predictors, useful case multiple predictors without interactions. Marginal contrasts, obtained via estimate_contrasts(), extension marginal means, allow investigate difference (.e., contrast) marginal means. , , often used get pairwise differences levels factor. works also continuous predictors, instance one also interested whether difference two extremes continuous predictor significant. Finally, marginal effects, obtained via estimate_slopes(), different focus values response variable, model's parameters. idea assess effect predictor specific configuration predictors. relevant case interactions non-linear relationships, effect predictor variable changes depending predictors. Moreover, effects can also \"averaged\" predictors, get instance \"general trend\" predictor different factor levels. Example: imagine following model lm(y ~ condition * x) condition factor 3 levels , B C x continuous variable (like age example). One idea see model performs, compare actual response y one predicted model (using estimate_expectation()). Another idea evaluate average mean condition's levels (using estimate_means()), can useful visualize . Another possibility evaluate difference levels (using estimate_contrasts()). Finally, one also estimate effect x averaged conditions, instead within condition (using [estimate_slopes]).","code":""},{"path":"https://easystats.github.io/modelbased/reference/estimate_slopes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Marginal Effects ‚Äî estimate_slopes","text":"","code":"library(ggplot2) # Get an idea of the data ggplot(iris, aes(x = Petal.Length, y = Sepal.Width)) +   geom_point(aes(color = Species)) +   geom_smooth(color = \"black\", se = FALSE) +   geom_smooth(aes(color = Species), linetype = \"dotted\", se = FALSE) +   geom_smooth(aes(color = Species), method = \"lm\", se = FALSE) #> `geom_smooth()` using method = 'loess' and formula = 'y ~ x' #> `geom_smooth()` using method = 'loess' and formula = 'y ~ x' #> `geom_smooth()` using formula = 'y ~ x'   # Model it model <- lm(Sepal.Width ~ Species * Petal.Length, data = iris) # Compute the marginal effect of Petal.Length at each level of Species slopes <- estimate_slopes(model, trend = \"Petal.Length\", by = \"Species\") slopes #> Estimated Marginal Effects #>  #> Species    | Slope |   SE |        95% CI |    t |      p #> --------------------------------------------------------- #> setosa     |  0.39 | 0.26 | [-0.12, 0.90] | 1.49 |  0.136 #> versicolor |  0.37 | 0.10 | [ 0.19, 0.56] | 3.89 | < .001 #> virginica  |  0.23 | 0.08 | [ 0.07, 0.39] | 2.86 |  0.004 #>  #> Marginal effects estimated for Petal.Length #> Type of slope was dY/dX  # \\dontrun{ # Plot it plot(slopes)  standardize(slopes) #> Estimated Marginal Effects (standardized) #>  #> Species    | Slope |   SE |        95% CI |    t |      p #> --------------------------------------------------------- #> setosa     |  0.39 | 0.60 | [-0.28, 2.06] | 1.49 |  0.136 #> versicolor |  0.37 | 0.22 | [ 0.43, 1.29] | 3.89 | < .001 #> virginica  |  0.23 | 0.19 | [ 0.17, 0.91] | 2.86 |  0.004 #>  #> Marginal effects estimated for Petal.Length #> Type of slope was dY/dX  model <- mgcv::gam(Sepal.Width ~ s(Petal.Length), data = iris) slopes <- estimate_slopes(model, by = \"Petal.Length\", length = 50) #> No numeric variable was specified for slope estimation. Selecting `trend #>   = \"Petal.Length\"`. summary(slopes) #> Average Marginal Effects #>  #> Start |  End | Petal.Length | Slope |   SE |         95% CI |     t |     p #> --------------------------------------------------------------------------- #> 1.00  | 1.96 |         1.48 |  0.13 | 0.30 | [-0.46,  0.71] |  0.30 | 0.420 #> 2.08  | 3.05 |         2.57 | -0.78 | 0.19 | [-1.15, -0.41] | -4.25 | 0.001 #> 3.17  | 3.65 |         3.41 | -0.10 | 0.26 | [-0.61,  0.41] | -0.31 | 0.344 #> 3.77  | 4.25 |         4.01 |  0.54 | 0.20 | [ 0.15,  0.92] |  2.71 | 0.010 #> 4.37  | 6.90 |         5.64 |  0.07 | 0.23 | [-0.39,  0.53] |  0.58 | 0.428 #>  #> Marginal effects estimated for Petal.Length #> Type of slope was dY/dX plot(slopes)   model <- mgcv::gam(Sepal.Width ~ s(Petal.Length, by = Species), data = iris) slopes <- estimate_slopes(model,   trend = \"Petal.Length\",   by = c(\"Petal.Length\", \"Species\"), length = 20 ) summary(slopes) #> Average Marginal Effects #>  #> Species    | Start |  End | Petal.Length | Slope |   SE |        95% CI |    t |      p #> --------------------------------------------------------------------------------------- #> setosa     |  1.00 | 1.62 |         1.31 |  0.27 | 0.28 | [-0.27, 0.82] | 0.99 |  0.324 #> versicolor |  3.17 | 5.04 |         4.11 |  0.38 | 0.10 | [ 0.19, 0.56] | 3.94 | < .001 #> virginica  |  4.73 | 5.66 |         5.19 |  0.29 | 0.13 | [ 0.04, 0.53] | 2.32 |  0.024 #> virginica  |  5.97 | 6.90 |         6.43 |  0.10 | 0.17 | [-0.23, 0.44] | 0.71 |  0.536 #>  #> Marginal effects estimated for Petal.Length #> Type of slope was dY/dX plot(slopes)  # }"},{"path":"https://easystats.github.io/modelbased/reference/fish.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample data set ‚Äî fish","title":"Sample data set ‚Äî fish","text":"sample data set, used tests examples. Useful demonstrating count models (without zero-inflation component). consists nine variables 250 observations.","code":""},{"path":"https://easystats.github.io/modelbased/reference/get_emmeans.html","id":null,"dir":"Reference","previous_headings":"","what":"Consistent API for 'emmeans' and 'marginaleffects' ‚Äî get_emcontrasts","title":"Consistent API for 'emmeans' and 'marginaleffects' ‚Äî get_emcontrasts","text":"functions convenient wrappers around emmeans marginaleffects packages. mostly available developers want leverage unified API getting model-based estimates, regular users use estimate_* set functions. get_emmeans(), get_emcontrasts() get_emtrends() functions wrappers around emmeans::emmeans() emmeans::emtrends().","code":""},{"path":"https://easystats.github.io/modelbased/reference/get_emmeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Consistent API for 'emmeans' and 'marginaleffects' ‚Äî get_emcontrasts","text":"","code":"get_emcontrasts(   model,   contrast = NULL,   by = NULL,   predict = NULL,   comparison = \"pairwise\",   transform = NULL,   verbose = TRUE,   ... )  get_emmeans(   model,   by = \"auto\",   predict = NULL,   transform = NULL,   verbose = TRUE,   ... )  get_emtrends(model, trend = NULL, by = NULL, verbose = TRUE, ...)  get_marginalcontrasts(   model,   contrast = NULL,   by = NULL,   predict = NULL,   comparison = \"pairwise\",   marginalize = \"average\",   ci = 0.95,   p_adjust = \"none\",   verbose = TRUE,   ... )  get_marginalmeans(   model,   by = \"auto\",   predict = NULL,   ci = 0.95,   marginalize = \"average\",   transform = NULL,   verbose = TRUE,   ... )  get_marginaltrends(model, trend = NULL, by = NULL, verbose = TRUE, ...)"},{"path":"https://easystats.github.io/modelbased/reference/get_emmeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Consistent API for 'emmeans' and 'marginaleffects' ‚Äî get_emcontrasts","text":"model statistical model. contrast character vector indicating name variable(s) compute contrasts. (focal) predictor variable(s) evaluate desired effect / mean / contrasts. predictors model included collapsed \"averaged\" (effect estimated across ). argument used create \"reference grid\" \"data grid\" representative values focal predictors. can character (vector) naming focal predictors (optionally, representative values levels), list named elements. See details insight::get_datagrid() learn create data grids predictors interest. predict passed type argument emmeans::emmeans() (backend = \"emmeans\") marginaleffects::avg_predictions() (backend = \"marginaleffects\"). emmeans, see also vignette. Valid options `predict‚Äú : backend = \"emmeans\": predict can \"response\", \"link\", \"mu\", \"unlink\", \"log\". predict = NULL (default), appropriate transformation selected (usually \"response\"). backend = \"marginaleffects\": predict can \"response\", \"link\" valid type option supported model's class predict() method (e.g., zero-inflation models package glmmTMB, can choose predict = \"zprob\" predict = \"conditional\" etc., see glmmTMB::predict.glmmTMB). default, predict = NULL, appropriate transformation selected, usually returns predictions contrasts response-scale. \"link\" leave values scale linear predictors. \"response\" (NULL) transform scale response variable. Thus logistic model, \"link\" give estimations expressed log-odds (probabilities logit scale) \"response\" terms probabilities. predict distributional parameters (called \"dpar\" packages), instance using complex formulae brms models, predict argument can take value parameter want estimate, instance \"sigma\", \"kappa\", etc. comparison Specify type contrasts tests carried . backend = \"emmeans\", can one \"pairwise\", \"poly\", \"consec\", \"eff\", \"del.eff\", \"mean_chg\", \"trt.vs.ctrl\", \"dunnett\", \"wtcon\" . See also method argument emmeans::contrast ?emmeans::emmc-functions. backend = \"marginaleffects\", can numeric value, vector, matrix, string equation specifying hypothesis test, string naming comparison method, formula, function. Strings, string equations formula probably common options described . options detailed descriptions options, see also marginaleffects::comparisons website. String: One \"pairwise\", \"reference\", \"sequential\", \"meandev\" \"meanotherdev\", \"poly\", \"helmert\", \"trt_vs_ctrl\". String equation: identify parameters output, either specify term name, \"b1\", \"b2\" etc. indicate rows, e.g.:\"hp = drat\", \"b1 = b2\", \"b1 + b2 + b3 = 0\". Formula: formula like comparison ~ pairs | group, left-hand side indicates type comparison (difference ratio), right-hand side determines pairs estimates compare (reference, sequential, meandev, etc., see string-options). Optionally, comparisons can carried within subsets indicating grouping variable vertical bar ( |). transform Deprecated, please use predict instead. verbose Use FALSE silence messages warnings. ... arguments passed, instance, insight::get_datagrid(), functions emmeans marginaleffects package, process Bayesian models via bayestestR::describe_posterior(). Examples: insight::get_datagrid(): Argument length range can used control (number ) representative values. marginaleffects: Internally used functions avg_predictions() means contrasts, avg_slope() slopes. Therefore, arguments instance like vcov, transform, equivalence slope can passed functions. emmeans: Internally used functions emmeans() emtrends(). Additional arguments can passed functions. Bayesian models: Bayesian models, parameters cleaned using describe_posterior(), thus, arguments like, example, centrality, rope_range, test passed function. trend character indicating name variable compute slopes. marginalize Character string, indicating type marginalization. dictates predictions \"averaged\" non-focal predictors, .e. variables specified contrast. \"average\" (default): Takes mean value non-focal numeric predictors marginalizes factor levels non-focal terms, computes kind \"weighted average\" values terms hold constant. predictions good representation sample, possible values levels non-focal predictors considered. answers question, \"predicted value 'average' observation data?\". refers randomly picking subject sample result get average. approach one taken default emmeans package. \"population\": Non-focal predictors marginalized observations sample, sample replicated multiple times produce \"counterfactuals\" takes average predicted values (aggregated/grouped focal terms). can considered extrapolation hypothetical target population. Counterfactual predictions useful, insofar results can also transferred contexts (Dickerman Hernan, 2020). answers question, \"predicted response value 'average' observation broader target population?\". refer actual data observed sample, also \"\" data, data different sample. words, distinction marginalization types resides whether prediction made : specific \"individual\" sample (.e., specific combination predictor values): obtained using estimate_relation() prediction functions. average individual sample: obtained estimate_means(..., marginalize = \"average\") broader, hypothetical target population: obtained estimate_means(..., marginalize = \"population\") ci Confidence Interval (CI) level. Default 0.95 (95%). p_adjust p-values adjustment method frequentist multiple comparisons. Can one \"none\" (default), \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"\", \"fdr\", \"tukey\" \"holm\". See p-value adjustment section emmeans::test documentation ?stats::p.adjust.","code":""},{"path":"https://easystats.github.io/modelbased/reference/get_emmeans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Consistent API for 'emmeans' and 'marginaleffects' ‚Äî get_emcontrasts","text":"","code":"# Basic usage model <- lm(Sepal.Width ~ Species, data = iris) get_emcontrasts(model) #> No variable was specified for contrast estimation. Selecting `contrast = #>   \"Species\"`. #>  contrast               estimate     SE  df t.ratio p.value #>  setosa - versicolor       0.658 0.0679 147   9.685  <.0001 #>  setosa - virginica        0.454 0.0679 147   6.683  <.0001 #>  versicolor - virginica   -0.204 0.0679 147  -3.003  0.0088 #>  #> P value adjustment: tukey method for comparing a family of 3 estimates   # \\dontrun{ # Dealing with interactions model <- lm(Sepal.Width ~ Species * Petal.Width, data = iris) # By default: selects first factor get_emcontrasts(model) #> No variable was specified for contrast estimation. Selecting `contrast = #>   \"Species\"`. #> NOTE: Results may be misleading due to involvement in interactions #>  contrast               estimate    SE  df t.ratio p.value #>  setosa - versicolor       1.590 0.394 144   4.039  0.0003 #>  setosa - virginica        1.774 0.413 144   4.293  0.0001 #>  versicolor - virginica    0.184 0.145 144   1.272  0.4131 #>  #> P value adjustment: tukey method for comparing a family of 3 estimates  # Can also run contrasts between points of numeric get_emcontrasts(model, contrast = \"Petal.Width\", length = 3) #> NOTE: Results may be misleading due to involvement in interactions #>  contrast                        estimate    SE  df t.ratio p.value #>  Petal.Width0.1 - Petal.Width1.3    -1.01 0.195 144  -5.180  <.0001 #>  Petal.Width0.1 - Petal.Width2.5    -2.02 0.390 144  -5.180  <.0001 #>  Petal.Width1.3 - Petal.Width2.5    -1.01 0.195 144  -5.180  <.0001 #>  #> Results are averaged over the levels of: Species  #> P value adjustment: tukey method for comparing a family of 3 estimates  # Or both get_emcontrasts(model, contrast = c(\"Species\", \"Petal.Width\"), length = 2) #>  contrast                                              estimate    SE  df #>  setosa Petal.Width0.1 - versicolor Petal.Width0.1       1.8275 0.279 144 #>  setosa Petal.Width0.1 - virginica Petal.Width0.1        1.5479 0.312 144 #>  setosa Petal.Width0.1 - setosa Petal.Width2.5          -2.0093 0.977 144 #>  setosa Petal.Width0.1 - versicolor Petal.Width2.5      -0.7012 0.268 144 #>  setosa Petal.Width0.1 - virginica Petal.Width2.5        0.0325 0.112 144 #>  versicolor Petal.Width0.1 - virginica Petal.Width0.1   -0.2797 0.406 144 #>  versicolor Petal.Width0.1 - setosa Petal.Width2.5      -3.8368 0.957 144 #>  versicolor Petal.Width0.1 - versicolor Petal.Width2.5  -2.5288 0.521 144 #>  versicolor Petal.Width0.1 - virginica Petal.Width2.5   -1.7951 0.282 144 #>  virginica Petal.Width0.1 - setosa Petal.Width2.5       -3.5571 0.967 144 #>  virginica Petal.Width0.1 - versicolor Petal.Width2.5   -2.2491 0.399 144 #>  virginica Petal.Width0.1 - virginica Petal.Width2.5    -1.5154 0.375 144 #>  setosa Petal.Width2.5 - versicolor Petal.Width2.5       1.3080 0.954 144 #>  setosa Petal.Width2.5 - virginica Petal.Width2.5        2.0417 0.922 144 #>  versicolor Petal.Width2.5 - virginica Petal.Width2.5    0.7337 0.272 144 #>  t.ratio p.value #>    6.550  <.0001 #>    4.955  <.0001 #>   -2.057  0.3158 #>   -2.614  0.1005 #>    0.289  0.9997 #>   -0.689  0.9829 #>   -4.009  0.0013 #>   -4.858  <.0001 #>   -6.355  <.0001 #>   -3.678  0.0044 #>   -5.642  <.0001 #>   -4.043  0.0012 #>    1.371  0.7441 #>    2.214  0.2379 #>    2.699  0.0817 #>  #> P value adjustment: tukey method for comparing a family of 6 estimates  # Or with custom specifications estimate_contrasts(model, contrast = c(\"Species\", \"Petal.Width=c(1, 2)\")) #> Marginal Contrasts Analysis #>  #> Level1        | Level2        | Difference |   SE |         95% CI | t(144) |      p #> ------------------------------------------------------------------------------------ #> setosa, 2     | setosa, 1     |       0.84 | 0.41 | [ 0.03,  1.64] |   2.06 |  0.041 #> versicolor, 1 | setosa, 1     |      -1.63 | 0.32 | [-2.27, -1.00] |  -5.09 | < .001 #> versicolor, 2 | setosa, 1     |      -0.58 | 0.35 | [-1.26,  0.10] |  -1.68 |  0.096 #> virginica, 1  | setosa, 1     |      -1.73 | 0.35 | [-2.43, -1.04] |  -4.93 | < .001 #> virginica, 2  | setosa, 1     |      -1.10 | 0.31 | [-1.72, -0.48] |  -3.52 | < .001 #> versicolor, 1 | setosa, 2     |      -2.47 | 0.72 | [-3.89, -1.05] |  -3.43 | < .001 #> versicolor, 2 | setosa, 2     |      -1.42 | 0.73 | [-2.86,  0.03] |  -1.94 |  0.055 #> virginica, 1  | setosa, 2     |      -2.57 | 0.73 | [-4.02, -1.12] |  -3.50 | < .001 #> virginica, 2  | setosa, 2     |      -1.94 | 0.72 | [-3.35, -0.52] |  -2.71 |  0.008 #> versicolor, 2 | versicolor, 1 |       1.05 | 0.22 | [ 0.62,  1.48] |   4.86 | < .001 #> virginica, 1  | versicolor, 1 |      -0.10 | 0.19 | [-0.47,  0.27] |  -0.54 |  0.589 #> virginica, 2  | versicolor, 1 |       0.53 | 0.09 | [ 0.35,  0.71] |   5.72 | < .001 #> virginica, 1  | versicolor, 2 |      -1.15 | 0.23 | [-1.60, -0.71] |  -5.13 | < .001 #> virginica, 2  | versicolor, 2 |      -0.52 | 0.16 | [-0.84, -0.21] |  -3.31 |  0.001 #> virginica, 2  | virginica, 1  |       0.63 | 0.16 | [ 0.32,  0.94] |   4.04 | < .001 #>  #> Variable predicted: Sepal.Width #> Predictors contrasted: Species, Petal.Width=c(1, 2) #> p-values are uncorrected. #>  # Or modulate it get_emcontrasts(model, by = \"Petal.Width\", length = 4) #> No variable was specified for contrast estimation. Selecting `contrast = #>   \"Species\"`. #> Petal.Width = 0.1: #>  contrast               estimate    SE  df t.ratio p.value #>  setosa - versicolor      1.8275 0.279 144   6.550  <.0001 #>  setosa - virginica       1.5479 0.312 144   4.955  <.0001 #>  versicolor - virginica  -0.2797 0.406 144  -0.689  0.7703 #>  #> Petal.Width = 0.9: #>  contrast               estimate    SE  df t.ratio p.value #>  setosa - versicolor      1.6544 0.288 144   5.743  <.0001 #>  setosa - virginica       1.7125 0.325 144   5.276  <.0001 #>  versicolor - virginica   0.0581 0.208 144   0.280  0.9577 #>  #> Petal.Width = 1.7: #>  contrast               estimate    SE  df t.ratio p.value #>  setosa - versicolor      1.4812 0.600 144   2.467  0.0390 #>  setosa - virginica       1.8771 0.597 144   3.144  0.0057 #>  versicolor - virginica   0.3959 0.113 144   3.502  0.0018 #>  #> Petal.Width = 2.5: #>  contrast               estimate    SE  df t.ratio p.value #>  setosa - versicolor      1.3080 0.954 144   1.371  0.3587 #>  setosa - virginica       2.0417 0.922 144   2.214  0.0722 #>  versicolor - virginica   0.7337 0.272 144   2.699  0.0212 #>  #> P value adjustment: tukey method for comparing a family of 3 estimates  # } model <- lm(Sepal.Length ~ Species + Petal.Width, data = iris)  # By default, 'by' is set to \"Species\" get_emmeans(model) #> We selected `by = c(\"Species\")`. #>  Species    emmean     SE  df lower.CL upper.CL #>  setosa       5.88 0.1970 146     5.49     6.27 #>  versicolor   5.82 0.0723 146     5.68     5.96 #>  virginica    5.83 0.1740 146     5.49     6.17 #>  #> Confidence level used: 0.95   # \\dontrun{ # Overall mean (close to 'mean(iris$Sepal.Length)') get_emmeans(model, by = NULL) #>  1       emmean     SE  df lower.CL upper.CL #>  overall   5.84 0.0393 146     5.77     5.92 #>  #> Results are averaged over the levels of: Species  #> Confidence level used: 0.95   # One can estimate marginal means at several values of a 'modulate' variable get_emmeans(model, by = \"Petal.Width\", length = 3) #>  Petal.Width emmean     SE  df lower.CL upper.CL #>          0.1   4.84 0.2170 146     4.41     5.26 #>          1.3   5.94 0.0439 146     5.85     6.02 #>          2.5   7.04 0.2550 146     6.53     7.54 #>  #> Results are averaged over the levels of: Species  #> Confidence level used: 0.95   # Interactions model <- lm(Sepal.Width ~ Species * Petal.Length, data = iris)  get_emmeans(model) #> We selected `by = c(\"Species\")`. #> NOTE: Results may be misleading due to involvement in interactions #>  Species    emmean     SE  df lower.CL upper.CL #>  setosa       4.32 0.5990 144     3.13     5.50 #>  versicolor   2.58 0.0658 144     2.45     2.71 #>  virginica    2.55 0.1540 144     2.25     2.86 #>  #> Confidence level used: 0.95  get_emmeans(model, by = c(\"Species\", \"Petal.Length\"), length = 2) #>  Species    Petal.Length emmean    SE  df lower.CL upper.CL #>  setosa              1.0   3.25 0.128 144    2.995     3.50 #>  versicolor          1.0   1.55 0.317 144    0.924     2.18 #>  virginica           1.0   1.91 0.375 144    1.165     2.65 #>  setosa              6.9   5.54 1.420 144    2.739     8.34 #>  versicolor          6.9   3.76 0.258 144    3.249     4.27 #>  virginica           6.9   3.29 0.119 144    3.055     3.53 #>  #> Confidence level used: 0.95  get_emmeans(model, by = c(\"Species\", \"Petal.Length = c(1, 3, 5)\"), length = 2) #>  Species    Petal.Length emmean     SE  df lower.CL upper.CL #>  setosa                1   3.25 0.1280 144    2.995     3.50 #>  versicolor            1   1.55 0.3170 144    0.924     2.18 #>  virginica             1   1.91 0.3750 144    1.165     2.65 #>  setosa                3   4.02 0.4030 144    3.229     4.82 #>  versicolor            3   2.30 0.1290 144    2.043     2.55 #>  virginica             3   2.38 0.2140 144    1.954     2.80 #>  setosa                5   4.80 0.9220 144    2.979     6.62 #>  versicolor            5   3.05 0.0840 144    2.881     3.21 #>  virginica             5   2.84 0.0636 144    2.719     2.97 #>  #> Confidence level used: 0.95  # } # \\dontrun{ model <- lm(Sepal.Width ~ Species * Petal.Length, data = iris)  get_emtrends(model) #> No numeric variable was specified for slope estimation. Selecting `trend #>   = \"Petal.Length\"`. #>  1       Petal.Length.trend     SE  df lower.CL upper.CL #>  overall              0.332 0.0964 144    0.142    0.523 #>  #> Results are averaged over the levels of: Species  #> Confidence level used: 0.95  get_emtrends(model, by = \"Species\") #> No numeric variable was specified for slope estimation. Selecting `trend #>   = \"Petal.Length\"`. #>  Species    Petal.Length.trend     SE  df lower.CL upper.CL #>  setosa                  0.388 0.2600 144  -0.1264    0.902 #>  versicolor              0.374 0.0961 144   0.1843    0.564 #>  virginica               0.234 0.0819 144   0.0725    0.396 #>  #> Confidence level used: 0.95  get_emtrends(model, by = \"Petal.Length\") #> No numeric variable was specified for slope estimation. Selecting `trend #>   = \"Petal.Length\"`. #> NOTE: Results may be misleading due to involvement in interactions #>  Petal.Length Petal.Length.trend     SE  df lower.CL upper.CL #>          1.00              0.332 0.0964 144    0.142    0.523 #>          1.66              0.332 0.0964 144    0.142    0.523 #>          2.31              0.332 0.0964 144    0.142    0.523 #>          2.97              0.332 0.0964 144    0.142    0.523 #>          3.62              0.332 0.0964 144    0.142    0.523 #>          4.28              0.332 0.0964 144    0.142    0.523 #>          4.93              0.332 0.0964 144    0.142    0.523 #>          5.59              0.332 0.0964 144    0.142    0.523 #>          6.24              0.332 0.0964 144    0.142    0.523 #>          6.90              0.332 0.0964 144    0.142    0.523 #>  #> Results are averaged over the levels of: Species  #> Confidence level used: 0.95  get_emtrends(model, by = c(\"Species\", \"Petal.Length\")) #> No numeric variable was specified for slope estimation. Selecting `trend #>   = \"Petal.Length\"`. #>  Species    Petal.Length Petal.Length.trend     SE  df lower.CL upper.CL #>  setosa             1.00              0.388 0.2600 144  -0.1264    0.902 #>  versicolor         1.00              0.374 0.0961 144   0.1843    0.564 #>  virginica          1.00              0.234 0.0819 144   0.0725    0.396 #>  setosa             1.66              0.388 0.2600 144  -0.1264    0.902 #>  versicolor         1.66              0.374 0.0961 144   0.1843    0.564 #>  virginica          1.66              0.234 0.0819 144   0.0725    0.396 #>  setosa             2.31              0.388 0.2600 144  -0.1264    0.902 #>  versicolor         2.31              0.374 0.0961 144   0.1843    0.564 #>  virginica          2.31              0.234 0.0819 144   0.0725    0.396 #>  setosa             2.97              0.388 0.2600 144  -0.1264    0.902 #>  versicolor         2.97              0.374 0.0961 144   0.1843    0.564 #>  virginica          2.97              0.234 0.0819 144   0.0725    0.396 #>  setosa             3.62              0.388 0.2600 144  -0.1264    0.902 #>  versicolor         3.62              0.374 0.0961 144   0.1843    0.564 #>  virginica          3.62              0.234 0.0819 144   0.0725    0.396 #>  setosa             4.28              0.388 0.2600 144  -0.1264    0.902 #>  versicolor         4.28              0.374 0.0961 144   0.1843    0.564 #>  virginica          4.28              0.234 0.0819 144   0.0725    0.396 #>  setosa             4.93              0.388 0.2600 144  -0.1264    0.902 #>  versicolor         4.93              0.374 0.0961 144   0.1843    0.564 #>  virginica          4.93              0.234 0.0819 144   0.0725    0.396 #>  setosa             5.59              0.388 0.2600 144  -0.1264    0.902 #>  versicolor         5.59              0.374 0.0961 144   0.1843    0.564 #>  virginica          5.59              0.234 0.0819 144   0.0725    0.396 #>  setosa             6.24              0.388 0.2600 144  -0.1264    0.902 #>  versicolor         6.24              0.374 0.0961 144   0.1843    0.564 #>  virginica          6.24              0.234 0.0819 144   0.0725    0.396 #>  setosa             6.90              0.388 0.2600 144  -0.1264    0.902 #>  versicolor         6.90              0.374 0.0961 144   0.1843    0.564 #>  virginica          6.90              0.234 0.0819 144   0.0725    0.396 #>  #> Confidence level used: 0.95  # }  model <- lm(Petal.Length ~ poly(Sepal.Width, 4), data = iris) get_emtrends(model) #> No numeric variable was specified for slope estimation. Selecting `trend #>   = \"Sepal.Width\"`. #>  1       Sepal.Width.trend    SE  df lower.CL upper.CL #>  overall             -2.67 0.548 145    -3.75    -1.58 #>  #> Confidence level used: 0.95  get_emtrends(model, by = \"Sepal.Width\") #> No numeric variable was specified for slope estimation. Selecting `trend #>   = \"Sepal.Width\"`. #>  Sepal.Width Sepal.Width.trend    SE  df lower.CL upper.CL #>         2.00             7.484 5.420 145   -3.225   18.192 #>         2.27             3.779 2.090 145   -0.358    7.916 #>         2.53             0.831 0.765 145   -0.681    2.342 #>         2.80            -1.337 0.706 145   -2.732    0.058 #>         3.07            -2.699 0.543 145   -3.772   -1.626 #>         3.33            -3.231 0.607 145   -4.430   -2.032 #>         3.60            -2.909 0.838 145   -4.564   -1.254 #>         3.87            -1.708 1.010 145   -3.702    0.287 #>         4.13             0.398 2.390 145   -4.330    5.125 #>         4.40             3.431 5.800 145   -8.028   14.890 #>  #> Confidence level used: 0.95  model <- lm(Sepal.Length ~ Species + Petal.Width, data = iris)  # By default, 'by' is set to \"Species\" get_marginalmeans(model) #> We selected `by=c(\"Species\")`. #>  #>     Species Estimate Std. Error    t Pr(>|t|)     S 2.5 % 97.5 %  Df #>  setosa         5.88     0.1969 29.9   <0.001 210.3  5.49   6.27 146 #>  versicolor     5.82     0.0723 80.5   <0.001 405.6  5.68   5.96 146 #>  virginica      5.83     0.1741 33.5   <0.001 231.4  5.49   6.17 146 #>  #> Type:  response  #>   # Overall mean (close to 'mean(iris$Sepal.Length)') get_marginalmeans(model, by = NULL) #>  #>  Estimate Std. Error   t Pr(>|t|)     S 2.5 % 97.5 %  Df #>      5.84     0.0393 149   <0.001 533.4  5.77   5.92 146 #>  #> Type:  response  #>   # \\dontrun{ # One can estimate marginal means at several values of a 'modulate' variable get_marginalmeans(model, by = \"Petal.Width\", length = 3) #>  #>  Petal.Width Estimate Std. Error     t Pr(>|t|)     S 2.5 % 97.5 %  Df #>          0.1     4.84     0.2167  22.3   <0.001 160.0  4.41   5.26 146 #>          1.3     5.94     0.0439 135.3   <0.001 513.6  5.85   6.02 146 #>          2.5     7.04     0.2552  27.6   <0.001 196.1  6.53   7.54 146 #>  #> Type:  response  #>   # Interactions model <- lm(Sepal.Width ~ Species * Petal.Length, data = iris)  get_marginalmeans(model) #> We selected `by=c(\"Species\")`. #>  #>     Species Estimate Std. Error     t Pr(>|t|)     S 2.5 % 97.5 %  Df #>  setosa         4.32     0.5990  7.21   <0.001  35.0  3.13   5.50 144 #>  versicolor     2.58     0.0658 39.24   <0.001 259.3  2.45   2.71 144 #>  virginica      2.55     0.1535 16.63   <0.001 115.0  2.25   2.86 144 #>  #> Type:  response  #>  get_marginalmeans(model, by = c(\"Species\", \"Petal.Length\"), length = 2) #>  #>     Species Petal.Length Estimate Std. Error     t Pr(>|t|)     S 2.5 % 97.5 % #>  setosa              1.0     3.25      0.128 25.33   <0.001 180.0 2.995   3.50 #>  setosa              6.9     5.54      1.415  3.91   <0.001  12.8 2.739   8.34 #>  versicolor          1.0     1.55      0.317  4.89   <0.001  18.5 0.924   2.18 #>  versicolor          6.9     3.76      0.258 14.58   <0.001  97.7 3.249   4.27 #>  virginica           1.0     1.91      0.375  5.08   <0.001  19.7 1.165   2.65 #>  virginica           6.9     3.29      0.119 27.63   <0.001 195.0 3.055   3.53 #>   Df #>  144 #>  144 #>  144 #>  144 #>  144 #>  144 #>  #> Type:  response  #>  get_marginalmeans(model, by = c(\"Species\", \"Petal.Length = c(1, 3, 5)\"), length = 2) #>  #>     Species Estimate Std. Error     t Pr(>|t|)     S 2.5 % 97.5 %  Df #>  setosa         3.25     0.1282 25.33   <0.001 180.0 2.995   3.50 144 #>  setosa         4.02     0.4026 10.00   <0.001  58.0 3.229   4.82 144 #>  setosa         4.80     0.9216  5.21   <0.001  20.6 2.979   6.62 144 #>  versicolor     1.55     0.3166  4.89   <0.001  18.5 0.924   2.18 144 #>  versicolor     2.30     0.1291 17.80   <0.001 124.5 2.043   2.55 144 #>  versicolor     3.05     0.0840 36.26   <0.001 244.3 2.881   3.21 144 #>  virginica      1.91     0.3753  5.08   <0.001  19.7 1.165   2.65 144 #>  virginica      2.38     0.2137 11.12   <0.001  67.8 1.954   2.80 144 #>  virginica      2.84     0.0636 44.74   <0.001 284.5 2.719   2.97 144 #>  #> Type:  response  #>  # } model <- lm(Sepal.Width ~ Species * Petal.Length, data = iris)  get_marginaltrends(model, trend = \"Petal.Length\", by = \"Species\") #>  #>     Species Estimate Std. Error    z Pr(>|z|)    S   2.5 % 97.5 % #>  setosa        0.388     0.2602 1.49  0.13606  2.9 -0.1221  0.898 #>  versicolor    0.374     0.0963 3.89  < 0.001 13.3  0.1856  0.563 #>  virginica     0.234     0.0819 2.86  0.00421  7.9  0.0739  0.395 #>  #> Term: Petal.Length #> Type:  response  #> Comparison: dY/dX #>  get_marginaltrends(model, trend = \"Petal.Length\", by = \"Petal.Length\") #>  #>  Petal.Length Estimate Std. Error    z Pr(>|z|)   S  2.5 % 97.5 % #>          1.00    0.388       0.26 1.49    0.136 2.9 -0.122  0.898 #>          1.66    0.388       0.26 1.49    0.136 2.9 -0.122  0.898 #>          2.31    0.388       0.26 1.49    0.136 2.9 -0.122  0.898 #>          2.97    0.388       0.26 1.49    0.136 2.9 -0.122  0.898 #>          3.62    0.388       0.26 1.49    0.136 2.9 -0.122  0.898 #>          4.28    0.388       0.26 1.49    0.136 2.9 -0.122  0.898 #>          4.93    0.388       0.26 1.49    0.136 2.9 -0.122  0.898 #>          5.59    0.388       0.26 1.49    0.136 2.9 -0.122  0.898 #>          6.24    0.388       0.26 1.49    0.136 2.9 -0.122  0.898 #>          6.90    0.388       0.26 1.49    0.136 2.9 -0.122  0.898 #>  #> Term: Petal.Length #> Type:  response  #> Comparison: dY/dX #>  get_marginaltrends(model, trend = \"Petal.Length\", by = c(\"Species\", \"Petal.Length\")) #>  #>     Species Petal.Length Estimate Std. Error    z Pr(>|z|)    S   2.5 % 97.5 % #>  setosa             1.00    0.388     0.2602 1.49  0.13601  2.9 -0.1221  0.898 #>  setosa             1.66    0.388     0.2601 1.49  0.13596  2.9 -0.1220  0.898 #>  versicolor         3.62    0.374     0.0963 3.89  < 0.001 13.3  0.1856  0.563 #>  versicolor         4.28    0.374     0.0963 3.89  < 0.001 13.3  0.1856  0.563 #>  versicolor         4.93    0.374     0.0963 3.89  < 0.001 13.3  0.1856  0.563 #>  virginica          4.93    0.234     0.0819 2.86  0.00420  7.9  0.0739  0.395 #>  virginica          5.59    0.234     0.0819 2.86  0.00421  7.9  0.0739  0.395 #>  virginica          6.24    0.234     0.0818 2.86  0.00418  7.9  0.0740  0.395 #>  virginica          6.90    0.234     0.0819 2.86  0.00420  7.9  0.0739  0.395 #>  #> Term: Petal.Length #> Type:  response  #> Comparison: dY/dX #>"},{"path":"https://easystats.github.io/modelbased/reference/modelbased-package.html","id":null,"dir":"Reference","previous_headings":"","what":"modelbased: Estimation of Model-Based Predictions, Contrasts and Means ‚Äî modelbased-package","title":"modelbased: Estimation of Model-Based Predictions, Contrasts and Means ‚Äî modelbased-package","text":"modelbased package helping model-based estimations, easily compute marginal means, contrast analysis model predictions.","code":""},{"path":"https://easystats.github.io/modelbased/reference/modelbased-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"modelbased: Estimation of Model-Based Predictions, Contrasts and Means ‚Äî modelbased-package","text":"modelbased","code":""},{"path":[]},{"path":"https://easystats.github.io/modelbased/reference/modelbased-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"modelbased: Estimation of Model-Based Predictions, Contrasts and Means ‚Äî modelbased-package","text":"Maintainer: Dominique Makowski dom.makowski@gmail.com (ORCID) Authors: Daniel L√ºdecke d.luedecke@uke.de (ORCID) Mattan S. Ben-Shachar matanshm@post.bgu.ac.il (ORCID) Indrajeet Patil patilindrajeet.science@gmail.com (ORCID)","code":""},{"path":"https://easystats.github.io/modelbased/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages ‚Äî reexports","title":"Objects exported from other packages ‚Äî reexports","text":"objects imported packages. Follow links see documentation. datawizard standardize, unstandardize, visualisation_recipe insight print_html, print_md","code":""},{"path":"https://easystats.github.io/modelbased/reference/smoothing.html","id":null,"dir":"Reference","previous_headings":"","what":"Smoothing a vector or a time series ‚Äî smoothing","title":"Smoothing a vector or a time series ‚Äî smoothing","text":"Smoothing vector time series. data.frames, function smooth numeric variables stratified factor levels (.e., smooth within factor level combination).","code":""},{"path":"https://easystats.github.io/modelbased/reference/smoothing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Smoothing a vector or a time series ‚Äî smoothing","text":"","code":"smoothing(x, method = \"loess\", strength = 0.25, ...)"},{"path":"https://easystats.github.io/modelbased/reference/smoothing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Smoothing a vector or a time series ‚Äî smoothing","text":"x numeric vector. method Can \"loess\" (default) \"smooth\". loess smoothing can slow. strength argument applies method = \"loess\". Degree smoothing passed span (see loess()). ... Arguments passed methods.","code":""},{"path":"https://easystats.github.io/modelbased/reference/smoothing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Smoothing a vector or a time series ‚Äî smoothing","text":"smoothed vector data frame.","code":""},{"path":"https://easystats.github.io/modelbased/reference/smoothing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Smoothing a vector or a time series ‚Äî smoothing","text":"","code":"x <- sin(seq(0, 4 * pi, length.out = 100)) + rnorm(100, 0, 0.2) plot(x, type = \"l\") lines(smoothing(x, method = \"smooth\"), type = \"l\", col = \"blue\") lines(smoothing(x, method = \"loess\"), type = \"l\", col = \"red\")   x <- sin(seq(0, 4 * pi, length.out = 10000)) + rnorm(10000, 0, 0.2) plot(x, type = \"l\") lines(smoothing(x, method = \"smooth\"), type = \"l\", col = \"blue\") lines(smoothing(x, method = \"loess\"), type = \"l\", col = \"red\")"},{"path":"https://easystats.github.io/modelbased/reference/visualisation_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a reference grid ‚Äî visualisation_matrix","title":"Create a reference grid ‚Äî visualisation_matrix","text":"function alias (another name) insight::get_datagrid() function. arguments apply.","code":""},{"path":"https://easystats.github.io/modelbased/reference/visualisation_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a reference grid ‚Äî visualisation_matrix","text":"","code":"visualisation_matrix(x, ...)  # S3 method for class 'data.frame' visualisation_matrix(   x,   by = \"all\",   factors = \"reference\",   numerics = \"mean\",   preserve_range = FALSE,   reference = x,   ... )  # S3 method for class 'numeric' visualisation_matrix(x, ...)  # S3 method for class 'factor' visualisation_matrix(x, ...)"},{"path":"https://easystats.github.io/modelbased/reference/visualisation_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a reference grid ‚Äî visualisation_matrix","text":"x object construct reference grid. ... Arguments passed methods (instance, length range control spread numeric variables.). Indicates focal predictors (variables) reference grid values focal predictors represented. specified otherwise, representative values numeric variables predictors evenly distributed minimum maximum, total number length values covering range (see 'Examples'). Possible options : \"\", include variables predictors. character vector one variable predictor names, like c(\"Species\", \"Sepal.Width\"), create grid combinations unique values. factors, use levels, numeric variables, use range length length (evenly spread minimum maximum) character vectors, use unique values. list named elements, indicating focal predictors representative values, e.g. = list(Sepal.Length = c(2, 4), Species = \"setosa\"). string assignments, e.g. = \"Sepal.Length = 2\" = c(\"Sepal.Length = 2\", \"Species = 'setosa'\") - note usage single double quotes assign strings within strings. special handling assignments brackets, .e. values defined inside [ ].numeric variables, value(s) inside brackets either two values, indicating minimum maximum (e.g. = \"Sepal.Length = [0, 5]\"), range length length (evenly spread given minimum maximum) created. two numeric values = \"Sepal.Length = [2,3,4,5]\", case values used representative values. \"token\" creates pre-defined representative values: mean -/+ 1 SD around mean: \"x = [sd]\" median -/+ 1 MAD around median: \"x = [mad]\" Tukey's five number summary (minimum, lower-hinge, median, upper-hinge, maximum): \"x = [fivenum]\" terciles, including minimum maximum: \"x = [terciles]\" terciles, excluding minimum maximum: \"x = [terciles2]\" quartiles, including minimum maximum: \"x = [quartiles]\" (\"x = [fivenum]\") quartiles, excluding minimum maximum: \"x = [quartiles2]\" pretty value range: \"x = [pretty]\" minimum maximum value: \"x = [minmax]\" 0 maximum value: \"x = [zeromax]\" random sample values: \"x = [sample <number>]\", <number> positive integer, e.g. \"x = [sample 15]\". factor variables, value(s) inside brackets indicate one factor levels, like = \"Species = [setosa, versicolor]\". Note: length argument ignored using brackets-tokens. remaining variables specified fixed (see also arguments factors numerics). factors Type summary factors. Can \"reference\" (set reference level), \"mode\" (set common level) \"\" keep levels. numerics Type summary numeric values. Can \"\" (duplicate grid unique values), function (\"mean\", \"median\", ...) value (e.g., numerics = 0). preserve_range case combinations numeric variables factors, setting preserve_range = TRUE drop observations value numeric variable originally present range factor level. leads unbalanced grid. Also, want minimum maximum closely match actual ranges, increase length argument. reference reference vector compute mean SD. Used standardizing unstandardizing grid using effectsize::standardize.","code":""},{"path":"https://easystats.github.io/modelbased/reference/visualisation_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a reference grid ‚Äî visualisation_matrix","text":"Reference grid data frame.","code":""},{"path":"https://easystats.github.io/modelbased/reference/visualisation_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a reference grid ‚Äî visualisation_matrix","text":"","code":"# See `?insight::get_datagrid`"},{"path":"https://easystats.github.io/modelbased/reference/visualisation_recipe.estimate_predicted.html","id":null,"dir":"Reference","previous_headings":"","what":"Automated plotting for 'modelbased' objects ‚Äî visualisation_recipe.estimate_predicted","title":"Automated plotting for 'modelbased' objects ‚Äî visualisation_recipe.estimate_predicted","text":"'modelbased' objects can visualized using plot() function, internally calls visualisation_recipe() function. See examples information examples create customize plots.","code":""},{"path":"https://easystats.github.io/modelbased/reference/visualisation_recipe.estimate_predicted.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Automated plotting for 'modelbased' objects ‚Äî visualisation_recipe.estimate_predicted","text":"","code":"# S3 method for class 'estimate_predicted' visualisation_recipe(   x,   show_data = FALSE,   point = NULL,   line = NULL,   pointrange = NULL,   ribbon = NULL,   facet = NULL,   grid = NULL,   join_dots = getOption(\"modelbased_join_dots\", TRUE),   ... )  # S3 method for class 'estimate_slopes' visualisation_recipe(   x,   line = NULL,   pointrange = NULL,   ribbon = NULL,   facet = NULL,   grid = NULL,   ... )  # S3 method for class 'estimate_grouplevel' visualisation_recipe(   x,   line = NULL,   pointrange = NULL,   ribbon = NULL,   facet = NULL,   grid = NULL,   ... )"},{"path":"https://easystats.github.io/modelbased/reference/visualisation_recipe.estimate_predicted.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Automated plotting for 'modelbased' objects ‚Äî visualisation_recipe.estimate_predicted","text":"x modelbased object. show_data Logical, TRUE, display \"raw\" data background model-based estimation. point, line, pointrange, ribbon, facet, grid Additional aesthetics parameters geoms (see customization example). join_dots Logical, TRUE categorical focal terms , dots (estimates) connected lines, .e. plots combination dots error bars connecting lines. FALSE, dots error bars shown. possible set global default value using options(), e.g. options(\"modelbased_join_dots\" = FALSE). ... used.","code":""},{"path":"https://easystats.github.io/modelbased/reference/visualisation_recipe.estimate_predicted.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Automated plotting for 'modelbased' objects ‚Äî visualisation_recipe.estimate_predicted","text":"plotting works mapping predictors argument x-axis, colors, alpha (transparency) facets. Thus, appearance plot depends order variables specify argument. instance, plots corresponding estimate_relation(model, =c(\"Species\", \"Sepal.Length\")) estimate_relation(model, =c(\"Sepal.Length\", \"Species\")) look different. automated plotting primarily meant convenient visual checks, publication-ready figures, recommend re-creating figures using ggplot2 package directly. two options remove confidence bands errors bars plot. remove error bars, simply set pointrange geom point, e.g. plot(..., pointrange = list(geom = \"point\")). remove confidence bands line geoms, use ribbon = \"none\".","code":""},{"path":"https://easystats.github.io/modelbased/reference/visualisation_recipe.estimate_predicted.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Automated plotting for 'modelbased' objects ‚Äî visualisation_recipe.estimate_predicted","text":"","code":"library(ggplot2) library(see) # ============================================== # estimate_relation, estimate_expectation, ... # ============================================== # Simple Model --------------- x <- estimate_relation(lm(mpg ~ wt, data = mtcars)) layers <- visualisation_recipe(x) layers #> Layer 1 #> -------- #> Geom type: ribbon #> data = [10 x 6] #> aes_string( #>   y = 'Predicted' #>   x = 'wt' #>   ymin = 'CI_low' #>   ymax = 'CI_high' #>   group = '.group' #> ) #> alpha = 0.3333333 #>  #> Layer 2 #> -------- #> Geom type: line #> data = [10 x 6] #> aes_string( #>   y = 'Predicted' #>   x = 'wt' #>   group = '.group' #> ) #>  #> Layer 3 #> -------- #> Geom type: labs #> y = 'Predicted value of mpg' #>  plot(layers)   # visualization_recipe() is called implicitly when you call plot() plot(estimate_relation(lm(mpg ~ qsec, data = mtcars)))   # \\dontrun{ # And can be used in a pipe workflow lm(mpg ~ qsec, data = mtcars) |>   estimate_relation(ci = c(0.5, 0.8, 0.9)) |>   plot()   # Customize aesthetics ----------  plot(x,   point = list(color = \"red\", alpha = 0.6, size = 3),   line = list(color = \"blue\", size = 3),   ribbon = list(fill = \"green\", alpha = 0.7) ) +   theme_minimal() +   labs(title = \"Relationship between MPG and WT\")   # Customize raw data -------------  plot(x, point = list(geom = \"density_2d_filled\"), line = list(color = \"white\")) +   scale_x_continuous(expand = c(0, 0)) +   scale_y_continuous(expand = c(0, 0)) +   theme(legend.position = \"none\")   # Single predictors examples -----------  plot(estimate_relation(lm(Sepal.Length ~ Species, data = iris)))   # 2-ways interaction ------------  # Numeric * numeric x <- estimate_relation(lm(mpg ~ wt * qsec, data = mtcars)) plot(x)   # Numeric * factor x <- estimate_relation(lm(Sepal.Width ~ Sepal.Length * Species, data = iris)) plot(x)   # ============================================== # estimate_means # ============================================== # Simple Model --------------- x <- estimate_means(lm(Sepal.Width ~ Species, data = iris), by = \"Species\") layers <- visualisation_recipe(x) layers #> Layer 1 #> -------- #> Geom type: line #> data = [3 x 8] #> aes_string( #>   y = 'Mean' #>   x = 'Species' #>   group = '.group' #> ) #>  #> Layer 2 #> -------- #> Geom type: pointrange #> data = [3 x 8] #> aes_string( #>   y = 'Mean' #>   x = 'Species' #>   ymin = 'CI_low' #>   ymax = 'CI_high' #>   group = '.group' #> ) #>  #> Layer 3 #> -------- #> Geom type: labs #> y = 'Mean of Sepal.Width' #>  plot(layers)   # Customize aesthetics layers <- visualisation_recipe(x,   point = list(width = 0.03, color = \"red\"),   pointrange = list(size = 2, linewidth = 2),   line = list(linetype = \"dashed\", color = \"blue\") ) plot(layers)   # Two levels --------------- data <- mtcars data$cyl <- as.factor(data$cyl)  model <- lm(mpg ~ cyl * wt, data = data)  x <- estimate_means(model, by = c(\"cyl\", \"wt\")) plot(x)    # GLMs --------------------- data <- data.frame(vs = mtcars$vs, cyl = as.factor(mtcars$cyl)) x <- estimate_means(glm(vs ~ cyl, data = data, family = \"binomial\"), by = c(\"cyl\")) plot(x)  # } # ============================================== # estimate_slopes # ============================================== model <- lm(Sepal.Width ~ Species * Petal.Length, data = iris) x <- estimate_slopes(model, trend = \"Petal.Length\", by = \"Species\")  layers <- visualisation_recipe(x) layers #> Layer 1 #> -------- #> Geom type: line #> data = [3 x 8] #> aes_string( #>   y = 'Slope' #>   x = 'Species' #>   group = '.group' #> ) #>  #> Layer 2 #> -------- #> Geom type: pointrange #> data = [3 x 8] #> aes_string( #>   y = 'Slope' #>   x = 'Species' #>   ymin = 'CI_low' #>   ymax = 'CI_high' #>   group = '.group' #> ) #>  #> Layer 3 #> -------- #> Geom type: labs #> y = 'Slope of Sepal.Width' #>  plot(layers)   # \\dontrun{ # Customize aesthetics and add horizontal line and theme layers <- visualisation_recipe(x, pointrange = list(size = 2, linewidth = 2)) plot(layers) +   geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +   theme_minimal() +   labs(y = \"Effect of Petal.Length\", title = \"Marginal Effects\")   model <- lm(Petal.Length ~ poly(Sepal.Width, 4), data = iris) x <- estimate_slopes(model, trend = \"Sepal.Width\", by = \"Sepal.Width\", length = 20) plot(visualisation_recipe(x))   model <- lm(Petal.Length ~ Species * poly(Sepal.Width, 3), data = iris) x <- estimate_slopes(model, trend = \"Sepal.Width\", by = c(\"Sepal.Width\", \"Species\")) plot(visualisation_recipe(x))  # } # ============================================== # estimate_grouplevel # ============================================== # \\dontrun{ data <- lme4::sleepstudy data <- rbind(data, data) data$Newfactor <- rep(c(\"A\", \"B\", \"C\", \"D\"))  # 1 random intercept model <- lme4::lmer(Reaction ~ Days + (1 | Subject), data = data) x <- estimate_grouplevel(model) layers <- visualisation_recipe(x) layers #> Layer 1 #> -------- #> Geom type: pointrange #> data = [18 x 9] #> aes_string( #>   y = 'Coefficient' #>   x = 'Level' #>   ymin = 'CI_low' #>   ymax = 'CI_high' #>   group = '.group' #> ) #>  #> Layer 2 #> -------- #> Geom type: coord_flip #>  plot(layers)   # 2 random intercepts model <- lme4::lmer(Reaction ~ Days + (1 | Subject) + (1 | Newfactor), data = data) x <- estimate_grouplevel(model) plot(x) +   geom_hline(yintercept = 0, linetype = \"dashed\") +   theme_minimal()  # Note: we need to use hline instead of vline because the axes is flipped  model <- lme4::lmer(Reaction ~ Days + (1 + Days | Subject) + (1 | Newfactor), data = data) x <- estimate_grouplevel(model) plot(x)  # }"},{"path":"https://easystats.github.io/modelbased/reference/zero_crossings.html","id":null,"dir":"Reference","previous_headings":"","what":"Find zero-crossings and inversion points ‚Äî zero_crossings","title":"Find zero-crossings and inversion points ‚Äî zero_crossings","text":"Find zero crossings vector, .e., indices numeric variable crosses 0. useful finding points function changes looking zero crossings derivative.","code":""},{"path":"https://easystats.github.io/modelbased/reference/zero_crossings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find zero-crossings and inversion points ‚Äî zero_crossings","text":"","code":"zero_crossings(x)  find_inversions(x)"},{"path":"https://easystats.github.io/modelbased/reference/zero_crossings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find zero-crossings and inversion points ‚Äî zero_crossings","text":"x numeric vector.","code":""},{"path":"https://easystats.github.io/modelbased/reference/zero_crossings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find zero-crossings and inversion points ‚Äî zero_crossings","text":"Vector zero crossings points inversion.","code":""},{"path":[]},{"path":"https://easystats.github.io/modelbased/reference/zero_crossings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find zero-crossings and inversion points ‚Äî zero_crossings","text":"","code":"x <- sin(seq(0, 4 * pi, length.out = 100)) plot(x, type = \"b\")   zero_crossings(x) #> [1]  1.00000 25.74975 50.50000 75.25025 find_inversions(x) #> [1] 12.87478 37.62484 62.37516 87.12522"},{"path":[]},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"breaking-changes-0-9-0","dir":"Changelog","previous_headings":"","what":"Breaking Changes","title":"modelbased 0.9.0","text":"default package used estimate_means(), estimate_slopes() estimate_contrasts() now marginaleffects. can set preferred package backend using either backend argument, general setting options(modelbased_backend = \"marginaleffects\") options(modelbased_backend = \"emmeans\"). Deprecated argument function names removed. Argument fixed removed, can fix predictor certain values using argument. Argument transform deprecated. Please use predict instead. Argument method estimate_contrasts() renamed comparison. model_*() alias names removed. Use related get_*() functions instead. show_data argument plot() defaults FALSE.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"major-changes-0-9-0","dir":"Changelog","previous_headings":"","what":"Major Changes","title":"modelbased 0.9.0","text":"\"marginaleffects\" backend now fully implemented longer work--progress. can set preferred package backend using either backend argument, general setting options(modelbased_backend = \"marginaleffects\") options(modelbased_backend = \"emmeans\"). estimate_*() functions get predict argument, can used modulate type transformation applied predictions (.e.¬†whether predictions response scale, link scale, etc.). can also used predict auxiliary (distributional) parameters. estimate_means() estimate_contrasts() get marginalize argument, specify marginalize non-focal terms. results slightly different predicted values, approach answering different question. estimate_contrasts() gains backend argument. defaults \"marginaleffects\", can set \"emmeans\" use features package estimate contrasts pairwise comparisons. estimate_expectation() related functions also get argument, alternative create datagrid data argument. Many functions get verbose argument, silence warnings messages.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"bug-fixes-0-9-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"modelbased 0.9.0","text":"estimate_contrasts() calculate contrasts levels predictor interest converted factor inside model formula. Fixed issue estimate_contrasts() comparsison (formerly: method) \"pairwise\".","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-089","dir":"Changelog","previous_headings":"","what":"modelbased 0.8.9","title":"modelbased 0.8.9","text":"CRAN release: 2024-10-26 Fixed issues related updates easystats packages.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-086","dir":"Changelog","previous_headings":"","what":"modelbased 0.8.6","title":"modelbased 0.8.6","text":"CRAN release: 2023-01-13","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"breaking-changes-0-8-6","dir":"Changelog","previous_headings":"","what":"Breaking Changes","title":"modelbased 0.8.6","text":"minimum needed R version bumped 3.6.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-085","dir":"Changelog","previous_headings":"","what":"modelbased 0.8.5","title":"modelbased 0.8.5","text":"CRAN release: 2022-08-18 Fixed issues printing-methods. Maintenance release fix failing tests CRAN checks.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-081","dir":"Changelog","previous_headings":"","what":"modelbased 0.8.1","title":"modelbased 0.8.1","text":"CRAN release: 2022-05-30 Maintenance release fix failing tests CRAN checks.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-080","dir":"Changelog","previous_headings":"","what":"modelbased 0.8.0","title":"modelbased 0.8.0","text":"CRAN release: 2022-03-31 visualisation_matrix() now become alias (alternative name) get_datagrid() function, implemented insight package.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-072","dir":"Changelog","previous_headings":"","what":"modelbased 0.7.2","title":"modelbased 0.7.2","text":"CRAN release: 2022-02-27 Patch release. update fixes failing tests updating insight package.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-071","dir":"Changelog","previous_headings":"","what":"modelbased 0.7.1","title":"modelbased 0.7.1","text":"CRAN release: 2022-01-13 API changes: levels estimate_contrasts replaced contrast. levels modulate general aggregated . estimate_prediction() deprecated favour estimate_response(). estimate_expectation() now data=NULL default.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-070","dir":"Changelog","previous_headings":"","what":"modelbased 0.7.0","title":"modelbased 0.7.0","text":"CRAN release: 2021-06-06 General overhaul package. Entire refactoring visualisation_matrix(). Option standardizing/unstandardizing predictions, contrasts means now available via standardize() instead via options. Introduction model_emmeans() wrapper easily create emmeans objects. estimate_smooth() transformed describe_nonlinear() made explicit.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-060","dir":"Changelog","previous_headings":"","what":"modelbased 0.6.0","title":"modelbased 0.6.0","text":"CRAN release: 2021-04-12 estimate_link() now transform predictions response scale GLMs. keep previous behaviour, use new estimate_relation() instead. follows change predictions made internally (now relies get_predicted(), details can found ).","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-051","dir":"Changelog","previous_headings":"","what":"modelbased 0.5.1","title":"modelbased 0.5.1","text":"CRAN release: 2021-01-27 Minor improvements.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-030","dir":"Changelog","previous_headings":"","what":"modelbased 0.3.0","title":"modelbased 0.3.0","text":"CRAN release: 2020-09-26","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"breaking-changes-0-3-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"modelbased 0.3.0","text":"Predicted now name predicted column Bayesian models (similarly Frequentist ones), instead centrality index (e.g., Median).","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"new-supported-models-0-3-0","dir":"Changelog","previous_headings":"","what":"New supported models","title":"modelbased 0.3.0","text":"Models package glmmTMB now supported.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"bug-fixes-0-3-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"modelbased 0.3.0","text":"estimate_slope() now gives informative error numeric predictor present.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-020","dir":"Changelog","previous_headings":"","what":"modelbased 0.2.0","title":"modelbased 0.2.0","text":"Partial support formulas. Refactor emmeans wrapping.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-013","dir":"Changelog","previous_headings":"","what":"modelbased 0.1.3","title":"modelbased 0.1.3","text":"Fix CRAN check issues.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-012","dir":"Changelog","previous_headings":"","what":"modelbased 0.1.2","title":"modelbased 0.1.2","text":"CRAN release: 2020-03-12 Minor code changes address changes forthcoming parameters package update.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-011","dir":"Changelog","previous_headings":"","what":"modelbased 0.1.1","title":"modelbased 0.1.1","text":"CRAN release: 2020-01-26 Fix CRAN check issues.","code":""},{"path":"https://easystats.github.io/modelbased/news/index.html","id":"modelbased-010","dir":"Changelog","previous_headings":"","what":"modelbased 0.1.0","title":"modelbased 0.1.0","text":"CRAN release: 2020-01-12 Added NEWS.md file track changes package","code":""}]
